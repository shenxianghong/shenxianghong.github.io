<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>🐾Corgi</title>
  
  
  <link href="http://shenxianghong.github.io/atom.xml" rel="self"/>
  
  <link href="http://shenxianghong.github.io/"/>
  <updated>2023-07-10T09:47:30.108Z</updated>
  <id>http://shenxianghong.github.io/</id>
  
  <author>
    <name>Shen Xianghong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「 Kubernetes 」InPlacePodVerticalScaling 特性</title>
    <link href="http://shenxianghong.github.io/2023/07/10/2023-07-10%20Kubernetes%20Pod%20%E8%B5%84%E6%BA%90%E7%9A%84%E5%8E%9F%E5%9C%B0%E7%BA%B5%E5%90%91%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E7%89%B9%E6%80%A7/"/>
    <id>http://shenxianghong.github.io/2023/07/10/2023-07-10%20Kubernetes%20Pod%20%E8%B5%84%E6%BA%90%E7%9A%84%E5%8E%9F%E5%9C%B0%E7%BA%B5%E5%90%91%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E7%89%B9%E6%80%A7/</id>
    <published>2023-07-09T16:00:00.000Z</published>
    <updated>2023-07-10T09:47:30.108Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kubernetes/logo.svg"></div><hr><blockquote><p>based on <strong>v1.27.3</strong></p></blockquote><h1 id="InPlacePodVerticalScaling"><a href="#InPlacePodVerticalScaling" class="headerlink" title="InPlacePodVerticalScaling"></a>InPlacePodVerticalScaling</h1><p>在 Kubernetes v1.27 中，添加了一个新的 alpha 功能 — InPlacePodVerticalScaling，允许用户在不重启容器的情况下调整分配给 Pod 的 CPU 或内存资源的大小。为了实现这一点，Pod resources 字段现在允许对 CPU 和内存资源进行更改，可以通过 patch 修改正在运行的 Pod spec 来实现。</p><p>这也意味着 Pod spec 中 resources 字段不能再作为 Pod 实际资源的指标。监控工具和其他此类应用程序现在必须查看 Pod status 中的新字段。Kubernetes 通过 CRI API 调用运行时来查询实际的 CPU 和内存的 request 与 limit，来自容器运行时的响应反映在 Pod 的 status 中。</p><p>对于原地调整 Pod 资源而言：</p><ul><li><p>针对 CPU 和内存资源的容器的 requests 和 limits 是可变更的</p></li><li><p>Pod 状态中 containerStatuses 的 <code>allocatedResources</code> 字段反映了分配给 Pod 容器的资源</p></li><li><p>Pod 状态中 containerStatuses 的 resources 字段反映了如同容器运行时所报告的、针对正运行的容器配置的实际资源 requests 和 limits</p></li><li><p>Pod 状态中 <code>resize</code> 字段显示上次请求待处理的调整状态：</p><ul><li><p><code>Proposed</code>：此值表示请求调整已被确认，并且请求已被验证和记录</p></li><li><p><code>InProgress</code>：此值表示节点已接受调整请求，并正在将其应用于 Pod 的容器</p></li><li><p><code>Deferred</code>：此值意味着在此时无法批准请求的调整，节点将继续重试。 当其他 Pod 退出并释放节点资源时，调整可能会被真正实施</p></li><li><p><code>Infeasible</code>：此值是一种信号，表示节点无法承接所请求的调整值。 如果所请求的调整超过节点可分配给 Pod 的最大资源，则可能会发生这种情况</p></li></ul></li></ul><p><strong>容器调整策略</strong></p><p>调整策略允许更精细地控制 Pod 中的容器如何针对 CPU 和内存资源进行调整。 例如，容器的应用程序可以处理 CPU 资源的调整而不必重启， 但是调整内存可能需要应用程序重启，因此容器也必须重启。</p><p>为了实现这一点，容器规约允许用户指定 <code>resizePolicy</code>。 针对调整 CPU 和内存可以设置以下重启策略：</p><ul><li><code>NotRequired</code>：在运行时调整容器的资源，默认值<br><em>如果 Pod 的 restartPolicy 为 Never，则 Pod 中所有容器的调整重启策略必须被设置为 NotRequired</em></li><li><code>RestartContainer</code>：重启容器并在重启后应用新资源</li></ul>]]></content>
    
    
    <summary type="html">Kubernetes v1.27 版本中的 Pod 资源原地纵向弹性伸缩特性的实践验证</summary>
    
    
    
    <category term="Scheduling &amp; Orchestration" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/"/>
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>「 Containerd 」NRI 接口设计</title>
    <link href="http://shenxianghong.github.io/2023/07/03/2023-07-03%20Containerd%20NRI%20%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/"/>
    <id>http://shenxianghong.github.io/2023/07/03/2023-07-03%20Containerd%20NRI%20%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-07-02T16:00:00.000Z</published>
    <updated>2023-07-06T09:32:53.353Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/containerd/logo.svg"></div><hr><blockquote><p>based on <strong>v0.3.0</strong></p></blockquote><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>NRI（Node Resource Interface）是 Containerd 的一个子项目，允许将自定义逻辑插入到 OCI 兼容的运行时中，从而实现在容器生命周期的某些特定时间点对容器进行更改操作或执行 OCI 规范之外的额外操作。例如，用于改进设备和其他容器资源的分配和管理。NRI 本身对任何容器运行时的内部实现细节是不感知的。它为 CRI 运行时提供了一个适配库，用于集成 NRI 和扩展插件进行交互。</p><p>NRI 提供了接口定义和基础组件，可以实现可插拔的 CRI 运行时插件，这些插件就是 NRI 插件。这些 NRI 插件是与运行时类型无关的，插件既可以应用于 Containerd，也可以应用于 CRI-O。原则上，任何 NRI 插件都应该能够和启用 NRI 的运行时正常协作。</p><p>NRI 插件是一个类似守护进程的实例。插件的单个实例会处理 NRI 所有的事件和请求，使用 socket 来进行数据传输和通信，NRI 定义了一套基于 protobuf 的协议：NRI plugin protocal，并通过 ttRPC 进行实现。这样可以通过降低每条信息的开销提高通信效率，并且可以实现有状态的 NRI 插件。</p><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><p>NRI 实现包含了两个核心组件：<a href="https://github.com/containerd/nri/tree/main/pkg/api">NRI 协议</a>和 <a href="https://github.com/containerd/nri/tree/main/pkg/adaptation">NRI 运行时适配器</a>。</p><p>这些组件一起建立了运行时如何与 NRI 交互以及插件如何通过 NRI 与运行时中的容器交互的模型。它们还定义了插件可以在哪些条件下对容器进行更改以及这些更改的程度。</p><p>其余的组件是 <a href="https://github.com/containerd/nri/tree/main/pkg/stub">NRI 插件 stub 库</a>和一些 <a href="https://github.com/containerd/nri/tree/main/plugins">NRI 示例插件</a>。其中，一些插件在实际应用场景中实现了有用的功能，另外一些插件则用于调试。所有示例插件都可以作为如何使用 stub 库实现 NRI 插件的示例。</p><h2 id="API-协议"><a href="#API-协议" class="headerlink" title="API 协议"></a>API 协议</h2><p>NRI API 协议中定义了两个服务：runtime 和 plugin</p><ul><li><p>runtime 服务是运行时向 NRI 插件暴漏的接口。在此接口上的所有请求都由插件发起。该接口提供以下功能：</p><ul><li><p>启动插件注册</p></li><li><p>请求对容器的更新</p></li></ul></li><li><p>plugin 服务是 NRI 用于与插件交互的公共接口。在此接口上的所有请求都由 NRI 或运行时发起。该接口提供以下功能：</p><ul><li><p>配置插件</p></li><li><p>获取已存在的 Pod 和容器的初始列表</p></li><li><p>将插件 hook 到 Pod&#x2F;container 的生命周期事件中</p></li><li><p>关闭插件</p></li></ul></li></ul><p>插件需要向 NRI 注册，用于接收和处理容器事件。在注册过程中，插件和 NRI 执行以下步骤的顺序：</p><ul><li>插件注册至运行时</li><li>NRI 向插件下发特定的配置数据</li><li>插件订阅 Pod 和容器生命周期事件</li><li>NRI 向插件发送已存在的 Pod 和容器列表</li><li>插件请求对现有容器的更新</li></ul><p>通过插件名称和插件索引向 NRI 注册插件。NRI 通过插件索引来确定所有插件在 hook Pod 和容器的生命周期事件的处理顺序。</p><p>NRI 插件名称用于 NRI 服务从默认插件配置路径 <code>/etc/nri/conf.d</code> 中选择对应插件的配置文件发送给 NRI 插件。只有当对应的 NRI 插件被 NRI 服务内部调用时，才会读取对应的配置文件。如果 NRI 插件是从外部启动的，那么它也可以通过其他方式获取配置。NRI 插件可以根据需要订阅 Pod 和容器的生命周期，并且返回修改后的配置。NRI 插件如果采用预注册的方式运行时，需要将可执行文件的命名规则需要符合 <code>xx-plugin_name</code>，例如 01-logger。其中 xx 必须为两位数字，作为 NRI 插件的索引，决定了插件的的执行顺序。</p><p>在注册和握手的最后一步，NRI 发送 CRI 运行时已知的所有的 Pod和容器的信息。此时插件可以对任何已经存在的 Pod 和容器进行更新。一旦握手结束，并且 NRI 插件成功向 NRI 服务注册之后，它将开始根据自己的订阅接收 Pod 和容器的生命周期事件。</p><h2 id="运行时适配器"><a href="#运行时适配器" class="headerlink" title="运行时适配器"></a>运行时适配器</h2><p>NRI 运行时适配包是用于集成到 NRI 并与 NRI 插件交互的接口运行时。它实现了插件发现，启动和配置。它还提供了将 NRI 插件插入到 CRI 运行时的 Pod 和容器的生命周期事件中的必要功能。</p><p>运行时适配器实现了多个 NRI 插件可能在处理同一个 Pod 或者容器的生命周期事件。它负责按照索引顺序依次调用插件，并把插件的修改内容合并后返回。在合并插件修改的 OCI spec 时，当检测到到多个 NRI 插件对同一个容器产生了冲突的修改，就会返回一个错误。</p><h2 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h2><p>NRI 还包含一个 NRI 插件 stub 库，为 NRI 插件的实现提供了一个简洁易用的框架。stub 库屏蔽了 NRI 插件的底层实现细节，它负责连接建立、插件注册、配置和事件订阅。</p><p>同时 NRI 也提供了一些 NRI 插件的示例，这些示例都是结合实际使用场景创建的，其中一些示例非常适合调试场景。目前，NRI 提供的所有示例插件都基于 stub 库实现的。这些示例插件的实现都可以用作学习使用 stub 库的教程。</p><p>另外，NRI 还包含一个 OCI 规范生成器主要用于 NRI 插件用来调整和更新 OCI spec，然后更新到容器。</p><h1 id="可订阅事件"><a href="#可订阅事件" class="headerlink" title="可订阅事件"></a>可订阅事件</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Handlers for NRI plugin event and request.</span></span><br><span class="line"><span class="keyword">type</span> handlers <span class="keyword">struct</span> &#123;</span><br><span class="line">Configure           <span class="function"><span class="keyword">func</span><span class="params">(context.Context, <span class="type">string</span>, <span class="type">string</span>, <span class="type">string</span>)</span></span> (api.EventMask, <span class="type">error</span>)</span><br><span class="line">Synchronize         <span class="function"><span class="keyword">func</span><span class="params">(context.Context, []*api.PodSandbox, []*api.Container)</span></span> ([]*api.ContainerUpdate, <span class="type">error</span>)</span><br><span class="line">Shutdown            <span class="function"><span class="keyword">func</span><span class="params">(context.Context)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Pod 事件</span></span><br><span class="line">RunPodSandbox       <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox)</span></span> <span class="type">error</span></span><br><span class="line">StopPodSandbox      <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox)</span></span> <span class="type">error</span></span><br><span class="line">RemovePodSandbox    <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox)</span></span> <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器事件</span></span><br><span class="line">CreateContainer     <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> (*api.ContainerAdjustment, []*api.ContainerUpdate, <span class="type">error</span>)</span><br><span class="line">StartContainer      <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> <span class="type">error</span></span><br><span class="line">UpdateContainer     <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container, *api.LinuxResources)</span></span> ([]*api.ContainerUpdate, <span class="type">error</span>)</span><br><span class="line">StopContainer       <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> ([]*api.ContainerUpdate, <span class="type">error</span>)</span><br><span class="line">RemoveContainer     <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> <span class="type">error</span></span><br><span class="line">PostCreateContainer <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> <span class="type">error</span></span><br><span class="line">PostStartContainer  <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> <span class="type">error</span></span><br><span class="line">PostUpdateContainer <span class="function"><span class="keyword">func</span><span class="params">(context.Context, *api.PodSandbox, *api.Container)</span></span> <span class="type">error</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在事件中可以获得的 Pod 元信息：</p><ul><li>ID</li><li>name</li><li>UID</li><li>namespace</li><li>labels</li><li>annotations</li><li>cgroup parent directory</li><li>runtime handler name</li></ul><p>在事件中可以获得的容器元数据：</p><ul><li>ID</li><li>pod ID</li><li>name</li><li>state</li><li>labels</li><li>annotations</li><li>command line arguments</li><li>environment variables</li><li>mounts</li><li>OCI hooks</li><li>linux<ul><li>namespace IDs</li><li>devices</li><li>resources<ul><li>memory<ul><li>limit</li><li>reservation</li><li>swap limit</li><li>kernel limit</li><li>kernel TCP limit</li><li>swappiness</li><li>OOM disabled flag</li><li>hierarchical accounting flag</li><li>hugepage limits</li></ul></li><li>CPU<ul><li>shares</li><li>quota</li><li>period</li><li>realtime runtime</li><li>realtime period</li><li>cpuset CPUs</li><li>cpuset memory</li></ul></li><li>Block I&#x2F;O class</li><li>RDT class</li></ul></li></ul></li></ul><p><strong>容器调整</strong></p><p>在容器创建过程中可以调整容器的参数，在容器创建后，任何生命周期事件都可以更新容器的参数，但是调整参数和更新参数的范围是不同的，容器创建时支持更多的参数设置，容器创建完成后，只有部分参数可以修改。其中 ID、pod ID、name、state、labels、command line arguments、OCI hooks 和 linux.namespace IDs 信息不可修改。</p><p><strong>容器更新</strong></p><p>容器创建完成后，NRI 插件可以对容器进行更新。这个更新操作也可以由其他任何容器创建、更新或者停止的事件触发，或者可以主动更新容器参数。更新过程中，可以改的容器的参数要少于创建时可修改的参数，其中仅 linux.resources 信息可修改。</p><h1 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h1><p>从安全角度来看，应该将 NRI 插件视为容器运行时的一部分。NRI 没有实现对其提供的功能的细粒度访问控制。访问 NRI 是通过限制对系统范围的 NRI socket 的访问来控制的。如果进程可以连接到 NRI socket 并发送数据，则可以访问通过 NRI 可用的完整功能范围。</p><p>特别是包括：</p><ul><li>注入OCI hook，允许以与容器运行时相同的特权级别执行任意进程</li><li>对挂载点进行任意更改，包括新的绑定挂载点、更改 proc、sys、mqueue、shm 和 tmpfs 挂载点</li><li>添加或删除任意设备</li><li>对可用内存、CPU、block I&#x2F;O 和 RDT 资源的限制进行任意更改，包括通过设置非常低的限制来拒绝服务</li></ul><p>保护 NRI socket 的注意事项和原则与保护运行时本身的 socket 相同。除非它已经存在，否则 NRI 本身会创建目录来保存其 socket，该目录具有仅允许运行时进程的用户 ID 访问的权限。默认情况下，这限制 NRI 访问以 root UID 0 身份运行的进程。强烈建议不要更改默认 socket 权限。如果没有对容器安全的全部影响和潜在后果的充分理解，就永远不应该对 NRI 启用更宽松的访问控制。</p><p>当运行时管理 Kubernetes 集群中的 Pod 和容器时，使用 Kubernetes DaemonSets 可以方便地部署和管理 NRI 插件。除此之外，这需要将 NRI socket 挂载到运行插件的特权容器的文件系统中。对于保护 NRI socket 和 NRI 插件，应采取与 Kubelet Device Manager socket 和 Kubernetes device-plugin 类似的手段。</p><p>集群配置应确保未经授权的用户无法挂载 host 目录并创建特权容器来访问这些 socket 并充当 NRI 或 device-plugin。</p><h1 id="与运行时集成"><a href="#与运行时集成" class="headerlink" title="与运行时集成"></a>与运行时集成</h1><h2 id="Containerd"><a href="#Containerd" class="headerlink" title="Containerd"></a>Containerd</h2><div align=center><img width="700" style="border: 0px" src="/gallery/containerd/nri-integration.png"></div><p>Containerd 在 v1.7.0 版本中新增对 NRI 特性的支持，通过在 Containerd 配置文件的 <code>[plugins.&quot;io.containerd.nri.v1.nri&quot;]</code> 部分中配置：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[plugins.&quot;io.containerd.nri.v1.nri&quot;]</span></span><br><span class="line">  <span class="comment"># Enable NRI support in containerd.</span></span><br><span class="line">  <span class="attr">disable</span> = <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Allow connections from externally launched NRI plugins.</span></span><br><span class="line">  <span class="attr">disable_connections</span> = <span class="literal">false</span></span><br><span class="line">  <span class="comment"># plugin_config_path is the directory to search for plugin-specific configuration.</span></span><br><span class="line">  <span class="attr">plugin_config_path</span> = <span class="string">&quot;/etc/nri/conf.d&quot;</span></span><br><span class="line">  <span class="comment"># plugin_path is the directory to search for plugins to launch on startup.</span></span><br><span class="line">  <span class="attr">plugin_path</span> = <span class="string">&quot;/opt/nri/plugins&quot;</span></span><br><span class="line">  <span class="comment"># plugin_registration_timeout is the timeout for a plugin to register after connection.</span></span><br><span class="line">  <span class="attr">plugin_registration_timeout</span> = <span class="string">&quot;5s&quot;</span></span><br><span class="line">  <span class="comment"># plugin_requst_timeout is the timeout for a plugin to handle an event/request.</span></span><br><span class="line">  <span class="attr">plugin_request_timeout</span> = <span class="string">&quot;2s&quot;</span></span><br><span class="line">  <span class="comment"># socket_path is the path of the NRI socket to create for plugins to connect to.</span></span><br><span class="line">  <span class="attr">socket_path</span> = <span class="string">&quot;/var/run/nri/nri.sock&quot;</span></span><br></pre></td></tr></table></figure><p>有两种方法可以启动 NRI 插件：</p><ul><li><p>预注册（pre-connected）：当 NRI 适配器实例化时，NRI 插件就会自动启动。预注册就是将 NRI 的可执行文件放置到 NRI 插件的指定路径中，默认路径通过 plugin_path 指定，当 Containerd 启动时，就会自动加载并运行在该路径下注册的 NRI 插件</p></li><li><p>外部运行（external）：NRI 插件进程可以由 systemd 创建，或者运行在 Pod 中。只要保证 NRI 插件可以通过 NRI socket 和 Containerd 进行通信即可，默认的 NRI socket 存储路径通过 socket_path 指定</p></li></ul><p>预注册的插件是通过一个预先连接到 NRI 的 socket 启动，外部运行的插件通过 NRI socket 向 NRI 适配器注册自己。预注册插件和外部启动插件，这两种运行方式唯一的不同点就是如何启动以及如何连接到 NRI。一旦建立了连接，所有的 NRI 插件都是相同的。</p><p>NRI 可以通过 disable_connections 选项禁用外部运行插件的连接，在这种情况下 NRI socket 将不会被创建。</p><h1 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h1><p><em>以 <a href="https://github.com/containerd/nri/tree/main/plugins/logger">NRI logger</a> 插件为例。</em></p><p><strong>插件编译</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/containerd/nri.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> plugins/logger/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命名格式必须为“索引-名称”，其中索引必须为 2 位数字，否则无法通过校验</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">FATAL  [0000] failed to create plugin stub: invalid plugin index <span class="string">&quot;nri&quot;</span>, must be 2 digits</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">go build -o 01-logger nri-logger</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> 01-logger /opt/nri/plugins/00-logger</span></span><br></pre></td></tr></table></figure><p>logger 插件逻辑就是在各个 Pod 和容器生命周期节点格式化输出元数据信息。此外， CreateContainer 阶段中会设置环境变量和注解等信息：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *plugin)</span></span> CreateContainer(_ context.Context, pod *api.PodSandbox, container *api.Container) (*api.ContainerAdjustment, []*api.ContainerUpdate, <span class="type">error</span>) &#123;</span><br><span class="line">dump(<span class="string">&quot;CreateContainer&quot;</span>, <span class="string">&quot;pod&quot;</span>, pod, <span class="string">&quot;container&quot;</span>, container)</span><br><span class="line"></span><br><span class="line">adjust := &amp;api.ContainerAdjustment&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cfg.AddAnnotation != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">adjust.AddAnnotation(cfg.AddAnnotation, fmt.Sprintf(<span class="string">&quot;logger-pid-%d&quot;</span>, os.Getpid()))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> cfg.SetAnnotation != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">adjust.RemoveAnnotation(cfg.SetAnnotation)</span><br><span class="line">adjust.AddAnnotation(cfg.SetAnnotation, fmt.Sprintf(<span class="string">&quot;logger-pid-%d&quot;</span>, os.Getpid()))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> cfg.AddEnv != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">adjust.AddEnv(cfg.AddEnv, fmt.Sprintf(<span class="string">&quot;logger-pid-%d&quot;</span>, os.Getpid()))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> cfg.SetEnv != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">adjust.RemoveEnv(cfg.SetEnv)</span><br><span class="line">adjust.AddEnv(cfg.SetEnv, fmt.Sprintf(<span class="string">&quot;logger-pid-%d&quot;</span>, os.Getpid()))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> adjust, <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>配置启动</strong></p><p>这里采用外部启动（00-logger）和预先配置（01-logger）两种启动方式</p><ul><li>00-logger：设置环境变量 logger-env 与注解 logger-annotation，值为 logger-pid-&lt;PID&gt;</li><li>01-logger：设置环境变量 logger-env，值为 logger-pid-&lt;PID&gt;</li></ul><p>重启 Containerd 发现预先配置的 01-logger 插件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -xeu containerd</span></span><br><span class="line">Jul 05 17:35:43 wnx containerd[84985]: time=&quot;2023-07-05T17:35:43.730685674+08:00&quot; level=info msg=&quot;using experimental NRI integration - disable nri plugin to prevent this&quot;</span><br><span class="line">...</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.019786972+08:00&quot; level=info msg=&quot;starting plugins...&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.019915270+08:00&quot; level=info msg=&quot;discovered plugin 01-logger&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.019929420+08:00&quot; level=info msg=&quot;starting plugin \&quot;logger\&quot;...&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.049078817+08:00&quot; level=info msg=&quot;plugin \&quot;pre-connected:01-logger[84985]\&quot; registered as \&quot;01-logger\&quot;&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.050249456+08:00&quot; level=info msg=&quot;plugin invocation order&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.050284541+08:00&quot; level=info msg=&quot;  #1: \&quot;01-logger\&quot; (pre-connected:01-logger[84985])&quot;</span><br><span class="line">Jul 05 17:35:44 wnx containerd[84985]: time=&quot;2023-07-05T17:35:44.050528623+08:00&quot; level=info msg=&quot;containerd successfully booted in 1.616308s&quot;</span><br></pre></td></tr></table></figure><p>00-logger 插件注册后，订阅了所有的 Pod 和容器事件；插件启动后，即收到了运行时所有的 Pod 和容器信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./00-logger --set-annotation logger-annotation</span></span><br><span class="line">INFO   [0000] Created plugin 00-logger (00-logger, handles RunPodSandbox,StopPodSandbox,RemovePodSandbox,CreateContainer,PostCreateContainer,StartContainer,PostStartContainer,UpdateContainer,PostUpdateContainer,StopContainer,RemoveContainer) </span><br><span class="line">INFO   [0000] Registering plugin 00-logger...              </span><br><span class="line">INFO   [0000] Configuring plugin 00-logger for runtime containerd/v1.7.2... </span><br><span class="line">INFO   [0000] got configuration data: &quot;&quot; from runtime containerd v1.7.2 </span><br><span class="line">INFO   [0000] Subscribing plugin 00-logger (00-logger) for events RunPodSandbox,StopPodSandbox,RemovePodSandbox,CreateContainer,PostCreateContainer,StartContainer,PostStartContainer,UpdateContainer,PostUpdateContainer,StopContainer,RemoveContainer </span><br><span class="line">INFO   [0000] Started plugin 00-logger...                  </span><br><span class="line">INFO   [0000] Synchronize: pods:                           </span><br><span class="line">INFO   [0000] Synchronize:    - annotations:               </span><br><span class="line">INFO   [0000] Synchronize:        io.kubernetes.cri.container-type: sandbox </span><br><span class="line">INFO   [0000] Synchronize:        io.kubernetes.cri.sandbox-cpu-period: &quot;100000&quot; </span><br><span class="line">INFO   [0000] Synchronize:        io.kubernetes.cri.sandbox-cpu-quota: &quot;100000&quot; </span><br><span class="line">INFO   [0000] Synchronize:        io.kubernetes.cri.sandbox-cpu-shares: &quot;1024&quot; </span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Containerd 服务也收到了来自外部启动的 00-logger 插件信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -xeu containerd</span></span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.236103390+08:00&quot; level=info msg=&quot;plugin \&quot;external:00-logger[87525]\&quot; registered as \&quot;00-logger\&quot;&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.237601881+08:00&quot; level=info msg=&quot;Synchronizing NRI (plugin) with current runtime state&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.328071227+08:00&quot; level=info msg=&quot;synchronizing plugin 00-logger&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.797028952+08:00&quot; level=info msg=&quot;plugin invocation order&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.797164886+08:00&quot; level=info msg=&quot;  #1: \&quot;00-logger\&quot; (external:00-logger[87525])&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.797197017+08:00&quot; level=info msg=&quot;  #2: \&quot;01-logger\&quot; (pre-connected:01-logger[84985])&quot;</span><br><span class="line">Jul 05 17:38:49 wnx containerd[84985]: time=&quot;2023-07-05T17:38:49.797226434+08:00&quot; level=info msg=&quot;plugin \&quot;00-logger\&quot; connected&quot;</span><br></pre></td></tr></table></figure><p>多 NRI 插件是按照索引顺序执行，因此 01-logger 会重新设置 00-logger 设置的 logger-env 环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl inspect 6577fa85ac7e6 | grep logger</span></span><br><span class="line">          &quot;logger-env=logger-pid-85262&quot;</span><br><span class="line">        &quot;logger-annotation&quot;: &quot;logger-pid-87525&quot;</span><br></pre></td></tr></table></figure><h1 id="更多价值"><a href="#更多价值" class="headerlink" title="更多价值"></a>更多价值</h1><h2 id="节点细粒度资源管理"><a href="#节点细粒度资源管理" class="headerlink" title="节点细粒度资源管理"></a>节点细粒度资源管理</h2><p>为了满足不同业务应用场景的需求，特别是在在线任务与离线任务混布的场景下，在提高资源利用率的同时，也要保证延迟敏感服务可以得到充分的资源保证，这就需要 Kubernetes 提供更加细粒度的资源管理功能，增强容器的隔离性，减少容器之间的互相干扰。例如，CPU 编排，内存分层，缓存管理，IO 管理等。目前有很多方案，但是都有其一定的局限性。</p><p>截至目前，Kubernetes 并没有提供一个非常完善的资源管理方案，很多 Kubernetes 周边的开源项目通过一些自己的方式修改 Pod 的部署和管理流程，实现资源分配的细粒度管理。例如 <a href="https://github.com/intel/cri-resource-manager">cri-resource-manager</a>、<a href="https://github.com/koordinator-sh/koordinator">Koordinator</a>、<a href="https://github.com/gocrane/crane">Crane</a> 等项目。</p><p>这些项目对 Kubernetes 创建和更新 Pod 的流程的优化可以大致分为两种模式，一种是 proxy 模式，一种是 standalone 模式：</p><ul><li><p>proxy</p><div align=center><img width="800" style="border: 0px" src="/gallery/containerd/proxy.png"></div><p>proxy 模式是在客户端 Kubelet 和 CRI 运行时之间增加一个 CRI proxy 中继请求和响应，在 proxy 中劫持 Pod 以及容器的创建&#x2F;更新&#x2F;删除事件，对 Pod spec 进行修改或者完善，将硬件感知的资源分配策略应用于容器中。</p></li><li><p>standalone</p><div align=center><img width="800" style="border: 0px" src="/gallery/containerd/standalone.png"></div><p>standalone 模式是在每一个工作节点上创建一个 agent，当这个 agent 监听到在本节点的 Pod 创建或者修改事件的时候，再根据 Pod spec 中的注解等扩展信息，转换成细粒度资源配置的 spec，然后调用 CRI 运行时实现对 Pod 的更新。</p></li></ul><p>这两种方式在满足特定业务需求的同时也存在一定的缺点, 两种方式都需要依赖额外的组件，来捕获 Pod 的生命周期事件。proxy 模式增加了 Pod 创建管理流程的链路以及部署和维护成本，standalone 模式是在侦听到 Pod 创建以及修改的事件后，才会对 Pod 进行更新，会有一定的延迟。</p><div align=center><img width="800" style="border: 0px" src="/gallery/containerd/nri.png"></div><p>使用 NRI 可以将 Kubelet 的 Resource Manager 下沉到 CRI 运行时层进行管理。Kubelet 当前不适合处理多种需求的扩展，在 Kubelet 层增加细粒度的资源分配会导致 Kubelet 和 CRI 的界限越来越模糊。而 NRI，则是在 CRI 生命周期间做调用，更适合做资源绑定和节点的拓扑感知。并且在 CRI 内部做插件定义和迭代，可以做到上层 Kubenetes 以最小的代价来适配变化。</p><p>到现在为止，已经有越来越多的节点资源细粒度管理方案开始探索使用 NRI 实现的可能性。当 NRI 成为节点细粒度资源分配管理方案后，可以进一步提高资源管理方案的标准化，提高相关组件的可复用性。参考：<a href="https://github.com/containers/nri-plugins%E3%80%82">https://github.com/containers/nri-plugins。</a></p>]]></content>
    
    
    <summary type="html">Containerd 中 Node Resource Interface 插件设计理念与简单使用示例</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Containerd" scheme="http://shenxianghong.github.io/tags/Containerd/"/>
    
  </entry>
  
  <entry>
    <title>「 Kubernetes 」CPU 精细化管理</title>
    <link href="http://shenxianghong.github.io/2023/06/25/2023-06-25%20Kubernetes%20CPU%20%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/"/>
    <id>http://shenxianghong.github.io/2023/06/25/2023-06-25%20Kubernetes%20CPU%20%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/</id>
    <published>2023-06-24T16:00:00.000Z</published>
    <updated>2023-07-06T01:22:33.691Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kubernetes/logo.svg"></div><hr><blockquote><p>based on <strong>v1.24.10</strong></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>现代多核服务器大多采用非统一内存访问架构（Non-uniform memory access，简称 NUMA）来提高硬件的可伸缩性。NUMA 是一种为多处理器的电脑设计的内存架构，内存访问时间取决于内存相对于处理器的位置。在 NUMA 架构下，处理器访问它自己的本地内存的速度比非本地内存（内存位于另一个处理器，或者是处理器之间共享的内存）快一些。</p><p>在 Kubernetes 中，调度器的调度粒度为节点级别，并不感知和考虑节点硬件拓扑的存在。在某些延迟敏感的场景下，可能希望 Kubernetes 为 Pod 分配拓扑最优的节点和硬件，以提升硬件利用率和程序性能。CPU 敏感型应用有如下特点：</p><ul><li>对 CPU throttling 敏感</li><li>对上下文切换敏感</li><li>对处理器缓存未命中敏感</li><li>对跨 socket 内存访问敏感</li></ul><p>同时，在某些复杂场景下，部分的 Pod 属于 CPU 密集型工作负载，Pod 之间会争抢节点的 CPU 资源。当争抢剧烈的时候，Pod 会在不同的 CPU core 之间进行频繁的切换，更糟糕的是在 NUMA node 之间的切换。这种大量的上下文切换，会影响程序运行的性能。Kubernetes 的 CPU manager 一定程度可以解决以上问题，但是因为 CPU manager 特性是节点级别的 CPU 调度选择，所以无法在集群维度中选择最优的 CPU core 组合。同时 CPU manager 特性要求 Pod QoS 为 Guaranteed 时才能生效，且无法适用于所有 QoS 类型的 Pod。</p><p>Kubernetes 中虽然有 Topology Manager 来管理节点资源的拓扑对齐，但是没有与调度器联动，导致调度结果和设备资源分配结果可能不一致。此外，Topology Manager 在进行资源对齐时，仅仅停留在 NUMA 维度，并未考量到 CPU socket 和 core 拓扑等细粒度概念。</p><h1 id="设计思考"><a href="#设计思考" class="headerlink" title="设计思考"></a>设计思考</h1><h2 id="NUMA-拓扑感知调度"><a href="#NUMA-拓扑感知调度" class="headerlink" title="NUMA 拓扑感知调度"></a>NUMA 拓扑感知调度</h2><p><em><a href="https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/kep/119-node-resource-topology-aware-scheduling/README.md">KEP 议题</a></em></p><p>引入 Topology Manager 后，支持 Pod 在存在不同的 NUMA 拓扑和不同数量的拓扑资源集群节点中启动。但是存在 Pod 可能被调度到总资源量足够的节点上，但资源分配却无法满足预期的拓扑策略，从而导致 Pod 启动失败（TopologyAffinityError）。对于 Kube-scheduler 来说，更好的行为方式应该是选择适当的节点，与 Kubelet Topology Manager 策略对齐，以便 Kubelet 可以允许 Pod 运行。</p><p><strong>需要做出的改动有</strong></p><ul><li>当节点上有 NUMA 拓扑时，通过使用 scheduler-plugin 使调度过程更加精确</li><li>考虑 NUMA 拓扑，做出更优化的调度决策</li></ul><p>需要一个在 Kubelet 外部运行的 agent（<a href="https://github.com/k8stopologyawareschedwg/resource-topology-exporter">社区参考实现</a>），用于收集有关正在运行 Pod 的所有必要信息，根据节点的可分配资源和 Pod 消耗的资源，它将在 CRD 中提供可用资源，其中一个 CRD 实例代表一个节点。 CRD 实例的名称就是节点的名称。</p><p>Filter 插件实现了一个与原 Topology Manager 算法不同的简化版的 Topology Manager。该插件以 single-numa-node 策略的标准检查各节点是否具备运行 Pod 的能力。由于这是最严格的 Topology Manager 策略，如果该策略条件通过，则意味着也必然满足其他策略条件。Filter 插件将使用 CRD 来识别节点上启用的拓扑策略以及节点上可用资源的拓扑信息。另外，Score 插件将进一步考虑最适合运行 Pod 的节点。</p><p><strong>CRD 设计</strong></p><p>具有节点拓扑的可用资源应存储在 CRD 中，其格式应遵循 <a href="https://docs.google.com/document/d/12kj3fK8boNuPNqob6F_pPU9ZTaNEnPGaXEooW1Cilwg/edit?pli=1">Kubernetes Node Resource Topology Custom Resource Definition Standard</a>。<a href="https://github.com/k8stopologyawareschedwg/noderesourcetopology-api">社区参考设计</a>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// NodeResourceTopologyList is a list of NodeResourceTopology resources</span></span><br><span class="line"><span class="keyword">type</span> NodeResourceTopologyList <span class="keyword">struct</span> &#123;</span><br><span class="line">metav1.TypeMeta <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">metav1.ListMeta <span class="string">`json:&quot;metadata&quot;`</span></span><br><span class="line"></span><br><span class="line">Items []NodeResourceTopology <span class="string">`json:&quot;items&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NodeResourceTopology is a specification for a NodeResourceTopology resource</span></span><br><span class="line"><span class="keyword">type</span> NodeResourceTopology <span class="keyword">struct</span> &#123;</span><br><span class="line">metav1.TypeMeta   <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">metav1.ObjectMeta <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line"></span><br><span class="line">TopologyPolicies []<span class="type">string</span> <span class="string">`json:&quot;topologyPolicies&quot;`</span></span><br><span class="line">Zones            ZoneList <span class="string">`json:&quot;zones&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Zone is the spec for a NodeResourceTopology resource</span></span><br><span class="line"><span class="keyword">type</span> Zone <span class="keyword">struct</span> &#123;</span><br><span class="line">Name       <span class="type">string</span>           <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">Type       <span class="type">string</span>           <span class="string">`json:&quot;type&quot;`</span></span><br><span class="line">Parent     <span class="type">string</span>           <span class="string">`json:&quot;parent,omitempty&quot;`</span></span><br><span class="line">Costs      CostList         <span class="string">`json:&quot;costs,omitempty&quot;`</span></span><br><span class="line">Attributes AttributeList    <span class="string">`json:&quot;attributes,omitempty&quot;`</span></span><br><span class="line">Resources  ResourceInfoList <span class="string">`json:&quot;resources,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ZoneList []Zone</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ResourceInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">Name        <span class="type">string</span>             <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">Allocatable intstr.IntOrString <span class="string">`json:&quot;allocatable&quot;`</span></span><br><span class="line">Capacity    intstr.IntOrString <span class="string">`json:&quot;capacity&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> ResourceInfoList []ResourceInfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> CostInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">Name  <span class="type">string</span> <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">Value <span class="type">int</span>    <span class="string">`json:&quot;value&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> CostList []CostInfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> AttributeInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">Name  <span class="type">string</span> <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">Value <span class="type">string</span> <span class="string">`json:&quot;value&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> AttributeList []AttributeInfo</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">topology.node.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NodeResourceTopology</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node1</span></span><br><span class="line"><span class="attr">topologyPolicies:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SingleNUMANodeContainerLevel</span></span><br><span class="line"><span class="attr">zones:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">costs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">21</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">memory</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Node</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">costs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">21</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">memory</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Node</span></span><br></pre></td></tr></table></figure><p><strong>已知限制</strong></p><p>Kube-scheduler 在 NUMA 感知调度 Pod 流程之后，并不知道节点上 Topology Manager 实际为 Pod 分配的 NUMA 情况，节点上的 Topology Manager 也未必按照 scheduler-plugin 中的预选算法进行分配。 </p><p>因此，KEP 中建议 Kube-scheduler 可以将分配的 NUMA ID 作为 Pod 提示透传，节点的 Topology Manager 也可以根据 Pod 中的相关提示信息考虑实际的分配策略（这部分涉及到 Topology Manager 的改动，暂未实现）。</p><h2 id="节点-CPU-编排"><a href="#节点-CPU-编排" class="headerlink" title="节点 CPU 编排"></a>节点 CPU 编排</h2><div align=center><img width="600" style="border: 0px" src="/gallery/cpu-manage/cpu-assign.png"></div><p><strong>分配优先级</strong></p><ol><li>为了多核共享 L1 和 L2 cache，优先分配位于同一物理核心的两个逻辑核心。即图中的 0 和 16 号 CPU 分配优先级高于 0 和 1 号 CPU</li><li>为了多核共享 L3 cache ，优先分配位于同一 NUMA 的两个逻辑核心。即图中的 0 和 1 号 CPU 分配优先级高于 0 和 4 号 CPU</li></ol><p><strong>扩展思考点</strong></p><ul><li>考虑到超线程性能的发挥瓶颈，对于 CPU 满载服务而言，同一物理核心的两个逻辑核心未必比来自不同物理核心的性能强，因此可以针对应用本身的业务模型，是否分配自同一个物理核心有待考量</li><li>CPU 的分配优先级可以不仅仅从静态拓扑结构角度思考设计，也可以结合 CPU 频率、flag 等属性信息以及 CPU 真实使用率等动态实时信息，多维度的考量</li><li>考虑到节点资源利用率，对于非 Guaranteed QoS 的 Pod 而言，往往也需要不同程度的 CPU 精细化管理</li><li>由于集群资源动态变化，最初未满足最佳分配策略的服务，可以借助适时重分配或重调度调整至最优分配效果</li><li>拓扑资源对齐不仅仅限制于 CPU 资源，往往一套完整的拓扑资源对齐方案会将 CPU、内存、GPU、网卡等硬件设备均考虑在内</li><li>现阶段，在不修改 CPU Manager、Topology Manager 等原有模块逻辑的前提下，往往需要一个旁路 agent（standalone 模式）或者 hook CRI（proxy 模式）调用的模式来接管资源管理的能力，并且往往需要禁用原生的管理策略</li><li>随着 NRI（Node Resource Interface）规范的完善，可以基于 NRI hook 扩展，实现资源编排</li></ul><h1 id="社区成果"><a href="#社区成果" class="headerlink" title="社区成果"></a>社区成果</h1><h2 id="Crane"><a href="#Crane" class="headerlink" title="Crane"></a>Crane</h2><p><em><a href="https://github.com/gocrane/crane">https://github.com/gocrane/crane</a></em></p><div align=center><img width="800" style="border: 0px" src="/gallery/crane/overview.png"></div><p>Crane 是一个基于 FinOps 的云资源分析与成本优化平台。它的愿景是在保证客户应用运行质量的前提下实现极致的降本。</p><p><strong>设计概述</strong></p><div align=center><img width="600" style="border: 0px" src="/gallery/crane/topology-awareness-architecture.png"></div><p>Crane-scheduler 和 Crane-agent 配合工作，完成拓扑感知调度与资源分配的工作：</p><ol><li>Crane-agent 从节点采集资源拓扑，包括 NUMA、socket、设备等信息，汇总到 NodeResourceTopology CRD 中</li><li>Crane-scheduler 在调度时会参考节点的 NodeResourceTopology 对象获取到节点详细的资源拓扑结构，在调度到节点的同时还会为 Pod 分配拓扑资源，并将结果写到 Pod 的 annotations 中</li><li>Crane-agent 在节点上 watch 到 Pod 被调度后，从 Pod 的 annotations 中获取到拓扑分配结果，并按照用户给定的 CPU 绑定策略进行 CPUset 的细粒度分配</li></ol><div align=center><img width="1000" style="border: 0px" src="/gallery/crane/topology-awareness-details.png"></div><p><strong>CPU 分配策略</strong></p><p>Crane 中提供了四种 CPU 分配策略，分别如下：</p><ol><li>none：该策略不进行特别的 CPUset 分配，Pod 会使用节点 CPU 共享池</li><li>exclusive：该策略对应 Kubelet 的 static 策略，Pod 会独占 CPU 核心，其他任何 Pod 都无法使用</li><li>numa：该策略会指定 NUMA Node，Pod 会使用该 NUMA Node 上的 CPU 共享池</li><li>immovable：该策略会将 Pod 固定在某些 CPU 核心上，但这些核心属于共享池，其他 Pod 仍可使用</li></ol><p><strong>为系统组件预留 CPU</strong></p><p>在某些场景下，希望能对 Kubelet 预留的 CPU 做一些保护，使用场景包括但不限于：</p><ul><li>在混部场景下，不希望离线任务绑定系统预留的 CPU 核心，防止对 K8s 系统组件产生影响</li><li>0 号核心在 Linux 有独特用途，比如处理网络包、内核调用、处理中断等，因此不希望任务绑定 0 号核心</li></ul><p>在 Crane 中，可以通过以下方式为系统组件预留 CPU：</p><ol><li>Kubelet 设置预留 CPU：按照<a href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#explicitly-reserved-cpu-list">官方指引</a>设置预留的 CPU 列表</li><li>查看 NodeResourceTopology 对象，spec.attributes 中的 <code>go.crane.io/reserved-system-cpus</code> 存储了预留的 CPU 列表</li><li>在 Pod 的 annotations 中添加 <code>topology.crane.io/exclude-reserved-cpus</code>，表明 Pod 不绑定预留的 CPU 核心</li></ol><h2 id="Koordinator"><a href="#Koordinator" class="headerlink" title="Koordinator"></a>Koordinator</h2><p><u><em><a href="https://github.com/koordinator-sh/koordinator">https://github.com/koordinator-sh/koordinator</a></em></u></p><div align=center><img width="700" style="border: 0px" src="/gallery/koordinator/overview.png"></div><p>Koordinator 是一个基于 QoS 的 Kubernetes 混合工作负载调度系统，旨在提高对延迟敏感的工作负载和批处理作业的运行时效率和可靠性，简化与资源相关的配置调整的复杂性，并增加 Pod 部署密度以提高资源利用率。</p><p><strong>设计概述</strong></p><div align=center><img width="1000" style="border: 0px" src="/gallery/koordinator/cpu-orchestration.svg"></div><p>当 Koordlet 启动时，Koordlet 从 Kubelet 收集 NUMA 拓扑信息，包括 NUMA 拓扑、CPU 拓扑、Kubelet CPU 管理策略、Kubelet 为 Guaranteed Pod 分配的 CPU 等，并更新到节点资源拓扑 CRD。当延迟敏感的应用程序扩容时，可以为新 Pod 设置 Koordinator QoS LSE&#x2F;LSR、CPU 绑定策略和 CPU 独占策略，要求 Koord-scheduler 分配最适合的 CPU 以获得最佳性能。当 Koord-scheduler 调度 Pod 时，Koord-scheduler 会过滤满足 NUMA 拓扑对齐策略的节点，并通过评分选择最佳节点，在 Reserve 阶段分配 CPU，并在 PreBinding 时将结果记录到 Pod annotations。Koordlet 通过 hook Kubelet CRI 请求，替换通过 Koord-scheduler 调度的 CPU 配置参数到运行时，例如配置 cgroup。</p><p><strong>QoS</strong></p><p>Koordinator 调度系统支持的 QoS 有五种类型:</p><table><thead><tr><th>QoS</th><th>特点</th><th>说明</th></tr></thead><tbody><tr><td>SYSTEM</td><td>系统进程，资源受限</td><td>对于 DaemonSets 等系统服务，虽然需要保证系统服务的延迟，但也需要限制节点上这些系统服务容器的资源使用，以确保其不占用过多的资源</td></tr><tr><td>LSE(Latency Sensitive Exclusive)</td><td>保留资源并组织同 QoS 的 Pod 共享资源</td><td>很少使用，常见于中间件类应用，一般在独立的资源池中使用</td></tr><tr><td>LSR(Latency Sensitive Reserved)</td><td>预留资源以获得更好的确定性</td><td>类似于社区的 Guaranteed，CPU 核被绑定</td></tr><tr><td>LS(Latency Sensitive)</td><td>共享资源，对突发流量有更好的弹性</td><td>微服务工作负载的典型QoS级别，实现更好的资源弹性和更灵活的资源调整能力</td></tr><tr><td>BE(Best Effort)</td><td>共享不包括 LSE 的资源，资源运行质量有限，甚至在极端情况下被杀死</td><td>批量作业的典型 QoS 水平，在一定时期内稳定的计算吞吐量，低成本资源</td></tr></tbody></table><p>Koordinator 和 Kubernetes QoS 之间是有对应关系的:</p><table><thead><tr><th>Koordinator QoS</th><th>Kubernetes QoS</th></tr></thead><tbody><tr><td>SYSTEM</td><td>—</td></tr><tr><td>LSE</td><td>Guaranteed</td></tr><tr><td>LSR</td><td>Guaranteed</td></tr><tr><td>LS</td><td>Guaranteed&#x2F;Burstable</td></tr><tr><td>BE</td><td>BestEffort</td></tr></tbody></table><p><strong>CPU 编排基本原则</strong></p><ol><li>仅支持 Pod 维度的 CPU 分配机制</li><li>Koordinator 将机器上的 CPU 分为 CPU Shared Pool，statically exclusive CPUs 和 BE CPU Shared Pool：<ol><li>CPU Shared Pool 是一组共享 CPU 池，Burstable 和 LS Pod 中的任何容器都可以在其上运行。Guaranteed fractional CPU requests 的 Pod 也可以运行在 CPU Shared Pool 中。CPU Shared Pool 包含节点中所有未分配的 CPU，但不包括由 Guaranteed、LSE 和 LSR Pod 分配的 CPU。如果 Kubelet 保留 CPU，则 CPU Shared Pool 包括保留的 CPU</li><li>statically exclusive CPUs 是指分配给 Guaranteed、LSE&#x2F;LSR Pods 使用的一组独占 CPU。当 Guaranteed、LSE 和 LSR Pod 申请 CPU 时，Koord-scheduler 将从 CPU Shared Pool 中分配</li><li>BE CPU Shared Pool 是一组 BestEffort 和 BE 的 Pod 都可运行的 CPU 池。BE CPU Shared Pool 包含节点中除 Guaranteed 和 LSE Pod 分配的之外的所有 CPU</li></ol></li></ol><p><strong>Koordinator QoS CPU 编排原则</strong></p><ol><li>LSE&#x2F;LSR Pod 的 requests 和 limits 必须相等，CPU 值必须是 1000 的整数倍</li><li>LSE Pod 分配的 CPU 是完全独占的，不得共享。如果节点是超线程架构，只保证逻辑核心维度是隔离的，但是可以通过 CPUBindPolicyFullPCPUs 策略获得更好的隔离</li><li>LSR Pod 分配的 CPU 只能与 BE Pod 共享</li><li>LS Pod 绑定了与 LSE&#x2F;LSR Pod 独占之外的共享 CPU 池</li><li>BE Pod 绑定使用节点中除 LSE Pod 独占之外的所有 CPU </li><li>如果 Kubelet 的 CPU 管理器策略为 static 策略，则已经运行的 Guaranteed Pods 等价于 LSR</li><li>如果 Kubelet 的 CPU 管理器策略为 none 策略，则已经运行的 Guaranteed Pods 等价于 LS</li><li>新创建但未指定 Koordinator QoS 的 Guaranteed Pod 等价于 LS</li></ol><div align=center><img width="800" style="border: 0px" src="/gallery/koordinator/qos-cpu-orchestration.png"></div><p><strong>Kubelet CPU Manager 策略兼容原则</strong></p><ol><li>如果 Kubelet 设置 CPU Manager 策略选项 <code>full-pcpus-only=true</code> 或者 <code>distribute-cpus-across-numa=true</code>，并且节点中没有 Koordinator 定义的新 CPU 绑定策略，则遵循 Kubelet 定义的这些参数的定义</li><li>如果 Kubelet 设置了 Topology Manager 策略，并且节点中没有 Koordinator 定义的新的 NUMA Topology Alignment 策略，则遵循 Kubelet 定义的这些参数的定义</li></ol><p><strong>接管 Kubelet CPU 管理策略</strong></p><p>Kubelet 预留的 CPU 主要服务于 BestEffort 和 Burstable Pods。但 Koordinator 不会遵守该策略。Burstable Pod 应该使用 CPU Shared Pool，而 BestEffort Pods 应该使用 BE CPU Shared Pool。LSE 和 LSR Pod 不会从被 Kubelet 预留的 CPU 中分配。</p><ol><li>对于 Burstable 和 LS Pod<ol><li>当 Koordlet 启动时，计算 CPU Shared Pool 并将共享池应用到节点中的所有 Burstable 和 LS Pod，即更新它们的 CPU cgroups, 设置 CPUset。在创建或销毁 LSE&#x2F;LSR Pod 时执行相同的逻辑</li><li>Koordlet 会忽略 Kubelet 预留的 CPU，将其替换为 Koordinator 定义的 CPU Shared Pool</li></ol></li><li>对于 BestEffort 和 BE Pod<ol><li>如果 Kubelet 预留了 CPU，BestEffort Pod 会首先使用预留的 CPU</li><li>Koordlet 可以使用节点中的所有 CPU，但不包括由具有整数 CPU 的 Guaranteed 和 LSE Pod 分配的 CPU。这意味着如果 Koordlet 启用 CPU Suppress 功能，则应遵循约束以保证不会影响 LSE Pod。同样，如果 Kubelet 启用了 CPU Manager static 策略，则也应排除 Guaranteed Pod</li></ol></li><li>对于 Guaranteed Pod<ol><li>如果 Pod 的 annotations 中有 Koord-scheduler 更新的 <code>scheduling.koordinator.sh/resource-status</code>，在 sandbox&#x2F;container 创建阶段，则会替换 Kubelet CRI 请求中的 CPUset</li><li>Kubelet 有时会调用 CRI 中定义的 Update 方法来更新容器 cgroup 以设置新的 CPU，因此 Koordlet 和 koord-runtime-proxy 需要 hook 该方法</li></ol></li><li>自动调整 CPU Shared Pool 大小<ol><li>Koordlet 会根据 Pod 创建&#x2F;销毁等变化自动调整 CPU Shared Pool 的大小。如果 CPU Shared Pool 发生变化，Koordlet 应该更新所有使用共享池的 LS 或 Burstable Pod 的 cgroups</li><li>如果 Pod 的 annotations <code>scheduling.koordinator.sh/resource-status</code> 中指定了对应的 CPU Shared Pool，Koordlet 在配置 cgroup 时只需要绑定对应共享池的 CPU 即可</li></ol></li></ol><p>接管逻辑要求 koord-runtime-proxy 添加新的扩展点并且 Koordlet 实现新的运行时插件的 hook 。当没有安装 koord-runtime-proxy 时，这些接管逻辑也将能够实现。</p><p><strong>CPU 绑定策略</strong></p><p>标签 <code>node.koordinator.sh/cpu-bind-policy</code> 限制了调度时如何绑定 CPU：</p><ul><li>None 或空值 — 不执行任何策略</li><li>FullPCPUsOnly — 要求调度器必须分配完整的物理核。等效于 Kubelet CPU Manager 策略选项 full-pcpus-only&#x3D;true</li><li>SpreadByPCPUs — 要求调度器必须按照物理核维度均匀的分配 CPU</li></ul><p><strong>NUMA 分配策略</strong></p><p>标签 <code>node.koordinator.sh/numa-allocate-strategy</code> 表示在调度时如何选择满意的 NUMA 节点：</p><ul><li>MostAllocated — 表示从可用资源最少的 NUMA 节点分配</li><li>LeastAllocated — 表示从可用资源最多的 NUMA 节点分配</li><li>DistributeEvenly — 表示在 NUMA 节点上平均分配 CPU</li></ul><p><strong>NUMA 拓扑对齐策略</strong></p><p>标签 <code>node.koordinator.sh/numa-topology-alignment-policy</code> 表示如何根据 NUMA 拓扑对齐资源分配。策略语义遵循 K8s 社区。相当于 NodeResourceTopology 中的 TopologyPolicies 字段，拓扑策略 SingleNUMANodePodLevel 和 SingleNUMANodeContainerLevel 映射到 SingleNUMANode 策略：</p><ul><li>None — 是默认策略，不执行任何拓扑对齐</li><li>BestEffort — 表示优先选择拓扑对齐的 NUMA node，如果没有，则继续为 Pod 分配资源</li><li>Restricted — 表示每个 Pod 在 NUMA 节点上请求的资源是拓扑对齐的，如果不是，Koord-scheduler 会在调度时跳过该节点</li><li>SingleNUMANode — 表示一个 Pod 请求的所有资源都必须在同一个 NUMA 节点上，如果不是，Koord-scheduler 调度时会跳过该节点</li></ul><p><strong>NodeResourceTopology 维护</strong></p><p>Koordinator 在社区提供的 NodeResourceTopology CRD 基础之上通过 annotations 和 label 扩展了更多的 CPU 管理策略与限制。</p><ul><li>Koordlet 负责创建&#x2F;更新 NodeResourceTopology</li><li>建议 Koordlet 通过解析 <code>/var/lib/kubelet/cpu_manager_state</code> 文件来获取现有 Guaranteed Pod 的 CPU 分配信息。或者通过 Kubelet 提供的 CRI 接口和 gRPC 获取这些信息</li><li>当 Koord-scheduler 分配 Pod 的 CPU 时，替换 Kubelet 状态检查点文件中的 CPU</li><li>建议 Koordlet 从 <a href="https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/">kubeletConfiguration</a> 获取 CPU Manager 策略和选项</li></ul><p><strong>NRI 重构设计</strong></p><p>Koordinator 社区有计划将 CRI proxy 的增强方案以 NRI 理念重构：<a href="https://github.com/koordinator-sh/koordinator/blob/main/docs/proposals/20230608-nri-mode-resource-management.md%E3%80%82">https://github.com/koordinator-sh/koordinator/blob/main/docs/proposals/20230608-nri-mode-resource-management.md。</a></p><p>与 standalone 和 proxy 不同，Koodlet 将启动一个 NRI 插件从 CRI 运行时订阅 Pod&#x2F;容器生命周期事件，然后 Koordlet NRI 插件将调用运行时 hook 来调整 Pod 资源或 OCI 规范。流程大致为：</p><ol><li>从 CRI 运行时获取 Pod&#x2F;容器生命周期事件和 OCI 格式信息</li><li>将 OCI 格式信息转换为内部协议，以重用现有的运行时 hook 插件</li><li>将运行时 hook 插件的响应转换为 OCI 规范格式</li><li>将 OCI 规范格式响应返回到 CRI 运行时</li></ol><div align=center><img width="700" style="border: 0px" src="/gallery/koordinator/nri-proposal.png"></div><h2 id="CRI-Resource-Manager"><a href="#CRI-Resource-Manager" class="headerlink" title="CRI Resource Manager"></a>CRI Resource Manager</h2><p><em><a href="https://github.com/intel/cri-resource-manager">https://github.com/intel/cri-resource-manager</a></em></p><div align=center><img width="400" style="border: 0px" src="/gallery/cri-resource-manager/overview.png"></div><p>CRI Resource Manager 是 CRI 代理，位于客户端和实际容器运行时实现（Containerd、CRI-O）之间，用于转发请求和响应。代理的主要目的是通过在转发请求之前修改请求或在处理和代理期间执行与请求相关的额外操作来应用策略以将硬件感知的资源分配策略应用于系统中运行的容器。</p><p><strong>架构概述</strong></p><div align=center><img width="400" style="border: 0px" src="/gallery/cri-resource-manager/cri-resmgr.svg"></div><p>CRI Resource Manager 可以通过加载节点静态配置文件，也可以通过 gRPC 请求 CRI Resource Manager Node Agent 组件动态配置。 Node Agent 组件的主要功能是维护节点级别或者全局级别的 ConfigMap，以响应 CRI Resource Manager 的 gRPC 请求，返回策略配置。</p><p>默认情况下，CRI Resource Manager 无法获取 Pod spec 中指定的原始容器资源需求。它尝试使用 CRI 容器创建请求中的相关参数来预估 CPU 和内存资源。但是，无法使用这些参数来预估其他扩展资源。如果想确保 CRI Resource Manager 使用原始 Pod spec 资源需求，CRI Resource Manager Webhook 组件负责将这部分声明复制到 Pod annotations 中，用于 CRI Resource Manager 感知扩展资源。</p><p>CRI Resource Manager 提供了极为丰富的硬件拓扑感知的能力，包括但不限于 CPU、内存、blockIO、RDT、SST 等；提供了 topology-aware、static-pools、balloons、podpools 等多种策略。</p><p><em>CRI Resource Manager 聚焦在节点级别的拓扑资源管理，并未提供 NUMA 拓扑感知调度器。</em></p><p><strong>topology-aware 策略</strong></p><p>topology-aware 策略根据检测到的硬件拓扑自动构建池树。每个池都有一组分配为其资源的 CPU 和内存区域。工作负载的资源分配首先选择最适合工作负载资源需求的池，然后从该池中分配 CPU 和内存：</p><ul><li>CPU 和内存拓扑对齐分配，以最严格的可用对齐方式将 CPU 和内存分配给工作负载</li><li>设备的对齐分配，根据已分配设备的位置选择工作负载池</li><li>CPU 核心共享分配，将工作负载分配给池 CPU 的共享子集</li><li>CPU 核心独占分配，从共享子集中动态分割 CPU 核心并分配给工作负载</li><li>CPU 核心混合分配，将独占和共享 CPU 核心分配给工作负载</li><li>发现和使用内核隔离的 CPU 核心 ( <a href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html#cpu-lists">isolcpus</a> )，将内核隔离的 CPU 核心用于专门分配的 CPU 核心</li><li>将分配的资源暴露给工作负载</li><li>通知工作负载有关资源分配的更改</li><li>动态放缓内存对齐以防止 OOM，动态加宽工作负载内存集以避免池&#x2F;工作负载 OOM</li><li>多层内存分配：将工作负载分配到其首选类型的内存区域，该策略感知三种内存：DRAM 是常规系统主存储器；PMEM 是大容量内存，例如 <a href="https://www.intel.com/content/www/us/en/products/memory-storage/optane-dc-persistent-memory.html">Intel® Optane™内存</a>；<a href="https://en.wikipedia.org/wiki/High_Bandwidth_Memory">HBM</a> 是高速存储器，通常出现在一些专用计算系统上</li><li>冷启动，在初始预热期间将工作负载专门固定到 PMEM</li><li>动态页面降级，强制将只读和空闲容器内存页迁移到 PMEM</li></ul><p><strong>static-pools 策略</strong></p><p>static-pools 策略是 <a href="https://github.com/intel/CPU-Manager-for-Kubernetes">Intel CMK </a>项目的功能移植。</p><p><strong>balloons 策略</strong> </p><p>balloons 策略是一种用于管理系统中容器 CPU 资源分配的方法。它涉及将可用的 CPU 划分为相互独立的池，称为 balloon，每个 balloon 可以根据容器的资源请求进行扩大或缩小，即可以增加或减少其中的 CPU 数量。</p><p>balloon 可以是静态的或动态的。静态 balloon 需要手动创建并保持固定的大小，而动态 balloon 则可以根据容器的资源需求自动创建和销毁。这可以实现更高效的资源利用，因为 balloon 可以实时调整以满足不断变化的需求。</p><p>除了控制每个 balloon 中 CPU 数量外，balloon 还可以配置特定的设置，例如 CPU 核心和非核心的最小和最大频率。这可以对 CPU 资源的分配进行精细控制，确保每个容器都分配了其运行所需的资源。</p><p>大致流程为：</p><ol><li>用户可以配置不同类型的 balloon，策略可以根据这些配置实例化 balloon</li><li>balloon 有一组 CPU 和一组在 CPU 上运行的容器</li><li>每个容器都被分配给一个 balloon。容器可以使用其 balloon 的所有 CPU，而不能使用其他 CPU</li><li>每个逻辑 CPU 最多属于一个 balloon，也可能存在不属于任何 balloon 的 CPU</li><li>balloon 中的 CPU 数量在 balloon 的生命周期内可能会发生变化。如果 balloon 膨胀，也就是增加了 CPU，那么 balloon 中的所有容器都可以使用更多的 CPU，反之亦然</li><li>当在 Kubernetes 节点上创建新容器时，策略首先决定将运行该容器的 balloon 的类型。该决定基于 Pod annotations，或者如果未给出 annotations 则基于命名空间</li><li>接下来，策略决定哪个 balloon 将运行容器。选项有：<ul><li>现有的 balloon 已经有足够的 CPU 来运行当前和新的容器</li><li>现有的 balloon 可以扩大以适应其当前和新的容器</li><li>新 balloon</li></ul></li><li>当向 balloon 添加或从其中移除 CPU 时，会根据 balloon 的 CPU 类属性或空闲 CPU 类属性重新配置 CPU</li></ol><p><strong>podpools 策略</strong></p><p>podpools 策略实现 Pod 级别的工作负载放置。它将 Pod 的所有容器分配到同一个 CPU&#x2F;内存池。池中的 CPU 数量可由用户配置。</p><p><strong>容器亲和与反亲和</strong></p><p>亲和与反亲和的提示是通过 Pod annotations 声明：</p><ul><li>同一 NUMA 节点内的 CPU 视为彼此亲和</li><li>同一 socket 中不同 NUMA 节点内的 CPU，以及不同 socket 内的 CPU 视为彼此反亲和</li></ul><p><strong>blockIO</strong></p><p>blockIO 提供以下控制：</p><ul><li>块设备 IO 调度优先级（权重）</li><li>限制 IO 带宽</li><li>限制 IO 操作的数量</li></ul><p>CRI Resource Manager 通过 cgroups blockIO 控制器将 blockIO 的相关参数应用于 Pod。</p><h2 id="Volcano"><a href="#Volcano" class="headerlink" title="Volcano"></a>Volcano</h2><p><em><a href="https://github.com/volcano-sh/volcano">https://github.com/volcano-sh/volcano</a></em></p><div align=center><img width="600" style="border: 0px" src="/gallery/volcano/overview.png"></div><p>Volcano 是 CNCF 下首个也是唯一的基于 Kubernetes 的容器批量计算平台，主要用于高性能计算场景。它提供了 Kubernetes 目前缺少的一套机制，这些机制通常是机器学习大数据应用、科学计算、特效渲染等多种高性能工作负载所需的。作为一个通用批处理平台，Volcano 与几乎所有的主流计算框架无缝对接，如Spark、TensorFlow 、PyTorch、 Flink 、Argo 、MindSpore 、 PaddlePaddle 等。它还提供了包括基于各种主流架构的 CPU、GPU 在内的异构设备混合调度能力。Volcano 的设计理念建立在 15 年来多种系统和平台大规模运行各种高性能工作负载的使用经验之上，并结合来自开源社区的最佳思想和实践。</p><p><strong>感知调度流程</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/volcano/numa-aware-process.png"></div><table><thead><tr><th>policy</th><th>action</th></tr></thead><tbody><tr><td>none</td><td>无</td></tr><tr><td>best-effort</td><td>过滤出拓扑策略为 best-effort 的节点</td></tr><tr><td>restricted</td><td>过滤出拓扑策略为 restricted 且满足 CPU 拓扑要求的节点</td></tr><tr><td>single-numa-node</td><td>过滤出拓扑策略为 single-numa-node 且满足 CPU 拓扑要求的节点</td></tr></tbody></table><p>Volcano 在的感知调度和其他项目类似，将 Kubernetes Topology Manager 的原生策略扩展至调度器层面，只不过 CRD 采用的是 Volcano 设计的 <a href="https://github.com/volcano-sh/apis/blob/master/pkg/apis/nodeinfo/v1alpha1/numatopo_types.go">Numatopology</a>，而非社区提出的 NodeResourceTopology CRD，其他流程方面大同小异。</p><p><strong>节点 CPU 编排</strong></p><p>Volcano 并未提供节点 CPU 编排的能力，但是参考华为 CCE 产品文档中，CCE 基于社区原生的 CPU Manager 策略的基础上，提出了 enhanced-static 策略，是在兼容 static 策略的基础上，新增一种符合某些资源特征的 Burstable Pod（CPU 的 requests 和 limits 值都是正整数）优先使用某些 CPU 的能力，以减少应用在多个 CPU 间频繁切换带来的影响。</p><p>该特性是基于 Huawei Cloud EulerOS 2.0 内核中优化了 CPU 调度能力实现的。在 Pod 容器优先使用的 CPU 利用率超过 85% 时，会自动分配到其他利用率较低的 CPU 上，进而保障了应用的响应能力。</p><div align=center><img width="500" style="border: 0px" src="/gallery/volcano/enhanced-static.png"></div><ul><li>开启 enhanced-static 策略时，应用性能优于 none 策略，但弱于 static 策略</li><li>应用分配的优先使用的 CPU 并不会被独占，仍处于共享的 CPU 池中。因此在该 Pod 处于业务波谷时，节点上其他 Pod 可使用该部分 CPU 资源</li></ul><h1 id="实践验证"><a href="#实践验证" class="headerlink" title="实践验证"></a>实践验证</h1><p><em>以 cri-resource-manager为例</em></p><blockquote><p>based on <strong>v0.8.3</strong></p></blockquote><p><strong>服务安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 cri-resource-manager 服务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum -y install https://github.com/intel/cri-resource-manager/releases/download/v0.8.3/cri-resource-manager-0.8.3-0.centos-7.x86_64.rpm</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 cri-resmgr-agent 服务（需要手动编译并替换 IMAGE_PLACEHOLDER 占位符，这里不做详述）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f https://raw.githubusercontent.com/intel/cri-resource-manager/master/cmd/cri-resmgr-agent/agent-deployment.yaml</span></span><br></pre></td></tr></table></figure><p><strong>安装结果</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start cri-resource-manager</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl status cri-resource-manager</span></span><br><span class="line">● cri-resource-manager.service - A CRI proxy with (hardware) resource aware container placement policies.</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/cri-resource-manager.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Mon 2023-06-28 16:26:04 CST; 29min ago</span><br><span class="line">     Docs: https://github.com/intel/cri-resource-manager</span><br><span class="line"> Main PID: 32130 (cri-resmgr)</span><br><span class="line">    Tasks: 49</span><br><span class="line">   Memory: 41.6M</span><br><span class="line">   CGroup: /system.slice/cri-resource-manager.service</span><br><span class="line">           └─32130 /usr/bin/cri-resmgr --fallback-config /etc/cri-resmgr/fallback.cfg</span><br><span class="line">           </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get ds -A</span></span><br><span class="line">NAMESPACE            NAME                  DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span><br><span class="line">kube-system          cri-resmgr-agent      1         1         1       1            1           &lt;none&gt;                   11m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">采用 cri-resmgr-agent 维护的动态配置，采用 topology-aware 策略</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">节点全量的 CPU 为 0-47</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">- 0-4 用于非 Kubernetes 平台使用，如节点系统服务等</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">- AvailableResources 中的 5-47 号 CPU 用于 Kubernetes 平台使用</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  - ReservedResources 5-10 号 CPU 用于 Kubernetes 的预留命名空间下的服务使用</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  - 剩余的 10-47 号 CPU 用于 Kubernetes 的其他命名空间下的服务使用</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get cm -n kube-system cri-resmgr-config.node.node1 -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  policy: |</span><br><span class="line">    Active: topology-aware</span><br><span class="line">    topology-aware:</span><br><span class="line">      ReservedPoolNamespaces: [kube-system,arsdn,secboat]</span><br><span class="line">    ReservedResources:</span><br><span class="line">      cpu: cpuset:5-10</span><br><span class="line">    AvailableResources:</span><br><span class="line">      cpu: cpuset:5-47</span><br><span class="line">kind: ConfigMap</span><br></pre></td></tr></table></figure><p><strong>服务配置</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置 Kubelet 的 CRI endpoint 为 cri-resmgr.sock</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /var/lib/kubelet/kubeadm-flags.env</span></span><br><span class="line">KUBELET_KUBEADM_ARGS=&quot;--container-runtime=remote --container-runtime-endpoint=unix:///var/run/cri-resmgr/cri-resmgr.sock&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/kubernetes/kubelet.env</span></span><br><span class="line">...</span><br><span class="line">KUBELET_ARGS=&quot;--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf \</span><br><span class="line">--config=/etc/kubernetes/kubelet-config.yaml \</span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf \</span><br><span class="line">--log-dir=/var/log/kubelet \</span><br><span class="line">--log-file=/var/log/kubelet/kubelet.log \</span><br><span class="line">--logtostderr=false \</span><br><span class="line">--alsologtostderr=false \</span><br><span class="line">--feature-gates=CSIInlineVolume=true,CSIVolumeHealth=true,CPUManagerPolicyOptions=true \</span><br><span class="line">--pod-infra-container-image=harbor.archeros.cn:443/library/ake/pause:3.5-amd64 \</span><br><span class="line">--container-runtime=remote \</span><br><span class="line">--runtime-request-timeout=15m \</span><br><span class="line">--container-runtime-endpoint=unix:///var/run/cri-resmgr/cri-resmgr.sock \</span><br><span class="line">--runtime-cgroups=/systemd/system.slice \</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span></span><br></pre></td></tr></table></figure><p><strong>节点 CPU 编排</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">numactl -H</span></span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 24 25 26 27 28 29 30 31 32 33 34 35</span><br><span class="line">node 0 size: 65413 MB</span><br><span class="line">node 0 free: 15969 MB</span><br><span class="line">node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23 36 37 38 39 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 65536 MB</span><br><span class="line">node 1 free: 21933 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  21</span><br><span class="line">  1:  21  10</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署共享 CPU 的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f besteffort.yaml &amp;&amp; kubectl apply -f busterable.yaml &amp;&amp; kubectl apply -f guaranteed.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 CPU 分配情况：共享一个合适的 NUMA node</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep besteffort | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep busterable | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,           </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署独占 CPU 的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f guaranteed-exclusive.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 CPU 分配情况：独占同一物理核心的两个逻辑核心</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed-exclusive | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;23,47&quot;,</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看热更新，共享 CPU 中将独占的 CPU 扣除</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep besteffort | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep busterable | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">预留 namespace CPU 分配</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f reserved.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep reserved | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;5-10&quot;,</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Kubernetes NUMA 感知调度与节点 CPU 编排方案的探索与优化</summary>
    
    
    
    <category term="Scheduling &amp; Orchestration" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/"/>
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>「 Kubernetes 」节点资源超卖</title>
    <link href="http://shenxianghong.github.io/2023/06/13/2023-06-13%20Kubernetes%20%E8%8A%82%E7%82%B9%E8%B5%84%E6%BA%90%E8%B6%85%E5%8D%96/"/>
    <id>http://shenxianghong.github.io/2023/06/13/2023-06-13%20Kubernetes%20%E8%8A%82%E7%82%B9%E8%B5%84%E6%BA%90%E8%B6%85%E5%8D%96/</id>
    <published>2023-06-12T16:00:00.000Z</published>
    <updated>2023-07-10T05:23:25.847Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kubernetes/logo.svg"></div><hr><blockquote><p>based on <strong>v1.24.10</strong></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Kubernetes 设计原语中，Pod 声明的 spec.resources.requests 用于描述容器所需资源的最小规格，Kube-scheduler 会根据资源请求量执行调度流程，并在节点资源视图中扣除；spec.resources.limits 用于限制容器资源最大使用量，避免容器服务使用过多的资源导致节点性能下降或崩溃。Kubelet 通过参考 Pod 的 QoS 等级来管理容器的资源质量，例如 OOM 优先级控制等。Pod 的 QoS 级别分为 Guaranteed、Burstable 和 BestEffort，QoS 级别并不是显式定义，而是取决于 Pod 声明的 spec.resources.requests 和 spec.resources.limits 中 CPU 与内存。</p><p>而在实际使用过程中，为了提高稳定性，应用管理员在提交 Guaranteed 和 Burstable 这两类 QoS Pod 时会预留相当数量的资源缓冲来应对上下游链路的负载波动，在大部分时间段，服务的资源请求量会远高于实际的资源使用率。</p><div align=center><img width="600" style="border: 0px" src="/gallery/overcommitted/twitter.png"></div><p>为了提升集群资源利用率，应用管理员会提交一些 BestEffort QoS 的低优任务，来充分使用那些已分配但未使用的资源。即基于 Pod QoS 的服务混部（co-location）以实现 Kubernetes 节点资源的超卖（overcommitted）。</p><div align=center><img width="500" style="border: 0px" src="/gallery/overcommitted/overcommitted.png"></div><p>这种策略常用于容器服务平台的在离线业务混部，但是这种基础的混部方案存在一些弊端：</p><ul><li>混部会带来底层共享资源（CPU、内存、网络、磁盘等）的竞争，会导致在线业务性能下降，并且这种下降是不可预测的</li><li>节点可容纳低优任务的资源量没有任何参考，即使节点实际负载已经很高，由于 BestEffort 任务在资源规格上缺少容量约束，仍然会被调度到节点上运行</li><li>BestEffort 任务间缺乏公平性保证，任务资源规格存在区别，但无法在 Pod 描述上体现</li></ul><h1 id="设计思考"><a href="#设计思考" class="headerlink" title="设计思考"></a>设计思考</h1><p>在基于 Pod QoS 混部实现的 Kubernetes 节点资源超卖方案中，所要解决的核心问题是如何充分合理的利用缓冲资源，即 request buffer 与 limit buffer。</p><p>其中，limit buffer 在 Kubernetes 设计中天然支持超卖，Pod 在声明 spec.resources.limits 时，不受集群剩余资源的影响，集群中 Pod limits 之和也存在超出节点资源容量的情况，limit buffer 部分的资源是共享抢占的；而 request buffer 部分的资源是逻辑独占的，也就是说 spec.resources.requests 的大小会决定 Pod 能否调度，进而直接影响到节点资源的使用率。</p><p>因此，节点资源超卖理念更多的是对 request buffer 如何充分利用的思考。</p><h2 id="资源回收与超卖"><a href="#资源回收与超卖" class="headerlink" title="资源回收与超卖"></a>资源回收与超卖</h2><p>资源回收是指回收业务应用已申请的，目前还处于空闲的资源，将其给低优业务使用。但是这部分资源是低质量的，不具备太高的可用性保证。</p><div align=center><img width="600" style="border: 0px" src="/gallery/overcommitted/reclaim.png"></div><p>如图所示，reclaimed 资源代表可动态超卖的资源量，这部分需要根据节点真实负载情况动态更新，并以标准扩展资源的形式实时更新到 Kubernetes 的 Node 元信息中。低优任务可以通过在 spec.resources.requests 和 spec.resources.limits 中定义的 reclaimed 资源配置来使用这部分资源，这部分配置同时也会体现在节点侧的资源限制参数上，保证低优作业之间的公平性。</p><p>可回收资源的推导公式大致如下：</p><blockquote><p>reclaimed &#x3D; nodeAllocatable * thresholdPercent - podUsage - systemUsage</p></blockquote><ul><li><em>nodeAllocatable — 节点可分配资源总量</em></li><li><em>thresholdPercent — 预留水位比例</em></li><li><em>podUsage — 高优任务 Pod 的资源使用量</em></li><li><em>systemUsage — 系统资源真实使用量</em></li></ul><h2 id="弹性资源限制"><a href="#弹性资源限制" class="headerlink" title="弹性资源限制"></a>弹性资源限制</h2><p>原生的 BestEffort 应用缺乏资源用量的公平保证，而使用动态资源的 BestEffort 应用需要保证其 CPU 使用量被限制在其允许使用的合理范围内，避免在不同 QoS 混部的场景下对高优 Pod 的干扰，确保整机的资源使用率控制在安全水位之下。</p><p>考虑到 Kubelet cgroup manager 不支持接口扩展，所以需要借助 agent 类型的组件维护容器的 cgroup，同时在 CPU 竞争时也能按照各自声明量公平竞争。</p><h1 id="社区成果"><a href="#社区成果" class="headerlink" title="社区成果"></a>社区成果</h1><p>国内社区在节点资源超卖方面的落地思路整体相似，都是围绕弹性资源的回收、超卖与限制三个部分展开。无论是阿里 Koordinator、腾讯 Crane、华为 Volcano、字节 Katalyst 等开源项目，还是网易轻舟 NCS 和美团 LAR 等内部平台等都是类似的解决方案，它们的本质相同，只是在弹性资源结算方式等细节点上有所不同。</p><h2 id="Koordinator"><a href="#Koordinator" class="headerlink" title="Koordinator"></a>Koordinator</h2><p><u><em><a href="https://github.com/koordinator-sh/koordinator">https://github.com/koordinator-sh/koordinator</a></em></u></p><div align=center><img width="700" style="border: 0px" src="/gallery/koordinator/overview.png"></div><p>Koordinator 是一个基于 QoS 的 Kubernetes 混合工作负载调度系统，旨在提高对延迟敏感的工作负载和批处理作业的运行时效率和可靠性，简化与资源相关的配置调整的复杂性，并增加 Pod 部署密度以提高资源利用率。</p><p><strong>SLO</strong></p><p>在集群中运行的 Pod 资源 SLO（Service Level Objectives）由两个概念组成，即优先级和 QoS</p><ul><li>优先级，即资源的优先级，代表了请求资源被调度的优先级。通常情况下，优先级会影响 Pod 在调度器待定队列中的相对位置</li><li>QoS，代表 Pod 运行时的服务质量。如 cgroups cpu share、cfs 配额、LLC、内存、OOM 优先级等等</li></ul><p>Koordinator 定义了五种类型的 QoS，用于编排调度与资源隔离场景：</p><table><thead><tr><th>QoS</th><th>特点</th><th>说明</th></tr></thead><tbody><tr><td>SYSTEM</td><td>系统进程，资源受限</td><td>对于 DaemonSets 等系统服务，虽然需要保证系统服务的延迟，但也需要限制节点上这些系统服务容器的资源使用，以确保其不占用过多的资源</td></tr><tr><td>LSE(Latency Sensitive Exclusive)</td><td>保留资源并组织同 QoS 的 Pod 共享资源</td><td>很少使用，常见于中间件类应用，一般在独立的资源池中使用</td></tr><tr><td>LSR(Latency Sensitive Reserved)</td><td>预留资源以获得更好的确定性</td><td>类似于社区的 Guaranteed，CPU 核被绑定</td></tr><tr><td>LS(Latency Sensitive)</td><td>共享资源，对突发流量有更好的弹性</td><td>微服务工作负载的典型 QoS 级别，实现更好的资源弹性和更灵活的资源调整能力</td></tr><tr><td>BE(Best Effort)</td><td>共享不包括 LSE 的资源，资源运行质量有限，甚至在极端情况下被杀死</td><td>批量作业的典型 QoS 水平，在一定时期内稳定的计算吞吐量，低成本资源</td></tr></tbody></table><p>此外，进一步定义了四类优先级，用于扩展优先级维度以对混部场景的细粒度支持：</p><table><thead><tr><th>PriorityClass</th><th>优先级范围</th><th>描述</th></tr></thead><tbody><tr><td>koord-prod</td><td>[9000, 9999]</td><td>需要提前规划资源配额，并且保证在配额内成功</td></tr><tr><td>koord-mid</td><td>[7000, 7999]</td><td>需要提前规划资源配额，并且保证在配额内成功</td></tr><tr><td>koord-batch</td><td>[5000, 5999]</td><td>需要提前规划资源配额，一般允许借用配额</td></tr><tr><td>koord-free</td><td>[3000, 3999]</td><td>不保证资源配额，可分配的资源总量取决于集群的总闲置资源</td></tr></tbody></table><p><strong>弹性资源回收与超卖</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/koordinator/colocation.png"></div><p>Koordinator 的混部资源模型，其基本思想是利用那些已分配但未使用的资源来运行低优先级的 Pod。如图所示，有四条线：</p><ol><li>limit：灰色，高优先级 Pod 所请求的资源量，对应于 Kubernetes 的 Pod 请求。</li><li>usage：红色，Pod 实际使用的资源量，横轴为时间线，红线为 Pod 负载随时间变化的波动曲线。</li><li>short-term reservation：深蓝色，这是基于过去（较短）时期内的资源使用量，对未来一段时间内其资源使用量的估计。预留和限制的区别在于，分配的未使用（未来不会使用的资源）可以用来运行短期执行的批处理 Pod。</li><li>long-term reservation：浅蓝色，与 short-term reservation 类似，但估计的历史使用期更长。从保留到限制的资源可以用于生命周期较长的 Pod，与短期的预测值相比，可用的资源较少，但更稳定。</li></ol><p>Koordinator 的差异化 SLO 提供将这部分资源量化的能力。将上图中的红线定义为 usage，蓝线到红线预留部分资源定义为 buffered，绿色覆盖部分定义为 reclaimed。为体现与原生资源类型的差异性，Koordinator 使用 Batch 优先级的概念描述该部分超卖资源，也就是 batch-cpu 和 batch-memory。</p><p>节点中可超卖资源的计算公式为：</p><blockquote><p>nodeBatchAllocatable &#x3D; nodeAllocatable * thresholdPercent - podRequest(non-BE) - systemUsage</p></blockquote><p><em>公式中的 thresholdPercent 为可配置参数，通过修改 ConfigMap 中的配置项可以实现对资源的灵活管理。</em></p><p>Pod 通过声明标准扩展资源的方式使用超卖资源：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="comment"># 必填，标记为低优先级 Pod</span></span><br><span class="line">    <span class="attr">koordinator.sh/qosClass:</span> <span class="string">&quot;BE&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="comment"># 单位为千分之一核，如下表示 1 核</span></span><br><span class="line">        <span class="attr">kubernetes.io/batch-cpu:</span> <span class="string">&quot;1k&quot;</span></span><br><span class="line">        <span class="comment"># 单位为字节，如下表示 1 GB</span></span><br><span class="line">        <span class="attr">kubernetes.io/batch-memory:</span> <span class="string">&quot;1Gi&quot;</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">kubernetes.io/batch-cpu:</span> <span class="string">&quot;1k&quot;</span></span><br><span class="line">        <span class="attr">kubernetes.io/batch-memory:</span> <span class="string">&quot;1Gi&quot;</span></span><br></pre></td></tr></table></figure><p>此外，Koordinator 提供了一个 ClusterColocationProfile CRD 和对应的 webhook 修改和验证新创建的 Pod，主要为 Pod 注入 ClusterColocationProfile 中声明的 Koordinator QoSClass、Koordinator Priority 等，以及将 Pod 申请的标准资源变更至扩展资源。工作流程如下：</p><div align=center><img width="800" style="border: 0px" src="/gallery/koordinator/clustercolocationprofile.png"></div><p><strong>弹性资源限制</strong></p><p>Koordinator 在宿主机节点提供了弹性资源限制能力，确保低优先级 BE（BestEffort）类型 Pod 的 CPU 资源使用在合理范围内，保障节点内容器稳定运行。</p><p>在 Koordinator 提供的动态资源超卖模型中，reclaimed 资源总量根据高优先级 LS（Latency Sensitive）类型 Pod 的实际资源用量而动态变化，这部分资源可以供低优先级 BE（BestEffort）类型 Pod 使用。通过动态资源超卖能力，可以将 LS 与 BE 类型容器混合部署，以此提升集群资源利用率。为了确保 BE 类型Pod 的 CPU 资源使用在合理范围内，避免 LS 类型应用的运行质量受到干扰，Koordinator  在节点侧提供了 CPU 资源弹性限制的能力。弹性资源限制功能可以在整机资源用量安全水位下，控制 BE 类型 Pod 可使用的 CPU 资源量，保障节点内容器稳定运行。</p><p>如下图所示，在整机安全水位下（CPU Threshold），随着 LS 类型 Pod 资源使用量的变化（Pod（LS）.Usage），BE 类型 Pod 可用的 CPU 资源被限制在合理的范围内（CPU Restriction for BE）。限制水位的配置与动态资源超卖模型中的预留水位基本一致，以此保证 CPU 资源使用的一致性。</p><div align=center><img width="700" style="border: 0px" src="/gallery/koordinator/restriction.png"></div><p>Koordinator 支持通过 ConfigMap 配置弹性限制参数。</p><h1 id="实践验证"><a href="#实践验证" class="headerlink" title="实践验证"></a>实践验证</h1><p><em>以 Koordinator 为例</em></p><blockquote><p>based on <strong>v1.2.0</strong></p></blockquote><p><strong>使用 helm 安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Firstly add koordinator charts repository <span class="keyword">if</span> you haven<span class="string">&#x27;t do this.</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">helm repo add koordinator-sh https://koordinator-sh.github.io/charts/</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">[Optional]</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">helm repo update</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Install the latest version.</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">helm install koordinator koordinator-sh/koordinator --version 1.2.0</span></span></span><br></pre></td></tr></table></figure><p><strong>安装结果</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get all -n koordinator-system</span></span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/koord-descheduler-68845fcc47-k72l5   1/1     Running   0          3d4h</span><br><span class="line">pod/koord-descheduler-68845fcc47-vk79v   1/1     Running   0          3d4h</span><br><span class="line">pod/koord-manager-7f68bbcf77-cbscj       1/1     Running   0          3d4h</span><br><span class="line">pod/koord-manager-7f68bbcf77-sjpw7       1/1     Running   0          3d4h</span><br><span class="line">pod/koord-scheduler-f4db87d4c-5p5j4      1/1     Running   0          3d4h</span><br><span class="line">pod/koord-scheduler-f4db87d4c-x242f      1/1     Running   0          3d4h</span><br><span class="line">pod/koordlet-nz58m                       1/1     Running   0          3d4h</span><br><span class="line"></span><br><span class="line">NAME                                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/koordinator-webhook-service   ClusterIP   10.96.178.39   &lt;none&gt;        443/TCP   3d4h</span><br><span class="line"></span><br><span class="line">NAME                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/koordlet   1         1         1       1            1           &lt;none&gt;          3d4h</span><br><span class="line"></span><br><span class="line">NAME                                READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/koord-descheduler   2/2     2            2           3d4h</span><br><span class="line">deployment.apps/koord-manager       2/2     2            2           3d4h</span><br><span class="line">deployment.apps/koord-scheduler     2/2     2            2           3d4h</span><br><span class="line"></span><br><span class="line">NAME                                           DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/koord-descheduler-68845fcc47   2         2         2       3d4h</span><br><span class="line">replicaset.apps/koord-manager-7f68bbcf77       2         2         2       3d4h</span><br><span class="line">replicaset.apps/koord-scheduler-f4db87d4c      2         2         2       3d4h</span><br></pre></td></tr></table></figure><p>Koordinator 由两个控制面 Koordinator Scheduler、Koordinator Manager 和一个 DaemonSet 组件 Koordlet 组成。Koordinator 在 Kubernetes 原有的能力基础上增加了混部功能，并兼容了 Kubernetes 原有的工作负载。</p><p><em><strong>Koordinator Scheduler</strong></em></p><p>Koordinator Scheduler 以 Deployment 的形式部署，用于增强 Kubernetes 在混部场景下的资源调度能力，包括:</p><ul><li>更多的场景支持，包括弹性配额调度、资源超卖、资源预留、Gang 调度、异构资源调度</li><li>更好的性能，包括动态索引优化、等价 class 调度、随机算法优化</li><li>更安全的 descheduling，包括工作负载感知、确定性的 Pod 迁移、细粒度的流量控制和变更审计支持</li></ul><p><em><strong>Koordinator Manager</strong></em></p><p>Koordinator Manager 以 Deployment 的形式部署，通常由两个实例组成，一个 leader 实例和一个 backup 实例。Koordinator Manager 由几个控制器和 webhooks 组成，用于协调混部场景下的工作负载，资源超卖和 SLO 管理。</p><p>目前，提供了三个组件:</p><ul><li>Colocation Profile，用于支持混部而不需要修改工作负载。用户只需要在集群中做少量的配置，原来的工作负载就可以在混部模式下运行</li><li>SLO 控制器，用于资源超卖管理，根据节点混部时的运行状态，动态调整集群的超发配置比例。该控制器的核心职责是管理混部时的 SLO，如智能识别出集群中的异常节点并降低其权重，动态调整混部时的水位和压力策略，从而保证集群中 Pod 的稳定性和吞吐量</li><li>Recommender，它使用 histograms 来统计和预测工作负载的资源使用细节，用来预估工作负载的峰值资源需求，从而支持更好地分散热点，提高混部的效率。此外，提供资源画像功能，预估工作负载的峰值资源需求，资源 profiling 还将用于简化用户资源规范化配置的复杂性，如支持 VPA</li></ul><p><em><strong>Koordlet</strong></em></p><p>Koordlet 以 DaemonSet 的形式部署在 Kubernetes 集群中，用于支持混部场景下的资源超卖、干扰检测、QoS 保证等。</p><p>在 Koordlet 内部，它主要包括以下模块:</p><ul><li>资源 profiling，估算 Pod 资源的实际使用情况，回收已分配但未使用的资源，用于低优先级 Pod 的 overcommit</li><li>资源隔离，为不同类型的 Pod 设置资源隔离参数，避免低优先级的 Pod 影响高优先级 Pod 的稳定性和性能</li><li>干扰检测，对于运行中的 Pod，动态检测资源争夺，包括 CPU 调度、内存分配延迟、网络、磁盘 IO 延迟等</li><li>QoS 管理器，根据资源剖析、干扰检测结果和 SLO 配置，动态调整混部节点的水位，抑制影响服务质量的 Pod</li><li>资源调优，针对混部场景进行容器资源调优，优化容器的 CPU Throttle、OOM 等，提高服务运行质量</li></ul><p><strong>弹性资源配置</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ack-slo-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">colocation-config:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      # 是否开启节点 Batch 资源的动态更新，关闭时 Batch 资源量会被重置为 0。默认值为 false</span></span><br><span class="line"><span class="string">      &quot;enable&quot;: true,</span></span><br><span class="line"><span class="string">      # Batch 资源最小更新频率，单位为秒。通常建议保持为 1 分钟</span></span><br><span class="line"><span class="string">      &quot;metricAggregateDurationSeconds&quot;: 60,</span></span><br><span class="line"><span class="string">      # 计算节点 batch-cpu 资源容量时的预留系数。默认值为 65，单位为百分比</span></span><br><span class="line"><span class="string">      &quot;cpuReclaimThresholdPercent&quot;: 60,</span></span><br><span class="line"><span class="string">      # 计算节点 batch-memory 资源容量时的预留系数。默认值为 65，单位为百分比</span></span><br><span class="line"><span class="string">      &quot;memoryReclaimThresholdPercent&quot;: 70,</span></span><br><span class="line"><span class="string">      # 计算节点 batch-memory 资源容量时的策略</span></span><br><span class="line"><span class="string">      # &quot;usage&quot;：默认值，表示 batch-memory 内存资源按照高优先级 Pod 的内存真实用量计算，包括了节点未申请的资源，以及已申请但未使用的资源量。</span></span><br><span class="line"><span class="string">      # &quot;request&quot;：表示 batch-memory 内存资源按照高优先级 Pod 的内存请求量计算，仅包括节点未申请的资源</span></span><br><span class="line"><span class="string">      &quot;memoryCalculatePolicy&quot;: &quot;usage&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span>  <span class="attr">resource-threshold-config:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;clusterStrategy&quot;: &#123;</span></span><br><span class="line"><span class="string">        # 集群是否开启弹性资源限制能力</span></span><br><span class="line"><span class="string">        &quot;enable&quot;: true,</span></span><br><span class="line"><span class="string">        # 单位为百分比，表示弹性资源限制对应的节点安全水位阈值，默认为 65</span></span><br><span class="line"><span class="string">        &quot;cpuSuppressThresholdPercent&quot;: 65</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br></pre></td></tr></table></figure><p>开启后动态资源后，可以看到节点已经识别到扩展资源 <code>kubernetes.io/batch-cpu</code> 与 <code>kubernetes.io/batch-memory</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe node wnx</span></span><br><span class="line">Capacity:</span><br><span class="line">  cpu:                         8</span><br><span class="line">  memory:                      12057632Ki</span><br><span class="line">  kubernetes.io/batch-cpu:     4034</span><br><span class="line">  kubernetes.io/batch-memory:  4455468942</span><br><span class="line">Allocatable:</span><br><span class="line">  cpu:                         8</span><br><span class="line">  memory:                      11955232Ki</span><br><span class="line">  kubernetes.io/batch-cpu:     4034</span><br><span class="line">  kubernetes.io/batch-memory:  4455468942</span><br><span class="line">Allocated resources:</span><br><span class="line">  (Total limits may be over 100 percent, i.e., overcommitted.)</span><br><span class="line">  Resource                    Requests      Limits</span><br><span class="line">  --------                    --------      ------</span><br><span class="line">  cpu                         4100m (51%)   6500m (81%)</span><br><span class="line">  memory                      1776Mi (15%)  6740Mi (57%)</span><br><span class="line">  kubernetes.io/batch-cpu     0             0</span><br><span class="line">  kubernetes.io/batch-memory  0             0</span><br></pre></td></tr></table></figure><p>mutating webook 注入的信息是根据 ClusterColocationProfile 决定的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">config.koordinator.sh/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterColocationProfile</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">colocation-profile-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">namespaceSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">koordinator.sh/enable-colocation:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">koordinator.sh/enable-colocation:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">BE</span></span><br><span class="line">  <span class="attr">priorityClassName:</span> <span class="string">koord-batch</span></span><br><span class="line">  <span class="attr">koordinatorPriority:</span> <span class="number">1000</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">koord-scheduler</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">koordinator.sh/mutated:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">annotations:</span> </span><br><span class="line">    <span class="attr">koordinator.sh/intercepted:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">patch:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br></pre></td></tr></table></figure><p><strong>模拟在离线服务混部</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">online</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ubuntu:18.04</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/bash&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;tail -f /dev/null&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;3000Mi&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;3000Mi&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">offline</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">koordinator.sh/enable-colocation:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ubuntu:18.04</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/bash&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;tail -f /dev/null&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br></pre></td></tr></table></figure><p>在节点剩余 4C 左右的资源时，通过离线服务使用超卖资源、在线服务使用标准资源的混部模式，可以让服务均成功部署在节点上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod</span> </span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">offline     1/1     Running   0          2m25s</span><br><span class="line">online      1/1     Running   0          2m23s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe node wnx</span></span><br><span class="line">Non-terminated Pods:    (18 in total)</span><br><span class="line">  Namespace    Name        CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age</span><br><span class="line">  ---------    ----        ------------  ----------  ---------------  -------------  ---</span><br><span class="line">  default      offline     0 (0%)        0 (0%)      0 (0%)           0 (0%)         8s</span><br><span class="line">  default      online      3 (37%)       3 (37%)     3000Mi (25%)     3000Mi (25%)   6s</span><br><span class="line">Allocated resources:</span><br><span class="line">  (Total limits may be over 100 percent, i.e., overcommitted.)</span><br><span class="line">  Resource                    Requests      Limits</span><br><span class="line">  --------                    --------      ------</span><br><span class="line">  cpu                         7100m (88%)   9500m (118%)</span><br><span class="line">  memory                      4776Mi (40%)  9740Mi (83%)</span><br><span class="line">  kubernetes.io/batch-cpu     3k            3k</span><br><span class="line">  kubernetes.io/batch-memory  100Mi         100Mi</span><br></pre></td></tr></table></figure><p><strong>弹性资源限制</strong></p><p>虽然离线服务的 cgroup 还是位于 kubepods 的 besteffort 组中（由于原本声明的标准资源被 webhook 变更为扩展资源，也就变成了 BestEffort QoS 的 Pod），但是 Koordlet 会根据扩展资源的声明规格手动维护。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpu/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod4bb9f204_6690_43cf_a871_808874ad0ed4.slice/cpu.cfs_quota_us</span> </span><br><span class="line">300000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpu/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod4bb9f204_6690_43cf_a871_808874ad0ed4.slice/cpu.cfs_period_us</span> </span><br><span class="line">100000</span><br></pre></td></tr></table></figure><p>此外，在离线服务所使用的 CPU 是有区别的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">BE QoS Pod 使用的 CPU 为 0-4</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl logs -n koordinator-system   koordlet-bw5kj</span></span><br><span class="line">nodeSuppressBE[CPU(Core)]:5 = node.Total:8 * SLOPercent:65% - systemUsage:1 - podLSUsed:1</span><br><span class="line">calculated BE suppress policy: cpuset [0 1 2 3 4]</span><br><span class="line">suppressBECPU finished, suppress be cpu successfully: current cpuset [0 1 2 3 4]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在线服务使用的 CPU 仍然为 0-7</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpuset/kubepods/pod7090d2d1-48db-4fb2-8318-dea7084334e2/c108b3e5f44969b6f9a71fd4217b909f3639dafe4cc88665db93b986abe0a031/cpuset.cpus</span></span><br><span class="line">0-7</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">离线服务使用的 CPU 为 0-4</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpuset/kubepods/besteffort/podcee106b7-48ff-4441-9bba-b37c0e4620f9/ef02220e4d28ff6ebd8768ac55a4f73b22b80fac5321f1acbde35acebaa1a74f/cpuset.cpus</span></span><br><span class="line">0-4</span><br></pre></td></tr></table></figure><p>并且，随着节点负载上升（通过在线服务容器 stress 进程模拟），节点中可用的弹性资源（capacity 与 allocatable）也会逐渐变少，离线服务使用的 CPU 也会相应的缩减，但是不会停止离线服务。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpuset/kubepods/besteffort/podcee106b7-48ff-4441-9bba-b37c0e4620f9/ef02220e4d28ff6ebd8768ac55a4f73b22b80fac5321f1acbde35acebaa1a74f/cpuset.cpus</span></span><br><span class="line">0-4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当在线服务资源用量提升时，离线服务使用的 CPU 被逐渐缩减</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /sys/fs/cgroup/cpuset/kubepods/besteffort/podcee106b7-48ff-4441-9bba-b37c0e4620f9/ef02220e4d28ff6ebd8768ac55a4f73b22b80fac5321f1acbde35acebaa1a74f/cpuset.cpus</span></span><br><span class="line">0-1</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">基于 Pod QoS 混部实现 Kubernetes 节点资源超卖方案的探索与优化</summary>
    
    
    
    <category term="Scheduling &amp; Orchestration" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/"/>
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>「 OpenFaaS 」快速开始</title>
    <link href="http://shenxianghong.github.io/2023/06/05/2023-06-05%20OpenFaaS%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2023/06/05/2023-06-05%20OpenFaaS%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2023-06-04T16:00:00.000Z</published>
    <updated>2023-07-05T09:56:10.152Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/openfaas/logo.png"></div><hr><p>OpenFaaS 支持部署至以下环境中：</p><ul><li>Kubernetes、K3s、OpenShift 等容器编排环境</li><li>运行 faasd 服务的单点服务器环境</li></ul><p>相比之下，与 Kubernetes 等容器编排环境集成能够提供更好的可扩展能力。</p><h1 id="OpenFaaS-CE"><a href="#OpenFaaS-CE" class="headerlink" title="OpenFaaS CE"></a>OpenFaaS CE</h1><blockquote><p>based on <strong>0.26.3</strong></p></blockquote><p><em>OpenFaaS  Community Edition 版本面向内部使用、开发和概念验证。</em></p><p>OpenFaaS CE 安装方法：</p><ul><li><a href="https://arkade.dev/">arkade</a><br><em>arkade 本质上为一站式部署工具，支持许多服务部署，其中对于 OpenFaaS 服务支持完善。内部集成了二进制的下载与 Helm chart 的安装，arkade 封装了 helm 的参数赋值与部署，也就是在 helm 中通过 –set 设置的变量，arkade 通过 –flags 的方式处理了</em></li><li>Helm chart、Flux 或者 ArgoCD</li><li>静态 YAML 配置文件</li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="faas-cli"><a href="#faas-cli" class="headerlink" title="faas-cli"></a>faas-cli</h3><p><strong>使用 arkade 安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 arkade</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -sSL https://get.arkade.dev | sudo -E sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 faas-cli</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">arkade get faas-cli</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mv</span> /root/.arkade/bin/faas-cli /usr/local/bin/</span></span><br></pre></td></tr></table></figure><p><strong>使用 bash 安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -sSL https://cli.openfaas.com | sh</span></span><br><span class="line">New version of faas-cli installed to /usr/local/bin</span><br><span class="line">Creating alias &#x27;faas&#x27; for &#x27;faas-cli&#x27;.</span><br></pre></td></tr></table></figure><h3 id="OpenFaaS"><a href="#OpenFaaS" class="headerlink" title="OpenFaaS"></a>OpenFaaS</h3><p><strong>使用 arkade 安装</strong></p><p><em>arkade 封装了 helm 的参数赋值与部署，也就是在 helm 中通过 –set 设置的变量，arkade 通过 –flags 的方式处理了</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 arkade</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -sSL https://get.arkade.dev | sudo -E sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认安装</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">arkade install openfaas</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装可选参数</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">arkade install openfaas --<span class="built_in">help</span></span></span><br></pre></td></tr></table></figure><p><strong>使用 helm 安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 helm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -sSLf https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">推荐创建两个 namespace：openfaas 和 openfaas-fn，前者用于部署 OpenFaaS 服务组件，后者用于部署函数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arkade 部署中，默认创建了这两个 namespace</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f https://raw.githubusercontent.com/openfaas/faas-netes/master/namespaces.yml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm repo add openfaas https://openfaas.github.io/faas-netes/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm repo update &amp;&amp; helm upgrade openfaas --install openfaas/openfaas --namespace openfaas</span></span><br></pre></td></tr></table></figure><p><strong>安装结果</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deploy -n openfaas</span></span><br><span class="line">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">alertmanager   1/1     1            1           71s</span><br><span class="line">gateway        1/1     1            1           71s</span><br><span class="line">nats           1/1     1            1           71s</span><br><span class="line">prometheus     1/1     1            1           71s</span><br><span class="line">queue-worker   1/1     1            1           71s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n openfaas</span></span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">alertmanager       ClusterIP   10.96.76.14     &lt;none&gt;        9093/TCP         74s</span><br><span class="line">gateway            ClusterIP   10.96.4.162     &lt;none&gt;        8080/TCP         74s</span><br><span class="line">gateway-external   NodePort    10.96.10.134    &lt;none&gt;        8080:31112/TCP   74s</span><br><span class="line">nats               ClusterIP   10.96.196.157   &lt;none&gt;        4222/TCP         74s</span><br><span class="line">prometheus         ClusterIP   10.96.166.131   &lt;none&gt;        9090/TCP         74s</span><br></pre></td></tr></table></figure><h2 id="网关认证"><a href="#网关认证" class="headerlink" title="网关认证"></a>网关认证</h2><p>这里采用 NodePort 的形式部署 OpenFaaS CE 服务。其中，gateway-external 为对外暴露的网关服务，gateway 为对内暴露的网关服务，其后端均为 gateway Pod。无论哪种方式均采用 HTTP 认证登录方式，认证用户名和密码在 Secret 中保存：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">USER=$(kubectl get secret -n openfaas basic-auth -o jsonpath=<span class="string">&quot;&#123;.data.basic-auth-user&#125;&quot;</span> | <span class="built_in">base64</span> --decode; <span class="built_in">echo</span>)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath=<span class="string">&quot;&#123;.data.basic-auth-password&#125;&quot;</span> | <span class="built_in">base64</span> --decode; <span class="built_in">echo</span>)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;OpenFaaS user: <span class="variable">$USER</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;OpenFaaS password: <span class="variable">$PASSWORD</span>&quot;</span></span></span><br></pre></td></tr></table></figure><p><strong>gateway</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout status -n openfaas deploy/gateway</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl port-forward -n openfaas svc/gateway 8080:8080 &amp;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> -n <span class="variable">$PASSWORD</span> | faas-cli login --username admin --password-stdin</span></span><br><span class="line">Calling the OpenFaaS server to validate the credentials...</span><br><span class="line">Handling connection for 8080</span><br><span class="line">credentials saved for admin http://127.0.0.1:8080</span><br></pre></td></tr></table></figure><p>默认 faas-cli 操作的 OpenFaaS 实例为 <code>http://127.0.0.1:8080</code>，也可以通过 –gateway 进一步指定。</p><p><strong>gateway-external</strong></p><p>HTTP 认证登录 gateway-external 暴露的服务，即 <code>http://178.104.162.69:31112/ui/</code>。认证后，即可进入 OpenFaaS UI：</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/home.png"></div><h2 id="模板商店"><a href="#模板商店" class="headerlink" title="模板商店"></a>模板商店</h2><p>社区提供的模板商店为 <a href="https://github.com/openfaas/store/blob/master/templates.json%EF%BC%8C%E5%85%B6%E4%B8%AD%E6%9D%A5%E6%BA%90%E8%87%AA">https://github.com/openfaas/store/blob/master/templates.json，其中来源自</a> OpenFaaS 官方社区与周边社区。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&#123;</span><br><span class="line">        &quot;template&quot;: &quot;go&quot;,</span><br><span class="line">        &quot;platform&quot;: &quot;x86_64&quot;,</span><br><span class="line">        &quot;language&quot;: &quot;Go&quot;,</span><br><span class="line">        &quot;source&quot;: &quot;openfaas&quot;,</span><br><span class="line">        &quot;description&quot;: &quot;Legacy Golang template&quot;,</span><br><span class="line">        &quot;repo&quot;: &quot;https://github.com/openfaas/templates&quot;,</span><br><span class="line">        &quot;official&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;template&quot;: &quot;rust&quot;,</span><br><span class="line">        &quot;platform&quot;: &quot;x86_64&quot;,</span><br><span class="line">        &quot;language&quot;: &quot;Rust&quot;,</span><br><span class="line">        &quot;source&quot;: &quot;openfaas-incubator&quot;,</span><br><span class="line">        &quot;description&quot;: &quot;Community Rust template&quot;,</span><br><span class="line">        &quot;repo&quot;: &quot;https://github.com/openfaas-incubator/openfaas-rust-template&quot;,</span><br><span class="line">        &quot;official&quot;: &quot;false&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看默认支持的模板商店。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli template store list</span></span><br><span class="line">NAME                     RECOMMENDED DESCRIPTION        SOURCE</span><br><span class="line">bash-streaming           [x]         openfaas-incubator Bash Streaming template</span><br><span class="line">dockerfile               [x]         openfaas           Classic Dockerfile template</span><br><span class="line">golang-middleware        [x]         openfaas           HTTP middleware interface in Go</span><br><span class="line">java11-vert-x            [x]         openfaas           Java 11 Vert.x template</span><br><span class="line">node18                   [x]         openfaas           HTTP-based Node 18 template</span><br><span class="line">php8                     [x]         openfaas           Classic PHP 8 template</span><br><span class="line">python3-http             [x]         openfaas           Python 3 with Flask and HTTP</span><br><span class="line">python3-http-debian      [x]         openfaas           Python 3 with Flask and HTTP based on Debian</span><br><span class="line">ruby-http                [x]         openfaas           Ruby 2.4 HTTP template</span><br><span class="line">cobol                    [ ]         devries            COBOL Template</span><br><span class="line">crystal                  [ ]         tpei               Crystal template</span><br><span class="line">crystal-http             [ ]         koffeinfrei        Crystal HTTP template</span><br><span class="line">csharp-httprequest       [ ]         distantcam         C# HTTP template</span><br><span class="line">csharp-kestrel           [ ]         burtonr            C# Kestrel HTTP template</span><br><span class="line">lua53                    [ ]         affix              Lua 5.3 Template</span><br><span class="line">perl-alpine              [ ]         tmiklas            Perl language template based on Alpine image</span><br><span class="line">python3-dlrs             [ ]         intel              Deep Learning Reference Stack v0.4 for ML workloads</span><br><span class="line">quarkus-native           [ ]         pmlopes            Quarkus.io native image template</span><br><span class="line">rust                     [ ]         openfaas-incubator Community Rust template</span><br><span class="line">rust-http                [ ]         openfaas-incubator Community Rust template with HTTP bindings</span><br><span class="line">swift                    [ ]         affix              Swift 4.2 Template</span><br><span class="line">vala                     [ ]         affix              Vala Template</span><br><span class="line">vala-http                [ ]         affix              Non-Forking Vala Template</span><br><span class="line">vertx-native             [ ]         pmlopes            Eclipse Vert.x native image template</span><br><span class="line">csharp                   [ ]         openfaas           Classic C# template</span><br><span class="line">go                       [ ]         openfaas           Legacy Golang template</span><br><span class="line">golang-http              [ ]         openfaas           Request/response style HTTP template</span><br><span class="line">java11                   [ ]         openfaas           Java 11 template</span><br><span class="line">node                     [ ]         openfaas           Legacy Node 12 template</span><br><span class="line">node12                   [ ]         openfaas           HTTP-based Node 12 template</span><br><span class="line">node14                   [ ]         openfaas           HTTP-based Node 14 template</span><br><span class="line">node16                   [ ]         openfaas           HTTP-based Node 16 template</span><br><span class="line">node17                   [ ]         openfaas           HTTP-based Node 17 template</span><br><span class="line">php7                     [ ]         openfaas           Classic PHP 7 template</span><br><span class="line">powershell-http-template [ ]         openfaas-incubator Powershell Core HTTP Ubuntu:16.04 template</span><br><span class="line">powershell-template      [ ]         openfaas-incubator Powershell Core Ubuntu:16.04 template</span><br><span class="line">puppeteer-nodelts        [ ]         alexellis          A puppeteer template for headless Chrome</span><br><span class="line">python                   [ ]         openfaas           Classic Python 2.7 template</span><br><span class="line">python27-flask           [ ]         openfaas           Python 2.7 Flask template</span><br><span class="line">python3                  [ ]         openfaas           Classic Python 3 template</span><br><span class="line">python3-debian           [ ]         openfaas           Python 3 Debian template</span><br><span class="line">python3-flask            [ ]         openfaas           Python 3 Flask template</span><br><span class="line">python3-flask-debian     [ ]         openfaas           Python 3 Flask template based on Debian</span><br><span class="line">ruby                     [ ]         openfaas           Classic Ruby 2.5 template</span><br></pre></td></tr></table></figure><p>获取托管在模板商店中的 OpenFaaS 官方经典模板。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli template pull</span></span><br><span class="line">Fetch templates from repository: https://github.com/openfaas/templates.git at </span><br><span class="line">2023/06/05 17:15:07 Attempting to expand templates from https://github.com/openfaas/templates.git</span><br><span class="line">2023/06/05 17:15:09 Fetched 18 template(s) : [csharp dockerfile go java11 java11-vert-x node node12 node12-debian node14 node16 node17 node18 php7 php8 python python3 python3-debian ruby] from https://github.com/openfaas/templates.git</span><br></pre></td></tr></table></figure><p>获取托管在模板商店中的指定模板。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli template store pull rust</span></span><br><span class="line">Fetch templates from repository: https://github.com/openfaas-incubator/openfaas-rust-template at </span><br><span class="line">2023/06/05 17:41:58 Attempting to expand templates from https://github.com/openfaas-incubator/openfaas-rust-template</span><br><span class="line">2023/06/05 17:42:02 Fetched 1 template(s) : [rust] from https://github.com/openfaas-incubator/openfaas-rust-template</span><br></pre></td></tr></table></figure><p>也可以通过 –url 参数，获取指定来源的模板。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli template store pull --url=https://raw.githubusercontent.com/openfaas/store/master/templates.json</span></span><br></pre></td></tr></table></figure><p>获取到的模板文件保存在当前的 template 目录中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> template/</span></span><br><span class="line">csharp  dockerfile  go  java11  java11-vert-x  node  node12  node12-debian  node14  node16  node17  node18  php7  php8  python  python3  python3-debian  ruby</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree template/golang-middleware/</span></span><br><span class="line">template/golang-middleware/</span><br><span class="line">├── Dockerfile# 函数最终会构建成镜像</span><br><span class="line">├── function# 业务代码，比如实现 HTTP endpoint 处理请求</span><br><span class="line">│   ├── go.mod</span><br><span class="line">│   └── handler.go</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.work</span><br><span class="line">├── main.go# 函数入口，用于启动 HTTP 服务器，注册 endpoint</span><br><span class="line">└── template.yml# 模板说明</span><br><span class="line"></span><br><span class="line">1 directory, 7 files</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli new --list</span></span><br><span class="line">Languages available as templates:</span><br><span class="line">- csharp</span><br><span class="line">- dockerfile</span><br><span class="line">- go</span><br><span class="line">- java11</span><br><span class="line">- java11-vert-x</span><br><span class="line">- node</span><br><span class="line">- node12</span><br><span class="line">- node12-debian</span><br><span class="line">- node14</span><br><span class="line">- node16</span><br><span class="line">- node17</span><br><span class="line">- node18</span><br><span class="line">- php7</span><br><span class="line">- php8</span><br><span class="line">- python</span><br><span class="line">- python3</span><br><span class="line">- python3-debian</span><br><span class="line">- ruby</span><br></pre></td></tr></table></figure><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><blockquote><p>based on <strong>Kubernetes 1.24.10</strong></p></blockquote><h3 id="创建函数"><a href="#创建函数" class="headerlink" title="创建函数"></a>创建函数</h3><p><em>这里以 Golang 的 golang-middleware 函数模板为例，该函数为简单的 HTTP 请求响应。</em></p><table><thead><tr><th>可选模板</th><th>托管商店</th><th>watchdog</th><th>Go 版本</th><th>基础 OS</th><th>说明</th></tr></thead><tbody><tr><td>go</td><td><a href="https://github.com/openfaas/templates">https://github.com/openfaas/templates</a></td><td>classic</td><td>1.18</td><td>Alpine Linux</td><td>Legacy Golang template</td></tr><tr><td>golang-middleware</td><td><a href="https://github.com/openfaas/golang-http-template">https://github.com/openfaas/golang-http-template</a></td><td>of-watchdog</td><td>1.19</td><td>Alpine Linux</td><td>HTTP middleware interface in Go</td></tr><tr><td>golang-http</td><td><a href="https://github.com/openfaas/golang-http-template">https://github.com/openfaas/golang-http-template</a></td><td>of-watchdog</td><td>1.19</td><td>Alpine Linux</td><td>Request&#x2F;response style HTTP template</td></tr></tbody></table><p>使用 golang-middleware 模板创建名为 go-fn 的函数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli new go-fn --lang golang-middleware</span></span><br><span class="line">Folder: go-fn created.</span><br><span class="line">  ___                   _____           ____</span><br><span class="line"> / _ \ _ __   ___ _ __ |  ___|_ _  __ _/ ___|</span><br><span class="line">| | | | &#x27;_ \ / _ \ &#x27;_ \| |_ / _` |/ _` \___ \</span><br><span class="line">| |_| | |_) |  __/ | | |  _| (_| | (_| |___) |</span><br><span class="line"> \___/| .__/ \___|_| |_|_|  \__,_|\__,_|____/</span><br><span class="line">      |_|</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Function created in folder: go-fn</span><br><span class="line">Stack file written: go-fn.yml</span><br><span class="line"></span><br><span class="line">Notes:</span><br><span class="line">You have created a new function which uses Go 1.19 and Alpine</span><br><span class="line">Linux as its base image.</span><br><span class="line"></span><br><span class="line">To disable the go module, for private vendor code, please use</span><br><span class="line">&quot;--build-arg GO111MODULE=off&quot; with faas-cli build or configure this</span><br><span class="line">via your stack.yml file.</span><br><span class="line"></span><br><span class="line">See more: https://docs.openfaas.com/cli/templates/</span><br><span class="line"></span><br><span class="line">For the template&#x27;s repo and more examples:</span><br><span class="line">https://github.com/openfaas/golang-http-template</span><br></pre></td></tr></table></figure><p>函数模板创建后，会在当前目录生成 go-fn 目录，其内容源自于 template&#x2F;golang-middleware&#x2F;function 以及 go-fn.yml 文件，用于描述函数构建的具体规格，例如：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="number">1.0</span></span><br><span class="line"><span class="attr">provider:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">openfaas</span></span><br><span class="line">  <span class="attr">gateway:</span> <span class="string">http://127.0.0.1:8080</span></span><br><span class="line"><span class="attr">functions:</span></span><br><span class="line">  <span class="attr">go-fn:</span></span><br><span class="line">    <span class="attr">lang:</span> <span class="string">golang-middleware</span></span><br><span class="line">    <span class="attr">handler:</span> <span class="string">./go-fn</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">harbor.archeros.cn/dev/ake/openfaas-fn:dev</span></span><br></pre></td></tr></table></figure><h3 id="构建函数镜像"><a href="#构建函数镜像" class="headerlink" title="构建函数镜像"></a>构建函数镜像</h3><p><code>faas-cli build</code> 构建函数时，默认读取当前目录下的 stack.yml 文件，也可以通过 -f 指定。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli build -f go-fn.yml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker images</span></span><br><span class="line">harbor.archeros.cn/dev/ake/openfaas-fn     dev     891e42d0a44c     23 minutes ago     21MB</span><br></pre></td></tr></table></figure><p>构建时使用的 Dockerfile 位于 build&#x2F;go-fn&#x2F;Dockerfile（源自 template&#x2F;golang-middleware&#x2F;Dockerfile）。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> --platform=$&#123;TARGETPLATFORM:-linux/amd64&#125; ghcr.io/openfaas/of-watchdog:<span class="number">0.9</span>.<span class="number">11</span> as watchdog</span><br><span class="line"><span class="keyword">FROM</span> --platform=$&#123;BUILDPLATFORM:-linux/amd64&#125; golang:<span class="number">1.19</span>-alpine as build</span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> TARGETPLATFORM</span><br><span class="line"><span class="keyword">ARG</span> BUILDPLATFORM</span><br><span class="line"><span class="keyword">ARG</span> TARGETOS</span><br><span class="line"><span class="keyword">ARG</span> TARGETARCH</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apk --no-cache add git</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --from=watchdog /fwatchdog /usr/bin/fwatchdog</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chmod</span> +x /usr/bin/fwatchdog</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /go/src/handler</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /go/src/handler</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> GO111MODULE=<span class="string">&quot;on&quot;</span></span><br><span class="line"><span class="keyword">ARG</span> GOPROXY=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">ARG</span> GOFLAGS=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">ARG</span> CGO_ENABLED=<span class="number">0</span></span><br><span class="line"><span class="keyword">ENV</span> CGO_ENABLED=$&#123;CGO_ENABLED&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run a gofmt and exclude all vendored code.</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">test</span> -z <span class="string">&quot;<span class="subst">$(gofmt -l $(find . -type f -name &#x27;*.go&#x27; -not -path <span class="string">&quot;./vendor/*&quot;</span> -not -path <span class="string">&quot;./function/vendor/*&quot;</span>)</span>)&quot;</span> || &#123; <span class="built_in">echo</span> <span class="string">&quot;Run \&quot;gofmt -s -w\&quot; on your Golang code&quot;</span>; <span class="built_in">exit</span> 1; &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /go/src/handler/function</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /go/src/handler/function/static</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> GOOS=<span class="variable">$&#123;TARGETOS&#125;</span> GOARCH=<span class="variable">$&#123;TARGETARCH&#125;</span> go <span class="built_in">test</span> ./... -cover</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /go/src/handler</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> GOOS=<span class="variable">$&#123;TARGETOS&#125;</span> GOARCH=<span class="variable">$&#123;TARGETARCH&#125;</span> \</span></span><br><span class="line"><span class="language-bash">    go build --ldflags <span class="string">&quot;-s -w&quot;</span> -o handler .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> --platform=$&#123;TARGETPLATFORM:-linux/amd64&#125; alpine:<span class="number">3.17</span>.<span class="number">2</span> as ship</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add non root user and certs</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apk --no-cache add ca-certificates \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; addgroup -S app &amp;&amp; adduser -S -g app app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Split instructions so that buildkit can run &amp; cache</span></span><br><span class="line"><span class="comment"># the previous command ahead of time.</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /home/app \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; <span class="built_in">chown</span> app /home/app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /home/app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --from=build --<span class="built_in">chown</span>=app /go/src/handler/handler           .</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --from=build --<span class="built_in">chown</span>=app /usr/bin/fwatchdog                .</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --from=build --<span class="built_in">chown</span>=app /go/src/handler/function/static   static</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">USER</span> app</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> fprocess=<span class="string">&quot;./handler&quot;</span></span><br><span class="line"><span class="keyword">ENV</span> mode=<span class="string">&quot;http&quot;</span></span><br><span class="line"><span class="keyword">ENV</span> upstream_url=<span class="string">&quot;http://127.0.0.1:8082&quot;</span></span><br><span class="line"><span class="keyword">ENV</span> prefix_logs=<span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;./fwatchdog&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>此外，构建参数可以通过 stack.yml 文件中的 build_args 选项指定，效果等价于 <code>faas-cli build --build-arg key1=value1,key2=value2</code>。最终，build_args 指定的参数会通过 docker build –build-arg 透传给 Dockerfile 中的 ARG。</p><p>例如，指定使用本地 vendor 构建 Golang 应用</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">functions:</span></span><br><span class="line">  <span class="attr">with_go_modules:</span></span><br><span class="line">    <span class="attr">handler:</span> <span class="string">./with_go_modules</span></span><br><span class="line">    <span class="attr">lang:</span> <span class="string">go</span></span><br><span class="line">    <span class="attr">build_args:</span></span><br><span class="line">      <span class="attr">GO111MODULE:</span> <span class="string">off</span></span><br><span class="line">      <span class="attr">GOFLAGS:</span> <span class="string">&quot;-mod=vendor&quot;</span></span><br></pre></td></tr></table></figure><p>默认函数应用镜像拉取策略为 Always，需要将镜像推送至远程仓库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli push -f go-fn.yml</span></span><br></pre></td></tr></table></figure><h3 id="发布函数"><a href="#发布函数" class="headerlink" title="发布函数"></a>发布函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli deploy -f go-fn.yml</span> </span><br><span class="line">Deploying: go-fn.</span><br><span class="line">Handling connection for 8080</span><br><span class="line"></span><br><span class="line">Deployed. 202 Accepted.</span><br><span class="line">URL: http://127.0.0.1:8080/function/go-fn</span><br></pre></td></tr></table></figure><p>函数发布后，对应着一个 Deploy 创建。OpenFaaS CE 版本中，副本数最小为 1。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -n openfaas-fn</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">go-fn-757f844cc5-v5tvn   1/1     Running   0          8s</span><br></pre></td></tr></table></figure><p>Pod 的关键参数为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fprocess</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">./handler</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">harbor.archeros.cn/dev/ake/openfaas-fn:dev</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/_/health</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">go-fn</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">readinessProbe:</span></span><br><span class="line">      <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/_/health</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">securityContext:</span></span><br><span class="line">      <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line">    <span class="attr">terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kube-api-access-b7kx5</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">  <span class="attr">enableServiceLinks:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">wnx</span></span><br><span class="line">  <span class="attr">preemptionPolicy:</span> <span class="string">PreemptLowerPriority</span></span><br><span class="line">  <span class="attr">priority:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line">  <span class="attr">securityContext:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">serviceAccount:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">serviceAccountName:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">  <span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoExecute</span></span><br><span class="line">    <span class="attr">key:</span> <span class="string">node.kubernetes.io/not-ready</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">    <span class="attr">tolerationSeconds:</span> <span class="number">300</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoExecute</span></span><br><span class="line">    <span class="attr">key:</span> <span class="string">node.kubernetes.io/unreachable</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">    <span class="attr">tolerationSeconds:</span> <span class="number">300</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-api-access-b7kx5</span></span><br><span class="line">    <span class="attr">projected:</span></span><br><span class="line">      <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">      <span class="attr">sources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">serviceAccountToken:</span></span><br><span class="line">          <span class="attr">expirationSeconds:</span> <span class="number">3607</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">token</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">ca.crt</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">ca.crt</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">kube-root-ca.crt</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">downwardAPI:</span></span><br><span class="line">          <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">namespace</span></span><br></pre></td></tr></table></figure><p>已发布的函数中，Invocations 为调用次数，Replicas 为当前函数应用的副本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli list</span></span><br><span class="line">Function    Invocations    Replicas</span><br><span class="line">go-fn        0              1   </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas describe go-fn</span></span><br><span class="line">Name:               go-fn</span><br><span class="line">Status:             Not Ready</span><br><span class="line">Replicas:           1</span><br><span class="line">Available Replicas: 0</span><br><span class="line">Invocations:        17542</span><br><span class="line">Image:              harbor.archeros.cn/dev/ake/openfaas-fn:dev</span><br><span class="line">Function Process:   ./handler</span><br><span class="line">URL:                http://127.0.0.1:8080/function/go-fn</span><br><span class="line">Async URL:          http://127.0.0.1:8080/async-function/go-fn</span><br><span class="line">Labels:</span><br><span class="line"> faas_function: go-fn</span><br><span class="line">Annotations:</span><br><span class="line"> prometheus.io.scrape: false</span><br></pre></td></tr></table></figure><p>也可以通过部署时指定 –label 限制扩容规格等信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli deploy -f go-fn.yml --label com.openfaas.scale.max=2</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">此时无论多大的请求量，最大扩容规格为 2 副本</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli describe go-fn</span></span><br><span class="line">Name:               go-fn</span><br><span class="line">Status:             Ready</span><br><span class="line">Replicas:           2</span><br><span class="line">Available Replicas: 2</span><br><span class="line">Invocations:        21517</span><br><span class="line">Image:              harbor.archeros.cn/dev/ake/openfaas-fn:dev</span><br><span class="line">Function Process:   ./handler</span><br><span class="line">URL:                http://127.0.0.1:8080/function/go-fn</span><br><span class="line">Async URL:          http://127.0.0.1:8080/async-function/go-fn</span><br><span class="line">Labels:</span><br><span class="line"> com.openfaas.scale.max: 2</span><br><span class="line"> faas_function: go-fn</span><br><span class="line">Annotations:</span><br><span class="line"> prometheus.io.scrape: false</span><br></pre></td></tr></table></figure><p>除了 faas-cli，函数的创建、构建与发布也可以通过 OpenFaaS UI 操作：</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/deploy.png"></div><h3 id="调用函数"><a href="#调用函数" class="headerlink" title="调用函数"></a>调用函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli invoke go-fn</span></span><br><span class="line">Reading from STDIN - hit (Control + D) to stop.</span><br><span class="line">Hello World</span><br><span class="line">Body: Hello World</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等价于</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> Hello World | faas-cli invoke go-fn</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli invoke go-fn --from-literal=<span class="string">&quot;Hello World&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli invoke go-fn --from-file=~/Downloads/derek.pem</span></span><br></pre></td></tr></table></figure><p>UI 调用方式为：</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/invoke.png"></div><p>此外，根据函数调用的路由，也分为同步调用与异步调用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步调用 <span class="keyword">function</span> 路由</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i -d <span class="string">&quot;Hello World&quot;</span> http://127.0.0.1:8080/function/go-fn</span></span><br><span class="line">Handling connection for 8080</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 17</span><br><span class="line">Content-Type: text/plain; charset=utf-8</span><br><span class="line">Date: Fri, 09 Jun 2023 03:43:13 GMT</span><br><span class="line">X-Call-Id: 98630f05-1b39-4fc5-bb89-7c2c66c1cf7f</span><br><span class="line">X-Duration-Seconds: 0.002147</span><br><span class="line">X-Start-Time: 1686282193791968394</span><br><span class="line"></span><br><span class="line">Body: Hello World</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">异步调用 async-function 路由</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -i -d <span class="string">&quot;Hello World&quot;</span> http://127.0.0.1:8080/async-function/go-fn</span></span><br><span class="line">Handling connection for 8080</span><br><span class="line">HTTP/1.1 202 Accepted</span><br><span class="line">X-Call-Id: fea5f39d-e7ad-4454-8283-1a213710f3a7</span><br><span class="line">X-Start-Time: 1686282228379248896</span><br><span class="line">Date: Fri, 09 Jun 2023 03:43:48 GMT</span><br><span class="line">Content-Length: 0</span><br></pre></td></tr></table></figure><h3 id="自动扩缩容"><a href="#自动扩缩容" class="headerlink" title="自动扩缩容"></a>自动扩缩容</h3><p>模拟海量请求，观察 OpenFaaS 函数应用的自动扩容。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">while</span> <span class="literal">true</span> ;<span class="keyword">do</span> <span class="built_in">echo</span> Hello World | faas-cli invoke go-fn; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure><p>随着请求调用量的增加，副本数也逐渐增加。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deploy -n openfaas-fn   go-fn -w</span></span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">go-fn   1/1     1            1           7m57s</span><br><span class="line">go-fn   1/2     2            1           8m35s</span><br><span class="line">go-fn   2/2     2            2           8m38s</span><br><span class="line">go-fn   2/3     3            2           9m15s</span><br><span class="line">go-fn   3/3     3            3           9m18s</span><br><span class="line">go-fn   3/4     3            3           9m55s</span><br><span class="line">go-fn   4/4     4            4           9m59s</span><br><span class="line">go-fn   4/5     4            4           10m</span><br><span class="line">go-fn   5/5     5            5           10m</span><br></pre></td></tr></table></figure><p>当停止模拟请求时，副本数也逐渐减少。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deploy -n openfaas-fn   go-fn -w</span></span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">go-fn   5/5     5            5           11m</span><br><span class="line">go-fn   5/1     5            5           11m</span><br><span class="line">go-fn   1/1     1            1           11m</span><br></pre></td></tr></table></figure><p>也可以通过部署时指定 –label 限制扩容规格等信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli deploy -f go-fn.yml --label com.openfaas.scale.max=2</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli describe go-fn</span></span><br><span class="line">Name:               go-fn</span><br><span class="line">Status:             Ready</span><br><span class="line">Replicas:           2</span><br><span class="line">Available Replicas: 2</span><br><span class="line">Invocations:        21517</span><br><span class="line">Image:              harbor.archeros.cn/dev/ake/openfaas-fn:dev</span><br><span class="line">Function Process:   ./handler</span><br><span class="line">URL:                http://127.0.0.1:8080/function/go-fn</span><br><span class="line">Async URL:          http://127.0.0.1:8080/async-function/go-fn</span><br><span class="line">Labels:</span><br><span class="line"> com.openfaas.scale.max: 2</span><br><span class="line"> faas_function: go-fn</span><br><span class="line">Annotations:</span><br><span class="line"> prometheus.io.scrape: false</span><br></pre></td></tr></table></figure><h3 id="函数日志"><a href="#函数日志" class="headerlink" title="函数日志"></a>函数日志</h3><p>针对 Kubernetes 的日志 provider 为 faas-netes 组件，其获取日志的方式等价于 <code>kubectl logs -n openfaas-fn deploy/function</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli logs go-fn</span></span><br><span class="line">2023-06-07T16:15:23+08:00 2023/06/07 08:15:23 POST / - 200 OK - ContentLength: 18B (0.0008s)</span><br><span class="line">2023-06-07T16:15:23+08:00 2023/06/07 08:15:23 POST / - 200 OK - ContentLength: 18B (0.0005s)</span><br><span class="line">2023-06-07T16:15:24+08:00 2023/06/07 08:15:24 POST / - 200 OK - ContentLength: 18B (0.0015s)</span><br><span class="line">2023-06-07T16:15:24+08:00 2023/06/07 08:15:24 POST / - 200 OK - ContentLength: 18B (0.0007s)</span><br><span class="line">2023-06-07T16:15:24+08:00 2023/06/07 08:15:24 POST / - 200 OK - ContentLength: 18B (0.0017s)</span><br></pre></td></tr></table></figure><h3 id="移除函数"><a href="#移除函数" class="headerlink" title="移除函数"></a>移除函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli remove go-fn</span></span><br><span class="line">Deleting: go-fn.</span><br><span class="line">Handling connection for 8080</span><br><span class="line">Removing old function.</span><br></pre></td></tr></table></figure><h2 id="Secret-管理"><a href="#Secret-管理" class="headerlink" title="Secret 管理"></a>Secret 管理</h2><p>之所以二次封装 API，是为了便于管理函数所用到的 Secret。</p><p>默认操作的 Secret 位于 openfaas-fn 命名空间下，可以通过 –namespace 指定；默认操作的 OpenFaaS 实例为 </p><p><strong>create</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret create my-secret</span></span><br><span class="line">Reading from STDIN - hit (Control + D) to stop.</span><br><span class="line">my-password</span><br><span class="line">Creating secret: my-secret.</span><br><span class="line">Handling connection for 8080</span><br><span class="line">Created: 202 Accepted</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等价于</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> my-password | faas-cli secret create my-secret</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret create my-secret --from-literal=<span class="string">&quot;my-password&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret create my-secret --from-file=~/Downloads/derek.pem</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">my-secret:</span> <span class="string">bXktcGFzc3dvcmQ=</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2023-06-07T06:19:14Z&quot;</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">openfaas</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">openfaas-fn</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;11584461&quot;</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">dd0803f2-76d8-453a-a770-ec2633cd6b22</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br></pre></td></tr></table></figure><p><strong>update</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret update my-secret</span></span><br><span class="line">Reading from STDIN - hit (Control + D) to stop.</span><br><span class="line">my-new-pasword</span><br><span class="line">Updating secret: my-secret</span><br><span class="line">Handling connection for 8080</span><br><span class="line">Updated: 202 Accepted</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等价于</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> my-new-secret | faas-cli secret update my-secret</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret update my-secret --from-literal=<span class="string">&quot;my-password&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret update my-secret --from-file=~/Downloads/derek.pem</span></span><br></pre></td></tr></table></figure><p><strong>list</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret list</span></span><br><span class="line">Handling connection for 8080</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">my-secret</span><br></pre></td></tr></table></figure><p><strong>delete</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli secret remove my-secret</span></span><br><span class="line">faas-cli secret remove my-secret</span><br><span class="line">Handling connection for 8080</span><br><span class="line">Removed.. OK.</span><br></pre></td></tr></table></figure><h1 id="OpenFaaS-Pro"><a href="#OpenFaaS-Pro" class="headerlink" title="OpenFaaS Pro"></a>OpenFaaS Pro</h1><blockquote><p>based on <strong>0.26.3</strong></p></blockquote><p><em>OpenFaaS Pro 是 OpenFaaS 的商业许可发行版，具有附加功能、配置和商业支持。</em></p><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><h3 id="faas-cli-pro"><a href="#faas-cli-pro" class="headerlink" title="faas-cli pro"></a>faas-cli pro</h3><p>faas-cli 对于 OpenFaaS Pro 的支持是通过插件的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli plugin get pro</span></span><br><span class="line">Fetching plugin: pro</span><br><span class="line">Downloaded in (4s)</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  faas-cli pro</span><br></pre></td></tr></table></figure><p>根据 github 账号校验 OpenFaaS Pro 购买认证：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faas-cli pro <span class="built_in">enable</span></span></span><br><span class="line">Please visit: https://github.com/login/device</span><br><span class="line">and enter the code: 168C-29B2</span><br><span class="line">Waiting for authorization...</span><br><span class="line">Waiting for authorization...</span><br><span class="line">Waiting for authorization...</span><br><span class="line">Waiting for authorization...</span><br><span class="line">GET https://api.github.com/user/memberships/orgs: 401 Bad credentials []</span><br></pre></td></tr></table></figure><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><h3 id="Support"><a href="#Support" class="headerlink" title="Support"></a>Support</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Suitability</td><td align="left">Open Source developers and initial exploration</td><td align="left">Production, business critical, or PoC</td><td align="left">Regulated companies which may have additional legal and compliance requirements</td></tr><tr><td align="left">SLA</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Response within 1 business day for P1</td></tr><tr><td align="left">Buying process</td><td align="left">N&#x2F;a</td><td align="left">Invoice paid by bank transfer</td><td align="left">Supplier portals, custom paperwork, negotiation with procurement.</td></tr><tr><td align="left">Legal review of contract</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Yes</td></tr><tr><td align="left">Signing of Mutual NDA</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Subject to agreement</td></tr><tr><td align="left">Additional compliance needs</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Subject to agreement</td></tr><tr><td align="left">Support via email</td><td align="left">N&#x2F;a</td><td align="left">Pro features only</td><td align="left">All certified Open Source and commercial components</td></tr><tr><td align="left">Support via GitHub</td><td align="left">N&#x2F;a</td><td align="left">Pro features only using the Customer Community</td><td align="left">N&#x2F;a</td></tr><tr><td align="left">Support via Slack</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Up to 5 developers</td></tr><tr><td align="left">License</td><td align="left"><a href="https://github.com/openfaas/faas/blob/master/LICENSE">MIT</a></td><td align="left"><a href="https://github.com/openfaas/faas/blob/master/pro/EULA">Commercial license EULA</a></td><td align="left">As per Pro</td></tr><tr><td align="left">Architecture review</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">With our team via Zoom</td></tr><tr><td align="left">Onboarding call</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">With our team via Zoom</td></tr><tr><td align="left"><a href="https://github.com/openfaas/customers">Customer Community</a></td><td align="left">N&#x2F;a</td><td align="left">Private access to <a href="https://github.com/openfaas/customers">Customer Community</a> - one user per licensed cluster</td><td align="left">Custom amount of users</td></tr></tbody></table><h3 id="Autoscaling"><a href="#Autoscaling" class="headerlink" title="Autoscaling"></a>Autoscaling</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Scale to Zero</td><td align="left">Not supported</td><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/scale-to-zero">Global default, or custom time per function</a></td><td align="left">As per Pro</td></tr><tr><td align="left">Maximum replicas per function</td><td align="left">5 Pods</td><td align="left">No limit applied</td><td align="left">As per Pro</td></tr><tr><td align="left">Scale to From</td><td align="left">Not supported</td><td align="left">Supported, with additional checks for Istio</td><td align="left">As per Pro</td></tr><tr><td align="left">Autoscaling strategy</td><td align="left">RPS-only</td><td align="left"><a href="https://docs.openfaas.com/architecture/autoscaling">CPU utilization, Capacity (inflight requests) or RPS</a></td><td align="left">As per Pro</td></tr><tr><td align="left">Autoscaling granularity</td><td align="left">Single rule for all functions</td><td align="left">Configurable per function</td><td align="left">As per Pro</td></tr></tbody></table><h3 id="Core-Features"><a href="#Core-Features" class="headerlink" title="Core Features"></a>Core Features</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">UI Dashboard</td><td align="left">Legacy UI (in code-freeze)</td><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/dashboard">New UI dashboard</a> with metrics, logs &amp; CI integration</td><td align="left">As per Pro, but with support for multiple namespaces</td></tr><tr><td align="left">Consume secrets in <code>faas-cli build</code> for npm, Go and Pypy</td><td align="left">Not available</td><td align="left">Via build-time secrets</td><td align="left">As Per Pro</td></tr><tr><td align="left">Kubernetes service accounts for functions</td><td align="left">N&#x2F;a</td><td align="left"><a href="https://docs.openfaas.com/reference/workloads">Supported per function</a></td><td align="left">As per Pro</td></tr><tr><td align="left">Async &#x2F; queueing</td><td align="left">In-memory only, max 10 items in queue, 256KB message size</td><td align="left">JetStream with shared queue</td><td align="left">JetStream with dedicated queues</td></tr><tr><td align="left">Metrics</td><td align="left">Basic function metrics</td><td align="left">Function, HTTP, CPU&#x2F;RAM usage, and async&#x2F;queue metrics</td><td align="left">As per Pro</td></tr><tr><td align="left">CPU &amp; RAM utilization</td><td align="left">Not available</td><td align="left">Integrated with Prometheus metrics, OpenFaaS REST API &amp; CLI</td><td align="left">As per Pro</td></tr><tr><td align="left">Grafana Dashboards</td><td align="left">N&#x2F;a</td><td align="left">4x dashboards supplied in <a href="https://github.com/openfaas/customers">Customer Community</a> - overview, spotlight for debugging a function, queue-worker and Function Builder API</td><td align="left">As per Pro</td></tr><tr><td align="left">GitOps &amp; CRD support</td><td align="left">Not available</td><td align="left">ArgoCD, FluxCD and Helm compatibility using the Function CRD</td><td align="left">As per Pro</td></tr><tr><td align="left">Deployment options</td><td align="left">faas-cli or REST API</td><td align="left">As per CE, plus: Function CRD with kubectl, Helm or GitOps</td><td align="left">As per Pro</td></tr><tr><td align="left">Custom Resource Definition</td><td align="left">Not available</td><td align="left">Function and Profile</td><td align="left"></td></tr></tbody></table><h3 id="Event-Connectors"><a href="#Event-Connectors" class="headerlink" title="Event Connectors"></a>Event Connectors</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Number of topics per function</td><td align="left">One topic per function</td><td align="left">Multiple topics per function</td><td align="left">As per Pro</td></tr><tr><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/kafka-events">Kafka event trigger</a></td><td align="left">Not supported</td><td align="left">Supports SASL or TLS auth, Aiven, Confluent and self-hosted</td><td align="left">Support with SLA</td></tr><tr><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/postgres-events">Postgres trigger</a></td><td align="left">Not supported</td><td align="left">Supports insert, update and delete, with table-level filters using WAL or LISTEN&#x2F;NOTIFY.</td><td align="left">Support with SLA</td></tr><tr><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/sqs-events">AWS SQS trigger</a></td><td align="left">Not supported</td><td align="left">Standard support</td><td align="left">Support with SLA</td></tr><tr><td align="left"><a href="https://docs.openfaas.com/reference/cron">Cron and scheduled invocations</a></td><td align="left">Community support</td><td align="left">Standard support</td><td align="left">Support with SLA</td></tr></tbody></table><h3 id="Durability-and-Reliability"><a href="#Durability-and-Reliability" class="headerlink" title="Durability and Reliability"></a>Durability and Reliability</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Readiness probes</td><td align="left">Not supported</td><td align="left"><a href="https://docs.openfaas.com/reference/workloads">Readiness probes</a> supported with custom HTTP path and intervals per function</td><td align="left">As per Pro</td></tr><tr><td align="left">Retries for failed function invocations</td><td align="left">Not supported</td><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/retries">Retry invocations</a> for configured HTTP codes with an exponential back-off</td><td align="left">As per Pro</td></tr><tr><td align="left">Highly Available messaging</td><td align="left">Not available, in-memory only</td><td align="left">Available for NATS JetStream, with 3x servers.</td><td align="left">As per Pro</td></tr><tr><td align="left">Long executions of async functions</td><td align="left">Limited to 5 minutes</td><td align="left">Configurable duration</td><td align="left">As per Pro</td></tr><tr><td align="left">Callback to custom URL for async functions</td><td align="left">Supported</td><td align="left">As per CE</td><td align="left">As per CE</td></tr></tbody></table><h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Authentication for OpenFaaS API, CLI and UI</td><td align="left">Shared admin password between everyone who uses OpenFaaS</td><td align="left">N&#x2F;a</td><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/sso">Single Sign-On with OIDC</a></td></tr><tr><td align="left">Compatibility with Istio for mTLS</td><td align="left">N&#x2F;a</td><td align="left">Supported</td><td align="left">As per Pro</td></tr><tr><td align="left">PCI&#x2F;GDPR compliance</td><td align="left">Sensitive information such as the request body&#x2F;response body, headers may be printed into the logs for each asynchronous invocation</td><td align="left">Sensitive information is not printed to the logs for asynchronous requests</td><td align="left">As per Pro</td></tr><tr><td align="left">Secure isolation with Kata containers or gVisor</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left">Supported using an <a href="https://docs.openfaas.com/reference/profiles">OpenFaaS Pro Profile and runtimeClass</a></td></tr><tr><td align="left"><a href="https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#accessing-the-service">Service links</a> injected as environment variables</td><td align="left">Yes, cannot be disabled</td><td align="left">Disabled as a default</td><td align="left">As per Pro</td></tr><tr><td align="left"><a href="https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted">Pod privilege escalation</a></td><td align="left">Default for Kubernetes</td><td align="left">Explicitly disabled</td><td align="left">As per Pro</td></tr><tr><td align="left">Split installation without ClusterAdmin role</td><td align="left">N&#x2F;a</td><td align="left">Provided in <a href="https://github.com/openfaas/customers">Customer Community</a></td><td align="left">As per Pro</td></tr></tbody></table><h3 id="Platform-Features"><a href="#Platform-Features" class="headerlink" title="Platform Features"></a>Platform Features</h3><table><thead><tr><th align="left">Description</th><th align="left">OpenFaaS CE</th><th align="left">OpenFaaS Pro</th><th align="left">OpenFaaS for Enterprise</th></tr></thead><tbody><tr><td align="left">Deploy functions via REST API</td><td align="left">Yes</td><td align="left">As per CE</td><td align="left">As per CE</td></tr><tr><td align="left">Build containers and functions via REST API</td><td align="left">N&#x2F;a</td><td align="left">N&#x2F;a</td><td align="left"><a href="https://docs.openfaas.com/openfaas-pro/builder">Yes via Function Builder API</a></td></tr><tr><td align="left">Multiple namespace support</td><td align="left">No support</td><td align="left">N&#x2F;a</td><td align="left">Supported with Kubernetes namespaces</td></tr></tbody></table><h1 id="faasd"><a href="#faasd" class="headerlink" title="faasd"></a>faasd</h1><blockquote><p>based on <strong>0.16.9</strong></p></blockquote><p>faasd 是 OpenFaaS 的重新构想，但没有 Kubernetes 的成本和复杂性。其本质就是一个 Golang 二进制文件，它可以在要求非常低的单个主机上运行，使其快速且易于管理。在底层，它使用 Containerd 和 CNI 以及来自主项目的相同核心 OpenFaaS 组件，因此在使用层面可以完全参考 OpenFaaS CE 的操作。</p><h2 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/openfaas/faasd/releases/download/0.16.9/faasd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x faasd &amp;&amp; <span class="built_in">mv</span> faasd /usr/local/bin</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">basic-auth-user 和 secrets/basic-auth-password 为网关认证的用户名和密码</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">faasd install</span></span><br><span class="line">2023/06/08 17:53:15 Writing to: &quot;/var/lib/faasd/secrets/basic-auth-password&quot;</span><br><span class="line">2023/06/08 17:53:15 Writing to: &quot;/var/lib/faasd/secrets/basic-auth-user&quot;</span><br><span class="line">Check status with:</span><br><span class="line">  sudo journalctl -u faasd --lines 100 -f</span><br><span class="line"></span><br><span class="line">Login with:</span><br><span class="line">  sudo cat /var/lib/faasd/secrets/basic-auth-password | faas-cli login -s</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl status faasd</span></span><br><span class="line">● faasd.service - faasd</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/faasd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Thu 2023-06-08 17:53:17 CST; 4min 26s ago</span><br><span class="line"> Main PID: 43031 (faasd)</span><br><span class="line">    Tasks: 11</span><br><span class="line">   Memory: 30.9M (limit: 500.0M)</span><br><span class="line">   CGroup: /system.slice/faasd.service</span><br><span class="line">           └─43031 /usr/local/bin/faasd up</span><br><span class="line"></span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Looking up IP for: &quot;prometheus&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;localhost&quot;=&quot;127.0.0.1&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;faasd-provider&quot;=&quot;10.62.0.1&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;nats&quot;=&quot;10.62.0.2&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;prometheus&quot;=&quot;10.62.0.3&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;gateway&quot;=&quot;10.62.0.4&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Resolver: &quot;queue-worker&quot;=&quot;10.62.0.5&quot;</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Proxy from: 127.0.0.1:9090, to: prometheus:9090 (10.62.0.3)</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 faasd: waiting for SIGTERM or SIGINT</span><br><span class="line">Jun 08 17:54:34 wnx faasd[43031]: 2023/06/08 17:54:34 Proxy from: 0.0.0.0:8080, to: gateway:8080 (10.62.0.4)</span><br></pre></td></tr></table></figure><p>通过服务状态可以看到，10.62.0.1 ~ 10.62.0.5 用于监听 OpenFaaS 核心服务，位于 Containerd 的 openfaas 命名空间中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ctr -n openfaas c <span class="built_in">ls</span></span></span><br><span class="line">CONTAINER       IMAGE                                      RUNTIME                  </span><br><span class="line">gateway         ghcr.io/openfaas/gateway:0.26.3            io.containerd.runc.v2    </span><br><span class="line">nats            docker.io/library/nats-streaming:0.25.3    io.containerd.runc.v2    </span><br><span class="line">prometheus      docker.io/prom/prometheus:v2.42.0          io.containerd.runc.v2    </span><br><span class="line">queue-worker    ghcr.io/openfaas/queue-worker:0.13.3       io.containerd.runc.v2 </span><br></pre></td></tr></table></figure><h2 id="网关认证-1"><a href="#网关认证-1" class="headerlink" title="网关认证"></a>网关认证</h2><p>外部网关为 <code>http://178.104.162.69:8080/ui</code>，认证信息位于 &#x2F;var&#x2F;lib&#x2F;faasd&#x2F;secrets&#x2F;basic-auth-user 和 &#x2F;var&#x2F;lib&#x2F;faasd&#x2F;secrets&#x2F;basic-auth-password。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /var/lib/faasd/secrets/basic-auth-password | faas-cli login -s</span></span><br><span class="line">Calling the OpenFaaS server to validate the credentials...</span><br><span class="line">credentials saved for admin http://127.0.0.1:8080</span><br></pre></td></tr></table></figure><p>其余模板商店和使用方式等操作和 OpenFaaS CE 完全一致。其中，OpenFaaS 函数容器托管在 Containerd 的 openfaas-fn 命名空间中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ctr -n openfaas-fn c <span class="built_in">ls</span></span></span><br><span class="line">CONTAINER    IMAGE                                         RUNTIME                  </span><br><span class="line">go-fn        harbor.archeros.cn/dev/ake/openfaas-fn:dev    io.containerd.runc.v2</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">OpenFaaS 在不同服务驱动下（OpenFaaS CE、OpenFaaS Pro 和 faasd）的简单使用示例</summary>
    
    
    
    <category term="Serverless" scheme="http://shenxianghong.github.io/categories/Serverless/"/>
    
    
    <category term="OpenFaaS" scheme="http://shenxianghong.github.io/tags/OpenFaaS/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/hypervisor</title>
    <link href="http://shenxianghong.github.io/2023/05/19/2023-05-19%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20hypervisor/"/>
    <id>http://shenxianghong.github.io/2023/05/19/2023-05-19%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20hypervisor/</id>
    <published>2023-05-18T16:00:00.000Z</published>
    <updated>2023-06-20T06:53:58.308Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="Hypervisor"><a href="#Hypervisor" class="headerlink" title="Hypervisor"></a>Hypervisor</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;hypervisor.go</u></em></p><p>Kata Containers 支持的 hypervisor 有 QEMU、Cloud Hypervisor、Firecracker、ACRN 以及 DragonBall，其中 DragonBall 是 Kata Containers 3.0 为新增的 runtime-rs 组件引入的内置 hypervisor，而 runtime-rs 的整体架构区别于当前的 runtime，不在此详读 DragonBall 实现。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// qemu is an Hypervisor interface implementation for the Linux qemu hypervisor.</span></span><br><span class="line"><span class="keyword">type</span> qemu <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 针对不同 CPU 架构下的 QEMU 配置项，后续会进一步构建成 qemuConfig</span></span><br><span class="line">arch qemuArch</span><br><span class="line"></span><br><span class="line">virtiofsDaemon VirtiofsDaemon</span><br><span class="line"></span><br><span class="line">ctx context.Context</span><br><span class="line">id <span class="type">string</span></span><br><span class="line">mu sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// fds is a list of file descriptors inherited by QEMU process</span></span><br><span class="line"><span class="comment">// they&#x27;ll be closed once QEMU process is running</span></span><br><span class="line">fds []*os.File</span><br><span class="line"></span><br><span class="line"><span class="comment">// HotplugVFIOOnRootBus: [hypervisor].hotplug_vfio_on_root_bus</span></span><br><span class="line"><span class="comment">// PCIeRootPort: [hypervisor].pcie_root_port</span></span><br><span class="line">state QemuState</span><br><span class="line"></span><br><span class="line">qmpMonitorCh qmpChannel</span><br><span class="line"></span><br><span class="line"><span class="comment">// QEMU 进程的配置参数</span></span><br><span class="line">qemuConfig govmmQemu.Config</span><br><span class="line"></span><br><span class="line"><span class="comment">// QEMU 实现下的 hypervisor 配置</span></span><br><span class="line">config HypervisorConfig</span><br><span class="line"></span><br><span class="line"><span class="comment">// if in memory dump progress</span></span><br><span class="line">memoryDumpFlag sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// NVDIMM 设备数量</span></span><br><span class="line">nvdimmCount <span class="type">int</span></span><br><span class="line"></span><br><span class="line">stopped <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 前置说明</span></span><br><span class="line"><span class="comment"> protection</span></span><br><span class="line"><span class="comment"> - amd64：默认为 noneProtection</span></span><br><span class="line"><span class="comment">   如果启用 [hypervisor].confidential_guest，则进一步判断 protection</span></span><br><span class="line"><span class="comment">   - 如果 host 上 /sys/firmware/tdx_seam/ 文件夹存在或者 CPU flags 中包含 tdx，则为 tdxProtection（Intel Trust Domain Extensions）</span></span><br><span class="line"><span class="comment">   - 如果 host 上 /sys/module/kvm_amd/parameters/sev 文件存在且内容为 1 或者 Y 则为 sevProtection（AMD Secure Encrypted Virtualization）</span></span><br><span class="line"><span class="comment">  - arm64：noneProtection </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Config is the qemu configuration structure.</span></span><br><span class="line"><span class="comment">// It allows for passing custom settings and parameters to the qemu API.</span></span><br><span class="line"><span class="comment">// nolint: govet</span></span><br><span class="line"><span class="keyword">type</span> Config <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Path is the qemu binary path.</span></span><br><span class="line"><span class="comment">// - amd64: /usr/bin/qemu-system-x86_64</span></span><br><span class="line"><span class="comment">// - arm64: /usr/bin/qemu-system-aarch64</span></span><br><span class="line">Path <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Ctx is the context used when launching qemu.</span></span><br><span class="line">Ctx context.Context</span><br><span class="line"><span class="comment">// User ID.</span></span><br><span class="line">Uid <span class="type">uint32</span></span><br><span class="line"><span class="comment">// Group ID.</span></span><br><span class="line">Gid <span class="type">uint32</span></span><br><span class="line"><span class="comment">// Supplementary group IDs.</span></span><br><span class="line">Groups []<span class="type">uint32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Name is the qemu guest name</span></span><br><span class="line"><span class="comment">// -name 参数，例如 sandbox-4230a13dac935c3fef99f8b15d27d493ff1de957224043354374efd50bdfeeb7</span></span><br><span class="line"><span class="comment">// sandbox-&lt;qemuID&gt;</span></span><br><span class="line">Name <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// UUID is the qemu process UUID.</span></span><br><span class="line"><span class="comment">// -uuid 参数，例如 -uuid 42f0c7b9-7aa9-4581-a26c-2d84b40f1190</span></span><br><span class="line"><span class="comment">// 随机生成</span></span><br><span class="line">UUID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CPUModel is the CPU model to be used by qemu.</span></span><br><span class="line"><span class="comment">// -cpu 参数，例如 -cpu host,pmu=off</span></span><br><span class="line"><span class="comment">// 默认为 host，如果指定 [hypervisor].cpu_features 则继续追加</span></span><br><span class="line">CPUModel <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// SeccompSandbox is the qemu function which enables the seccomp feature</span></span><br><span class="line"><span class="comment">// [hypervisor].seccompsandbox</span></span><br><span class="line">SeccompSandbox <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Machine</span></span><br><span class="line"><span class="comment">// -machine 参数，例如 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on</span></span><br><span class="line"><span class="comment">// Type: [hypervisor].machine_type</span></span><br><span class="line"><span class="comment">// - amd64: 默认为 q35</span></span><br><span class="line"><span class="comment">// - arm64: virt</span></span><br><span class="line"><span class="comment">// Options: </span></span><br><span class="line"><span class="comment">// - amd64: 默认为 accel=kvm,kernel_irqchip=on</span></span><br><span class="line"><span class="comment">//   如果启用 [hypervisor].confidential_guest 或者启用 hypervisor[enable_iommu]，则覆盖 Options 为 accel=kvm,kernel_irqchip=split</span></span><br><span class="line"><span class="comment">//   如果 sgxEPCSize 不为 0，则追加 sgx-epc.0.memdev=epc0,sgx-epc.0.node=0</span></span><br><span class="line"><span class="comment">//   如果启用 [hypervisor].confidential_guest: </span></span><br><span class="line"><span class="comment">//   - 如果 protection 为 tdxProtection，则追加 kvm-type=tdx,confidential-guest-support=tdx</span></span><br><span class="line"><span class="comment">//   - 如果 protection 为 sevProtection，则追加 confidential-guest-support=sev</span></span><br><span class="line"><span class="comment">//   如果镜像类型为 [hypervisor].image 且 disableNvdimm 为 false，则追加 nvdimm=on</span></span><br><span class="line"><span class="comment">// - arm64: usb=off,accel=kvm,gic-version=host</span></span><br><span class="line"><span class="comment">// 如果指定 [hypervisor].machine_accelerators，则继续追加</span></span><br><span class="line">Machine Machine</span><br><span class="line"></span><br><span class="line"><span class="comment">// QMPSockets is a slice of QMP socket description.</span></span><br><span class="line"><span class="comment">// -qmp 参数，例如 -qmp unix:/run/vc/vm/&lt;qemuid&gt;/qmp.sock,server=on,wait=off</span></span><br><span class="line"><span class="comment">// Type: unix</span></span><br><span class="line"><span class="comment">// Name: </span></span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/qmp.sock</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/qmp.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line"><span class="comment">// Server: true</span></span><br><span class="line"><span class="comment">// NoWait: true</span></span><br><span class="line">QMPSockets []QMPSocket</span><br><span class="line"></span><br><span class="line"><span class="comment">// Devices is a list of devices for qemu to create and drive.</span></span><br><span class="line"><span class="comment">// -device 参数</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== Bridge ===========</span></span><br><span class="line"><span class="comment">// 例如 -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m</span></span><br><span class="line"><span class="comment">// BridgeDevice（数量等于 [hypervisor].default_bridges）</span></span><br><span class="line"><span class="comment">//   Type: 默认为 0，即 PCI，如果 bridge 类型为 PCIe，则为 PCIe</span></span><br><span class="line"><span class="comment">//   Bus: 默认为 pci.0，如果 Machine.Type 为 q35 或者 virt，则为 pcie.0</span></span><br><span class="line"><span class="comment">//   ID: &lt;bt&gt;-bridge-&lt;idx&gt;，其中 idx 为 0 ~ [hypervisor].default_bridges 的递增索引</span></span><br><span class="line"><span class="comment">//   - 如果 Machine.Type 为 q35、virt 和 pseries，则 bt 为 pci，容量为 30</span></span><br><span class="line"><span class="comment">//   - 如果 Machine.Type 为 s390-ccw-virtio，则 bt 为 ccw，容量为 65535</span></span><br><span class="line"><span class="comment">//   Chassis: idx + 1，其中 idx 为 bridge 列表的索引</span></span><br><span class="line"><span class="comment">//  SHPC: false</span></span><br><span class="line"><span class="comment">//   Addr: idx + 2，其中 idx 为 bridge 列表的索引</span></span><br><span class="line"><span class="comment">//   IOReserve: 4k</span></span><br><span class="line"><span class="comment">//   MemReserve: 1m</span></span><br><span class="line"><span class="comment">//   Pref64Reserve: 1m</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== Console ===========</span></span><br><span class="line"><span class="comment">// - 禁用 [hypervisor].use_legacy_serial</span></span><br><span class="line"><span class="comment">//   例如 -device virtio-serial-pci,disable-modern=true,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/&lt;qemuID&gt;/console.sock,server=on,wait=off</span></span><br><span class="line"><span class="comment">//   CharDevice</span></span><br><span class="line"><span class="comment">//     Driver: virtconsole</span></span><br><span class="line"><span class="comment">//     Backend: socket</span></span><br><span class="line"><span class="comment">//     DeviceID: console0</span></span><br><span class="line"><span class="comment">//     ID: charconsole0</span></span><br><span class="line"><span class="comment">//     Path: </span></span><br><span class="line"><span class="comment">//     - root 权限: /run/vc/vm/&lt;qemuID&gt;/console.sock</span></span><br><span class="line"><span class="comment">//     - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/console.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line"><span class="comment">//   SerialDevice</span></span><br><span class="line"><span class="comment">//     Driver: virtio-serial</span></span><br><span class="line"><span class="comment">//     ID: serial0</span></span><br><span class="line"><span class="comment">//     DisableModern: </span></span><br><span class="line"><span class="comment">//     - amd64: 当未禁用 [hypervisor].disable_nesting_checks，且 CPU flags 中有 hypervisor，视为 true；否则，为 false</span></span><br><span class="line"><span class="comment">//     - arm64: false</span></span><br><span class="line"><span class="comment">//     MaxPorts: 2</span></span><br><span class="line"><span class="comment">// - 启用 [hypervisor].use_legacy_serial</span></span><br><span class="line"><span class="comment">//   例如 -serial chardev:charconsole0 -chardev socket,id=charconsole0,path=/run/vc/vm/&lt;qemuID&gt;/console.sock,server=on,wait=off</span></span><br><span class="line"><span class="comment">//   CharDevice</span></span><br><span class="line"><span class="comment">//     Driver: serial</span></span><br><span class="line"><span class="comment">//     Backend: socket</span></span><br><span class="line"><span class="comment">//     DeviceID: console0</span></span><br><span class="line"><span class="comment">//     ID: charconsole0</span></span><br><span class="line"><span class="comment">//     Path: </span></span><br><span class="line"><span class="comment">//     - root 权限: /run/vc/vm/&lt;qemuID&gt;/console.sock</span></span><br><span class="line"><span class="comment">//     - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/console.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line"><span class="comment">//   LegacySerialDevice</span></span><br><span class="line"><span class="comment">//     Chardev: charconsole0</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== Image（当镜像类型为 [hypervisor].image） ===========</span></span><br><span class="line"><span class="comment">// - 禁用 [hypervisor].disable_image_nvdimm</span></span><br><span class="line"><span class="comment">//   例如 -drive id=image-199896efe4d8ad3b,file=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,aio=threads,format=raw,if=none,readonly=on</span></span><br><span class="line"><span class="comment">//   BlockDrive</span></span><br><span class="line"><span class="comment">//     File: [hypervisor].image</span></span><br><span class="line"><span class="comment">//   Format: raw</span></span><br><span class="line"><span class="comment">//   ID: image-&lt;随机字符串&gt;</span></span><br><span class="line"><span class="comment">//   ShareRW: true</span></span><br><span class="line"><span class="comment">//   ReadOnly: true</span></span><br><span class="line"><span class="comment">// - 启用 [hypervisor].disable_image_nvdimm</span></span><br><span class="line"><span class="comment">//   例如 -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,size=134217728,readonly=on</span></span><br><span class="line"><span class="comment">//   Object</span></span><br><span class="line"><span class="comment">//     Driver: nvdimm</span></span><br><span class="line"><span class="comment">//     Type: memory-backend-file</span></span><br><span class="line"><span class="comment">//     DeviceID: nv0</span></span><br><span class="line"><span class="comment">//     ID: mem0</span></span><br><span class="line"><span class="comment">//     MemPath: [hypervisor].image</span></span><br><span class="line"><span class="comment">//     Size: [hypervisor].image 大小</span></span><br><span class="line"><span class="comment">//     ReadOnly: true</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== IOMMU（当启用 [hypervisor].enable_iommu） ===========</span></span><br><span class="line"><span class="comment">// IommuDev</span></span><br><span class="line"><span class="comment">//   Intremap: true</span></span><br><span class="line"><span class="comment">//   DeviceIotlb: true</span></span><br><span class="line"><span class="comment">//   CachingMode: true</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== PVPanic（当指定 [hypervisor].guest_memory_dump_path） ===========</span></span><br><span class="line"><span class="comment">// PVPanicDevice</span></span><br><span class="line"><span class="comment">//   NoShutdown: true</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// =========== BlockDeviceDriver（当 [hypervisor].block_device_driver 为 virtio-scsi） ===========</span></span><br><span class="line"><span class="comment">// 例如 -device virtio-scsi-pci,id=scsi0,disable-modern=true</span></span><br><span class="line"><span class="comment">// SCSIController</span></span><br><span class="line"><span class="comment">//   ID: scsi0</span></span><br><span class="line"><span class="comment">//   DisableModern: </span></span><br><span class="line"><span class="comment">//   - amd64: 当未禁用 [hypervisor].disable_nesting_checks，且 CPU flags 中有 hypervisor，视为 true；否则，为 false</span></span><br><span class="line"><span class="comment">//   - arm64: false</span></span><br><span class="line"><span class="comment">//   IOThread:（当启用 [hypervisor].enable_iothreads）</span></span><br><span class="line"><span class="comment">//     ID: iothread-&lt;随机字符串&gt;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// =========== Protection ===========</span></span><br><span class="line"><span class="comment">// Object（当 sgxEPCSize 不为 0 时）</span></span><br><span class="line"><span class="comment">//   Type: memory-backend-epc</span></span><br><span class="line"><span class="comment">//   ID: epc0</span></span><br><span class="line"><span class="comment">//   Prealloc: true</span></span><br><span class="line"><span class="comment">//   Size: sgxEPCSize</span></span><br><span class="line"><span class="comment">// Object（当 protection 为 tdxProtection 时）</span></span><br><span class="line"><span class="comment">//   Driver: loader</span></span><br><span class="line"><span class="comment">//   Type: tdx-guest</span></span><br><span class="line"><span class="comment">//   ID: tdx</span></span><br><span class="line"><span class="comment">//   DeviceID: fd&lt;idx&gt;，其中 idx 为 loader 类型 Driver 的统计数量</span></span><br><span class="line"><span class="comment">//   Debug: false</span></span><br><span class="line"><span class="comment">//   File: [hypervisor].firmware</span></span><br><span class="line"><span class="comment">//   FirmwareVolume: [hypervisor].firmware_volume</span></span><br><span class="line"><span class="comment">// Object（当 protection 为 sevProtection 时）</span></span><br><span class="line"><span class="comment">//   Type: sev-guest</span></span><br><span class="line"><span class="comment">// ID: sev</span></span><br><span class="line"><span class="comment">//   Debug: false</span></span><br><span class="line"><span class="comment">//   File: [hypervisor].firmware</span></span><br><span class="line"><span class="comment">//   CBitPos: ebx &amp; 0x3F</span></span><br><span class="line"><span class="comment">//   ReducedPhysBits: (ebx &gt;&gt; 6) &amp; 0x3F</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// =========== rngDev（当 Machine.Type 不为 s390-ccw-virtio）===========</span></span><br><span class="line"><span class="comment">// RNGDev</span></span><br><span class="line"><span class="comment">// 例如 -object rng-random,id=rng0,filename=/dev/urandom</span></span><br><span class="line"><span class="comment">//   ID: rng0</span></span><br><span class="line"><span class="comment">//   FileName: [hypervisor].entropy_source</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// =========== PCIe（当 [hypervisor].pcie_root_port 大于 0 且 Machine.Type 为 q35 或 virt）===========</span></span><br><span class="line"><span class="comment">// PCIeRootPortDevice（数量等于 [hypervisor].pcie_root_port）</span></span><br><span class="line"><span class="comment">// 例如 -device pcie-root-port,id=rp1,bus=pcie.0,chassis=0,slot=1,multifunction=off,pref64-reserve=2097152B,mem-reserve=4194304B</span></span><br><span class="line"><span class="comment">//   ID: rp&lt;idx&gt;，其中 idx 为 0 ~ [hypervisor].pcie_root_port 的递增索引</span></span><br><span class="line"><span class="comment">//   Bus: pcie.0</span></span><br><span class="line"><span class="comment">//   Chassis: 0</span></span><br><span class="line"><span class="comment">//   Slot: idx</span></span><br><span class="line"><span class="comment">//   Multifunction: false</span></span><br><span class="line"><span class="comment">//   Addr: 0</span></span><br><span class="line"><span class="comment">//   MemReserve: 默认 4MB，如果累加每个 BAR 的 32 位内存窗口值更大，则以此值为准，并乘以 2</span></span><br><span class="line"><span class="comment">//   Pref64Reserve: 默认 2MB，如果累加每个 BAR 的 64 位内存窗口值更大，则以此值为准</span></span><br><span class="line">Devices []Device</span><br><span class="line"></span><br><span class="line"><span class="comment">// RTC is the qemu Real Time Clock configuration</span></span><br><span class="line"><span class="comment">// -rtc 参数，例如 -rtc base=utc,driftfix=slew,clock=host</span></span><br><span class="line"><span class="comment">// Base: utc</span></span><br><span class="line"><span class="comment">// Clock: host</span></span><br><span class="line"><span class="comment">// DriftFix: slew</span></span><br><span class="line">RTC RTC</span><br><span class="line"></span><br><span class="line"><span class="comment">// VGA is the qemu VGA mode.</span></span><br><span class="line"><span class="comment">// -vga 参数，例如 -vga none</span></span><br><span class="line"><span class="comment">// none</span></span><br><span class="line">VGA <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Kernel is the guest kernel configuration.</span></span><br><span class="line"><span class="comment">// -kernel 参数，例如 -kernel /opt/kata/share/kata-containers/vmlinux-5.19.2-96</span></span><br><span class="line"><span class="comment">// -initrd 参数，例如 -initrd /opt/kata/share/kata-containers/kata-alpine-3.15.initrd</span></span><br><span class="line"> <span class="comment">// -append 参数，例如 -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k cryptomgr.notests net.ifnames=0 pci=lastbus=0 console=hvc0 console=hvc1 debug panic=1 nr_cpus=8 scsi_mod.scan=none agent.log=debug agent.debug_console agent.debug_console_vport=1026</span></span><br><span class="line"><span class="comment">// Path: [hypervisor].kernel</span></span><br><span class="line"><span class="comment">// InitrdPath: [hypervisor].initrd，当镜像类型为 [hypervisor].image 时，没有 -initrd 参数</span></span><br><span class="line"><span class="comment">// Params: </span></span><br><span class="line"><span class="comment">// - kernelParams: </span></span><br><span class="line"><span class="comment">//   - amd64: 默认为 tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k cryptomgr.notests net.ifnames=0 pci=lastbus=0 panic=1 nr_cpus=[hypervisor].default_maxvcpus</span></span><br><span class="line"><span class="comment">//     如果启用 [hypervisor].enable_iommu，则追加 intel_iommu=on iommu=pt</span></span><br><span class="line"><span class="comment">//     如果镜像类型为 [hypervisor].image: </span></span><br><span class="line"><span class="comment">//     - 如果 disableNvdimm 为 true，则追加 root=/dev/vda1 rootflags=data=ordered errors=remount-ro ro rootfstype=ext4</span></span><br><span class="line"><span class="comment">//     - 如果 disableNvdimm 为 false: </span></span><br><span class="line"><span class="comment">//       - 如果 dax 为 false，则追加 root=/dev/pmem0p1 rootflags=data=ordered errors=remount-ro ro rootfstype=ext4</span></span><br><span class="line"><span class="comment">//       - 如果 dax 为 true，则追加 root=/dev/pmem0p1 rootflags=dax data=ordered errors=remount-ro ro rootfstype=ext4</span></span><br><span class="line"><span class="comment">//     如果启用 [hypervisor].use_legacy_serial，则追加 console=ttyS0，否则，则追加 console=hvc0 console=hvc1</span></span><br><span class="line"><span class="comment">//   - arm64: iommu.passthrough=0 panic=1 nr_cpus=[hypervisor].default_maxvcpus</span></span><br><span class="line"><span class="comment">// - kernelParamsDebug: 默认为 debug，如果镜像类型为 [hypervisor].image，则追加 systemd.show_status=true systemd.log_level=debug</span></span><br><span class="line"><span class="comment">// - kernelParamsNonDebug: 默认为 quiet，如果镜像类型为 [hypervisor].image，则追加 systemd.show_status=false</span></span><br><span class="line"><span class="comment">// 由以上三个参数组成，具体为 kernelParams + kernelParamsDebug/kernelParamsNonDebug（取决于 [hypervisor].enable_debug），如果指定 [hypervisor].kernel_params，则继续追加</span></span><br><span class="line">Kernel Kernel</span><br><span class="line"></span><br><span class="line"><span class="comment">// Memory is the guest memory configuration.</span></span><br><span class="line"><span class="comment">// -m 参数，例如 -m 2048M,slots=10,maxmem=12799M</span></span><br><span class="line"><span class="comment">// Size: [hypervisor].default_memory</span></span><br><span class="line"><span class="comment">// Slots: [hypervisor].memory_slots</span></span><br><span class="line"><span class="comment">// MaxMem: </span></span><br><span class="line"><span class="comment">// - amd64: [hypervisor].memory_offset + [hypervisor].default_maxmemory</span></span><br><span class="line"><span class="comment">// - arm64: [hypervisor].default_maxmemory</span></span><br><span class="line"><span class="comment">// Path: </span></span><br><span class="line"><span class="comment">// - 如果为 VM factory 场景，则为 [factory].template_path/memory</span></span><br><span class="line"><span class="comment">// - 如果 [hypervisor].shared_fs 为 virtio-fs 或者 virtio-fs-nydus, 再或者 annotations[&quot;io.katacontainers.config.hypervisor.file_mem_backend&quot;] 不为空，则为 /dev/shm（如果 annotations 传递，则以 annotations 为准）</span></span><br><span class="line">Memory Memory</span><br><span class="line"></span><br><span class="line"><span class="comment">// SMP is the quest multi processors configuration.</span></span><br><span class="line"><span class="comment">// -smp 参数，例如 -smp 1,cores=1,threads=1,sockets=8,maxcpus=8</span></span><br><span class="line"><span class="comment">// CPUs: [hypervisor].default_vcpus</span></span><br><span class="line"><span class="comment">// Cores: 1</span></span><br><span class="line"><span class="comment">// Threads: 1</span></span><br><span class="line"><span class="comment">// Sockets: [hypervisor].default_maxvcpus</span></span><br><span class="line"><span class="comment">// MaxCPUs: [hypervisor].default_maxvcpus</span></span><br><span class="line">SMP SMP</span><br><span class="line"></span><br><span class="line"><span class="comment">// GlobalParam is the -global parameter.</span></span><br><span class="line"><span class="comment">// -global 参数，例如 -global kvm-pit.lost_tick_policy=discard</span></span><br><span class="line"><span class="comment">// kvm-pit.lost_tick_policy=discard</span></span><br><span class="line">GlobalParam <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Knobs is a set of qemu boolean settings.</span></span><br><span class="line"><span class="comment">// -no-user-config -nodefaults -nographic --no-reboot -daemonize 参数</span></span><br><span class="line"><span class="comment">// NoUserConfig、NoDefaults、NoGraphic、NoReboot、Daemonize: true</span></span><br><span class="line"><span class="comment">// MemPrealloc: 默认为 [hypervisor].enable_mem_prealloc，如果 [hypervisor].shared_fs 为 virtio-fs 或者 virtio-fs-nydus, 再或者 annotations[&quot;io.katacontainers.config.hypervisor.file_mem_backend&quot;] 不为空，并且启用 [hypervisor].enable_hugepages，则为 true</span></span><br><span class="line"><span class="comment">// HugePages: [hypervisor].enable_hugepages</span></span><br><span class="line"><span class="comment">// IOMMUPlatform: [hypervisor].enable_iommu_platform</span></span><br><span class="line"><span class="comment">// FileBackedMem: </span></span><br><span class="line"><span class="comment">// - 如果为 VM factory 场景，则为 true</span></span><br><span class="line"><span class="comment">// - 如果 [hypervisor].shared_fs 为 virtio-fs 或者 virtio-fs-nydus, 再或者 annotations[&quot;io.katacontainers.config.hypervisor.file_mem_backend&quot;] 不为空，则为 true</span></span><br><span class="line"><span class="comment">// MemShared: </span></span><br><span class="line"><span class="comment">// - 如果为 VM factory 中的启动为模板场景，则为 true</span></span><br><span class="line"><span class="comment">// - 如果 [hypervisor].shared_fs 为 virtio-fs 或者 virtio-fs-nydus, 再或者 annotations[&quot;io.katacontainers.config.hypervisor.file_mem_backend&quot;] 不为空，则为 true</span></span><br><span class="line"><span class="comment">// - 如果启用 [hypervisor].enable_vhost_user_store，则为 true</span></span><br><span class="line">Knobs Knobs</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bios is the -bios parameter</span></span><br><span class="line"><span class="comment">// -bios 参数</span></span><br><span class="line"><span class="comment">// [hypervisor].firmware</span></span><br><span class="line">Bios <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// PFlash specifies the parallel flash images (-pflash parameter)</span></span><br><span class="line"><span class="comment">// -pflash 参数</span></span><br><span class="line"><span class="comment">// [hypervisor].pflashes</span></span><br><span class="line">PFlash []<span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Incoming controls migration source preparation</span></span><br><span class="line"><span class="comment">// MigrationType: 如果为 VM factory 中的从模板启动场景，则为 3</span></span><br><span class="line">Incoming Incoming</span><br><span class="line"></span><br><span class="line"><span class="comment">// fds is a list of open file descriptors to be passed to the spawned qemu process</span></span><br><span class="line">fds []*os.File</span><br><span class="line"></span><br><span class="line"><span class="comment">// FwCfg is the -fw_cfg parameter</span></span><br><span class="line">FwCfg []FwCfg</span><br><span class="line"></span><br><span class="line"><span class="comment">// Devices 中 SCSIController.IOThread</span></span><br><span class="line">IOThreads []IOThread</span><br><span class="line"></span><br><span class="line"><span class="comment">// PidFile is the -pidfile parameter</span></span><br><span class="line"><span class="comment">// -pidfile 参数，例如 -pidfile /run/vc/vm/&lt;qemuID&gt;/pid</span></span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/pid</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/pid（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">PidFile <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// LogFile is the -D parameter</span></span><br><span class="line"><span class="comment">// -D 参数，例如 -D /run/vc/vm/&lt;qemuID&gt;/qemu.log</span></span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/qemu.log</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/qemu.log（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">LogFile <span class="type">string</span></span><br><span class="line"></span><br><span class="line">qemuParams []<span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> cloudHypervisor <span class="keyword">struct</span> &#123;</span><br><span class="line">console         console.Console</span><br><span class="line">virtiofsDaemon  VirtiofsDaemon</span><br><span class="line">APIClient       clhClient</span><br><span class="line">ctx             context.Context</span><br><span class="line">id              <span class="type">string</span></span><br><span class="line">netDevices      *[]chclient.NetConfig</span><br><span class="line">devicesIds      <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span></span><br><span class="line">netDevicesFiles <span class="keyword">map</span>[<span class="type">string</span>][]*os.File</span><br><span class="line">vmconfig        chclient.VmConfig</span><br><span class="line">state           CloudHypervisorState</span><br><span class="line">config          HypervisorConfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// firecracker is an Hypervisor interface implementation for the firecracker VMM.</span></span><br><span class="line"><span class="keyword">type</span> firecracker <span class="keyword">struct</span> &#123;</span><br><span class="line">console console.Console</span><br><span class="line">ctx     context.Context</span><br><span class="line"></span><br><span class="line">pendingDevices []firecrackerDevice <span class="comment">// Devices to be added before the FC VM ready</span></span><br><span class="line"></span><br><span class="line">firecrackerd *exec.Cmd              <span class="comment">//Tracks the firecracker process itself</span></span><br><span class="line">fcConfig     *types.FcConfig        <span class="comment">// Parameters configured before VM starts</span></span><br><span class="line">connection   *client.FirecrackerAPI <span class="comment">//Tracks the current active connection</span></span><br><span class="line"></span><br><span class="line">id               <span class="type">string</span> <span class="comment">//Unique ID per pod. Normally maps to the sandbox id</span></span><br><span class="line">vmPath           <span class="type">string</span> <span class="comment">//All jailed VM assets need to be under this</span></span><br><span class="line">chrootBaseDir    <span class="type">string</span> <span class="comment">//chroot base for the jailer</span></span><br><span class="line">jailerRoot       <span class="type">string</span></span><br><span class="line">socketPath       <span class="type">string</span></span><br><span class="line">hybridSocketPath <span class="type">string</span></span><br><span class="line">netNSPath        <span class="type">string</span></span><br><span class="line">uid              <span class="type">string</span> <span class="comment">//UID and GID to be used for the VMM</span></span><br><span class="line">gid              <span class="type">string</span></span><br><span class="line">fcConfigPath     <span class="type">string</span></span><br><span class="line"></span><br><span class="line">info   FirecrackerInfo</span><br><span class="line">config HypervisorConfig</span><br><span class="line">state  firecrackerState</span><br><span class="line"></span><br><span class="line">jailed <span class="type">bool</span> <span class="comment">//Set to true if jailer is enabled</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Acrn is an Hypervisor interface implementation for the Linux acrn hypervisor.</span></span><br><span class="line"><span class="keyword">type</span> Acrn <span class="keyword">struct</span> &#123;</span><br><span class="line">sandbox    *Sandbox</span><br><span class="line">ctx        context.Context</span><br><span class="line">arch       acrnArch</span><br><span class="line">store      persistapi.PersistDriver</span><br><span class="line">id         <span class="type">string</span></span><br><span class="line">state      AcrnState</span><br><span class="line">acrnConfig Config</span><br><span class="line">config     HypervisorConfig</span><br><span class="line">info       AcrnInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CreateVM"><a href="#CreateVM" class="headerlink" title="CreateVM"></a>CreateVM</h2><p><strong>准备创建 VM 所需的配置信息</strong></p><h3 id="QEMU"><a href="#QEMU" class="headerlink" title="QEMU"></a>QEMU</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/qemu.go#L490">source code</a></p><ol><li>根据 QEMU 实现的 hypervisor 配置项初始化对应架构下的 qemu，其中包含了 qemu-system（govmmQemu.Config）和 virtiofsd&#x2F;nydusd（VirtiofsDaemon）进程的配置参数</li></ol><h1 id="VirtiofsDaemon"><a href="#VirtiofsDaemon" class="headerlink" title="VirtiofsDaemon"></a>VirtiofsDaemon</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;virtiofsd.go</u></em></p><p>VirtiofsDaemon 是用于 host 与 guest 的文件共享的进程服务，实现包括传统的 virtiofsd 以及针对蚂蚁社区提出的 nydusd。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> virtiofsd <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Neded by tracing</span></span><br><span class="line">ctx context.Context</span><br><span class="line"><span class="comment">// PID process ID of virtiosd process</span></span><br><span class="line">PID <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// path to virtiofsd daemon</span></span><br><span class="line"><span class="comment">// [hypervisor].shared_fs</span></span><br><span class="line">path <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// socketPath where daemon will serve</span></span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/vhost-fs.sock</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/vhost-fs.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">socketPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// cache size for virtiofsd</span></span><br><span class="line"><span class="comment">// [hypervisor].virtio_fs_cache</span></span><br><span class="line">cache <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// sourcePath path that daemon will help to share</span></span><br><span class="line"><span class="comment">// - root 权限: /run/kata-containers/shared/sandboxes/&lt;containerID&gt;/shared</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/kata-containers/shared/sandboxes/&lt;containerID&gt;/shared（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">sourcePath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// extraArgs list of extra args to append to virtiofsd command</span></span><br><span class="line"><span class="comment">// [hypervisor].virtio_fs_extra_args</span></span><br><span class="line">extraArgs []<span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> nydusd <span class="keyword">struct</span> &#123;</span><br><span class="line">startFn         <span class="function"><span class="keyword">func</span><span class="params">(cmd *exec.Cmd)</span></span> <span class="type">error</span> <span class="comment">// for mock testing</span></span><br><span class="line">waitFn          <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">error</span>              <span class="comment">// for mock</span></span><br><span class="line">setupShareDirFn <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">error</span>              <span class="comment">// for mock testing</span></span><br><span class="line">  pid             <span class="type">int</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">// [hypervisor].shared_fs</span></span><br><span class="line">path <span class="type">string</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/vhost-fs.sock</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/vhost-fs.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">sockPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// - root 权限: /run/vc/vm/&lt;qemuID&gt;/nydusd-api.sock</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/vc/vm/&lt;qemuID&gt;/nydusd-api.sock（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">apiSockPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// - root 权限: /run/kata-containers/shared/sandboxes/&lt;containerID&gt;/shared</span></span><br><span class="line"><span class="comment">// - rootless 权限: &lt;XDG_RUNTIME_DIR&gt;/run/kata-containers/shared/sandboxes/&lt;containerID&gt;/shared（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;）</span></span><br><span class="line">sourcePath <span class="type">string</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">// [hypervisor].virtio_fs_extra_args</span></span><br><span class="line">extraArgs []<span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// [hypervisor].debug</span></span><br><span class="line">debug <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">virtcontainers 中与 Hypervisor 等虚拟化相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」资源限制</title>
    <link href="http://shenxianghong.github.io/2023/05/15/2023-05-15%20Kata%20Containers%20%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
    <id>http://shenxianghong.github.io/2023/05/15/2023-05-15%20Kata%20Containers%20%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/</id>
    <published>2023-05-14T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.274Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="cgroup-管理"><a href="#cgroup-管理" class="headerlink" title="cgroup 管理"></a>cgroup 管理</h1><p>Kata Containers 目前支持 cgroups v1 和 v2。</p><p>Kata Containers 中，工作负载是在 VM 中运行，VM 由运行在 host 上的 VMM（virtual machine monitor）管理。因此，Kata Containers 运行在两层 cgroup 之上：一层为工作负载所在的 guest，另一层为运行 VMM 和相关线程的 host。</p><p>容器 cgroup 路径的配置是在 <a href="https://github.com/opencontainers/runtime-spec/blob/main/config-linux.md">OCI runtime spec</a> 中声明的 cgroupsPath 字段，可用于控制容器的 cgroup 层次结构以及在容器中运行的进程。在 Kubernetes 场景中，Pod 的 cgroup 是由 Kubelet 管理，而容器的 cgroup 是由运行时管理。 Kubelet 将根据容器资源需求调整 Pod 的 cgroup 大小，其中包含 Pod spec.Overhead 中声明的资源。</p><p>Kata Containers 的设计为 sandbox 引入了不可忽略的资源开销。通常，与基于进程级别的容器运行时相比，Kata shim（即 containerd-shim-kata-v2）会调用底层 VMM 创建额外的线程，例如半虚拟化 I&#x2F;O 后端、VMM 实例以及 Kata shim 进程。这些 host 进程消耗的内存和 CPU 资源是不与容器中的工作负载直接相关，而是属于引入 sandbox 带来的额外开销。为了使 Kata 工作负载在不显着降低性能的情况下运行，必须相应地配置其 sandbox 的开销。因此，可能有两种情况：</p><ul><li>上层编排器在调整 Pod cgroup 大小时考虑运行 sandbox 的额外开销。例如，Kubernetes 的 Pod Overhead 特性允许编排器将 sandbox 的额外开销计入其所有容器资源的总和中。在这种情况下，Kata 创建的所有进程都将在 Pod 的 cgroup 约束和限制下运行</li><li>上层编排器不考虑 sandbox 的额外开销，因此 Pod 的 cgroup 大小可能无法满足运行 Kata 创建的所有进程。在这种情况下，将所有 Kata 相关进程附加到 Pod 的 cgroup 中可能会导致不可忽略的工作负载性能下降。因此，Kata Containers 会将除 vCPU 线程之外的所有进程移动到名为 &#x2F;kata_overhead 下的子 cgroup 中。 Kata 运行时不会对该 cgroup 作出任何约束或限制，而由集群管理员选择性设置</li></ul><p>Kata Containers 并不会动态检测这两种情况，而是通过配置文件中的 [runtime].sandbox_cgroup_only 选项决定的。</p><p><strong>cgroup 种类</strong></p><ul><li><p>Pod cgroup</p><p>位于 &#x2F;kubepods 层级下的子 cgroup，命名为 &#x2F;kubepods&#x2F;&lt;PodUID&gt;，由 Kubelet 管理</p><ul><li><p>sandbox cgroup</p><p>位于 &#x2F;kubepods&#x2F;&lt;PodUID&gt; 层级下的子 cgroup，命名为 &#x2F;kata_&lt;sandboxID&gt;，由运行时管理</p></li></ul></li><li><p>overhead cgroup</p><p>位于 &#x2F;kata_overhead 层级下的子 cgroup，命名为 &#x2F;kata_overhead&#x2F;&lt;sandboxID&gt;，由运行时管理</p></li></ul><p><strong>测试负载</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kata</span><br><span class="line">spec:</span><br><span class="line">  runtimeClassName: kata</span><br><span class="line">  containers:</span><br><span class="line">  - name: kata</span><br><span class="line">    image: ubuntu:18.04</span><br><span class="line">    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;tail -f /dev/null&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        memory: &quot;1Gi&quot;</span><br><span class="line">        cpu: &quot;1&quot;</span><br><span class="line">      limits:</span><br><span class="line">        memory: &quot;1Gi&quot;</span><br><span class="line">        cpu: &quot;1&quot;</span><br></pre></td></tr></table></figure><h2 id="sandbox-cgroup-only-x3D-true"><a href="#sandbox-cgroup-only-x3D-true" class="headerlink" title="sandbox_cgroup_only &#x3D; true"></a>sandbox_cgroup_only &#x3D; true</h2><p>sandbox_cgroup_only 设置为 true 意味着 Kubelet 在设置 Pod cgroup 的大小时会将 Pod 的额外开销考虑在内（Kubernetes 1.16 起，借助 Pod Overhead 特性）。相对而言，这种方式较为推荐，Kata Containers 所有相关进程都可以简单地放置在给定的 cgroup 路径中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│  ┌──────────────────────────────────┐   │</span><br><span class="line">│  │ ┌─────────────────────────────┐  │   │</span><br><span class="line">│  │ │ ┌─────────────────────┐     │  │   │</span><br><span class="line">│  │ │ │ vCPU threads        │     │  │   │</span><br><span class="line">│  │ │ │ I/O threads         │     │  │   │</span><br><span class="line">│  │ │ │ VMM                 │     │  │   │</span><br><span class="line">│  │ │ │ Kata Shim           │     │  │   │</span><br><span class="line">│  │ │ │                     │     │  │   │</span><br><span class="line">│  │ │ │ /kata_&lt;sandboxID&gt;   │     │  │   │</span><br><span class="line">│  │ │ └─────────────────────┘     │  │   │</span><br><span class="line">│  │ │Pod                          │  │   │</span><br><span class="line">│  │ └─────────────────────────────┘  │   │</span><br><span class="line">│  │/kubepods                         │   │</span><br><span class="line">│  └──────────────────────────────────┘   │</span><br><span class="line">│ Node                                    │</span><br><span class="line">└─────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>当启用 sandbox_cgroup_only 时，Kata shim 将在 Pod cgroup 下创建一个名为 &#x2F;kata_&lt;sandboxID&gt; 的子 cgroup，即 sandbox cgroup。大多数情况下，sandbox cgroup 不作单独约束和限制，而是自继承父 cgroup。cpuset 和 devices cgroup 子系统除外，它们是由 Kata shim 管理。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">runC 的 cgroup 层级与限制</span></span><br><span class="line">└── /kubepods/pod505eb17b-78d4-4dce-bfb2-60085f629344</span><br><span class="line">├── tasks(空)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    ├── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    ├── 499316b3661bc989f0999dd51901d2afaad0dda0aa614a2ebcd39f2517e7c56b(业务容器)</span><br><span class="line">    |├── tasks(业务进程)</span><br><span class="line">    | ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    |└── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    └──fa6545c433f02a1c712db11cb58bb100a013f9622d725c6a41c60500c20031c5(infra 容器)</span><br><span class="line">    ├── tasks(pause 进程)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    └── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Kata 的 cgroup 层级与限制</span></span><br><span class="line">└── /kubepods/pod08ae4074-5398-439b-93ae-a63035cbd3ae</span><br><span class="line">├── tasks(空)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    ├── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    └── kata_dc5e4c1588ba3cdeb4fe1dffcb2420997408f42ad2545ddc792724b3bbfb7654(infra 容器)</span><br><span class="line">    ├── tasks(containerd-shim-kata-v2、virtiofsd、vhost 和 qemu-system 虚拟化进程)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    └── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Kata VM 中的 cgroup 层级与限制</span></span><br><span class="line">└── /kubepods/pod08ae4074-5398-439b-93ae-a63035cbd3ae</span><br><span class="line">├── tasks(空)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    ├── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line">    ├── 8d0a3396afc32d47276b4b25e76e23cdf80dfc51ca980846fb3c847effbe84f9(业务容器)</span><br><span class="line">    |├── tasks(业务进程)</span><br><span class="line">    |├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    |└── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    └──dc5e4c1588ba3cdeb4fe1dffcb2420997408f42ad2545ddc792724b3bbfb7654(infra 容器)</span><br><span class="line">    ├── tasks(pause 进程)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    └── cpu.cfs_quota_us(-&gt; -1)</span><br></pre></td></tr></table></figure><p>创建 sandbox cgroup 之后，Kata shim 会在 VM 启动之前将其自身加入到该 cgroup 中。因此，随后由 Kata shim 创建的所有进程（VMM 本身，以及所有 vCPU 和 I&#x2F;O 相关线程）都将受 sandbox cgroup 约束。</p><h3 id="sandbox-cgroup-的价值"><a href="#sandbox-cgroup-的价值" class="headerlink" title="sandbox cgroup 的价值"></a>sandbox cgroup 的价值</h3><p>为什么不直接将 sandbox、shim 等 Kata 相关进程添加到 Pod cgroup？</p><p>Kata shim 实现了 per-sandbox cgroup （即每一个 sandbox 都有一个对应的 sandbox cgroup）来支持 Docker 场景。尽管 Docker 没有 Pod 的概念，但 Kata Containers 仍然创建了一个 sandbox 来支持 Docker 实现的无 Pod、单一容器用例（即 single_container）。为了简化使用，Kata Containers 选择一个独立的 sandbox cgroup，而不是构建容器和 sandbox 之间的 cgroup 映射关系。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>将 Kata Containers 所有进程放置在适当大小的 Pod cgroup 中可以简化控制流程，有助于收集准确的指标统计数据并防止 Kata 工作负载产生近邻干扰（noisy neighbor），具体为：</p><p><strong>Pod 资源统计</strong></p><p>如果想获取 Kata 容器在 host 上的资源使用情况，可以从 Pod cgroup 中获取指标统计信息。其中，cgroup 的统计数据包括 Kata 的额外开销，提供了在 Pod 级别和容器级别收集使用静态信息的能力。</p><p><strong>更好的 host 资源隔离</strong></p><p>Kata 运行时会将所有 Kata 进程放在 Pod cgroup 中，所以对 Pod cgroup 设置的资源限制将作用于 host 中属于 Kata sandbox 的所有进程（例如 qemu-system、virtiofsd 等），从而可以改善 host 中的隔离，防止 Kata 产生近邻干扰（noisy neighbor）。</p><h2 id="sandbox-cgroup-only-x3D-false"><a href="#sandbox-cgroup-only-x3D-false" class="headerlink" title="sandbox_cgroup_only &#x3D; false"></a>sandbox_cgroup_only &#x3D; false</h2><p>如果提供给 Kata 容器的 Pod cgroup 大小不合适，Kata 组件将消耗实际容器工作负载期望使用的资源，导致不稳定和性能下降。</p><p>为避免这种情况，Kata Containers 创建了一个名为 &#x2F;kata_overhead 的 cgroup，即 overhead cgroup，并将所有与工作负载无关的进程（除 vCPU 线程外的任何进程）移至其中。</p><p>Kata Containers 不对 overhead cgroup 作任何约束或限制，因此可以</p><ul><li>预先创建并规划 overhead cgroup 的限制条件，Kata Containers 不会再额外创建，而是将所有与工作负载无关的进程移动到其中</li><li>让 Kata Containers 创建 overhead cgroup，让其不受约束或事后调整大小</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">┌────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│  ┌─────────────────────────────┐    ┌───────────────────────────┐  │</span><br><span class="line">│  │   ┌─────────────────────────┼────┼─────────────────────────┐ │  │</span><br><span class="line">│  │   │ ┌─────────────────────┐ │    │ ┌─────────────────────┐ │ │  │</span><br><span class="line">│  │   │ │  vCPU threads       │ │    │ │  VMM                │ │ │  │</span><br><span class="line">│  │   │ │                     │ │    │ │  I/O threads        │ │ │  │</span><br><span class="line">│  │   │ │                     │ │    │ │  Kata Shim          │ │ │  │</span><br><span class="line">│  │   │ │                     │ │    │ │                     │ │ │  │</span><br><span class="line">│  │   │ │ /kata_&lt;sandboxID&gt;   │ │    │ │ /&lt;sandboxID&gt;        │ │ │  │</span><br><span class="line">│  │   │ └─────────────────────┘ │    │ └─────────────────────┘ │ │  │</span><br><span class="line">│  │   │  Pod                    │    │                         │ │  │</span><br><span class="line">│  │   └─────────────────────────┼────┼─────────────────────────┘ │  │</span><br><span class="line">│  │ /kubepods                   │    │ /kata_overhead            │  │</span><br><span class="line">│  └─────────────────────────────┘    └───────────────────────────┘  │</span><br><span class="line">│ Node                                                               │</span><br><span class="line">└────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h3 id="实现细节-1"><a href="#实现细节-1" class="headerlink" title="实现细节"></a>实现细节</h3><p>当 sandbox_cgroup_only 被禁用时，Kata shim 将在 Pod cgroup 下创建 sandbox cgroup 子 cgroup，并在 overhead cgroup 下创建一个名为 &#x2F;&lt;sandboxID&gt; 的子 cgroup。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">runC 的 cgroup 层级与限制</span></span><br><span class="line">└── /kubepods/pod505eb17b-78d4-4dce-bfb2-60085f629344</span><br><span class="line">├── tasks(空)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    ├── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    ├── 499316b3661bc989f0999dd51901d2afaad0dda0aa614a2ebcd39f2517e7c56b(业务容器)</span><br><span class="line">    |├── tasks(业务进程)</span><br><span class="line">    | ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    |└── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    └──fa6545c433f02a1c712db11cb58bb100a013f9622d725c6a41c60500c20031c5(infra 容器)</span><br><span class="line">    ├── tasks(pause 进程)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    └── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Kata 的 cgroup 层级与限制</span></span><br><span class="line">├── /kubepods/podf2f4d981-27ab-4deb-87c0-07764f72f63c</span><br><span class="line">|├── tasks(空)</span><br><span class="line">|   ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">|   ├── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">|   └── kata_db541270577881d786b38b188d86959301c2e3e22bb7f08dcab009ed089d80d8(infra 容器)</span><br><span class="line">|    ├── tasks(有 PID，但是进程信息已销毁，应该就是社区说的 vCPU 线程)</span><br><span class="line">|    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">|    └── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line">└── /kata_overhead/db541270577881d786b38b188d86959301c2e3e22bb7f08dcab009ed089d80d8</span><br><span class="line">├── tasks(containerd-shim-kata-v2、virtiofsd、vhost 和 qemu-system 虚拟化进程)</span><br><span class="line">├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">└── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Kata VM 中的 cgroup 层级与限制</span></span><br><span class="line">└── /kubepods/podf2f4d981-27ab-4deb-87c0-07764f72f63c</span><br><span class="line">├── tasks(空)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    ├── cpu.cfs_quota_us(-&gt; -1)</span><br><span class="line">    ├── 87bd38d05b248b095e2feb4d3e1196a8ab604baf1ede6f81b55a3fca42545a83(业务容器)</span><br><span class="line">    |├── tasks(业务进程)</span><br><span class="line">    |├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    |└── cpu.cfs_quota_us(-&gt; 100000)</span><br><span class="line">    └──db541270577881d786b38b188d86959301c2e3e22bb7f08dcab009ed089d80d8(infra 容器)</span><br><span class="line">    ├── tasks(pause 进程)</span><br><span class="line">    ├── cpu.cfs_period_us(-&gt; 100000)</span><br><span class="line">    └── cpu.cfs_quota_us(-&gt; -1)</span><br></pre></td></tr></table></figure><p>与启用 sandbox_cgroup_only 时不同，Kata shim 将其自身加入到 overhead cgroup 中，然后将 vCPU 线程移动到 sandbox cgroup 中。除 vCPU 线程外的其他 Kata 进程和线程都将在 overhead cgroup 下运行。</p><p>在禁用 sandbox_cgroup_only 的情况下，Kata Containers 假定 Pod cgroup 的大小仅能满足容器工作负载进程。VMM 创建的 vCPU 线程是唯一在 Pod cgroup 下运行的 Kata 相关线程，降低了 VMM、Kata shim 和 I&#x2F;O 线程 OOM 的风险。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>在不受约束的 overhead cgroup 下运行所有非 vCPU 线程可能会导致工作负载潜在地消耗大量 host 资源。</p><p>另一方面，由于 overhead cgroup 的专用性，在 overhead cgroup 下运行所有非 vCPU 线程可以获取 Kata Container Pod 额外开销的准确指标，以此更合理的调整 overhead cgroup 大小和约束。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>VM 自身的规格用于限制 VM 中所有系统服务（如 Kata agent）与用户服务（如容器工作负载）的资源开销</li><li>VM 中的 cgroup 用于限制 Kata 容器的工作负载的资源开销</li><li>host 的 cgroup 用于限制 Kata 容器在 host 侧虚拟化层面的资源开销（视不同的 cgroup 管理方式而定）</li></ul><h1 id="runtimeClass-overhead"><a href="#runtimeClass-overhead" class="headerlink" title="runtimeClass.overhead"></a>runtimeClass.overhead</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">node.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RuntimeClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kata</span></span><br><span class="line"><span class="attr">handler:</span> <span class="string">kata</span></span><br><span class="line"><span class="attr">overhead:</span></span><br><span class="line">  <span class="attr">podFixed:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;1024Mi&quot;</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br></pre></td></tr></table></figure><p><strong>requests</strong>：resources.requests + runtimeClass.overhead</p><ul><li>节点调度时，无论是否声明 resources.requests，runtimeClass.overhead 均会追加到 resources.requests 中，两者之和作为调度的资源请求量</li></ul><p><strong>limits</strong>：resources.limits + runtimeClass.overhead</p><ul><li><p>资源限制时，如果声明了 resources.limit，则 runtimeClass.overhead 会追加到其中，两者之和作为资源的限制使用量</p><p>runtimeClass.overhead 部分会作用在 Pod cgroup 层面</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Namespace     Name     CPU Requests     CPU Limits     Memory Requests     Memory Limits     Age</span><br><span class="line">---------     ----     ------------     ----------     ---------------     -------------     ---</span><br><span class="line">default       kata     1500m (4%)       1500m (4%)     2Gi (13%)           2Gi (13%)         7s</span><br></pre></td></tr></table></figure><p>此外，overhead 的资源声明规范并不会影响到 Pod 的 QoS，也不会影响到 VM 最终的规格。</p><h1 id="VM-规格"><a href="#VM-规格" class="headerlink" title="VM 规格"></a>VM 规格</h1><p>VM 最终规格为</p><ul><li><strong>CPU</strong>：[hypervisor].default_vcpus + resources.limits，最大不超过 [hypervisor].default_maxvcpus</li><li><strong>MEM</strong>：[hypervisor].default_memory + resources.limits</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/# nproc</span><br><span class="line">2</span><br><span class="line">root@localhost:/# free -m</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           3017          46        2832           0         138        2929</span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Kata Containers 在 Kubernetes 集群场景中资源限制与实践验证</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 OpenFaaS 」架构与组件概述</title>
    <link href="http://shenxianghong.github.io/2023/05/08/2023-05-08%20OpenFaaS%20%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0/"/>
    <id>http://shenxianghong.github.io/2023/05/08/2023-05-08%20OpenFaaS%20%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0/</id>
    <published>2023-05-07T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.274Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/openfaas/logo.png"></div><hr><blockquote><p>based on <strong>0.26.3</strong></p></blockquote><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>Serverless Functions Made Simple</p></blockquote><p>OpenFaaS 使开发人员可以轻松地将事件驱动（event-driven）的功能和微服务部署到 Kubernetes 中，而无需重复的模板代码。OpenFaaS 将代码或现有的二进制文件打包到 Docker 镜像中，使其具有自动缩放和服务指标的高度可扩展点。</p><p><strong>OpenFaaS 亮点</strong></p><ul><li>支持丰富 UI 和一键安装，便于使用</li><li>借助<a href="https://www.openfaas.com/blog/template-store/">模板库</a> 或 Dockerfile 以任何语言编写服务和函数</li><li>构建和发布代码至 Docker 镜像或其他 OCI 兼容格式的镜像中</li><li>易于移植，借助 <a href="https://github.com/openfaas/faas-netes">faas-netes</a> 可在现有硬件或公有&#x2F;私有云上运行</li><li>支持 YAML 格式的命令行工具 — <a href="https://github.com/openfaas/faas-cli">faas-cli</a> ，用于模板化和定义函数</li><li>自动缩放，支持流量高峰扩容，并在空闲时缩减直至 0</li><li><a href="https://www.openfaas.com/pricing/">版本丰富</a>，包含社区版、标准版和商业版</li></ul><h1 id="设计与架构"><a href="#设计与架构" class="headerlink" title="设计与架构"></a>设计与架构</h1><h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h2><p>无论是本地环境、自托管集群，还是带有托管服务（如 AWS Elastic Kubernetes Service (EKS)）的平台，部署 OpenFaaS 的推荐平台都是 <strong>Kubernetes</strong>。</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/of-layer-overview.png"></div><h3 id="CI-x2F-GitOps-layer"><a href="#CI-x2F-GitOps-layer" class="headerlink" title="CI &#x2F; GitOps layer"></a>CI &#x2F; GitOps layer</h3><p>OpenFaaS 既可以运行函数，也可以运行 HTTP 微服务。每个工作负载都构建到一个容器镜像中，并发布至镜像仓库。</p><p>在开发阶段，通常使用 faas-cli 手动操作完成，而在生产阶段，有几个常见的选择：</p><ul><li><p>源代码控制管理（SCM）系统中内置的 CI 工具</p><p>GitHub Actions 或 GitLab pipeline 是通过在 Job 中执行 faas-cli deploy 或 faas-cli up 构建和部署函数。部署是在 Job 完成后进行的，将变更推送到集群中。如果需要访问私有 VPC 或本地的集群，可以通过使用私有且安全的入口隧道来实现</p></li><li><p>使用 ArgoCD 和 Flux 等 GitOps 控制器</p><p>GitOps 方式通常在新版本可用时立即持续部署 。部署是通过从特殊的配置库中获取预期状态来进行的</p></li></ul><h3 id="Application-Layer"><a href="#Application-Layer" class="headerlink" title="Application Layer"></a>Application Layer</h3><ul><li><a href="https://docs.openfaas.com/architecture/gateway/">OpenFaaS gateway</a> 提供了一个 REST API，用于管理函数、记录指标和缩放</li><li><a href="https://github.com/nats-io">NATS</a> 用于异步函数执行和排队</li><li>Prometheus 提供指标并启用 Community Edition 和 OpenFaaS Pro 的自动缩放特性</li></ul><p>使用 OpenFaaS Pro，可以通过 HTTP、Cron、AWS SQS 或 Apache Kafka 触发函数。</p><p>构成 OpenFaaS 的项目（Prometheus、Linux、OpenFaaS、NATS 和 Kubernetes）可以称为 <a href="https://www.openfaas.com/blog/plonk-stack/">PLONK Stack</a>。 PLONK Stack 能够运行事件驱动（event-driven）的功能和传统的基于 HTTP 的微服务。</p><p>这些应用程序可以通过 Helm charts 或使用 ArgoCD、Flux 等 GitOps 控制器安装。</p><h3 id="Infrastructure-Layer"><a href="#Infrastructure-Layer" class="headerlink" title="Infrastructure Layer"></a>Infrastructure Layer</h3><ul><li>函数的执行单元是 Pod，由 Containerd 或 Docker 管理</li><li>镜像仓库将每个函数作为不可变的制品保存，可以借助镜像仓库的 REST API、UI 或 CLI 将其部署到 OpenFaaS gateway</li><li>Kubernetes 是允许函数跨平台，faasd 是小型安装的更简单替代方案</li></ul><p>该 Layer 通常在探索和开发期间手动构建，在生产期间使用 Terraform 等工具构建。</p><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/of-workflow.png"></div><p>可以通过其 REST API、CLI 或 UI 访问 OpenFaas Gateway。所有服务或函数都会暴露一个默认路由，但自定义域也可以用于每个端点。</p><p>Prometheus 收集指标，这些指标可通过 OpenFaas Gateway 的 API 获得并用于自动缩放。</p><p>通过将函数的 URL 从同步的 &#x2F;function&#x2F;NAME 转变为异步的 &#x2F;async-function&#x2F;NAME，可以使用 NATS Streaming 在队列中运行调用。还可以传递一个可选的回调 URL。</p><p>faas-netes 是 OpenFaaS 最受欢迎的编排 Provider，但社区也提供了针对 Docker Swarm、Hashicorp Nomad、AWS Fargate&#x2F;ECS 和 AWS Lambda 的 Provider。 Provider 使用 <a href="https://github.com/openfaas/faas-provider">faas-provider</a> SDK 构建。</p><h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><p><em><a href="https://github.com/openfaas/faas/tree/master/gateway">https://github.com/openfaas/faas/tree/master/gateway</a></em></p><p>API Gateway 为函数提供外部路由，并通过 Prometheus 收集云原生指标。此外，API Gateway 内置的 UI 可用于部署用户自定义的函数或来自 OpenFaaS Function Store 的函数，并调用。</p><p>API Gateway 将通过更改 Kubernetes API 中的服务副本计数来满足需求扩展功能。API Gateway 的 &#x2F;system&#x2F;alert endpoint 用于接收 AlertManager 生成的自定义告警。</p><p><strong>核心特点</strong></p><ul><li>内置 UI</li><li>支持从 Function Store 部署函数或部署自定义函数</li><li>通过 Prometheus 检测</li><li>通过 AlertManager 和 Prometheus 自动缩放</li><li>缩放至 0</li><li>支持 REST API Swagger 文档</li></ul><p><strong>以 Kubernetes 作为编排 Provider 的流程示例</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/of-conceptual-operator.png"></div><h2 id="Watchdog"><a href="#Watchdog" class="headerlink" title="Watchdog"></a>Watchdog</h2><p>OpenFaaS watchdog 负责启动和监控 OpenFaaS 中的函数。通过使用 watchdog，任何二进制文件都可以成为一个函数。</p><p>watchdog 作为一个“初始化进程”，带有一个用 Golang 编写的嵌入式 HTTP 服务器，它可以支持并发请求、超时和健康检查。和 of-watchdog 类似，但非常适合流式的使用场景或需要在维护关键资源的情况，例如数据库连接、ML 模型或其他数据等请求之间。</p><p>官方提供的 <a href="https://github.com/openfaas/templates">templates repository</a> 模板仓库内置了的通用编程语言的 watchdog 模板：</p><table><thead><tr><th>Name</th><th>Language</th><th>Version</th><th>Linux base</th><th>Watchdog</th><th>Link</th></tr></thead><tbody><tr><td>dockerfile</td><td>Dockerfile</td><td>N&#x2F;A</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/dockerfile">Dockerfile template</a></td></tr><tr><td>go</td><td>Go</td><td>1.18</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/go">Go template</a></td></tr><tr><td>node12</td><td>NodeJS</td><td>12</td><td>Alpine Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node12">NodeJS template</a></td></tr><tr><td>node14</td><td>NodeJS</td><td>14</td><td>Alpine Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node14">NodeJS template</a></td></tr><tr><td>node16</td><td>NodeJS</td><td>16</td><td>Alpine Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node16">NodeJS template</a></td></tr><tr><td>node17</td><td>NodeJS</td><td>17</td><td>Alpine Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node17">NodeJS template</a></td></tr><tr><td>node18</td><td>NodeJS</td><td>18</td><td>Alpine Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node18">NodeJS template</a></td></tr><tr><td>node</td><td>NodeJS</td><td>12</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/node">NodeJS template</a></td></tr><tr><td>python3</td><td>Python</td><td>3</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/python3">Python 3 template</a></td></tr><tr><td>python3-debian</td><td>Python</td><td>3</td><td>Debian Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/python3-debian">Python 3 Debian template</a></td></tr><tr><td>python</td><td>Python</td><td>2.7</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/python">Python 2.7 template</a></td></tr><tr><td>java11-vert-x</td><td>Java and <a href="https://vertx.io/">Vert.x</a></td><td>11</td><td>Debian GNU&#x2F;Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/java11-vert-x">Java LTS template</a></td></tr><tr><td>java11</td><td>Java</td><td>11</td><td>Debian GNU&#x2F;Linux</td><td>of-watchdog</td><td><a href="https://github.com/openfaas/templates/tree/master/template/java11">Java LTS template</a></td></tr><tr><td>ruby</td><td>Ruby</td><td>2.7</td><td>Alpine Linux 3.11</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/ruby">Ruby template</a></td></tr><tr><td>php7</td><td>PHP</td><td>7.4</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/php7">PHP 7 template</a></td></tr><tr><td>php8</td><td>PHP</td><td>8.1</td><td>Alpine Linux</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/php8">PHP 8 template</a></td></tr><tr><td>csharp</td><td>C#</td><td>N&#x2F;A</td><td>Debian GNU&#x2F;Linux 9</td><td>classic</td><td><a href="https://github.com/openfaas/templates/tree/master/template/csharp">C# template</a></td></tr></tbody></table><p>此外，还有社区提供的 <a href="https://github.com/openfaas/store/blob/master/templates.json">community template store</a> 模板仓库。</p><h3 id="Classic-watchdog"><a href="#Classic-watchdog" class="headerlink" title="Classic watchdog"></a>Classic watchdog</h3><p>Classic watchdog 最初用于所有官方 OpenFaaS 模板，但 of-watchdog 现在更受青睐。<em>更多参考：<a href="https://github.com/openfaas/classic-watchdog/blob/master/README.md">https://github.com/openfaas/classic-watchdog/blob/master/README.md</a></em></p><p><strong>watchdog 调用流程</strong></p><div align=center><img width="600" style="border: 0px" src="/gallery/openfaas/classic-watchdog.jpeg"></div><h3 id="of-watchdog"><a href="#of-watchdog" class="headerlink" title="of-watchdog"></a>of-watchdog</h3><blockquote><p>Reverse proxy for HTTP microservices and STDIO</p></blockquote><p>of-watchdog 项目是对上述 Classic Watchdog 的补充（of-watchdog 适用于生产，是 openfaas GitHub 组织的一部分）。它于 2017 年 10 月启动，为 watchdog 和函数之间的通信提供了 STDIO 的替代方案。</p><p><strong>of-watchdog 组件的各种模式</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/watchdog-modes.png"></div><p>of-watchdog 实现了一个监听 8080 端口的 HTTP 服务器，作为运行函数和微服务的反向代理。它可以独立使用，也可以作为 OpenFaaS 容器的入口点。</p><p>这个版本的 OpenFaaS 看门狗增加了对 HTTP 代理和 STDIO 的支持，具有内存重用和高速请求服务响应的特性，主要区别在于在调用之间保持函数进程处于待命状态（warm）的能力。Classic watchdog 为每个请求 fork 一个进程，提供最高级别的可移植性，在较新的版本启用了一种 HTTP 模式，在该模式下，可以复用进程以抵消 fork 带来的延迟。</p><p>它的目的不是要取代 Classic watchdog，而是为那些需要这些功能的人提供另一种选择。</p><h2 id="Auto-Scaler"><a href="#Auto-Scaler" class="headerlink" title="Auto Scaler"></a>Auto Scaler</h2><p><em>仅 OpenFaas Pro 支持。</em></p><p>OpenFaas Pro 的自动缩放的策略是根据以下函数标签进行配置。通过网关的所有调用，无论是同步函数 <code>/function/</code> 还是异步函数 <code>/async-function</code> ，都采用这种自动缩放配置：</p><table><thead><tr><th>Label</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>com.openfaas.scale.max</code></td><td>The maximum number of replicas to scale to.</td><td><code>20</code></td></tr><tr><td><code>com.openfaas.scale.min</code></td><td>The minimum number of replicas to scale to.</td><td><code>1</code></td></tr><tr><td><code>com.openfaas.scale.zero</code></td><td>Whether to scale to zero.</td><td><code>false</code></td></tr><tr><td><code>com.openfaas.scale.zero-duration</code></td><td>Idle duration before scaling to zero</td><td><code>15m</code></td></tr><tr><td><code>com.openfaas.scale.target</code></td><td>Target load per replica for scaling</td><td><code>50</code></td></tr><tr><td><code>com.openfaas.scale.target-proportion</code></td><td>Proportion as a float of the target i.e. 1.0 &#x3D; 100% of target</td><td><code>0.90</code></td></tr><tr><td><code>com.openfaas.scale.type</code></td><td>Scaling mode of <code>rps</code>, <code>capacity</code>, <code>cpu</code></td><td><code>rps</code></td></tr></tbody></table><p>OpenFaaS Pro 自动缩放示例：</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/openfaas-pro-scale.jpeg"></div><p><strong>缩放依据</strong></p><p>OpenFaaS Pro 提供三种自动缩放模式：</p><ul><li><p>capacity</p><p>基于请求或连接总量。适用于长时间运行的函数或一次只能处理有限数量请求的函数</p></li><li><p>rps</p><p>基于函数每秒完成的请求。非常适合执行速度快且吞吐量高的函数</p></li><li><p>cpu</p><p>基于函数的 CPU 使用率，此策略适用于受 CPU 限制的工作负载，或者在 capacity 和 RPS 模式下未提供最佳扩展配置文件的情况。这里配置的值是以 milli-CPU 为单位的，所以1000 占 1 个 CPU 核</p></li></ul><p>无论哪种缩放模式，都需要在配置函数自动缩放时设置一个目标值，即函数每个副本的平均负载。OpenFaaS 会定期查询并计算当前负载，用于计算预期副本数，规则为：</p><blockquote><p>desired &#x3D; ready pods * ( mean load per pod &#x2F; target load per pod )</p></blockquote><p>此外，target-proportion 可用于调整提前或延迟缩放发生的时间：</p><blockquote><p>desired &#x3D; ready pods * ( mean load per pod &#x2F; ( target load per pod * target-proportion ) )</p></blockquote><p><strong>流程示例</strong></p><p>前置条件为：</p><ul><li>sleep 函数应用在 capacity 模式下运行，目标负载为 5 个请求量</li><li>当前 sleep 函数应用的实际负载为 15 个请求量</li><li>sleep 函数应用副本当前为 1</li><li>target-proportion 设置为 1.0，即为 100%</li></ul><p>缩放流程为：</p><ol><li>参考上述规则，平均每个副本的请求量为 <code>15 / 1 = 15</code>，超出 5 个 请求量的预期值，评估副本数为 <code>ceil ( 1 * ( 15 / 5 * 1 ) ) = 3</code></li><li>副本数调整为 3 后，请求量增加到 25，此时平均每个副本的请求量为 <code>25 / 3 = 8.33</code>，评估副本数为 <code>ceil ( 3 * ( 8.33 / 5 * 1 ) ) = 5</code></li><li>当不再有请求时，评估副本数为 <code>ceil ( 3 * ( 0 / 5 * 1) ) = 0</code></li><li>是否支持缩容为 0 取决于 OpenFaaS 版本</li></ol><p><strong>设计初衷</strong></p><p>在闲置时将函数缩容到零副本可以通过减少集群中所需的节点数量来节省成本，还可以减少静态大小或本地集群上的节点消耗。</p><p>在 OpenFaaS 中，缩放到零在默认情况下是关闭的，并且是 OpenFaaS Pro 一部分功能。安装后，空闲函数可以配置为在一段时间内未收到任何请求时缩减。社区建议将此数字设置为最大超时的 2 倍。</p><p>可以通过 OpenFaaS 网关的 scale_from_zero 环境变量切换从零副本向上扩展。该特性在 Kubernetes 和 faasd 上默认开启。</p><p>对不可用函数的请求，从发送处理到服务处理该请求之间的延迟成为冷启动。</p><ul><li><p>如果不想冷启动怎么办？</p><p>OpenFaaS 中的冷启动是严格可选的。对于时间敏感的操作，可以通过至少有 1 个或多个副本来避免冷启动。通过关键函数禁止缩放到 0，或者通过异步路由调用来实现，从而将请求时间与调用者分离</p></li><li><p>冷启动到底发生了什么？</p><p>冷启动包括以下流程：创建请求在节点上调度容器、找到合适的节点、拉取 Docker 镜像、在容器启动并运行后进行初始检查。可以通过在每个节点上预热镜像以及将 Kubernetes Liveness 和 Readiness Probes 设置为更快的节奏运行，可以降低总开销。更多参考：<a href="https://github.com/openfaas/faas-netes/tree/master/chart/openfaas">冷启动进行优化的说明</a>。</p><p>当启用 scale_from_zero 时，缓存会保留在内存中，根据每个函数的就绪情况，如果收到请求时函数未就绪，则 HTTP 连接将被阻止，函数将缩放到最小副本，一旦副本可用，请求就会按正常方式处理。具体流程在网关组件的日志中可以看到。更多参考：<a href="https://www.openfaas.com/blog/what-serverless-coldstart/">冷启动概述</a>。</p></li><li><p>如果函数在按比例缩小时仍在运行怎么办？</p><p>不应该发生，前提是已经为函数的空闲检测设置了足够的值。但如果是这样，OpenFaaS watchdog 和官方函数模板将允许函数正常终止。更多参考：<a href="https://www.openfaas.com/blog/long-running-jobs/">为 OpenFaaS 用户改进长时间运行的作业</a>。</p></li></ul><p>Prometheus 将监控指标发给 AlertManager 之后，AlertManager 会调用 &#x2F;system&#x2F;alert 接口，这个接口的 handler 是由 handlers.MakeAlertHandler 方法生成。MakeAlertHandler 方法接收的参数是 ServiceQuery。ServiceQuery 是一个接口，它有两个函数，用来获取或者设置最大的副本数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ServiceQuery provides interface for replica querying/setting</span></span><br><span class="line"><span class="keyword">type</span> ServiceQuery <span class="keyword">interface</span> &#123;</span><br><span class="line">GetReplicas(service, namespace <span class="type">string</span>) (response ServiceQueryResponse, err <span class="type">error</span>)</span><br><span class="line">SetReplicas(service, namespace <span class="type">string</span>, count <span class="type">uint64</span>) <span class="type">error</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MakeAlertHandler 的函数主要是从 http.Request 中读取 body，然后反序列化成 PrometheusAlert 对象，该对象是一个数组类型，支持对多个函数进行缩放。反序列化之后，调用 handleAlerts 方法，而 handleAlerts 对 alerts 进行遍历，针对每个 alert 调用了 scaleService 方法。scaleService 才是真正处理伸缩服务的函数。</p><p>对于 OpenFaaS CE 而言，Auto Scaler 能力相对而言较低，仅支持最大和最小的副本数：</p><table><thead><tr><th>Label</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>com.openfaas.scale.max</code></td><td>The maximum number of replicas to scale to.</td><td><code>5</code></td></tr><tr><td><code>com.openfaas.scale.min</code></td><td>The minimum number of replicas to scale to.</td><td><code>1</code></td></tr><tr><td><code>com.openfaas.scale.factor</code></td><td>Define the overall scaling behavior of the function.</td><td><code>20%</code></td></tr></tbody></table><h2 id="Faas-Provider"><a href="#Faas-Provider" class="headerlink" title="Faas Provider"></a>Faas Provider</h2><p>faas-provider 提供函数的 CRUD API 以及调用功能。</p><p>faas-provider 是一个用 Go 编写的 SDK，它符合 OpenFaaS Provider 的 HTTP REST API。实现接口声明的 provider 应该与 OpenFaaS 工具链和生态系统兼容，包括 UI、CLI、Function Store 和 Template Store。</p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/providers-conceptual-flow.png"></div><p>每个 Provider 都实现以下行为：</p><ul><li>函数（或微服务）的 CRUD</li><li>通过代理调用函数</li><li>函数缩放</li><li>Secret 的 CRUD（可选）</li><li>日志流（可选）</li></ul><table><thead><tr><th>Provider</th><th>Overview</th></tr></thead><tbody><tr><td>Kubernetes Provider (<a href="https://github.com/openfaas/faas-netes">faas-netes</a>)</td><td>针对 Kubernetes 的官方 OpenFaaS Provider，默认内置在 Helm chart 中</td></tr><tr><td>faasd Provider (<a href="https://github.com/openfaas/faasd">faasd</a>)</td><td>OpenFaaS 的另一种思路实现，抛去了 Kubernetes 的成本和复杂性。可以在要求非常低的单个主机上运行，且具备快速、易于管理的特点。其底层是由 Containerd 、容器网络接口 （CNI） 以及来自 OpenFaaS 项目的核心组件构成</td></tr><tr><td>Docker Swarm Provider <a href="https://github.com/openfaas/faas-swarm">faas-swarm</a>)</td><td>针对 Docker Swarm 的官方 OpenFaaS Provider，现已弃用且不再维护</td></tr><tr><td>faas-memory Provider (<a href="https://github.com/openfaas-incubator/faas-memory">faas-memory</a>)</td><td>使用本地代码内存空间存储状态，仅用于测试目的和简单示例</td></tr><tr><td>社区 Provider</td><td>参考实现：<a href="https://github.com/openfaas/faas/blob/master/community.md#openfaas-providers">https://github.com/openfaas/faas/blob/master/community.md#openfaas-providers</a></td></tr></tbody></table><p><strong>faas-netes</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/OpenFaaS on Kubernetes Cluster.png"></div><p><strong>faasd</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/openfaas/OpenFaaS on Containerd.png"></div><h2 id="Log-Provider"><a href="#Log-Provider" class="headerlink" title="Log Provider"></a>Log Provider</h2><p>OpenFaaS 支持集成自定义的 Log Provider。</p><p>Log Provider 是一个 HTTP 服务器，对外暴露 &#x2F;system&#x2F;logs endpoint，该 endpoint 支持具有以下查询参数的 GET 请求：</p><ul><li>name - 函数名称（必需）</li><li>instance - 容器名称（可选），允许从特定函数实例中请求日志</li><li>since - 日志起始时间（可选）</li><li>tail - 日志消息返回的最大数量，&lt;&#x3D;0 表示无限制</li><li>follow - 允许用户请求日志流直至超时（启用时，服务器必须使用 HTTP 分块编码来发送日志的实时流）</li></ul><p>默认情况下，OpenFaaS Gateway 会将日志请求代理到函数 Provider。可以在 OpenFaaS Gateway 服务中设置 logs_provider_url 环境变量，OpenFaaS Gateway 会将日志请求代理到此 URL，实现 Log Provider 替换。</p><table><thead><tr><th>Log Provider</th><th>Overview</th></tr></thead><tbody><tr><td>Kubernetes Provider (<a href="https://github.com/openfaas/faas-netes">faas-netes</a>)</td><td>Kubernetes Provider 并从 Kubernetes API 查询日志</td></tr><tr><td>faasd Provider (<a href="https://github.com/openfaas/faasd">faasd</a>)</td><td>从 journal 服务中查询日志，按函数和核心服务存储</td></tr><tr><td>Grafana Provider (<a href="https://github.com/LucasRoesler/openfaas-loki">openfaas-loki</a>)</td><td>社区提供的 Log Provider，使用 <a href="https://github.com/grafana/loki">Grafana Loki</a> 来收集和查询功能日志</td></tr><tr><td>自定义 Provider</td><td>借助 <code>github.com/openfaas/faas-provider/logs</code> 包提供的封装，可以构建自定义的 Log Provider HTTP 服务，参考示例：<a href="https://github.com/openfaas/faas-provider/tree/master/logs/example">https://github.com/openfaas/faas-provider/tree/master/logs/example</a></td></tr></tbody></table>]]></content>
    
    
    <summary type="html">OpenFaaS 架构设计理念与组件功能概述</summary>
    
    
    
    <category term="Serverless" scheme="http://shenxianghong.github.io/categories/Serverless/"/>
    
    
    <category term="OpenFaaS" scheme="http://shenxianghong.github.io/tags/OpenFaaS/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/network</title>
    <link href="http://shenxianghong.github.io/2023/04/15/2023-04-15%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20network/"/>
    <id>http://shenxianghong.github.io/2023/04/15/2023-04-15%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20network/</id>
    <published>2023-04-14T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.272Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;endpoint.go</u></em></p><p>Endpoint 代表了某一个物理或虚拟网络设备的基础结构，具体包括：veth、ipvlan、macvlan、macvtap、physical、vhostuser、tap 和 tuntap 8 种实现方式。借助 <code>github.com/vishvananda/netlink</code> 将抽象 endpoint 类型转变成具体的 netlink 类型，配置后回写到 endpoint 的具体属性（例如 netPair 等）后，交由 hypervisor 创建或配置该设备信息。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VethEndpoint gathers a network pair and its properties.</span></span><br><span class="line"><span class="keyword">type</span> VethEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 virtual</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// idx 为 VM 中 endpoint 设备的递增序号</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.Name 为逻辑网桥名称，固定为 br&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.HardAddr 为随机生成的 MAC 地址</span></span><br><span class="line"><span class="comment">// NetPair.NetInterworkingModel 为 [runtime].internetworking_model，可选有 macvtap 和 tcfilter（默认）</span></span><br><span class="line">NetPair NetworkInterfacePair</span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// IPVlanEndpoint represents a ipvlan endpoint that is bridged to the VM</span></span><br><span class="line"><span class="keyword">type</span> IPVlanEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 ipvlan</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// idx 为 VM 中 endpoint 设备的递增序号</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.Name 为逻辑网桥名称，固定为 br&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.HardAddr 为随机生成的 MAC 地址</span></span><br><span class="line"><span class="comment">// NetPair.NetInterworkingModel 为 tcfilter</span></span><br><span class="line">NetPair NetworkInterfacePair</span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MacvlanEndpoint represents a macvlan endpoint that is bridged to the VM</span></span><br><span class="line"><span class="keyword">type</span> MacvlanEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 macvlan</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// idx 为 VM 中 endpoint 设备的递增序号</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.Name 为逻辑网桥名称，固定为 br&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.HardAddr 为随机生成的 MAC 地址</span></span><br><span class="line"><span class="comment">// NetPair.NetInterworkingModel 为 [runtime].internetworking_model，可选有 macvtap 和 tcfilter（默认）</span></span><br><span class="line">NetPair NetworkInterfacePair</span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MacvtapEndpoint represents a macvtap endpoint</span></span><br><span class="line"><span class="keyword">type</span> MacvtapEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 macvtap</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// 元素数量等于 [hypervisor].default_vcpus 的 /dev/tap&lt;EndpointProperties.Iface.Index&gt; 文件句柄</span></span><br><span class="line">VMFds    []*os.File</span><br><span class="line"><span class="comment">// 元素数量等于 [hypervisor].default_vcpus 的 /dev/vhost-net 文件句柄</span></span><br><span class="line">VhostFds []*os.File</span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">    EndpointProperties NetworkInfo</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PhysicalEndpoint gathers a physical network interface and its properties</span></span><br><span class="line"><span class="keyword">type</span> PhysicalEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 physical</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 根据 IfaceName 解析获得，类比于 ethtool -i &lt;IfaceName&gt; 结果中的 bus-info</span></span><br><span class="line">BDF <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 软链接 /sys/bus/pci/devices/&lt;BDF&gt;/driver 指向实体文件路径的基础</span></span><br><span class="line">Driver <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 由 /sys/bus/pci/devices/&lt;BDF&gt;/vendor 和 /sys/bus/pci/devices/&lt;BDF&gt;/device 文件内容拼接而成</span></span><br><span class="line">VendorDeviceID <span class="type">string</span></span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">IfaceName          <span class="type">string</span></span><br><span class="line">HardAddr           <span class="type">string</span></span><br><span class="line">    EndpointProperties NetworkInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserEndpoint represents a vhost-user socket based network interface</span></span><br><span class="line"><span class="keyword">type</span> VhostUserEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 vhost-user</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// Path to the vhost-user socket on the host system</span></span><br><span class="line"><span class="comment">// 根据 endpoint 设备的所有 IP，获得一个存在的 /tmp/vhostuser_&lt;IP&gt;/vhu.sock 路径</span></span><br><span class="line">SocketPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">HardAddr           <span class="type">string</span></span><br><span class="line">IfaceName          <span class="type">string</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TapEndpoint represents just a tap endpoint</span></span><br><span class="line"><span class="keyword">type</span> TapEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 tap</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line">    </span><br><span class="line"><span class="comment">// TapInterface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// TapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line">TapInterface TapInterface</span><br><span class="line"></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line">    </span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line">    </span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TuntapEndpoint represents just a tap endpoint</span></span><br><span class="line"><span class="keyword">type</span> TuntapEndpoint <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 固定为 tuntap</span></span><br><span class="line">EndpointType EndpointType</span><br><span class="line"></span><br><span class="line"><span class="comment">// idx 为 VM 中设备的递增序号</span></span><br><span class="line"><span class="comment">// TuntapInterface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// TuntapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// TuntapInterface.TAPIface.HardAddr 为 tap 设备 MAC 地址</span></span><br><span class="line">TuntapInterface TuntapInterface</span><br><span class="line"></span><br><span class="line"><span class="comment">// idx 为 VM 中设备的递增序号</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.Name 为逻辑网桥名称，固定为 br&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.TapInterface.TAPIface.Name 为 tap 设备名称，固定为 tap&lt;idx&gt;_kata</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.Name 为 endpoint 设备名称，默认为 eth&lt;idx&gt;</span></span><br><span class="line"><span class="comment">// NetPair.VirtIface.HardAddr 为随机生成的 MAC 地址</span></span><br><span class="line"><span class="comment">// NetPair.NetInterworkingModel 为 [runtime].internetworking_model，可选有 macvtap 和 tcfilter（默认）</span></span><br><span class="line">NetPair NetworkInterfacePair</span><br><span class="line"></span><br><span class="line">    PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// endpoint 设备属性信息</span></span><br><span class="line">EndpointProperties NetworkInfo</span><br><span class="line">    </span><br><span class="line"><span class="comment">// endpoint 设备 inbound/outbound 限速标识</span></span><br><span class="line">RxRateLimiter <span class="type">bool</span></span><br><span class="line">TxRateLimiter <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NetworkInterfacePair defines a pair between VM and virtual network interfaces.</span></span><br><span class="line"><span class="keyword">type</span> NetworkInterfacePair <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 取决于具体 endpoint 实现，内容有所不同</span></span><br><span class="line">TapInterface</span><br><span class="line">VirtIface NetworkInterface</span><br><span class="line"></span><br><span class="line"><span class="comment">// [runtime].internetworking_model，可选的有 macvtap 和 tcfilter（默认）</span></span><br><span class="line">NetInterworkingModel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NetworkInterfacePair 即 netpair（例如 br0_kata），描述了 tap 设备（TapInterface）和 veth 设备（VirtIface，即位于容器命名空间内部的 veth-pair 设备，如 eth0）的数据结构（netPair 并非真实设备，而是一个用于描述如何连通容器网络和 VM 网络的逻辑网桥）。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NetworkInfo gathers all information related to a network interface.</span></span><br><span class="line"><span class="comment">// It can be used to store the description of the underlying network.</span></span><br><span class="line"><span class="keyword">type</span> NetworkInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">Iface     NetlinkIface</span><br><span class="line">DNS       DNSInfo</span><br><span class="line">Link      netlink.Link</span><br><span class="line">Addrs     []netlink.Addr</span><br><span class="line">Routes    []netlink.Route</span><br><span class="line">Neighbors []netlink.Neigh</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NetworkInfo 描述 endpoint 设备的通用属性信息，通过相关 Golang 系统调用库获得。</p><p>Endpoint 中声明的 <strong>Properties</strong>、<strong>Type</strong>、<strong>PciPath</strong>、<strong>SetProperties</strong>、<strong>SetPciPath</strong>、<strong>GetRxRateLimiter</strong>、<strong>SetRxRateLimiter</strong>、<strong>GetTxRateLimiter</strong> 和 <strong>GetTxRateLimiter</strong> 均为参数获取与赋值，无复杂逻辑，不作详述。<br>其中，<strong>Name</strong>、<strong>HardwareAddr</strong> 和 <strong>NetworkPair</strong> 视不同的 endpoint 实现，取值字段有所不同，具体为：</p><table><thead><tr><th>Endpoint</th><th>Name</th><th>HardwareAddr</th><th>NetworkPair</th></tr></thead><tbody><tr><td>VethEndpoint</td><td>NetPair.VirtIface.Name</td><td>NetPair.TAPIface.HardAddr</td><td>NetPair</td></tr><tr><td>IPVlanEndpoint</td><td>NetPair.VirtIface.Name</td><td>NetPair.TAPIface.HardAddr</td><td>NetPair</td></tr><tr><td>MacvlanEndpoint</td><td>NetPair.VirtIface.Name</td><td>NetPair.TAPIface.HardAddr</td><td>NetPair</td></tr><tr><td>MacvtapEndpoint</td><td>EndpointProperties.Iface.Name</td><td>EndpointProperties.Iface.HardwareAddr</td><td>—</td></tr><tr><td>PhysicalEndpoint</td><td>IfaceName</td><td>HardAddr</td><td>—</td></tr><tr><td>VhostUserEndpoint</td><td>IfaceName</td><td>HardAddr</td><td>—</td></tr><tr><td>TapEndpoint</td><td>TapInterface.Name</td><td>TapInterface.TAPIface.HardAddr</td><td>—</td></tr><tr><td>TuntapEndpoint</td><td>TuntapInterface.Name</td><td>TapInterface.TAPIface.HardAddr</td><td>NetPair</td></tr></tbody></table><h2 id="Attach"><a href="#Attach" class="headerlink" title="Attach"></a>Attach</h2><p><strong>添加 endpoint 设备到 VM 中</strong></p><h3 id="VethEndpoint、IPVlanEndpoint、MacvlanEndpoint、TuntapEndpoint"><a href="#VethEndpoint、IPVlanEndpoint、MacvlanEndpoint、TuntapEndpoint" class="headerlink" title="VethEndpoint、IPVlanEndpoint、MacvlanEndpoint、TuntapEndpoint"></a>VethEndpoint、IPVlanEndpoint、MacvlanEndpoint、TuntapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/veth_endpoint.go#L99">source code</a></p><ol><li>调用 network 的 <strong>xConnectVMNetwork</strong>，配置网络信息</li><li>调用 hypervisor 的 <strong>AddDevice</strong>，以 NetDev 类型添加 endpoint 设备到 VM 中</li></ol><h3 id="MacvtapEndpoint"><a href="#MacvtapEndpoint" class="headerlink" title="MacvtapEndpoint"></a>MacvtapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/macvtap_endpoint.go#L68">source code</a></p><ol><li>创建 &#x2F;dev&#x2F;tap&lt;endpoint.EndpointProperties.Iface.Index&gt;，构建 fds（[]*os.File，元素为数量等于 [hypervisor].default_vcpus 的 &#x2F;dev&#x2F;tap&lt;endpoint.EndpointProperties.Iface.Index&gt; 文件句柄），回写到 endpoint.VMFds 中</li><li>如果 [hypervisor].disable_vhost_net 未开启，则创建 &#x2F;dev&#x2F;vhost-net，构建 fds（[]*os.File，元素为数量等于 [hypervisor].default_vcpus 的 &#x2F;dev&#x2F;vhost-net 文件句柄），回写到 endpoint.VhostFds 中</li><li>调用 hypervisor 的 <strong>AddDevice</strong>，以 NetDev 类型添加 endpoint 设备到 VM 中</li></ol><h3 id="PhysicalEndpoint"><a href="#PhysicalEndpoint" class="headerlink" title="PhysicalEndpoint"></a>PhysicalEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/physical_endpoint.go#L82">source code</a></p><ol><li>将 endpoint.BDF 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;devices&#x2F;&lt;endpoint.BDF&gt;&#x2F;driver&#x2F;unbind 文件中<br><em>用于解除该设备在 host driver 上的绑定</em></li><li>将 endpoint.VendorDeviceID 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;drivers&#x2F;vfio-pci&#x2F;new_id 文件中；并将 endpoint.BDF 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;drivers&#x2F;vfio-pci&#x2F;bind 文件中<br><em>用于将该设备绑定到 vfio-pci driver 上，后续以 vfio-passthrough 传递给 hypervisor</em></li><li>获取 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;devices&#x2F;&lt;endpoint.BDF&gt;&#x2F;iommu_group 软链接的指向路径，得到其 base 路径（即路径最后一个元素），构建 vfio 设备路径，即 &#x2F;dev&#x2F;vfio&#x2F;&lt;base&gt; </li><li>根据 vfio 设备路径，获取设备信息，构建 DeviceInfo，并调用 devManager 的 <strong>NewDevice</strong>，初始化 vfio 类型设备</li><li>调用 devManager 的 <strong>AttachDevice</strong>，冷添加此设备到 VM 中</li></ol><h3 id="VhostUserEndpoint"><a href="#VhostUserEndpoint" class="headerlink" title="VhostUserEndpoint"></a>VhostUserEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/vhostuser_endpoint.go#L84">source code</a></p><ol><li>调用 hypervisor 的 <strong>AddDevice</strong>，以 VhostuserDev 类型添加 virtio-net-pci 设备（socketPath、MacAddress 等信息从 endpoint 中赋值）到 VM 中</li></ol><h3 id="TapEndpoint"><a href="#TapEndpoint" class="headerlink" title="TapEndpoint"></a>TapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/tap_endpoint.go#L76">source code</a></p><ol><li>暂不支持添加此类设备，返回错误</li></ol><h2 id="Detach"><a href="#Detach" class="headerlink" title="Detach"></a>Detach</h2><p><strong>移除 VM 中的 endpoint 设备</strong></p><h3 id="VethEndpoint、IPVlanEndpoint、MacvlanEndpoint"><a href="#VethEndpoint、IPVlanEndpoint、MacvlanEndpoint" class="headerlink" title="VethEndpoint、IPVlanEndpoint、MacvlanEndpoint"></a>VethEndpoint、IPVlanEndpoint、MacvlanEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/veth_endpoint.go#L114">source code</a></p><ol><li>如果 netns 不是由 Kata Containers 创建的，则直接跳过后续<br><em>根据创建 pod_sandbox 或者 single_container 时，spec.Linux.Namespace 中的 network 是否指定判断，如果未指定，表示需要由 Kata Containers 创建，反之表示 netns 已经提前创建好</em></li><li>进入到该 netns 中，调用 network 的 <strong>xDisconnectVMNetwork</strong>，移除网络信息</li></ol><h3 id="MacvtapEndpoint、VhostUserEndpoint"><a href="#MacvtapEndpoint、VhostUserEndpoint" class="headerlink" title="MacvtapEndpoint、VhostUserEndpoint"></a>MacvtapEndpoint、VhostUserEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/macvtap_endpoint.go#L92">source code</a></p><ol><li>无任何操作，直接返回</li></ol><h3 id="PhysicalEndpoint-1"><a href="#PhysicalEndpoint-1" class="headerlink" title="PhysicalEndpoint"></a>PhysicalEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/physical_endpoint.go#L112">source code</a></p><ol><li>将 endpoint.BDF 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;devices&#x2F;&lt;endpoint.BDF&gt;&#x2F;driver&#x2F;unbind 文件中<br><em>用于解除该设备在 vfio-pci driver 上的绑定</em></li><li>将 endpoint.VendorDeviceID 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;drivers&#x2F;vfio-pci&#x2F;remove_id 文件中；并将 endpoint.BDF 写入 &#x2F;sys&#x2F;bus&#x2F;pci&#x2F;drivers&#x2F;&lt;endpoint.Driver&gt;&#x2F;bind 文件中<br><em>用于将该设备绑定到 host driver 上</em></li></ol><h3 id="TapEndpoint、TuntapEndpoint"><a href="#TapEndpoint、TuntapEndpoint" class="headerlink" title="TapEndpoint、TuntapEndpoint"></a>TapEndpoint、TuntapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/tap_endpoint.go#L81">source code</a></p><ol><li>如果 netns 不是由 Kata Containers 创建的，并且 netns 路径存在，则直接跳过后续</li><li>进入到该 netns 中，获取名为 tap0_kata（示例名称，其中 0 为递增生成的索引）的设备，关停并移除</li></ol><h2 id="HotAttach"><a href="#HotAttach" class="headerlink" title="HotAttach"></a>HotAttach</h2><p><strong>热添加 endpoint 设备到 VM 中</strong></p><h3 id="VethEndpoint"><a href="#VethEndpoint" class="headerlink" title="VethEndpoint"></a>VethEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/veth_endpoint.go#L130">source code</a></p><ol><li>调用 Network 的 <strong>xConnectVMNetwork</strong>，配置网络信息</li><li>调用 hypervisor 的 <strong>HotplugAddDevice</strong>，以 NetDev 类型热添加 endpoint 设备到 VM 中</li></ol><h3 id="IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint"><a href="#IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint" class="headerlink" title="IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint"></a>IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/ipvlan_endpoint.go#L130">source code</a></p><ol><li>暂不支持热添加此类设备，返回错误</li></ol><h3 id="TapEndpoint-1"><a href="#TapEndpoint-1" class="headerlink" title="TapEndpoint"></a>TapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/tap_endpoint.go#L96">source code</a></p><ol><li>创建名为 tap0_kata（示例名称，其中 0 为递增生成的索引）的 tuntap 设备（mode 为 tap；队列长度取自 [hypervisor].default_vcpus 最大为 1，即如果队列长度大于 1，为了避免不支持多队列，需要重置为 1，参考 <a href="https://github.com/kata-containers/kata-containers/blob/e6e5d2593ac319329269d7b58c30f99ba7b2bf5a/src/runtime/vendor/github.com/vishvananda/netlink/link_linux.go#L1164-L1316">tuntap 实现</a>），并返回空的 fds，回写到 endpoint.TapInterface.VMFds 中</li><li>如果 [hypervisor].disable_vhost_net 未开启，则创建 &#x2F;dev&#x2F;vhost-net，构建 fds（[]*os.File，元素为队列长度数量的 &#x2F;dev&#x2F;vhost-net 文件句柄），回写到 endpoint.TapInterface.VhostFds 中</li><li>设置 endpoint.TapInterface.TAPIface.HardAddr 为 veth 设备的 MAC 地址<br><em>将 veth MAC 地址保存到 tap 中，以便稍后用于构建 hypervisor 命令行。 此 MAC 地址必须是 VM 内部的地址，以避免任何防火墙问题。 host 上的网络插件预期流量源自这个 MAC 地址</em></li><li>设置 tuntap 设备的 mtu 值为 veth 设备的 mtu 值</li><li>启用 tuntap 设备</li><li>调用 hypervisor 的 <strong>HotplugAddDevice</strong>，以 NetDev 类型热添加 endpoint 设备到 VM 中</li></ol><h3 id="TuntapEndpoint"><a href="#TuntapEndpoint" class="headerlink" title="TuntapEndpoint"></a>TuntapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/tuntap_endpoint.go#L107">source code</a></p><ol><li>创建名为 tap0_kata（示例名称，其中 0 为递增生成的索引）的 tuntap 设备（mode 为 tap；队列长度取自 [hypervisor].default_vcpus 最大为 1，即如果队列长度大于 1，为了避免不支持多队列，需要重置为 1，参考 <a href="https://github.com/kata-containers/kata-containers/blob/e6e5d2593ac319329269d7b58c30f99ba7b2bf5a/src/runtime/vendor/github.com/vishvananda/netlink/link_linux.go#L1164-L1316">tuntap 实现</a>）</li><li>设置 endpoint.TuntapInterface.TAPIface.HardAddr 为 veth 设备的 MAC 地址<br><em>将 veth MAC 地址保存到 tap 中，以便稍后用于构建 hypervisor 命令行。 此 MAC 地址必须是 VM 内部的地址，以避免任何防火墙问题。 host 上的网络插件预期流量源自这个 MAC 地址</em></li><li>设置 tuntap 设备的 mtu 值为 veth 设备的 mtu 值</li><li>启用 tuntap 设备</li><li>调用 hypervisor 的 <strong>HotplugAddDevice</strong>，以 NetDev 类型热添加 endpoint 设备到 VM 中</li></ol><h2 id="HotDetach"><a href="#HotDetach" class="headerlink" title="HotDetach"></a>HotDetach</h2><p><strong>热移除 VM 中的 endpoin 设备</strong></p><h3 id="VethEndpoint-1"><a href="#VethEndpoint-1" class="headerlink" title="VethEndpoint"></a>VethEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/veth_endpoint.go#L147">source code</a></p><ol><li>如果 netns 不是由 Kata Containers 创建的，则直接跳过后续<br><em>根据创建 pod_sandbox 或者 single_container 时，spec.Linux.Namespace 中的 network 是否指定判断，如果未指定，表示需要由 Kata Containers 创建，反之表示 netns 已经提前创建好</em></li><li>进入到该 netns 中，调用 <strong>xDisconnectVMNetwork</strong>，移除网络信息</li><li>调用 hypervisor 的 <strong>HotplugRemoveDevice</strong>，以 NetDev 热移除 endpoint 中 VM 的设备</li></ol><h3 id="IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint-1"><a href="#IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint-1" class="headerlink" title="IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint"></a>IPVlanEndpoint、MacvlanEndpoint、MacvtapEndpoint、PhysicalEndpoint、VhostUserEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/ipvlan_endpoint.go#L135">source code</a></p><ol><li>暂不支持热移除此类设备，返回错误</li></ol><h3 id="TapEndpoint、TuntapEndpoint-1"><a href="#TapEndpoint、TuntapEndpoint-1" class="headerlink" title="TapEndpoint、TuntapEndpoint"></a>TapEndpoint、TuntapEndpoint</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/tap_endpoint.go#L115">source code</a></p><ol><li>进入到该 netns 中，获取名为 tap0_kata（示例名称，其中 0 为递增生成的索引）的设备，关停并移除</li><li>调用 hypervisor 的 <strong>HotplugRemoveDevice</strong>，以 NetDev 热移除 VM 中的 endpoint 设备</li></ol><h1 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;network.go</u></em></p><p>实际操作均借助 <code>github.com/vishvananda</code> 实现，该库提供了等价于 ip addr、ip link、tc qdisc、tc filter 等命令行的功能。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LinuxNetwork represents a sandbox networking setup.</span></span><br><span class="line"><span class="keyword">type</span> LinuxNetwork <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// OCI spec 中类型为 network 的 linux.namespace.path</span></span><br><span class="line">netNSPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// netns 中的 endpoint 设备</span></span><br><span class="line">eps []Endpoint</span><br><span class="line"></span><br><span class="line"><span class="comment">// [runtime].internetworking_model，可选有 macvtap 和 tcfilter（默认）</span></span><br><span class="line">interworkingModel NetInterworkingModel</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表示当前 netns 是否为 Kata Containers 创建</span></span><br><span class="line"><span class="comment">// - false：netns 为事先准备好，创建 Kata 容器时，在 OCI spec 中传递该 netns（network 类型的 linux.namespace）。例如 Kubernetes 场景下，netns 由 CNI 创建</span></span><br><span class="line"><span class="comment">// - true：Kata Containers 发现 OCI spec 中不存在 network 类型的 linux.namespace，则会手动创建一个 netns（以 cnitest 开头）。例如 Containerd 场景下，运行 single_container</span></span><br><span class="line">netNSCreated <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Network 中声明的 <strong>NetworkID</strong>、<strong>NetworkCreated</strong>、<strong>Endpoints</strong> 和 <strong>SetEndpoints</strong> 均为参数获取与赋值，无复杂逻辑，不作详述。其中，<strong>Run</strong> 是封装了进入 netns 中执行回调函数的流程。</p><h2 id="xConnectVMNetwork"><a href="#xConnectVMNetwork" class="headerlink" title="xConnectVMNetwork"></a>xConnectVMNetwork</h2><p><strong>根据不同的网络模型，打通容器和 VM 之间的网络</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/network_linux.go#L518">source code</a></p><ol><li><p>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象的网络模型（即[runtime].internetworking_model，默认为 tcfilter）</p></li><li><p>调用 hypervisor 的 <strong>Capabilities</strong>，判断 hypervisor 是否支持多队列特性。如果支持，则队列数设为 [hypervisor].default_vcpus；否则为 0</p></li><li><p>根据网络模型，创建对应的 tap 设备，连通容器和 VM 之间的网络</p><p><em>无论哪种网络模式，VM 中的 eth0 都是 hypervisor 基于 tap 设备虚拟化出来，并 attach 到 VM 中建立两者的关联关系。区别在于 tap 设备和 veth 设备（即 CNI 为容器内分配的 eth0）的网络打通方式</em></p><ul><li><p>如果网络模型为 macvtap</p><ol><li>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象，并进一步获取 veth 设备</li><li>创建 macvtap 设备，其中名称为 tap0_kata（示例名称，其中 0 为递增生成的索引）、txQLen 属性继承自 veth 设备且 parentIndex 指向容器 eth0 设备（下称 veth 设备）<br><em>目前 macvtap 场景下需要特殊处理索引（该索引后续用作命名 &#x2F;dev&#x2F;tap&lt;idx&gt;），是由于 Linux 内核中存在一个限制，会导致 macvtap&#x2F;macvlan link 在网络 namespace 中创建时无法获得正确的 link 索引<br><a href="https://github.com/clearcontainers/runtime/issues/708">https://github.com/clearcontainers/runtime/issues/708</a><br>在修复该错误之前，需要随机一个非冲突索引（即 8192 + 随机一个数字）并尝试创建一个 link。 如果失败，则继续重试，上限为 128 次。所有内核都不会检查链接 ID 是否与主机上的 link ID 冲突，因此需要偏移 link ID 以防止与主机索引发生任何重叠，内核将确保没有竞争条件</em></li><li>设置 netPair.TAPIface.HardAddr 为 veth 设备的 MAC 地址<br><em>将 veth MAC 地址保存到 tap 中，以便稍后用于构建 hypervisor 命令行。 此 MAC 地址必须是 VM 内部的地址，以避免任何防火墙问题。 host 上的网络插件预期流量源自这个 MAC 地址</em></li><li>设置 macvtap 设备的 mtu 值为 veth 设备的 mtu 值</li><li>设置 veth 设备的 MAC 地址为随机生成的 MAC 地址（即 netPair.VirtIface.HardAddr，该字段初始化时为随机生成的 MAC  地址），并设置 macvtap 设备的 MAC 地址为 veth 设备的 MAC 地址</li><li>启用 macvtap 设备</li><li>获取 veth 设备的全部 IP 地址，保存至 netPair.VirtIface.Addrs，并从 veth 设备中移除这些 IP 地址<br><em>清理掉 veth 设备中由 CNI 分配的 IP 地址，避免 ARP 冲突</em></li><li>根据步骤 2 中生成随机索引，创建 &#x2F;dev&#x2F;tap&lt;idx&gt;，构建 fds（[]*os.File，元素为队列长度数量的 &#x2F;dev&#x2F;tap&lt;idx&gt; 文件句柄），回写到 netPair.VMFds 中</li><li>如果 [hypervisor].disable_vhost_net 未开启，则创建 &#x2F;dev&#x2F;vhost-net，构建 fds（[]*os.File，元素为队列长度数量的 &#x2F;dev&#x2F;vhost-net 文件句柄），回写到 netPair.VhostFds 中</li></ol><p>综上所述，macvtap 网络模式下，是将 veth 设备和 macvtap 设备的 mac 地址等信息互换，并将 veth 设备的网络信息转移到 VM 中 eth0 设备（实质上是清理 veth 设备网络信息，同时借助 VM dhcp 获取 CNI 分配的 IP 地址），结合 macvtap 设备的 parentIndex 指向 veth 设备，实现容器网络流量和 VM 网络流量的互通。</p></li><li><p>如果网络模型为 tcfilter</p><ol><li>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象，并进一步获取 veth 设备</li><li>创建名为 tap0_kata（示例名称，其中 0 为递增生成的索引）的 tuntap 设备（mode 为 tap；队列长度最大为 1，即如果队列长度大于 1，为了避免不支持多队列，需要重置为 1，参考 <a href="https://github.com/kata-containers/kata-containers/blob/e6e5d2593ac319329269d7b58c30f99ba7b2bf5a/src/runtime/vendor/github.com/vishvananda/netlink/link_linux.go#L1164-L1316">tuntap 实现</a>），并返回空的 fds，回写到 netPair.VMFds 中</li><li>如果 [hypervisor].disable_vhost_net 未开启，则创建 &#x2F;dev&#x2F;vhost-net，构建 fds（[]*os.File，元素为队列长度数量的 &#x2F;dev&#x2F;vhost-net 文件句柄），回写到 netPair.VhostFds 中</li><li>设置 netPair.TAPIface.HardAddr 为 veth 设备的 MAC 地址<br><em>将 veth MAC 地址保存到 tap 中，以便稍后用于构建 hypervisor 命令行。 此 MAC 地址必须是 VM 内部的地址，以避免任何防火墙问题。 host 上的网络插件预期流量源自这个 MAC 地址</em></li><li>设置 tuntap 设备的 mtu 值为 veth 设备的 mtu 值</li><li>启用 tuntap 设备</li><li>为 tuntap 设备和 veth 设备分别创建 ingress 类型的网络队列规则与 tc 规则，将一方的入站流量重定向到另一方进行出站处理，使得所有流量在两者之间可以被重定向</li></ol><p>综上所述，tcfilter 网络模式下，仅仅是在 veth 和 tap 设备之间配置 tc 规则，实现容器网络流量和 VM 网络流量的互通。</p></li></ul><p><em><strong>效果示例</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">网络模型为 macvtap 时</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-97333755-9052-db96-37fe-37d4e39bf046 ethtool -i tap0_kata</span></span><br><span class="line">driver: macvlan</span><br><span class="line">version: 0.1</span><br><span class="line">firmware-version: </span><br><span class="line">expansion-rom-version: </span><br><span class="line">bus-info: </span><br><span class="line">supports-statistics: no</span><br><span class="line">supports-test: no</span><br><span class="line">supports-eeprom-access: no</span><br><span class="line">supports-register-dump: no</span><br><span class="line">supports-priv-flags: no</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-fb0bd424-5621-3672-62d9-9233708dc54d ip a</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: eth0@if18: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc noqueue state UP group default </span><br><span class="line">    link/ether 46:ba:a7:d6:85:ec brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">55446: tap0_kata@eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc fq_codel state UP group default qlen 1500</span><br><span class="line">    link/ether c6:f1:06:ac:46:53 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::c4f1:6ff:feac:4653/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">exec</span> 7af17cb96ddaa59a4e370c0de584ea6df5759278ce6c203a188a3ab18b461216</span> </span><br><span class="line">root@localhost:/# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether c6:f1:06:ac:46:53 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.244.69.173/32 brd 10.244.69.173 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::c4f1:6ff:feac:4653/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">网络模型为 tcfilter 时</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-d7e932c4-51a6-53e0-e73c-662aa84b4653 ethtool -i tap0_kata</span></span><br><span class="line">driver: tun</span><br><span class="line">version: 1.6</span><br><span class="line">firmware-version: </span><br><span class="line">expansion-rom-version: </span><br><span class="line">bus-info: tap</span><br><span class="line">supports-statistics: no</span><br><span class="line">supports-test: no</span><br><span class="line">supports-eeprom-access: no</span><br><span class="line">supports-register-dump: no</span><br><span class="line">supports-priv-flags: no</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-d7e932c4-51a6-53e0-e73c-662aa84b4653 ip a</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: eth0@if17: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 1e:03:66:df:ad:5e brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.244.69.163/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::1c03:66ff:fedf:ad5e/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: tap0_kata: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc mq state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether ee:b0:99:52:54:ef brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::ecb0:99ff:fe52:54ef/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">exec</span> 8a390592512f2f27a35accd0fa5c2c82d29dea2f3d1eb982c6225be7856e78a6</span> </span><br><span class="line">root@localhost:/# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 1e:03:66:df:ad:5e brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.244.69.163/32 brd 10.244.69.163 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::1c03:66ff:fedf:ad5e/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></li></ol><h2 id="xDisconnectVMNetwork"><a href="#xDisconnectVMNetwork" class="headerlink" title="xDisconnectVMNetwork"></a>xDisconnectVMNetwork</h2><p><strong>根据不同的网络模型，移除容器和 VM 之间的网络配置</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/network_linux.go#L552">source code</a></p><ol><li>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象的网络模型（即[runtime].internetworking_model，默认为 tcfilter）</li><li>根据网络模型，移除对应的 tap 设备<ul><li>如果网络模型为 macvtap<ol><li>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象，并进一步获取 macvtap 设备与 veth 设备</li><li>移除 macvtap 设备</li><li>将 veth 设备的 MAC 地址还原（在 <strong>xConnextVMNetwork</strong> 流程中保存在 netPair.TAPIface.HardAddr）</li><li>关停 veth 设备</li><li>将 veth 设备的 IP 地址还原（在 <strong>xConnextVMNetwork</strong> 流程中保存在 netPair.VirtIface.Addrs）</li></ol></li><li>如果网络模型为 tcfilter<ol><li>调用 endpoint 的 <strong>NetworkPair</strong>，获取 netPair 对象，并进一步获取 tuntap 设备与 veth 设备</li><li>关停 tuntap 设备，并移除</li><li>删除 veth 设备所有的 tc 规则与 ingress 类型的网络队列规则</li><li>关停 veth 设备</li></ol></li></ul></li></ol><h2 id="addSingleEndpoint"><a href="#addSingleEndpoint" class="headerlink" title="addSingleEndpoint"></a>addSingleEndpoint</h2><p><strong>添加 endpoint 设备到 VM 中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/network_linux.go#L110">source code</a></p><ol><li><p>根据网口的类型，初始化对应的 endpoint<br><em>物理设备是根据 ethtools 获取指定网口名称的 bus 信息判断，如果 bus 格式为 0000:00:03.0（即以冒号切分后长度为 3），则表示为物理设备；<br>vhost-user 设备是根据 &#x2F;tmp&#x2F;vhostuser_&lt;addr&gt;&#x2F;vhu.sock（其中 addr 为网卡的每一个地址）文件是否存在，如果存在，则表示为 vhost-user 设备；<br>tuntap 设备仅支持 tap mode</em></p></li><li><p>调用 endpoint 的 <strong>SetProperties</strong>，设置 endpoint 属性信息</p></li><li><p>根据是否为 hotplug，则调用 endpoint 的 <strong>HotAttach</strong> 或 <strong>Attach</strong>，热（添加）endpoint 设备到 VM 中</p></li><li><p>调用 hypervisor 的 <strong>IsRateLimiterBuiltin</strong>，判断是否内置支持限速特性。如果本身不支持限速（例如 QEMU），则需要额外配置：</p><ul><li><p>网络 I&#x2F;O inbound 带宽限速（即 [hypervisor].rx_rate_limiter_max_rate 大于 0）</p><p><em>veth、ipvlan、tuntap 和 macvlan 类型的 endpoint，待限速设备为 endpoint.NetPair 的 tap 设备；<br>macvtap 和 tap 类型的 endpoint，待限速设备为其本身，即 endpoint.Name()</em></p><ol><li><p>调用 endpoint 的 <strong>SetRxRateLimiter</strong>，设置 inbound 限速标识</p></li><li><p>获取待限速设备的索引，使用 HTB（Hierarchical Token Bucket）qdisc traffic shaping 方案来控制网口流量，设置 class 的 rate 和 ceil 均为 [hypervisor].rx_rate_limiter_max_rate<br><em>class 1:2 是基于 class 1:1 创建，两者的 rate 和 ceil 流控指标保持一致，class 1:2 最终作为默认的 class，class 1:n 用于限制特定流量（截至 Kata 3.0，暂未实现）<br>之所以创建了 class 1:2 作为默认的 class，是一种常规做法，一般 class 1:1 承担限制整体的最大速率，class 1:2 用于控制非特权流量。如果统一由 class 1:1 负责，可能会导致非特权流量无法得到适当的控制和优先级管理。没有专门的子类别来定义规则和限制非特权流量，可能会导致这些流量占用过多的带宽，从而影响网络的性能和服务质量；难以灵活地调整限制策略。如果需要根据具体情况对非特权流量进行不同的限制和优先级分配，使用单一的1:1类别会显得不够灵活。而有一个专门的子类别，可以根据需要定义更具体的规则和策略，更好地控制非特权流量。所以，通过设置专门的 class 1:2，可以更好地组织和管理流量，确保网络的资源分配和性能满足特定的需求和优先级</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+-----+     +---------+     +-----------+      +-----------+</span><br><span class="line">|     |     |  qdisc  |     | class 1:1 |      | class 1:2 |</span><br><span class="line">| NIC |     |   htb   |     |   rate    |      |   rate    |</span><br><span class="line">|     | --&gt; | def 1:2 | --&gt; |   ceil    | -+-&gt; |   ceil    |</span><br><span class="line">+-----+     +---------+     +-----------+  |   +-----------+</span><br><span class="line">                                           |</span><br><span class="line">                                           |   +-----------+</span><br><span class="line">                                           |   | class 1:n |</span><br><span class="line">                                           |   |   rate    |</span><br><span class="line">                                           +-&gt; |   ceil    |</span><br><span class="line">                                           |   +-----------+</span><br></pre></td></tr></table></figure></li></ol></li><li><p>网络 I&#x2F;O outbound 带宽限速（即 [hypervisor].tx_rate_limiter_max_rate 大于 0）</p><p><em>veth、ipvlan、tuntap 和 macvlan 类型的 endpoint 且当网络模型为 tcfilter 时，待限速设备为 endpoint.NetPair 的 veth 设备，当网络模型为 macvtap 或 none 时，待限速设备为 endpoint.NetPair 的 tap 设备；<br>macvtap 和 tap 类型的 endpoint，待限速设备为设备本身，即 endpoint.Name()</em></p><ol><li>对于 veth、ipvlan、tuntap 和 macvlan 类型的 endpoint 且当网络模型为 tcfilter 时，则获取 endpoint.NetPair 中 veth 设备的索引，同样的使用 HTB（Hierarchical Token Bucket）qdisc traffic shaping 方案来控制 veth 网口流量，设置 class 的 rate 和 ceil 均为 [hypervisor].tx_rate_limiter_max_rate<br><em>对于 tcfilter，只需将 htb qdisc 应用于 veth pair。 对于其他网络模型，例如 macvtap，借助 ifb，通过将 endpoint 设备入口流量重定向到 ifb 出口，然后将 htb 应用于 ifb 出口，实现限速</em></li><li>其他场景时，调用 endpoint 的 <strong>SetTxRateLimiter</strong>，设置 outbound 限速标识</li><li>尝试加载 host 的 ifb 模块，创建名为 ifb0 的 ifb 设备并启用，返回 ifb 设备索引号</li><li>为待限速的设备创建 ingress 类型的网络队列规则</li><li>为待限速设备添加过滤器规则，将其入站流量重定向到 ifb 设备进行出站处理</li><li>使用 HTB（Hierarchical Token Bucket）qdisc traffic shaping 方案来控制 ifb 网口流量，设置 class 的 rate 和 ceil 均为 [hypervisor].tx_rate_limiter_max_rate</li></ol></li></ul><p><em><strong>限速示例（veth endpoint）</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">inbound 限速为 1024，outbound 限速为 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/kata-containers/configuration.toml | grep rate_limiter_max_rate</span></span><br><span class="line">rx_rate_limiter_max_rate = 1024</span><br><span class="line">tx_rate_limiter_max_rate = 2048</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">网络模型为 macvtap 时</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-593e147b-3839-2615-f57f-39dc53181ef5 tc qdisc show</span></span><br><span class="line">qdisc noqueue 0: dev lo root refcnt 2 </span><br><span class="line">qdisc noqueue 0: dev eth0 root refcnt 2 </span><br><span class="line">qdisc htb 1: dev tap0_kata root refcnt 2 r2q 10 default 2 direct_packets_stat 0 direct_qlen 1500</span><br><span class="line">qdisc ingress ffff: dev tap0_kata parent ffff:fff1 ---------------- </span><br><span class="line">qdisc htb 1: dev ifb0 root refcnt 2 r2q 10 default 2 direct_packets_stat 0 direct_qlen 32</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># inbound 限速作用在 tap0_kata 设备上</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-593e147b-3839-2615-f57f-39dc53181ef5 tc class show dev tap0_kata</span></span><br><span class="line">class htb 1:1 root rate 1024bit ceil 1024bit burst 1600b cburst 1600b </span><br><span class="line">class htb 1:2 parent 1:1 prio 0 rate 1024bit ceil 1024bit burst 1600b cburst 1600b </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># outbound 限速作用在 ifb0 设备上</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-593e147b-3839-2615-f57f-39dc53181ef5 tc class show dev eth0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-593e147b-3839-2615-f57f-39dc53181ef5 tc class show dev ifb0</span></span><br><span class="line">class htb 1:1 root rate 2048bit ceil 2048bit burst 1600b cburst 1600b </span><br><span class="line">class htb 1:2 parent 1:1 prio 0 rate 2048bit ceil 2048bit burst 1600b cburst 1600b</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">网络模型为 tcfilter 时</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-58d2c6b0-b9e5-797d-4c9f-291769802ac1 tc qdisc show</span></span><br><span class="line">qdisc noqueue 0: dev lo root refcnt 2 </span><br><span class="line">qdisc htb 1: dev eth0 root refcnt 2 r2q 10 default 2 direct_packets_stat 0 direct_qlen 1000</span><br><span class="line">qdisc ingress ffff: dev eth0 parent ffff:fff1 ---------------- </span><br><span class="line">qdisc htb 1: dev tap0_kata root refcnt 257 r2q 10 default 2 direct_packets_stat 0 direct_qlen 1000</span><br><span class="line">qdisc ingress ffff: dev tap0_kata parent ffff:fff1 ---------------- </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># inbound 限速作用在 tap0_kata 设备上</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-58d2c6b0-b9e5-797d-4c9f-291769802ac1 tc class show dev tap0_kata</span></span><br><span class="line">class htb 1:1 root rate 1024bit ceil 1024bit burst 1600b cburst 1600b </span><br><span class="line">class htb 1:2 parent 1:1 prio 0 rate 1024bit ceil 1024bit burst 1600b cburst 1600b </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># outbound 限速作用在容器 veth pair 的 eth0 设备上</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip netns <span class="built_in">exec</span> cni-58d2c6b0-b9e5-797d-4c9f-291769802ac1 tc class show dev eth0</span></span><br><span class="line">class htb 1:1 root rate 2048bit ceil 2048bit burst 1600b cburst 1600b </span><br><span class="line">class htb 1:2 parent 1:1 prio 0 rate 2048bit ceil 2048bit burst 1600b cburst 1600b</span><br></pre></td></tr></table></figure></li></ol><h2 id="AddEndpoints"><a href="#AddEndpoints" class="headerlink" title="AddEndpoints"></a>AddEndpoints</h2><p><strong>添加 endpoint 设备到 VM 中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/network_linux.go#L324">source code</a></p><ol><li>如果未指定 endpoint，则默认添加 netns 中所有的 enpoint 设备<ol><li>针对 netns 中每一个网络设备接口信息（即 NetworkInfo），获得其名称、类型、IP 地址、路由、ARP neighbor 等信息（后续会设置在 endpoint.EndpointProperties 中，用于描述 endpoint 的属性）</li><li>忽略缺少 IP 地址的网络接口，以及本地回环接口<br><em>缺少 IP 地址意味着要么是没有命名空间的基本隧道设备，如 gre0、gretap0、sit0、ipip0、tunl0，要么是错误设置的接口</em></li><li>进入到该 netns 中，调用 <strong>addSingleEndpoint</strong>，向 VM 中添加 endpoint 设备</li></ol></li><li>否则，针对每一个 endpoint，进入到该 netns 中，调用 <strong>addSingleEndpoint</strong>，向 VM 中添加 endpoint 设备</li></ol><h2 id="RemoveEndpoints"><a href="#RemoveEndpoints" class="headerlink" title="RemoveEndpoints"></a>RemoveEndpoints</h2><p><strong>移除 VM 中的 endpoint 设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/network_linux.go#L356">source code</a></p><ol><li>如果未指定 endpoint，则默认为 netns 中所有的 endpoint 设备（也就是 AddEndpoints 中添加的 endpoint 设备），针对每一个待移除的 endpoint<ol><li>调用 endpoint 的 <strong>GetRxRateLimiter</strong>，如果设置了 inbound 限速，则进入到该 netns 中，移除限速设备 htb 类型的网络队列规则<br><em>本质上就是对 addSingleEndpoint 中 inbound 限速处理的逆操作</em></li><li>调用 endpoint 的 <strong>GetTxRateLimiter</strong>，如果设置了 outbound 限速，则进入到该 netns 中，移除限速设备 htb 类型的网络队列规则、删除限速设备所有的 tc 规则与 ingress 类型的网络队列规则以及关停并移除 ifb0 设备<br><em>本质上就是对 addSingleEndpoint 中 outbound 限速处理的逆操作</em></li><li>根据是否为 hotplug，则调用 endpoint 的 <strong>HotDetach</strong> 或 <strong>Detach</strong>，（热）移除 VM 中的 endpoint 设备</li></ol></li><li>如果 netns 是由 Kata Containers 创建，并且未指定 endpoint（即删除了 netns 中所有的 endpoint），则移除该 netns 的挂载点，并删除该 netns</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 Endpoint、Network 等网络管理相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/resource controller</title>
    <link href="http://shenxianghong.github.io/2023/04/09/2023-04-09%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20resource%20controller%20-%20%E5%89%AF%E6%9C%AC/"/>
    <id>http://shenxianghong.github.io/2023/04/09/2023-04-09%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20resource%20controller%20-%20%E5%89%AF%E6%9C%AC/</id>
    <published>2023-04-08T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.272Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="ResourceController"><a href="#ResourceController" class="headerlink" title="ResourceController"></a>ResourceController</h1><p><em><u>src&#x2F;runtime&#x2F;pkg&#x2F;resourcecontrol&#x2F;controller.go</u></em></p><p>ResourceController 在 Linux 上的实现为 LinuxCgroup，而 LinuxCgroup 具体体现为两种：sandboxController 和 overheadController：</p><ul><li>当 [runtime].sandbox_cgroup_only 开启时，顾名思义仅有 sandboxController，用于管理 Pod 所有的线程资源</li><li>当 [runtime].sandbox_cgroup_only 未开启时，资源分为两类，其中 vCPU 线程资源会由 sandboxController 管理，其余资源由 overheadController 管理</li></ul><p><em>具体执行标准参考 OCI runtime-spec：<a href="https://github.com/opencontainers/runtime-spec/blob/main/config-linux.md%E3%80%82">https://github.com/opencontainers/runtime-spec/blob/main/config-linux.md。</a></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> LinuxCgroup <span class="keyword">struct</span> &#123;</span><br><span class="line">sync.Mutex</span><br><span class="line">    </span><br><span class="line"><span class="comment">// cgroup 实现，其中类型包括 legacy、hybrid 和 unified，用于区分 cgroups v1 和 v2</span></span><br><span class="line">cgroup  <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// cgroup 路径</span></span><br><span class="line">path    <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 待限制的 CPU</span></span><br><span class="line">cpusets *specs.LinuxCPU</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 待限制的 sandbox 设备</span></span><br><span class="line"><span class="comment">// 除了创建时指定的 sandbox 设备，还会追加以下设备：</span></span><br><span class="line"><span class="comment">//   默认设备：/dev/null、/dev/random、/dev/full、/dev/tty、/dev/zero、/dev/urandom 和 /dev/console</span></span><br><span class="line"><span class="comment">//   虚拟化设备：/dev/kvm、/dev/vhost-net、/dev/vfio/vfio 和 /dev/vhost-vsock</span></span><br><span class="line"><span class="comment">//   wildcard 设备（通过手动指定 major、minor、access 和 type 属性构造的设备）：tuntap、/dev/pts 等</span></span><br><span class="line">devices []specs.LinuxDeviceCgroup</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>LinuxCgroup 的实现方式本质上是封装了 <code>github.com/containerd/cgroups </code> 库，用于处理 cgroup 资源。因此，<strong>Type</strong>、<strong>ID</strong>、<strong>Parent</strong>、<strong>Delete</strong>、<strong>Stat</strong>、<strong>AddProcess</strong>、<strong>AddThread</strong>、<strong>Update</strong>、<strong>MoveTo</strong>、<strong>AddDevice</strong>、<strong>RemoveDevice</strong> 和 <strong>UpdateCpuSet</strong> 均为该库针对 cgroup v1 和 v2 不同版本下统一入口的二次封装。<em>该库不支持针对 systemd 创建具有 v1 和 v2 cgroup 的 scope，因此这部分是直接与 systemd 交互创建 cgroup，然后使用 containerd 的 api 加载它。 添加运行时进程，无需调用 setupCgroups</em></p><p><em>此外，以下的函数声明并非 ResourceController 的接口声明，而是 VCSandbox 的扩展封装，为了便于理解，将其归类至 ResourceController 下。</em></p><h2 id="setupResourceController"><a href="#setupResourceController" class="headerlink" title="setupResourceController"></a>setupResourceController</h2><p><strong>配置 resourceController</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2275">source code</a></p><ol><li>调用 sandboxController 或 overheadController（取决于 sandbox 资源是否分开管理，即 [runtime].sandbox_cgroup_only 的配置）的 <strong>AddProcess</strong>，将当前进程 ID 加入到 cgroup 中管理<br><em>确保运行时的任何子进程（即服务于 Kata Pod 的所有进程）都将存在于 resourceController 中，且如果有 overheadController 则由 overheadController 管理此类进程以及子进程</em></li></ol><h2 id="resourceControllerUpdate"><a href="#resourceControllerUpdate" class="headerlink" title="resourceControllerUpdate"></a>resourceControllerUpdate</h2><p><strong>更新 resourceController 以及 cgroup 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2191">source code</a></p><ol><li>聚合 sandbox 中所有容器的 CPUSet 和 MEMSet 信息，调用 sandboxController 的 <strong>UpdateCpuSet</strong>，更新到 cgroup 中</li><li>如果 sandbox 的资源分开管理（即存在 overheadController），则调用 hypervisor 的 <strong>GetThreadIDs</strong>，获取 vCPU 线程，并调用 sandboxController 的 <strong>AddThread</strong>，将 vCPU 线程的加入到 cgroup 中管理<br><em>因为当有 overheadController 时，意味着会产生新的 vCPU 线程会作为 hypervisor 的子线程，所以需要并入统一的 cgroup 中管理</em></li></ol><h2 id="resourceControllerDelete"><a href="#resourceControllerDelete" class="headerlink" title="resourceControllerDelete"></a>resourceControllerDelete</h2><p><strong>删除 resourceController 以及 cgroup 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2216">source code</a></p><ol><li>调用 <strong>LoadResourceController</strong>，根据 sandboxController 的 cgroupPath 获取 sandboxController</li><li>调用 sandboxController 的 <strong>Parent</strong>，获取父级信息；调用 sandboxController 的 <strong>MoveTo</strong>，将其管理的进程移至父级；并调用 sandboxController 的 <strong>Delete</strong>，删除 sandboxController 的 cgroup</li><li>如果 sandbox 的资源分开管理（即存在 overheadController），则执行同样的操作</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 ResourceController 等资源限制相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/device</title>
    <link href="http://shenxianghong.github.io/2023/03/18/2023-03-18%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20device/"/>
    <id>http://shenxianghong.github.io/2023/03/18/2023-03-18%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20device/</id>
    <published>2023-03-17T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.271Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><p>DeviceReceiver 是一组相对而言较底层的接口声明，其直接调用 hypervisor 执行设备热插拔等操作；而 Device 描述了设备的实现细节，内部会调用 DeviceReceiver 的接口实现各自的热插拔功能；而 DeviceManager 则对外提供设备管理能力，其内部屏蔽了设备的具体类型，而是直接调用 Device 的接口管理设备。</p><h1 id="DeviceReceiver"><a href="#DeviceReceiver" class="headerlink" title="DeviceReceiver"></a>DeviceReceiver</h1><p><em><u>src&#x2F;runtime&#x2F;pkg&#x2F;device&#x2F;api&#x2F;interface.go</u></em></p><p>DeviceReceiver 的实现由 Sandbox 接口完成。</p><p>DeviceReceiver 中声明的 <strong>GetHypervisorType</strong> 为参数获取，无复杂逻辑，不作详述。</p><h2 id="HotplugAddDevice"><a href="#HotplugAddDevice" class="headerlink" title="HotplugAddDevice"></a>HotplugAddDevice</h2><p><strong>热添加设备到 sandbox 中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1789">source code</a></p><ol><li>调用 sandboxController 的 <strong>AddDevice</strong>，将 device 的 <strong>GetHostPath</strong> 添加到 cgroup 管理中</li><li>如果设备类型为 vfio<ol><li>调用 device 的 <strong>GetDeviceInfo</strong>，获取 iommu group 中所有设备</li><li>调用 hypervisor 的 <strong>HotplugAddDevice</strong>，热添加所有 vfio 设备<br><em>group 是 IOMMU 能够进行 DMA 隔离的最小硬件单元，一个 group 内可能只有一个 device，也可能有多个 device，这取决于物理平台上硬件的 IOMMU 拓扑结构。 设备直通的时候一个 group 里面的设备必须都直通给一个虚拟机。 不能够让一个group 里的多个 device 分别从属于 2 个不同的 VM，也不允许部分 device 在 host 上而另一部分被分配到 guest 里， 因为就这样一个 guest 中的 device 可以利用 DMA 攻击获取另外一个 guest 里的数据，就无法做到物理上的 DMA 隔离。</em></li></ol></li><li>如果设备类型为 block 或 vhost-user-blk-pci，直接调用 hypervisor 的 <strong>HotplugAddDevice</strong>，热添加设备</li><li>如果设备类型为 generic（即非 vfio、block 或者 vhost-user 设备），则不做操作<br><em>根据注释的 TODO，猜测后续版本会有操作，截至 3.0.0 暂无逻辑</em></li><li>如果为其他设备类型，则不做操作</li></ol><h2 id="HotplugRemoveDevice"><a href="#HotplugRemoveDevice" class="headerlink" title="HotplugRemoveDevice"></a>HotplugRemoveDevice</h2><p><strong>热移除 sandbox 中的设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1843">source code</a></p><ol><li>如果设备类型为 vfio<ol><li>调用 device 的 <strong>GetDeviceInfo</strong>，获取 iommu group 中所有设备</li><li>调用 hypervisor 的 <strong>HotplugRemoveDevice</strong>，热移除所有 vfio 设备</li></ol></li><li>如果设备类型为 block（非 PMEM 设备，因为持久内存设备无法热移除）或 vhost-user-blk-pci<ol><li>调用 device 的 <strong>GetDeviceInfo</strong>，获取设备详情</li><li>调用 hypervisor 的 <strong>HotplugRemoveDevice</strong>，热移除设备</li></ol></li><li>如果设备类型为 generic（即非 vfio、block 或者 vhost-user 设备），则不做操作<br><em>根据注释的 TODO，猜测后续版本会有操作，截至 3.0.0 暂无逻辑</em></li><li>如果为其他设备类型，则不做操作</li><li>调用 sandboxController 的 <strong>RemoveDevice</strong>，将 device 的 <strong>GetHostPath</strong> 从 cgroup 管理中移除</li></ol><h2 id="GetAndSetSandboxBlockIndex"><a href="#GetAndSetSandboxBlockIndex" class="headerlink" title="GetAndSetSandboxBlockIndex"></a>GetAndSetSandboxBlockIndex</h2><p><strong>获取并设置 virtio-block 索引，仅支持 virtio-blk 和 virtio-scsi 类型设备</strong></p><p><em>用于记录分配给 sandbox 中容器的块设备索引（通过 BlockIndexMap（map[int]struct{}））</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1901">source code</a></p><ol><li>获取维护在 sandbox.state.BlockIndexMap 中，从 0 到 65534 范围内没有被使用的索引 ID</li></ol><h2 id="UnsetSandboxBlockIndex"><a href="#UnsetSandboxBlockIndex" class="headerlink" title="UnsetSandboxBlockIndex"></a>UnsetSandboxBlockIndex</h2><p><strong>释放记录的 virtio-block 索引，仅支持 virtio-blk 和 virtio-scsi 类型设备</strong></p><p><em>用于记录分配给 sandbox 中容器的块设备索引（通过 BlockIndexMap（map[int]struct{}））</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1907">source code</a></p><ol><li>移除维护在 sandbox.state.BlockIndexMap（map[int]struct{}）中的索引</li></ol><h2 id="AppendDevice"><a href="#AppendDevice" class="headerlink" title="AppendDevice"></a>AppendDevice</h2><p><strong>向 sandbox 中添加一个 vhost-user 类型的设备，用于向 hypervisor 传递启动参数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1914">source code</a></p><ol><li>如果设备类型为 vhost-user-scsi-pci、virtio-net-pci、vhost-user-blk-pci 和 vhost-user-fs-pci<ol><li>调用 device 的 <strong>GetDeviceInfo</strong>，获取设备信息</li><li>调用 hypervisor 的 <strong>AddDevice</strong>，添加设备</li></ol></li><li>如果设备类型为 vfio<ol><li>调用 device 的 <strong>GetDeviceInfo</strong>，获取 vfio group 中所有设备</li><li>调用 hypervisor 的 <strong>AddDevice</strong>，添加所有 vfio 设备</li></ol></li><li>其余设备类型均不支持</li></ol><h1 id="Device"><a href="#Device" class="headerlink" title="Device"></a>Device</h1><p><em><u>src&#x2F;runtime&#x2F;pkg&#x2F;device&#x2F;api&#x2F;interface.go</u></em></p><p>Device 有以下实现方式：GenericDevice、VFIODevice、BlockDevice、VhostUserBlkDevice、VhostUserFSDevice、VhostUserNetDevice 和 VhostUserSCSIDevice，其中均以 GenericDevice 为基础，扩展部分方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DeviceInfo is an embedded type that contains device data common to all types of devices.</span></span><br><span class="line"><span class="keyword">type</span> DeviceInfo <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// DriverOptions is specific options for each device driver</span></span><br><span class="line"><span class="comment">// for example, for BlockDevice, we can set DriverOptions[&quot;block-driver&quot;]=&quot;virtio-blk&quot;</span></span><br><span class="line">DriverOptions <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Hostpath is device path on host</span></span><br><span class="line">HostPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ContainerPath is device path inside container</span></span><br><span class="line">ContainerPath <span class="type">string</span> <span class="string">`json:&quot;-&quot;`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Type of device: c, b, u or p</span></span><br><span class="line"><span class="comment">// c , u - character(unbuffered)</span></span><br><span class="line"><span class="comment">// p - FIFO</span></span><br><span class="line"><span class="comment">// b - block(buffered) special file</span></span><br><span class="line"><span class="comment">// More info in mknod(1).</span></span><br><span class="line">DevType <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ID for the device that is passed to the hypervisor.</span></span><br><span class="line">ID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Major, minor numbers for device.</span></span><br><span class="line">Major <span class="type">int64</span></span><br><span class="line">Minor <span class="type">int64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// FileMode permission bits for the device.</span></span><br><span class="line">FileMode os.FileMode</span><br><span class="line"></span><br><span class="line"><span class="comment">// id of the device owner.</span></span><br><span class="line">UID <span class="type">uint32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// id of the device group.</span></span><br><span class="line">GID <span class="type">uint32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Pmem enabled persistent memory. Use HostPath as backing file</span></span><br><span class="line"><span class="comment">// for a nvdimm device in the guest.</span></span><br><span class="line">Pmem <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// If applicable, should this device be considered RO</span></span><br><span class="line">ReadOnly <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ColdPlug specifies whether the device must be cold plugged (true)</span></span><br><span class="line"><span class="comment">// or hot plugged (false).</span></span><br><span class="line">ColdPlug <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>DeviceInfo 描述了设备的属性信息，通常是根据 OCI spec 中获得，并根据具体的实际设备类型覆盖。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VFIODevice is a vfio device meant to be passed to the hypervisor</span></span><br><span class="line"><span class="comment">// to be used by the Virtual Machine.</span></span><br><span class="line"><span class="keyword">type</span> VFIODevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 元素为 /sys/kernel/iommu_groups/&lt;DeviceInfo.HostPath&gt;/devices 目录下的所有子设备（IOMMU）详情</span></span><br><span class="line">VfioDevs []*config.VFIODev</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个 VFIO 设备也就是一组 IOMMU 设备。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// BlockDevice refers to a block storage device implementation.</span></span><br><span class="line"><span class="keyword">type</span> BlockDevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">BlockDrive *config.BlockDrive</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserBlkDevice is a block vhost-user based device</span></span><br><span class="line"><span class="keyword">type</span> VhostUserBlkDevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">VhostUserDeviceAttrs *config.VhostUserDeviceAttrs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserFSDevice is a virtio-fs vhost-user device</span></span><br><span class="line"><span class="keyword">type</span> VhostUserFSDevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">config.VhostUserDeviceAttrs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserNetDevice is a network vhost-user based device</span></span><br><span class="line"><span class="keyword">type</span> VhostUserNetDevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">*config.VhostUserDeviceAttrs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserSCSIDevice is a SCSI vhost-user based device</span></span><br><span class="line"><span class="keyword">type</span> VhostUserSCSIDevice <span class="keyword">struct</span> &#123;</span><br><span class="line">*GenericDevice</span><br><span class="line">*config.VhostUserDeviceAttrs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// GenericDevice refers to a device that is neither a VFIO device, block device or VhostUserDevice.</span></span><br><span class="line"><span class="keyword">type</span> GenericDevice <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 设备的通用属性信息</span></span><br><span class="line">ID         <span class="type">string</span></span><br><span class="line">DeviceInfo *config.DeviceInfo</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设备引用与 Attach 计数</span></span><br><span class="line">RefCount    <span class="type">uint</span></span><br><span class="line">AttachCount <span class="type">uint</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VFIODev represents a VFIO drive used for hotplugging</span></span><br><span class="line"><span class="comment">// /sys/kernel/iommu_groups/&lt;DeviceInfo.HostPath&gt;/devices 目录下的所有文件均视为一个 VFIODev</span></span><br><span class="line"><span class="keyword">type</span> VFIODev <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// ID is used to identify this drive in the hypervisor options.</span></span><br><span class="line"><span class="comment">// 格式为 vfio-&lt;DeviceInfo.ID&gt;&lt;idx&gt;，最长保留 31 位，其中 idx 为遍历文件的递增索引</span></span><br><span class="line">ID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Type of VFIO device</span></span><br><span class="line"><span class="comment">// VFIO 设备进一步分为两种类型，可以通过文件名区别：</span></span><br><span class="line"><span class="comment">// - 常规类型，例如 0000:04:00.0</span></span><br><span class="line"><span class="comment">// - mediated 类型，例如 f79944e4-5a3d-11e8-99ce-479cbab002e4</span></span><br><span class="line">Type VFIODeviceType</span><br><span class="line">    </span><br><span class="line"><span class="comment">// BDF (Bus:Device.Function) of the PCI address</span></span><br><span class="line"><span class="comment">// - 常规类型，例如 0000:04:00.0 -&gt; 04:00.0</span></span><br><span class="line"><span class="comment">// - mediated 类型，例如 f79944e4-5a3d-11e8-99ce-479cbab002e4 -&gt; /sys/kernel/iommu_groups/&lt;DeviceInfo.HostPath&gt;/devices/f79944e4-5a3d-11e8-99ce-479cbab002e4 -&gt; /sys/devices/pci0000:00/0000:00:02.0/f79944e4-5a3d-11e8-99ce-479cbab002e4（软链接关系）-&gt; 0000:00:02.0 -&gt; 00:02.0</span></span><br><span class="line">BDF <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// sysfsdev of VFIO mediated device</span></span><br><span class="line"><span class="comment">// - 常规类型，例如 0000:04:00.0 -&gt; /sys/bus/pci/devices/0000:04:00.0</span></span><br><span class="line"><span class="comment">// - mediated 类型，例如 f79944e4-5a3d-11e8-99ce-479cbab002e4 -&gt; /sys/kernel/iommu_groups/&lt;DeviceInfo.HostPath&gt;/devices/f79944e4-5a3d-11e8-99ce-479cbab002e4 -&gt; /sys/devices/pci0000:00/0000:00:02.0/f79944e4-5a3d-11e8-99ce-479cbab002e4（软链接关系）</span></span><br><span class="line">SysfsDev <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// IsPCIe specifies device is PCIe or PCI</span></span><br><span class="line"><span class="comment">// 根据 /sys/bus/pci/devices/0000:&lt;BDF&gt;/config 文件大小判断是否为 PCI 设备</span></span><br><span class="line"><span class="comment">// - PCI 设备，大小为 256</span></span><br><span class="line"><span class="comment">// - PCIe 设备，大小为 4096</span></span><br><span class="line">IsPCIe <span class="type">bool</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// PCI Class Code</span></span><br><span class="line"><span class="comment">// /sys/bus/pci/devices/0000:&lt;BDF&gt;/class 文件内容</span></span><br><span class="line">Class <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Bus of VFIO PCIe device</span></span><br><span class="line"><span class="comment">// 如果为 PCIe 设备，则记录名称为 rp&lt;idx&gt;，其中 idx 为当前记录的 PCIe 总设备数量</span></span><br><span class="line">Bus <span class="type">string</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// VendorID specifies vendor id</span></span><br><span class="line">VendorID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// DeviceID specifies device id</span></span><br><span class="line">DeviceID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Guest PCI path of device</span></span><br><span class="line">GuestPciPath vcTypes.PciPath</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>VFIODev 描述了 VFIODevice 设备特有的属性信息，也可以理解为 IOMMU 设备的信息。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// BlockDrive represents a block storage drive which may be used in case the storage</span></span><br><span class="line"><span class="comment">// driver has an underlying block storage device.</span></span><br><span class="line"><span class="keyword">type</span> BlockDrive <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// File is the path to the disk-image/device which will be used with this drive</span></span><br><span class="line"><span class="comment">// - BlockDevice：&lt;DeviceInfo.HostPath&gt;</span></span><br><span class="line"><span class="comment">// - SWAP：&lt;XDG_RUNTIME_DIR&gt;/run/kata-containers/shared/sandboxes/swap&lt;idx&gt;，其中 idx 为 sandbox 中 SWAP 文件递增索引</span></span><br><span class="line">File <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Format of the drive</span></span><br><span class="line"><span class="comment">// - BlockDevice：DeviceInfo.DriverOptions[&quot;fstype&quot;] 指定，默认为 raw</span></span><br><span class="line"><span class="comment">// - SWAP：固定为 raw</span></span><br><span class="line">Format <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ID is used to identify this drive in the hypervisor options.</span></span><br><span class="line"><span class="comment">// - BlockDevice：格式为 drive-&lt;DeviceInfo.ID&gt;&lt;idx&gt;，最长保留 31 位</span></span><br><span class="line"><span class="comment">// - SWAP：sandbox 中 SWAP 文件递增索引</span></span><br><span class="line">ID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// MmioAddr is used to identify the slot at which the drive is attached (order?).</span></span><br><span class="line">MmioAddr <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// SCSI Address of the block device, in case the device is attached using SCSI driver</span></span><br><span class="line"><span class="comment">// SCSI address is in the format SCSI-Id:LUN</span></span><br><span class="line"><span class="comment">// - BlockDevice：如果 DeviceInfo.DriverOptions[&quot;block-driver&quot;] 为 virtio-scsi（不指定默认也为 virtio-scsi），则根据 Index 获取 SCSI-Id（Index / 256）以及 LUN（Index % 256），最终的 SCSI 地址为 &lt;SCSI-Id&gt;:&lt;LUN&gt;</span></span><br><span class="line">SCSIAddr <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// NvdimmID is the nvdimm id inside the VM</span></span><br><span class="line">NvdimmID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// VirtPath at which the device appears inside the VM, outside of the container mount namespace</span></span><br><span class="line"><span class="comment">// - BlockDevice：如果 DeviceInfo.DriverOptions[&quot;block-driver&quot;] 不为 virtio-scsi 或者 nvdimm，则进一步判断</span></span><br><span class="line"><span class="comment">// -- 如果 block-driver 为 virtio-blk 或 virtio-blk-ccw，则索引为 Index</span></span><br><span class="line"><span class="comment">// -- 如果 block-driver 为 virtio-mmio，则索引为 Index + 1</span></span><br><span class="line"><span class="comment">//    根据索引计算出设备路径，例如 0 -&gt; /dev/vda，25 -&gt; /dev/vdz，27 -&gt; /dev/vdab</span></span><br><span class="line">VirtPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// DevNo identifies the css bus id for virtio-blk-ccw</span></span><br><span class="line">DevNo <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// PCIPath is the PCI path used to identify the slot at which the drive is attached.</span></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// Index assigned to the drive. In case of virtio-scsi, this is used as SCSI LUN index</span></span><br><span class="line"><span class="comment">// - BlockDevice：调用 DeviceReceiver.GetAndSetSandboxBlockIndex 获取</span></span><br><span class="line">Index <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ShareRW enables multiple qemu instances to share the File</span></span><br><span class="line">ShareRW <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ReadOnly sets the device file readonly</span></span><br><span class="line"><span class="comment">// - BlockDevice：&lt;DeviceInfo.ReadOnly&gt;</span></span><br><span class="line">ReadOnly <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Pmem enables persistent memory. Use File as backing file</span></span><br><span class="line"><span class="comment">// for a nvdimm device in the guest</span></span><br><span class="line"><span class="comment">// - BlockDevice：&lt;DeviceInfo.Pmem&gt;</span></span><br><span class="line">Pmem <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// This block device is for swap</span></span><br><span class="line">Swap <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>BlockDrive 描述了 BlockDevice 设备特有的属性信息，除了在 BlockDevice 中使用，SWAP 和 VM 镜像也是由 BlockDrive 构建。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VhostUserDeviceAttrs represents data shared by most vhost-user devices</span></span><br><span class="line"><span class="keyword">type</span> VhostUserDeviceAttrs <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// VhostUserBlkDevice：格式为 blk-&lt;DeviceInfo.ID&gt;&lt;idx&gt;，最长保留 31 位</span></span><br><span class="line">DevID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// VhostUserBlkDevice：&lt;DeviceInfo.HostPath&gt;</span></span><br><span class="line">SocketPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// MacAddress is only meaningful for vhost user net device</span></span><br><span class="line">MacAddress <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// These are only meaningful for vhost user fs devices</span></span><br><span class="line">Tag <span class="type">string</span></span><br><span class="line"></span><br><span class="line">Cache <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// VhostUserBlkDevice：固定为 vhost-user-blk-pci</span></span><br><span class="line">Type DeviceType</span><br><span class="line"></span><br><span class="line"><span class="comment">// PCIPath is the PCI path used to identify the slot at which</span></span><br><span class="line"><span class="comment">// the drive is attached.  It is only meaningful for vhost</span></span><br><span class="line"><span class="comment">// user block devices</span></span><br><span class="line">PCIPath vcTypes.PciPath</span><br><span class="line"></span><br><span class="line"><span class="comment">// Block index of the device if assigned</span></span><br><span class="line"><span class="comment">// 默认为 -1，如果 DeviceInfo.DriverOptions[&quot;block-driver&quot;] 为 virtio-blk、virtio-blk-ccw 或 virtio-mmio，调用 DeviceReceiver.GetAndSetSandboxBlockIndex 获取</span></span><br><span class="line">Index <span class="type">int</span></span><br><span class="line"></span><br><span class="line">CacheSize <span class="type">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>VhostUserDeviceAttrs 描述了 VhostUserBlkDevice、VhostUserFSDevice、VhostUserNetDevice 和 VhostUserSCSIDevice 设备特有的属性信息。</p><p>Device 中声明的 <strong>DeviceID</strong>、<strong>GetAttachCount</strong>、<strong>GetHostPath</strong> 和 <strong>GetMajorMinor</strong> 均为参数获取与赋值，无复杂逻辑，不作详述。<br>此外，<strong>DeviceType</strong> 返回各自 Device 实现的类型（如 generic、vfio、vhost-user-blk-pci、vhost-user-fs-pci、virtio-net-pci 和 vhost-user-scsi-pci）；<strong>GetDeviceInfo</strong> 返回各自 Device 实现的属性信息；<strong>Reference</strong> 和 <strong>Dereference</strong> 用于维护设备的引用计数，未达到最多（^uint(0)，即 2 的 64 次方减一）和最少引用时，则计数加一或减一并返回；<strong>Save</strong> 和 <strong>Load</strong> 用于 Device 和 DeviceState（结构类似，用于描述状态数据）之间转换，不同的实现额外赋值其各自的属性信息。</p><h2 id="bumpAttachCount"><a href="#bumpAttachCount" class="headerlink" title="bumpAttachCount"></a>bumpAttachCount</h2><p><strong>记录设备的 attach 次数</strong></p><p><em>bumpAttachCount 并非 Device 声明的接口，而是 GenericDevice 的一个常用方法，用于判断是否需要执行实际 attach 或 detach 操作，函数入参中的 bool 用于表明是否为 attach 操作，出参中的 bool 用于表明是否为单纯的计数。</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/generic.go#L101">source code</a></p><ol><li>如果为 attach 操作<ol><li>如果当前 attach 计数为 0，则计数加一，并返回 false，即需要执行实际的 attach 操作</li><li>如果当前 attach 计数为 ^uint(0)（即 2 的 64 次方减一），则返回 true 和设备 attach 次数过多的错误</li><li>除此之外，默认计数加一，并返回 true，即不需要执行实际的 attach 操作</li></ol></li><li>如果为 detach 操作<ol><li>如果当前 attach 计数为 0，则返回 true 和设备并未 attach 的错误</li><li>如果当前 attach 次数为 1，则计数减一，并返回 false，即需要执行实际的 detach 操作</li><li>除此之外，默认计数减一，并返回 true，即不需要执行实际的 detach 操作</li></ol></li></ol><h2 id="Attach"><a href="#Attach" class="headerlink" title="Attach"></a>Attach</h2><p><strong>attach 设备</strong></p><p><em>根据不同的实现，可能是冷添加或者热添加</em></p><h3 id="GenericDevice"><a href="#GenericDevice" class="headerlink" title="GenericDevice"></a>GenericDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/generic.go#L36">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，不执行实际操作</li></ol><h3 id="VFIODevice"><a href="#VFIODevice" class="headerlink" title="VFIODevice"></a>VFIODevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/vfio#L58">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>遍历 &#x2F;sys&#x2F;kernel&#x2F;iommu_groups&#x2F;&lt;device.DeviceInfo.HostPath&gt;&#x2F;devices，获取 VFIO 设备的 BDF（PCIe 总线中的每一个功能都有一个唯一的标识符与之对应。这个标识符就是 BDF，即 Bus，Device，Function）、sysfsDev 和设备类型，判断是否为 PCIe 设备，获取 PCI class 等信息，如果为 PCIe 设备，生成 Bus 信息<br><em>具体参考 VFIODev 结构体注释</em></li><li>如果设备必须冷添加，则调用 devReceiver 的 <strong>AppendDevice</strong>，添加设备；否则调用 devReceiver 的 <strong>HotplugAddDevice</strong>，热添加设备</li></ol><h3 id="BlockDevice"><a href="#BlockDevice" class="headerlink" title="BlockDevice"></a>BlockDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/block.go#L38">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>调用 devReceiver 的 <strong>GetAndSetSandboxBlockIndex</strong>，设置并返回可用的索引 ID</li><li>根据 device.DeviceInfo.DriverOptions[“block-driver”]，回写对应的字段（SCSIAddr 和 VirtPath）<ol><li>如果未指定则视为 virtio-scsi，根据索引 ID 计算出 SCSIAddr，格式为 &lt;index &#x2F; 256&gt;:&lt;index % 256&gt;<br><em>qemu 代码建议 scsi-id 可以取值从 0 到 255（含），而 lun 可以取值从 0 到 16383（含）。 但是超过 255 的 lun 值似乎不遵循一致的 SCSI 寻址。 因此限制为 255</em></li><li>如果指定不为 nvdimm，则根据索引 ID 计算出 VirtPath，例如 &#x2F;dev&#x2F;vda<br><em>其中，索引 0 对应 vda，25 对应 vdz，27 对应 vdab，704 对应 vdaac，18277 对应 vdzzz</em></li></ol></li><li>调用 devReceiver 的 <strong>HotplugAddDevice</strong>，热添加设备</li></ol><h3 id="VhostUserBlkDevice"><a href="#VhostUserBlkDevice" class="headerlink" title="VhostUserBlkDevice"></a>VhostUserBlkDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/vhost_user_blk.go#L40">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>根据 device.DeviceInfo.DriverOptions[“block-driver”]，判断 block-driver 是否是 virtio-blk<br><em>如果未指定则视为 virtio-scsi；如果指定为 virtio-blk、virtio-blk-ccw 或 virtio-mmio 则视为 virtio-blk</em></li><li>如果是 virtio-blk，则调用 devReceiver 的 <strong>GetAndSetSandboxBlockIndex</strong>，获取未被使用的块索引；否则，索引默认为 -1</li><li>调用 devReceiver 的 <strong>HotplugAddDevice</strong>，热添加设备</li></ol><h3 id="VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice"><a href="#VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice" class="headerlink" title="VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice"></a>VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/vhost_user_fs.go#L25">source code</a></p><p><em>VhostUserFSDevice、VhostUserNetDevice 和 VhostUserSCSIDevice 实现方式一致，以 GenericDevice 为例</em></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>调用 devReceiver 的 <strong>AppendDevice</strong>，添加设备</li></ol><h2 id="Detach"><a href="#Detach" class="headerlink" title="Detach"></a>Detach</h2><p><strong>detach 设备</strong></p><p><em>不同的实现下未必支持 detach 操作</em></p><h3 id="GenericDevice、VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice"><a href="#GenericDevice、VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice" class="headerlink" title="GenericDevice、VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice"></a>GenericDevice、VhostUserFSDevice、VhostUserNetDevice、VhostUserSCSIDevice</h3><p><em>GenericDevice、VhostUserFSDevice、VhostUserNetDevice 和 VhostUserSCSIDevice 实现方式一致，以 GenericDevice 为例</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/generic.go#L42">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，不执行实际操作</li></ol><h3 id="VFIODevice-1"><a href="#VFIODevice-1" class="headerlink" title="VFIODevice"></a>VFIODevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/vfio#L128">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>如果设备是冷添加的，说明没有运行后的 attach 动作，因此则无需 detach；否则，调用 devReceiver 的 <strong>HotplugRemoveDevice</strong>，热移除设备</li></ol><h3 id="BlockDevice-1"><a href="#BlockDevice-1" class="headerlink" title="BlockDevice"></a>BlockDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/block.go#L124">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>调用 devReceiver 的 <strong>HotplugRemoveDevice</strong>，热移除设备</li></ol><h3 id="VhostUserBlkDevice-1"><a href="#VhostUserBlkDevice-1" class="headerlink" title="VhostUserBlkDevice"></a>VhostUserBlkDevice</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/drivers/vhost_user_blk.go#L118">source code</a></p><ol><li>调用 <strong>bumpAttachCount</strong>，维护 attach 计数，判断是否执行后续实际操作</li><li>调用 devReceiver 的 <strong>HotplugRemoveDevice</strong>，热移除设备</li><li>根据 device.DeviceInfo.DriverOptions[“block-driver”]，判断 block-driver 是否是 virtio-blk。如果是 virtio-blk，则调用 devReceiver 的 <strong>UnsetSandboxBlockIndex</strong>，释放记录的 virtio-block 索引<br><em>如果未指定则视为 virtio-scsi；如果指定为 virtio-blk、virtio-blk-ccw 或 virtio-mmio 则视为 virtio-blk</em></li></ol><h1 id="DeviceManager"><a href="#DeviceManager" class="headerlink" title="DeviceManager"></a>DeviceManager</h1><p><em><u>src&#x2F;runtime&#x2F;pkg&#x2F;device&#x2F;api&#x2F;interface.go</u></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> deviceManager <span class="keyword">struct</span> &#123;</span><br><span class="line">sync.RWMutex</span><br><span class="line">    </span><br><span class="line"><span class="comment">// VM 中的设备</span></span><br><span class="line">devices <span class="keyword">map</span>[<span class="type">string</span>]api.Device</span><br><span class="line"></span><br><span class="line"><span class="comment">// [hypervisor].block_device_driver，rootfs 块设备驱动，可选有 virtio-scsi、virtio-blk 和 nvdimm</span></span><br><span class="line">blockDriver <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// [hypervisor].vhost_user_store_path，默认为 /var/run/kata-containers/vhost-user</span></span><br><span class="line"><span class="comment">// Its sub-path &quot;block&quot; is used for block devices; &quot;block/sockets&quot; is</span></span><br><span class="line"><span class="comment">// where we expect vhost-user sockets to live; &quot;block/devices&quot; is where</span></span><br><span class="line"><span class="comment">// simulated block device nodes for vhost-user devices to live.</span></span><br><span class="line">vhostUserStorePath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// [hypervisor].enable_vhost_user_store，默认为 false</span></span><br><span class="line"><span class="comment">// Enabling this will result in some Linux reserved block type</span></span><br><span class="line"><span class="comment">// major range 240-254 being chosen to represent vhost-user devices.</span></span><br><span class="line">vhostUserStoreEnabled <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Device 中声明的 <strong>IsDeviceAttached</strong>、<strong>GetDeviceByID</strong> 和 <strong>GetAllDevices</strong> 为参数获取，无复杂逻辑，不作详述。</p><h2 id="NewDevice"><a href="#NewDevice" class="headerlink" title="NewDevice"></a>NewDevice</h2><p><strong>初始化设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/manager/manager.go#L136">source code</a></p><ol><li>如果设备不是 pmem 类型（即 devInfo.Pmem 为 false）<ol><li>如果启用了 [hypervisor].enable_vhost_user_store、devInfo.DevType 为 b 并且设备 devInfo.Major 是 242（即 vhost-user-scsi）或者 241（即 vhost-user-blk），则获取 &lt;vhostUserStorePath&gt;&#x2F;block&#x2F;devices 目录下，格式为 major:minor 的文件名，作为 socket 文件，返回 &lt;vhostUserStorePath&gt;&#x2F;block&#x2F;sockets&#x2F;&lt;socket&gt; 文件路径<br><em>用于获取 vhost-user 设备的主机路径。 对于 vhost-user 块设备，如 vhost-user-blk 或 vhost-user-scsi，其 socket 应位于目录 &lt;vhostUserStorePath&gt;&#x2F;block&#x2F;sockets&#x2F; 下，它对应的设备节点应该在目录 &lt;vhostUserStorePath&gt;&#x2F;block&#x2F;devices&#x2F; 下</em></li><li>如果 devInfo.DevType 为 c 或者 u，则 uevent 路径为 &#x2F;sys&#x2F;dev&#x2F;char&#x2F;&lt;major:minor&gt;&#x2F;uevent；如果 devInfo.DevType 为 b，则 uevent 路径为  &#x2F;sys&#x2F;dev&#x2F;block&#x2F;&lt;major:minor&gt;&#x2F;uevent。如果 uevent 文件不存在，则返回 devInfo.ContainerPath，否则读取文件内容（文件为 ini 格式），解析 DEVNAME 项，返回 &#x2F;dev&#x2F;&lt;DEVNAME &gt; 文件路径<br><em>某些设备（例如 &#x2F;dev&#x2F;fuse、&#x2F;dev&#x2F;cuse）并不总是在 &#x2F;sys&#x2F;dev 下实现 sysfs 接口，这些设备默认由 docker 传递。 只需返回在设备配置中传递的路径，这确实意味着这些设备不支持设备重命名</em></li><li>设置 devInfo.HostPath 为上述返回的路径</li></ol></li><li>根据 devInfo.Major 和 devInfo.Minor，判断设备是否已经存在 deviceManager 的 devices 中，存在则直接返回即可</li><li>为了避免 deviceID 冲突，重新生成 devInfo.ID</li><li>根据设备类别，初始化对应的设备<ol><li>如果 devInfo.HostPath 为 &#x2F;dev&#x2F;vfio&#x2F;xxx（排除 &#x2F;dev&#x2F;vfio&#x2F;vfio 字符设备），则视为 vfio 设备类型</li><li>如果 devInfo.DevType 为 b，并且 devInfo.Major 为 241，则视为 vhost-user-blk 设备类型</li><li>如果 devInfo.DevType 为 b，则视为 block 设备类型（也就是 devInfo.Major 不为 241）</li><li>除此之外，均视为 generic 设备类型（也就是 vhost-user-fs、vhost-user-net 和 vhost-user-scsi 设备均为此类型）</li></ol></li><li>调用 device 的 <strong>Reference</strong>，维护设备的引用计数</li><li>维护 deviceManager 中的设备信息，其中 key 为调用 device 的 <strong>DeviceID</strong> 获得，后续用于判断设备是否已经创建</li></ol><h2 id="RemoveDevice"><a href="#RemoveDevice" class="headerlink" title="RemoveDevice"></a>RemoveDevice</h2><p><strong>移除维护的设备信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/manager/manager.go#L147">source code</a></p><ol><li>校验设备是否已经创建</li><li>调用 device 的 <strong>Dereference</strong>，移除引用</li><li>如果移除后引用为 0，则并调用 device 的 <strong>GetAttachCount</strong>，校验当前设备 attach 次数是否为 0，移除维护在 deviceManager 的设备信息</li></ol><h2 id="AttachDevice"><a href="#AttachDevice" class="headerlink" title="AttachDevice"></a>AttachDevice</h2><p><strong>attach 设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/manager/manager.go#L181">source code</a></p><ol><li>校验设备是否已经创建</li><li>调用 device 的 <strong>Attach</strong>，attach 设备</li></ol><h2 id="DetachDevice"><a href="#DetachDevice" class="headerlink" title="DetachDevice"></a>DetachDevice</h2><p><strong>detach 设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/manager/manager.go#L196">source code</a></p><ol><li>校验设备是否已经创建</li><li>调用 device 的 <strong>GetAttachCount</strong>，校验当前设备 attach 次数是否不为 0</li><li>调用 device 的 <strong>Detach</strong>，detach 设备</li></ol><h2 id="LoadDevices"><a href="#LoadDevices" class="headerlink" title="LoadDevices"></a>LoadDevices</h2><p><strong>加载设备信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/device/manager/manager.go#L244">source code</a></p><ol><li>遍历入参 []config.DeviceState 中每一个设备信息，根据其类型初始化对应的 device 对象</li><li>调用 device 的 <strong>Load</strong>，加载设备</li><li>维护 deviceManager 中的设备信息，其中 key 为调用 device 的 <strong>DeviceID</strong> 获得，后续用于判断设备是否已经创建</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 DeviceReceiver、Device、DeviceManager 等设备管理相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/factory</title>
    <link href="http://shenxianghong.github.io/2023/03/12/2023-03-12%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20factory/"/>
    <id>http://shenxianghong.github.io/2023/03/12/2023-03-12%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20factory/</id>
    <published>2023-03-11T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.271Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="Factory"><a href="#Factory" class="headerlink" title="Factory"></a>Factory</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;factory.go</u></em></p><p>Factory 继承自 FactoryBase，两者的区别在于 FactoryBase 用于创建 base VM（即为模版 VM），创建后会将其暂停，而 Factory 会在 VM 使用时将其恢复，并热更新 VM 以满足运行时的规格要求。</p><p>FactoryBase 有四种实现：direct、template、grpccache 和 cache。但是它们并不会对外暴露使用，而是在 Factory 的工厂函数中根据具体的配置细节初始化对应的实现，作为统一的 Factory 对外提供接口调用，即 factory。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> direct <span class="keyword">struct</span> &#123;</span><br><span class="line">config vc.VMConfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> grpccache <span class="keyword">struct</span> &#123;</span><br><span class="line">conn   *grpc.ClientConn</span><br><span class="line">config *vc.VMConfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> template <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// [factory].template_path，默认为 /run/vc/vm/template</span></span><br><span class="line">statePath <span class="type">string</span></span><br><span class="line"></span><br><span class="line">config vc.VMConfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> cache <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// cache factory 的初始化必须基于 template factory 或者 direct factory。</span></span><br><span class="line">base base.FactoryBase</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于维护创建的 VM 模板</span></span><br><span class="line">vmm <span class="keyword">map</span>[*vc.VM]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">cacheCh   <span class="keyword">chan</span> *vc.VM</span><br><span class="line">closed    <span class="keyword">chan</span>&lt;- <span class="type">int</span></span><br><span class="line">wg        sync.WaitGroup</span><br><span class="line">closeOnce sync.Once</span><br><span class="line">vmmLock   sync.RWMutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// VMConfig is a collection of all info that a new blackbox VM needs.</span></span><br><span class="line"><span class="keyword">type</span> VMConfig <span class="keyword">struct</span> &#123;</span><br><span class="line">HypervisorType   HypervisorType</span><br><span class="line">AgentConfig      KataAgentConfig</span><br><span class="line">HypervisorConfig HypervisorConfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>VMConfig 针对 VM factory 场景下，聚合的配置文件中的相关信息。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> factory <span class="keyword">struct</span> &#123;</span><br><span class="line">base base.FactoryBase</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>工厂函数</strong></p><p><em>目前来看，grpccache 初始化的条件应该不存在。此外，当启用 VM factory 时，必然是 VM template 和 VM cache 二选一，所以 direct 不会作为 factory 直接对外使用，而是进一步初始化成 cache factory。</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/factory.go#L51">source code</a></p><ol><li>校验 VMConfig 配置的合法性，其中包括 [hypervisor].kernel 是否不为空，[hypervisor].image 和 [hypervisor].initrd 有且仅有一个。并设置 [hypervisor].default_vcpus 缺省时为 1（单位：Core），[hypervisor].default_memory 缺省时为 2048（单位：MiB）</li><li>当启用 VM template 时（即 [factory].enable_template 为 true），则初始化 template factory<ol><li>如果 fetchOnly 为 true，则校验 [factory].template_path 目录（默认为 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;template）下是否存在 state 和 memory 文件</li><li>如果 fetchOnly 为 false，则初始化 template factory<ol><li>校验 [factory].template_path 目录下是否不存在 state 和 memory 文件</li><li>创建 [factory].template_path 目录，将 tmps 挂载到此目录下，大小为 [hypervisor].default_memory + 8 MiB（amd64 架构下为 8 MiB；arm64 架构下为 300 MiB），并在此目录下创建 memory 文件</li><li>调用 <strong>NewVM</strong>，基于 VMConfig 创建 VM（创建后则作为模版 VM）</li><li>调用 agent 的 <strong>disconnect</strong>，断开与 agent 的链接</li><li>调用 hypervisor 的 <strong>PauseVM</strong>，暂停 VM</li><li>调用 hypervisor 的 <strong>SaveVM</strong>，保存 VM 到磁盘文件</li><li>调用 hypervisor 的 <strong>StopVM</strong>，关停 VM</li><li>调用 store 的 <strong>Destroy</strong>，删除状态数据目录</li></ol></li></ol></li><li>当启用 VM cache 时（即 [factory].vm_cache_number 大于 0），则初始化 cache factory<ol><li>初始化 direct factory（cache factory 的初始化必须依赖其他 factory）</li><li>反复调用 <strong>GetBaseVM</strong>（direct.GetBaseVM），直至创建暂停状态的 VM 数量等于 [factory].vm_cache_number</li><li>将这些事先创建好的 base VM 维护在 cache 中<br>*后续需要时通过 <strong>GetBaseVM</strong>（cache.GetBaseVM），获取 base VM，并通过 <strong>GetVM</strong> 热更新*</li></ol></li></ol><h2 id="NewVM"><a href="#NewVM" class="headerlink" title="NewVM"></a>NewVM</h2><p><strong>基于 VMConfig 创建 VM</strong></p><p><em>NewVM 并非 FactoryBase 定义接口，而是 virtcontainers 提供的一个基于 VMConfig 创建 VM 的工厂函数，仅用于 factory 相关流程</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/vm.go#L85">source code</a></p><ol><li>校验 VMConfig 配置的合法性，其中包括 [hypervisor].kernel 是否不为空，[hypervisor].image 和 [hypervisor].initrd 有且仅有一个。并设置 [hypervisor].default_vcpus 缺省时为 1，[hypervisor].default_memory 缺省时为 2048</li><li>初始化 hypervisor 和 agent</li><li>调用 hypervisor 的 <strong>CreateVM</strong>，创建一个不含网络信息的 VM</li><li>调用 agent 的 <strong>configure</strong> 和 <strong>setAgentURL</strong>，配置 agent 相关信息</li><li>调用 hypervisor 的 <strong>StartVM</strong>，启动 VM</li><li>如果 VM 不是从 template 启动（因为从 template 启动的 VM，会进入 pause 状态），则调用 agent 的 <strong>check</strong>，检测服务存活性</li></ol><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><p><strong>获取 base factory 的配置信息</strong></p><p><em>cache、direct、grpccache 和 template 实现方式相同。</em> </p><ol><li>返回 VMConfig</li></ol><h2 id="GetVMStatus"><a href="#GetVMStatus" class="headerlink" title="GetVMStatus"></a>GetVMStatus</h2><p><strong>获取 base VM 的状态信息</strong></p><p><em>direct、grpccache 和 template 实现下均不支持此接口，会触发 panic。</em></p><h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/cache/cache.go#L98">source code</a></p><ol><li>针对 cache 中缓存的每一个 VM，获取其 CPU 和内存大小（即配置中声明的默认大小），并调用 hypervisor 的 <strong>GetPids</strong>，获取相关的 PID</li></ol><h2 id="GetBaseVM"><a href="#GetBaseVM" class="headerlink" title="GetBaseVM"></a>GetBaseVM</h2><p><strong>获取 base VM</strong></p><h3 id="direct"><a href="#direct" class="headerlink" title="direct"></a>direct</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/direct/direct.go#L32">source code</a></p><ol><li>调用 <strong>NewVM</strong>，创建 VM</li><li>调用 hypervisor 的 <strong>PauseVM</strong>，将其暂停并返回</li></ol><h3 id="template"><a href="#template" class="headerlink" title="template"></a>template</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/template/template.go#L76">source code</a></p><ol><li>调用 <strong>NewVM</strong>，创建 VM（该 VM 基于模版创建，创建后不作为模版 VM）</li></ol><h3 id="grpccache"><a href="#grpccache" class="headerlink" title="grpccache"></a>grpccache</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/grpccache/grpccache.go#L53">source code</a></p><ol><li>gRPC 调用 cache server 的 <strong>GetBaseVM</strong>，获取 VM</li><li>调用 hypervisor 的 <strong>fromGrpc</strong>，配置 hypervisor 信息</li><li>调用 agent 的 <strong>configureFromGrpc</strong>，配置 agent 信息</li><li>基于配置后的 hypervisor、agent 和 gRPC 返回体构建并返回 VM</li></ol><h3 id="cache-1"><a href="#cache-1" class="headerlink" title="cache"></a>cache</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/cache/cache.go#L112">source code</a></p><ol><li>从缓存的 base VM 中返回一个</li></ol><h2 id="CloseFactory"><a href="#CloseFactory" class="headerlink" title="CloseFactory"></a>CloseFactory</h2><p><strong>关闭并销毁 factory</strong></p><p><em>direct、grpccache 实现下此接口不做任何处理，直接返回即可。</em></p><h3 id="template-1"><a href="#template-1" class="headerlink" title="template"></a>template</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/template/template.go#L81">source code</a></p><ol><li>移除 [factory].template_path 挂载点（默认为 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;template），并删除此目录</li></ol><h3 id="cache-2"><a href="#cache-2" class="headerlink" title="cache"></a>cache</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/cache/cache.go#L121">source code</a></p><ol><li>调用 base factory 的 <strong>ClostFactory</strong>，关闭 factory<br><em>如上所述，cache factory 也就是调用 direct factory 的 CloseFactory</em></li></ol><h2 id="GetVM"><a href="#GetVM" class="headerlink" title="GetVM"></a>GetVM</h2><p><strong>热更新 base VM 以满足需求</strong></p><p><em>GetVM 不是 base factory 的接口，而是 factory 的接口<br>GetVM 接受一个 VMConfig 类型的参数，该参数描述了预期的 VM 配置（下称 newConfig），而 factory 实现中的 VMConfig 是 base VM 的配置（下称 baseConfig），两者的差异点补齐便是 GetVM 操作的核心逻辑</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/factory/factory.go#L145">source code</a></p><ol><li>校验 newConfig 配置的合法性，其中包括 [hypervisor].kernel 是否不为空，[hypervisor].image 和 [hypervisor].initrd 有且仅有一个。并设置 [hypervisor].default_vcpus 缺省时为 1，[hypervisor].default_memory 缺省时为 2048</li><li>调用 <strong>Config</strong>，获取 baseConfig 信息，校验两个配置信息是否并不冲突</li><li>调用 <strong>GetBaseVM</strong>，获取 base VM</li><li>调用 hypervisor 的 <strong>ResumeVM</strong>，将 VM 从暂停状态恢复</li><li>借助 &#x2F;dev&#x2F;urandom 重新生成随机熵，调用 agent 的 <strong>reseedRNG</strong>，为 guest 内存重新生成随机数</li><li>为了补齐 VM 的暂停时间，调用 agent 的 <strong>setGuestDateTime</strong>，同步 host 时间至 guest 中</li><li>如果 base VM 中的 CPU 数量小于期望配置中的 CPU 数量，则调用 hypervisor 的 <strong>HotplugAddDevice</strong>，热添加差值 CPU；内存同理</li><li>当有 CPU 或内存的热添加动作后，调用 agent 的 <strong>onlineCPUMem</strong>，通知 agent 上线资源</li></ol><h1 id="Cache-Server"><a href="#Cache-Server" class="headerlink" title="Cache Server"></a>Cache Server</h1><p><em><u>src&#x2F;runtime&#x2F;protocols&#x2F;cachecache.pb.go</u></em></p><p>cache server 并非默认启动的 gRPC 服务，而是在 VM Cache 特性启用时，通过 kata-runtime factory init 命令启动。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> cacheServer <span class="keyword">struct</span> &#123;</span><br><span class="line">rpc     *grpc.Server</span><br><span class="line">factory vc.Factory</span><br><span class="line">done    <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>启动函数</strong></p><p> <a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L148">source code</a></p><ol><li>基于配置，初始化一个新的 factory（即 fetchOnly 为 false）</li><li>启动 gRPC 服务，监听 [factory].vm_cache_endpoint 地址（默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock）</li></ol><h2 id="Config-1"><a href="#Config-1" class="headerlink" title="Config"></a>Config</h2><p><strong>获取 base factory 的配置信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L54">source code</a></p><ol><li><p>返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> GrpcVMConfig <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// VMConfig</span></span><br><span class="line">Data                 []<span class="type">byte</span></span><br><span class="line"><span class="comment">// VMConfig.AgentConfig </span></span><br><span class="line">AgentConfig          []<span class="type">byte</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 factory 的 <strong>Config</strong>，获取 base factory 的配置信息<br><em>由于 base factory 在 cache server 启动后便固定规格，因此在首次调用后，会保存配置信息，之后的调用直接返回即可</em></p></li></ol><h2 id="GetBaseVM-1"><a href="#GetBaseVM-1" class="headerlink" title="GetBaseVM"></a>GetBaseVM</h2><p><strong>获取 base VM</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L69">source code</a></p><ol><li><p>返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> GrpcVM <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// VM.id</span></span><br><span class="line">Id                   <span class="type">string</span></span><br><span class="line"><span class="comment">// VM.hypervisor.toGrpc</span></span><br><span class="line">Hypervisor           []<span class="type">byte</span></span><br><span class="line">ProxyPid             <span class="type">int64</span></span><br><span class="line">ProxyURL             <span class="type">string</span></span><br><span class="line"><span class="comment">// VM.cpu</span></span><br><span class="line">Cpu                  <span class="type">uint32</span></span><br><span class="line"><span class="comment">// VM.memory</span></span><br><span class="line">Memory               <span class="type">uint32</span></span><br><span class="line"><span class="comment">// VM.cpuDelta</span></span><br><span class="line">CpuDelta             <span class="type">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 factory 的 <strong>Config</strong>，获取 base factory 的配置信息</p></li><li><p>调用 factory 的 <strong>GetBaseVM</strong>，获取 base VM</p></li></ol><h2 id="Status"><a href="#Status" class="headerlink" title="Status"></a>Status</h2><p><strong>获取 base VM 的状态信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L95">source code</a></p><ol><li><p>返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> GrpcStatus <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 当前进程的 PID</span></span><br><span class="line">Pid                  <span class="type">int64</span></span><br><span class="line"><span class="comment">// factory.GetVMStatus 的返回结果</span></span><br><span class="line">Vmstatus             []*GrpcVMStatus</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 factory 的 <strong>GetVMStatus</strong>，获取 base VM 的状态信息</p></li></ol><h2 id="Quit"><a href="#Quit" class="headerlink" title="Quit"></a>Quit</h2><p><strong>关闭 cache server</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L86">source code</a></p><ol><li>1 秒钟后，关闭 cache gRPC server</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 Factory、CacheServer 等工厂模式相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers/storage</title>
    <link href="http://shenxianghong.github.io/2023/03/05/2023-03-05%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20storage/"/>
    <id>http://shenxianghong.github.io/2023/03/05/2023-03-05%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers%20storage/</id>
    <published>2023-03-04T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.270Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="PersistDriver"><a href="#PersistDriver" class="headerlink" title="PersistDriver"></a>PersistDriver</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;persist&#x2F;api&#x2F;interface.go</u></em></p><p>PersistDriver（也称 store）的实现有两类：fs 和 rootless，其中 rootlessfs driver 完全继承 fs driver。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> FS <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 包括两种，fs 和 rootless，区别在于当前是否为 root 用户权限</span></span><br><span class="line">driverName <span class="type">string</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// - fs：/run/vc</span></span><br><span class="line"><span class="comment">// - rootless：&lt;XDG_RUNTIME_DIR&gt;/run/vc（XDG_RUNTIME_DIR 默认为 /run/user/&lt;UID&gt;</span></span><br><span class="line"><span class="comment">// 用于保存 sandbox（sbs，其中容器信息以子目录形式保存）和 VM（vm）相关状态信息</span></span><br><span class="line">storageRootPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 内存状态数据，用于内存数据和文件数据的持久化转换</span></span><br><span class="line">sandboxState   *persistapi.SandboxState</span><br><span class="line">containerState <span class="keyword">map</span>[<span class="type">string</span>]persistapi.ContainerState</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RootlessFS <span class="keyword">struct</span> &#123;</span><br><span class="line">*FS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>以下接口 fs 和 rootlessfs 实现方式完全一样。</em></p><h2 id="ToDisk"><a href="#ToDisk" class="headerlink" title="ToDisk"></a>ToDisk</h2><p><strong>保存 sandbox 和容器状态信息到文件中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L77">source code</a></p><ol><li>以当前用户组信息创建 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录（如果不存在）</li><li>创建 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt;&#x2F;persist.json 文件（如果不存在），写入 sandbox 状态信息</li><li>遍历所有的容器状态信息<ol><li>以当前用户组信息创建 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt;&#x2F;&lt;containerID&gt; 目录（如果不存在）</li><li>创建 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt;&#x2F;&lt;containerID&gt;&#x2F;persist.json 文件（如果不存在），写入容器状态信息</li></ol></li><li>遍历 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录（目录下的所有子目录名称均为 containerID），由于步骤 3 中为当前全量的容器状态信息，以此为准移除不存在的容器目录</li></ol><h2 id="FromDisk"><a href="#FromDisk" class="headerlink" title="FromDisk"></a>FromDisk</h2><p><strong>读取写入文件中的 sandbox 和容器状态信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L170">source code</a></p><ol><li>读取 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt;&#x2F;persist.json 文件内容，获取 sandbox 状态信息</li><li>遍历 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录（目录下的所有子目录名称均为 containerID），读取 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt;&#x2F;&lt;containerID&gt;&#x2F;persist.json 文件内容，获取容器状态信息</li></ol><h2 id="Destroy"><a href="#Destroy" class="headerlink" title="Destroy"></a>Destroy</h2><p><strong>删除 sandbox 状态信息目录</strong></p><p><em>因为 sandbox 和容器状态信息目录之间为父子目录关系，删除父目录即可</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L228">source code</a></p><ol><li>删除 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录</li></ol><h2 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h2><p><strong>对 sandbox 状态信息目录上锁</strong></p><p><em>因为 sandbox 和容器状态信息目录之间为父子目录关系，对父目录上锁即可</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L244">source code</a></p><ol><li>调用 syscall.Flock，对 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录上共享锁或排他锁（根据函数传参而定）</li><li>返回一个调用 syscall.Flock 的函数体，对 &lt;RunStoragePath&gt;&#x2F;&lt;sandboxID&gt; 目录释放锁（即 syscall.LOCK_UN）</li></ol><h2 id="GlobalWrite"><a href="#GlobalWrite" class="headerlink" title="GlobalWrite"></a>GlobalWrite</h2><p><strong>在状态信息目录中的文件写入内容</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L282">source code</a></p><ol><li>以当前用户组信息创建 &lt;storageRootPath&gt;&#x2F;&lt;relativePath&gt; （relativePath 为函数传参中的待写入内容的相对路径）所在目录（如果不存在）</li><li>创建 &lt;storageRootPath&gt;&#x2F;&lt;relativePath&gt; 文件，写入数据</li></ol><h2 id="GlobalRead"><a href="#GlobalRead" class="headerlink" title="GlobalRead"></a>GlobalRead</h2><p><strong>读取状态信息目录中的文件内容</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L315">source code</a></p><ol><li>读取 &lt;storageRootPath&gt;&#x2F;&lt;relativePath&gt; 文件内容</li></ol><h2 id="RunStoragePath"><a href="#RunStoragePath" class="headerlink" title="RunStoragePath"></a>RunStoragePath</h2><p><strong>获取 sandbox 状态信息目录</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L337">source code</a></p><ol><li>返回 &lt;storageRootPath&gt;&#x2F;sbs 路径</li></ol><h2 id="RunVMStoragePath"><a href="#RunVMStoragePath" class="headerlink" title="RunVMStoragePath"></a>RunVMStoragePath</h2><p><strong>获取 vm 状态信息目录</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/persist/fs/fs.go#L341">source code</a></p><ol><li>返回 &lt;storageRootPath&gt;&#x2F;vm 路径</li></ol><h1 id="FilesystemSharer"><a href="#FilesystemSharer" class="headerlink" title="FilesystemSharer"></a>FilesystemSharer</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;fs_share.go</u></em></p><p>FilesystemSharer（也称 fsSharer）仅有 linux 操作系统下的实现。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> FilesystemShare <span class="keyword">struct</span> &#123;</span><br><span class="line">sandbox *Sandbox</span><br><span class="line">sync.Mutex</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 表示文件系统是否准备就绪，在调用 Prepare 后，设置为 true</span></span><br><span class="line">prepared <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="bindMount"><a href="#bindMount" class="headerlink" title="bindMount"></a>bindMount</h2><p><strong>将 src 绑定挂载到 dst</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/mount.go#L257">source code</a></p><ol><li>处理 src 中的符号链接，获得绝对路径，校验其是否存在</li><li>创建 dst 的父目录（如果不存在）</li><li>根据 src 的格式（目录或文件），创建 dst</li><li>将 src 以 MS_BIND 的属性绑定挂载到 dst 下<br><em>等价于 mount –bind foo bar，也就是把 foo 目录绑定挂载到 bar 目录，bar 目录为 foo 目录的镜像挂载点。绑定后的两个目录类似于硬链接，无论读写 bar 还是读写 foo，都会反应在另一方，内核在底层所操作的都是同一个物理位置。将 bar 卸载后，bar 目录回归原始空目录状态，期间所执行的修改都保留在 foo 目录下</em></li><li>更改 dst 目录挂载属性（即 MS_SHARED、MS_PRIVATE、MS_SLAVE 和 MS_UNBINDABLE）<br><em>等价于 mount –make-slave bar，也可以和步骤 4 合并操作 mount –make-slave –bind foo bar。单向传播模式下，在 foo 下添加或移除子挂载点，会同步到 bar 挂载点，而在 bar 下添加或移除子挂载点，不会影响 foo</em></li><li>如果挂载为只读属性，则追加至绑定挂载属性中<br><em>等价于 mount –read-only –bind foo bar</em></li></ol><h2 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h2><p><strong>准备 host&#x2F;guest 的共享文件系统目录</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L127">source code</a></p><ol><li>创建 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;shared 目录（用于 9p&#x2F;virtiofs 在 host 和 guest 之间共享数据）</li><li>创建 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts 目录（用于维护所有 host 和 guest 之间的挂载点）</li><li>调用 <strong>bindMount</strong>，将 mounts 目录以只读和 MS_SLAVE 的属性绑定挂载到 shared 目录下（为了后面 mounts 挂载点下的子挂载也能出现在 shared 中）</li><li>处理 [runtime]. sandbox_bind_mounts 挂载点<ol><li>创建 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;sandbox-mounts 目录</li><li>针对 sandbox_bind_mounts 目录中的每一个挂载点，调用 <strong>bindMount</strong>，以只读和 MS_PRIVATE 的属性绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;sandbox-mounts&#x2F;&lt;sandbox_bind_mounts&gt; 中，并追加 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;shared&#x2F;sandbox-mounts&#x2F;&lt;sandbox_bind_mounts&gt; 绑定挂载的只读属性</li></ol></li><li>设置 prepared 为 true，表示共享文件系统已就绪（标识位也用于保证 Prepare 和 Cleanup 操作的幂等性）</li></ol><h2 id="Cleanup"><a href="#Cleanup" class="headerlink" title="Cleanup"></a>Cleanup</h2><p><strong>清理 host&#x2F;guest 的共享文件系统目录</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L180">source code</a></p><ol><li>处理 [runtime]. sandbox_bind_mounts 挂载点<ol><li>针对 sandbox_bind_mounts 目录中的每一个挂载点，移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;sandbox-mounts&#x2F;&lt;sandbox_bind_mounts&gt; 挂载点</li><li>删除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;sandbox-mounts 目录</li></ol></li><li>移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;shared 挂载点</li><li>移除 sandbox 中所有容器的挂载点。如果容器 rootfs 的类型为 fuse.nydus-overlayfs，则移除 &#x2F;rafs&#x2F;&lt;containerID&gt;&#x2F;lowerdir virtiofs 挂载点，移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;snapshotdir 挂载点并删除此目录，删除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 目录（该目录和 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs 数据同步，借助 9pfs&#x2F;virtiofs 实现容器文件系统共享，在 host 上以 overlay 挂载点形式存在）；否则，移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 挂载点并删除此目录</li><li>删除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt; 目录</li></ol><h2 id="ShareFile"><a href="#ShareFile" class="headerlink" title="ShareFile"></a>ShareFile</h2><p><strong>共享 host 文件至 guest 中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L227">source code</a></p><ol><li>共享文件（shareFile）名称格式为 &lt;containerID&gt;-&lt;random bytes&gt;-&lt;dst&gt;<br><em>例如：&lt;containerID&gt;-47dcc9007bca8805-hostname</em></li><li>调用 hypervisor 的 <strong>Capabilities</strong>，判断是否支持 host 文件系统共享特性（QEMU 场景下支持）<ul><li>如果不支持，则通过文件拷贝实现共享<ol><li>校验 src 是否存在。如果 src 非常规文件，则不做处理（这里并未视为错误，而是作为一种局限性将其忽略）</li><li>调用 agent 的 <strong>copyFile</strong>，将 src 文件拷贝至 sandbox 的 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;containers&#x2F;&lt;shareFile&gt; 文件位置</li></ol></li><li>如果支持，则通过文件挂载实现共享<ol><li>如果挂载为读写属性，则调用 <strong>bindMount</strong>，将 src 以读写和 MS_PRIVATE 的属性绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;shareFile&gt;</li><li>否则，调用 <strong>bindMount</strong>，将 src 以只读和 MS_PRIVATE 的属性绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;private&#x2F;&lt;shareFile&gt;，进而调用 <strong>bindMount</strong>，将 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;private&#x2F;&lt;shareFile&gt; 以读写和 MS_PRIVATE 的属性绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;shareFile&gt;<br><em>对于只读挂载，bindMount 重新挂载事件不会传播到挂载子树，并且它也不会出现在 virtiofsd 独立挂载命名空间中</em></li><li>设置挂载信息的 host 侧路径为 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;shareFile&gt;</li></ol></li></ul></li></ol><h2 id="UnshareFile"><a href="#UnshareFile" class="headerlink" title="UnshareFile"></a>UnshareFile</h2><p><strong>移除 host&#x2F;guest 共享文件的挂载点</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L296">source code</a></p><ol><li>移除挂载信息的 host 侧挂载点</li><li>如果挂载类型为 bind，校验 host 侧挂载点文件是否存在。如果为常规文件且为空，则直接删除；如果为目录，则移除目录</li></ol><h2 id="ShareRootFilesystem"><a href="#ShareRootFilesystem" class="headerlink" title="ShareRootFilesystem"></a>ShareRootFilesystem</h2><p><strong>创建 guest 中容器 rootfs 共享挂载</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L373">source code</a></p><ol><li>如果 rootfs 类型为 fuse.nydus-overlayfs<ol><li>通过 virtiofsd 挂载 &#x2F;rafs&#x2F;&lt;containerID&gt;&#x2F;lowerdir 目录至 guest 中</li><li>创建 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 目录</li><li>调用 <strong>bindMount</strong>，将 rootfs 挂载参数中的 snapshotdir 目录以只读和 MS_SLAVE 的属性绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;snapshotdir</li><li>挂载类型仍为联合文件系统的 overlay 形式</li></ol></li><li>如果 rootfs 类型不是 fuse.nydus-overlayfs，并且是基于块设备的 rootfs<ol><li>调用 devManager 的 <strong>GetDeviceByID</strong>，根据容器状态中的信息获取到设备信息</li><li>挂载类型视 [hypervisor].block_device_driver 而定</li><li>创建 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 目录</li></ol></li><li>对于传统的 rootfs（也就是非 fuse.nydus-overlayfs 类型，并且不是基于块设备的），调用 <strong>bindMount</strong>，以读写和 MS_PRIVATE 的属性将 rootfs（例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs）绑定挂载到 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs<br><em>这个目录本身为共享目录，因此无需告知 agent 去挂载，在 host 侧挂载后会自动在 guest 中出现</em></li><li>无论以上哪种挂载形式，最终 guest 中容器 rootfs 的挂载点均为 <XDG_RUNTIME_DIR>&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;containers&#x2F;&lt;containerID&gt;&#x2F;rootfs</li></ol><h2 id="UnshareRootFilesystem"><a href="#UnshareRootFilesystem" class="headerlink" title="UnshareRootFilesystem"></a>UnshareRootFilesystem</h2><p><strong>移除 guest 中容器 rootfs 共享挂载</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/fs_share_linux.go#L455">source code</a></p><ol><li>如果 rootfs 类型为 fuse.nydus-overlayfs<ol><li>通过 virtiofsd 移除 guest 中的 &#x2F;rafs&#x2F;&lt;containerID&gt;&#x2F;lowerdir 挂载点</li><li>移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;snapshotdir 挂载点，并删除目录</li><li>移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 目录</li></ol></li><li>如果 rootfs 类型不是 fuse.nydus-overlayfs，则移除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt;&#x2F;rootfs 挂载点，并删除目录</li><li>删除 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;&lt;sandboxID&gt;&#x2F;mounts&#x2F;&lt;containerID&gt; 目录</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 PersistDriver、FilesystemSharer 等文件存储相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — virtcontainers</title>
    <link href="http://shenxianghong.github.io/2023/01/30/2023-01-30%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers/"/>
    <id>http://shenxianghong.github.io/2023/01/30/2023-01-30%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20virtcontainers/</id>
    <published>2023-01-29T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.270Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><p>virtcontainers 本质上不是独立组件，而是一个用于构建硬件虚拟化容器运行时的 Golang 库。</p><p>现有的少数部分基于 VM 的容器运行时都共享相同的硬件虚拟化语义，但是使用不同的代码库来实现，virtcontainers 的目标就是将这部分封装成一个通用的 Golang 库。</p><p>理想情况下，基于 VM 的容器运行时，会从将它们实现的运行时规范（例如 OCI spec 或 Kubernetes CRI）转换成 virtcontainers API。</p><p>virtcontainers API 大致受到 Kubernetes CRI 的启发。然而，尽管这两个项目之间的 API 相似，但 virtcontainers 的目标不是构建 CRI 实现，而是提供一个通用的、运行时规范不可知的、硬件虚拟化的容器库，其他项目可以利用它来自己实现 CRI。</p><h1 id="VC"><a href="#VC" class="headerlink" title="VC"></a>VC</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;interfaces.go</u></em></p><p>virtcontainers 库的入口模块，VC 初始化 VCSandbox 模块管理 sandbox，进而初始化 VCContainer 模块管理容器。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> VCImpl <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// factory 的具体实现，不为空时表示为 VM factory 场景</span></span><br><span class="line">factory Factory</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>VC 中声明的 <strong>SetLogger</strong> 和 <strong>SetFactory</strong> 均为参数赋值，无复杂逻辑，不作详述。</p><h2 id="CreateSandbox"><a href="#CreateSandbox" class="headerlink" title="CreateSandbox"></a>CreateSandbox</h2><p><strong>创建 sandbox 与 pod_sandbox 容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/implementation.go#L34">source code</a></p><ol><li>创建 sandbox<ol><li>校验 sandboxConfig 的 annotation 中自定义运行时配置（称为 assets ）的合法性并设置<br><em>annotation 例如 io.katacontainers.hypervisor.kernel 为用户上层通过 Pod annotation 定义，CRI 会透传给底层运行时</em></li><li>初始化 VCSandbox，准备所需环境</li><li>如果 sandbox 中状态信息（即 sandbox.state）已经存在，则表明不是新创建的 pod_sandbox 容器，无需后续动作，仅用于状态更新维护，直接返回 sandbox 即可</li><li>调用 fsShare 的 <strong>Prepare</strong>，准备 sandbox 所需的共享文件系统目录</li><li>调用 agent 的 <strong>createSandbox</strong>，准备 sandbox 所需环境</li><li>设置 sandbox 状态为 ready</li></ol></li><li>如果未启用 [runtime].disable_new_netns 并且不是 VM factory 场景（在 VM factory 场景下，网卡是在 VM 启动后热插进去的），则调用 network 的 <strong>AddEndpoints</strong>，添加 netns 中的所有网卡到 VM 中<br><em>netns 要么是 Kata Containers 在运行时创建，要么是 CNI 等外部组件预先创建。总之，此时 netns 已经存在了</em></li><li>调用 resCtrl 的 <strong>setupResourceController</strong>，将当前进程加入 cgroup 中管理</li><li>启动 VM（在 1-2 步骤中的 VCSandbox 初始化流程中，已经创建了 VM）<ol><li>如果 [hypervisor].enable_debug 启用（用于输出  hypervisor 和 kernel 产生的消息），则调用 hypervisor 的 <strong>GetVMConsole</strong>，获取 VM console 地址（&#x2F;run&#x2F;vc&#x2F;vm&#x2F;&lt;sandboxID&gt;&#x2F;console.sock）</li><li>调用 network 的 <strong>Run</strong>，进入到该 netns 中，执行以下逻辑：如果为 VM factory 场景，则获取 factory 中缓存的 VM，调用 agent 的 <strong>reuseAgent</strong>，更新 agent 实例，并创建软链接 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;&lt;sandboxID&gt; 指向 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;&lt;vmID&gt;；否则，调用 hypervisor 的 <strong>StartVM</strong>，启动 VM 进程</li><li>如果为 VM factory 场景，则调用 network 的 <strong>AddEndpoints</strong>，热添加 netns 中的所有网卡到 VM 中</li><li>如果启用 [hypervisor].enable_debug，实时读取 VM console 地址获取其实时内容，并以 debug 级别日志形式输出</li><li>调用 agent 的 <strong>startSandbox</strong></li></ol></li><li>调用 network 的 <strong>Endpoints</strong>，获取 VM 所有的网卡设备，调用 endpoint 的 <strong>NetworkPair</strong>，关闭位于 host 侧的 vhost_net 句柄（即 &#x2F;dev&#x2F;vhost-net）<br><em>截至 Kata 3.0，目前仅对 macvtap 类型的 endpoint 生效</em></li><li>调用 agent 的 <strong>getGuestDetails</strong>，获取如 seccompSupported 等 guest 信息详情，更新至 sandbox 中</li><li>创建 sandbox 中的每一个容器（其实，此时 sandbox 中仅有一个容器，就是 pod_sandbox 容器本身）<ol><li>初始化 VCContainer，准备容器所需环境</li><li>根据 [hypervisor].disable_block_device_use、agent 是否具备使用块设备能力以及 hypervisor 是否允许块设备热插拔，判断是否当前支持块设备，并且容器的 rootfs 类型不是 fuse.nydus-overlayfs，也就是 rootfs 是基于块设备创建的<ol><li>通过 &#x2F;sys&#x2F;dev&#x2F;block&#x2F;&lt;major&gt;-&lt;minor&gt;&#x2F;dm 的存在性，判断是否为 devicemapper 块设备</li><li>如果是 devicemapper 块设备，则调用 devManager 的 <strong>NewDevice</strong>，初始化设备，并调用 devManager 的 <strong>AttachDevice</strong>，热插到 VM 中 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;containers&#x2F;&lt;sandboxID&gt; 路径</li></ol></li><li>针对容器中的每一个设备，调用 devManager 的 <strong>AttachDevice</strong>，attach 到 VM 中</li><li>调用 agent 的 <strong>createContainer</strong>，创建 pod_sandbox 容器</li><li>设置容器状态为 ready</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li><li>更新维护在 sandbox 中的容器信息</li></ol></li><li>调用 <strong>updateResources</strong>，热更新 VM 的资源规格（由于该流程中仅为创建 pod_sandbox，不涉及 pod_container，因此为配置中声明的 [hypervisor].default_vcpus 和 [hypervisor].default_memory）</li><li>调用 resCtrl 的 <strong>resourceControllerUpdate</strong>，更新 sandbox 的 cgroup</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="CleanupContainer"><a href="#CleanupContainer" class="headerlink" title="CleanupContainer"></a>CleanupContainer</h2><p><strong>关停、删除容器并销毁 sandbox 环境</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/implementation.go#L41">source code</a></p><ol><li>调用 store 的 <strong>FromDisk</strong>，读取 sandbox 状态信息</li><li>获取 sandbox 并更新其中的容器（更新的意义在于后续的删除操作以文件内容为准）</li><li>调用 VCSandbox 的 <strong>StopContainer</strong> 和 <strong>DeleteContainer</strong>，关停并删除该容器</li><li>调用 VCSandbox 的 <strong>GetAllContainers</strong>，获取 sandbox 中的所有容器，如果仍大于 0（说明当前 sandbox 仍有容器存在，需要保留 sandbox 环境），否则调用 VCSandbox 的 <strong>Stop</strong>，关停 sandbox，并调用 VCSandbox 的 <strong>Delete</strong>，删除 sandbox</li></ol><h1 id="VCSandbox"><a href="#VCSandbox" class="headerlink" title="VCSandbox"></a>VCSandbox</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;interfaces.go</u></em></p><p>virtcontainers 库中用于管理 sandbox 的模块，同时调用 VCContainer 模块间接管理容器。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sandbox is composed of a set of containers and a runtime environment.</span></span><br><span class="line"><span class="comment">// A Sandbox can be created, deleted, started, paused, stopped, listed, entered, and restored.</span></span><br><span class="line"><span class="keyword">type</span> Sandbox <span class="keyword">struct</span> &#123;</span><br><span class="line">ctx             context.Context</span><br><span class="line">id<span class="type">string</span></span><br><span class="line">sync.Mutex</span><br><span class="line">annotationsLock *sync.RWMutex</span><br><span class="line">wg              *sync.WaitGroup</span><br><span class="line">monitor         *monitor</span><br><span class="line">config          *SandboxConfig</span><br><span class="line">    </span><br><span class="line"><span class="comment">// virtcontainers 中的各类子模块</span></span><br><span class="line">devManager api.DeviceManager</span><br><span class="line">factory    Factory</span><br><span class="line">hypervisor Hypervisor</span><br><span class="line">agent      agent</span><br><span class="line">store      persistapi.PersistDriver</span><br><span class="line">fsShare    FilesystemSharer</span><br><span class="line">network    Network</span><br><span class="line"></span><br><span class="line"><span class="comment">// sandbox 中的 SWAP 设备</span></span><br><span class="line">swapDevices   []*config.BlockDrive</span><br><span class="line"><span class="comment">// sandbox 中的 SWAP 设备总大小</span></span><br><span class="line">swapSizeBytes <span class="type">int64</span></span><br><span class="line"><span class="comment">// sandbox 中的 SWAP 设备数量</span></span><br><span class="line">swapDeviceNum <span class="type">uint</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// host 和 sandbox 的共享卷</span></span><br><span class="line">volumes []types.Volume</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否所有容器共享相同的 sandbox 级别的 PID 命名空间</span></span><br><span class="line">sharePidNs <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于监视 guest console 输出流</span></span><br><span class="line">cw *consoleWatcher</span><br><span class="line"></span><br><span class="line"><span class="comment">// [runtime].sandbox_cgroup_only]，默认为 false</span></span><br><span class="line"><span class="comment">// - false：sandboxController 和 overheadController 同时存在</span></span><br><span class="line"><span class="comment">// - true：仅有 sandboxController，overheadController 为 nil</span></span><br><span class="line">sandboxController  resCtrl.ResourceController</span><br><span class="line">overheadController resCtrl.ResourceController</span><br><span class="line"></span><br><span class="line"><span class="comment">// sandbox 中的容器，Key 为 containerID</span></span><br><span class="line">containers <span class="keyword">map</span>[<span class="type">string</span>]*Container</span><br><span class="line"></span><br><span class="line"><span class="comment">// sandbox 状态信息，包括 cgroup 路径、块设备索引记录等</span></span><br><span class="line">state types.SandboxState</span><br><span class="line"></span><br><span class="line"><span class="comment">// destination 为 /dev/shm，type 为 bind 的挂载点的 source 大小</span></span><br><span class="line">shmSize <span class="type">uint64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// guest 特性，需要调用 agent 接口获得</span></span><br><span class="line"><span class="comment">// guest 是否支持 seccomp 特性</span></span><br><span class="line">seccompSupported  <span class="type">bool</span></span><br><span class="line"><span class="comment">// 是否禁止 VM 关机</span></span><br><span class="line">disableVMShutdown <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>工厂函数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L527">source code</a></p><ol><li>校验 [runtime].experimental 是否为可支持的特性</li><li>初始化 hypervisor、agent、store、fsSharer、devManager 等 virtcontainers 子模块</li><li>初始化 resourceController（[runtime].sandbox_cgroup_only 为 true 表示 Pod 所有的线程全部由 sandboxController 管理；反之，仅 vCPU 线程由 sandboxController 管理，而其余的由 overheadController 管理）<ol><li>获取到 spec.Linux.CgroupsPath（缺省为 &#x2F;vc），如果 cgroup 不是由 systemd 纳管（通过 cgroupPath 格式判断），则最后一级路径新增 kata_ 前缀</li><li>获取 spec.Linux.Resources.Devices 中 &#x2F;dev&#x2F;null 和 &#x2F;dev&#x2F;urandom 设备信息（如果未声明，则构建）</li><li>调用 devManager 的 <strong>GetAllDevices</strong>，获取所有的设备；进一步调用 device 的 <strong>GetHostPath</strong>，获取设备位于 host 上的路径，将其构建成 cgroup 管理形式</li><li>调用 resCtrl 的 <strong>NewSandboxResourceController</strong>，初始化 sandboxController（cgroupPath 为步骤 1 处理后的结果）</li><li>如果 [runtime].sandbox_cgroup_only 为 false，则调用 resCtrl 的 <strong>NewResourceController</strong>，初始化 overheadController （cgroupPath 为 &#x2F;kata_overhead&#x2F;&lt;sandboxID&gt;）</li></ol></li><li>从文件恢复 sandbox 状态信息<ol><li>调用 store 的 <strong>FromDisk</strong>，尝试从文件中恢复 sandbox 状态信息<br><em>当 sandbox 新创建的时候，并没有状态文件，因此必然失败，但是会忽略错误信息</em></li><li>调用 hypervisor 的 <strong>Load</strong>，加载 hypervisor 信息</li><li>调用 devManager 的 <strong>LoadDevices</strong>，加载设备信息</li><li>调用 agent 的 <strong>load</strong>，加载 agent 信息</li><li>调用 endpoint 的 <strong>load</strong>，加载网络 endpoint 信息</li></ol></li><li>校验 sandboxConfig 中的 hypervisor 配置的合法性，其中包括 [hypervisor].kernel 是否不为空，[hypervisor].image 和 [hypervisor].initrd 有且仅有一个。并设置 [hypervisor].default_vcpus 缺省时为 1，[hypervisor].default_memory 缺省时为 2048</li><li>调用 hypervisor 的 <strong>CreateVM</strong>，创建 VM</li><li>调用 agent 的 <strong>init</strong>，准备 agent 环境</li></ol><p>VCSandbox 中声明的 <strong>Annotations</strong>、<strong>GetNetNs</strong>、<strong>GetAllContainers</strong>、<strong>GetAnnotations</strong>、<strong>GetContainer</strong>、<strong>ID</strong> 和 <strong>SetAnnotations</strong> 均为参数获取与赋值，无复杂逻辑，不作详述。</p><h2 id="updateResources"><a href="#updateResources" class="headerlink" title="updateResources"></a>updateResources</h2><p><strong>热更新 VM 的资源规格</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1966">source code</a></p><ol><li><p>如果 [runtime].static_sandbox_resource_mgmt 启用时（Kata 将在启动虚拟机之前确定合适的 sandbox 内存和 CPU 大小，而非动态更新。 作为 hypervisor 不支持 CPU、内存热插拔时的解决方案），则不触发更新操作，直接返回</p></li><li><p>计算 sandbox 中所有状态非 stopped 容器的 CPU 、内存和 SWAP 总量（前提是 [hypervisor].enable_guest_swap 开启，并且 memory.swappiness 大于 0，才会考虑 SWAP 资源），加上基础 VM 大小，得出最后预期的 VM 大小，公式为</p><blockquote><p>CPU &#x3D; (C1.cpu-quota * 1000 &#x2F; C1.cpu-period + 999) &#x2F; 1000 + C2… + [hypervisor].default_vcpus</p><p>MEM &#x3D; C1.memory-limit + C1.hugepages-limit + C2… + [hypervisor].default_memory</p><p>SWAP &#x3D; </p><table><thead><tr><th><code>swap_in_bytes</code></th><th><code>memory_limit_in_bytes</code></th><th>swap size</th></tr></thead><tbody><tr><td>set</td><td>set</td><td><code>io.katacontainers.container.resource.swap_in_bytes</code>- <code>memory_limit_in_bytes</code></td></tr><tr><td>not set</td><td>set</td><td><code>memory_limit_in_bytes</code></td></tr><tr><td>not set</td><td>not set</td><td><code>io.katacontainers.config.hypervisor.default_memory</code></td></tr><tr><td>set</td><td>not set</td><td>cgroup doesn’t support this usage</td></tr></tbody></table></blockquote><p><em>截至 Kata 3.0，在 K8s 场景下，SWAP 功能仍存在异常：参考 <a href="https://github.com/kata-containers/kata-containers/issues/5627">https://github.com/kata-containers/kata-containers/issues/5627</a></em></p></li><li><p>如果预期 SWAP 比当前 sandbox 的 SWAP 多，则需要新增一个大小为两者差值的 SWAP 文件</p><ol><li>创建 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;swap&lt;ID&gt; 文件（sandbox 中的 SWAP 序号从 0 递增）</li><li>调整文件的大小为差值和 10 倍内存分页中最大值（小于 10 倍内页分页的 SWAP 会被 mkswap 拒绝：mkswap: error: swap area needs to be at least 40 KiB，内存分页：4096），并额外追加一个内存分页大小（SWAP 文件需要一个内存分页大小储存元数据）</li><li>调用系统命令 mkswap，转换为 SWAP 文件，并构建 raw 格式的块设备类型</li><li>调用 hypervisor 的 <strong>HotplugAddDevice</strong>，热添加 SWAP 文件到 VM 中</li><li>调用 agent 的 <strong>addSwap</strong>，配置 SWAP 文件</li></ol></li><li><p>调用 hypervisor 的 <strong>ResizeVCPUs</strong>，调整 VM CPU 数量</p></li><li><p>如果为新增调整，则调用 agent 的 <strong>onlineCPUMem</strong>，通知 agent 上线热添加部分的 CPU</p></li><li><p>循环调用 hypervisor 的 <strong>GetTotalMemoryMB</strong>，获取当前 VM 的内存数量，比对预期 VM 的内存数量，在不超出最大热添加内存数量限制的前提下（部分场景下，例如 ACPI 热插拔，内存的单次热添加有最大数量限制；而在 virtio-mem 下，即 [hypervisor].enable_virtio_mem 启用， 且 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;overcommit_memory 文件内容为 1，则没有最大热添加数量限制），调用 hypervisor 的 <strong>ResizeMemory</strong>，分批热添加 VM 内存</p></li><li><p>调用 agent 的 <strong>memHotplugByProbe</strong>，通知 agent 内存热插事件（如果 guest 内核支持内存热添加探测），并调用 agent 的 <strong>onlineCPUMem</strong>，通知 agent 上线热添加部分的内存</p></li></ol><h2 id="Stats"><a href="#Stats" class="headerlink" title="Stats"></a>Stats</h2><p><strong>获取 sandbox 的统计信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1547">source code</a></p><ol><li>调用 sandboxController 的 <strong>Stat</strong>，获取 sandbox 全部的 cgroup 统计信息（截至当前，并未聚合 kata_overhead 的统计信息，即 overheadController 部分）</li><li>调用 hypervisor 的 <strong>GetThreadIDs</strong>，获取 hypervisor 使用的 CPU 数量</li><li>聚合以上信息并返回</li></ol><h2 id="Start"><a href="#Start" class="headerlink" title="Start"></a>Start</h2><p><strong>启动 sandbox 与 pod_sandbox 容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1662">source code</a></p><ol><li>校验 sandbox 状态是否为 ready、paused 或 stopped</li><li>设置 sandbox 状态为 running</li><li>针对 sandbox 中的每一个容器，调用 VCContainer 的 <strong>start</strong>，启动容器（其实，此时 sandbox 中仅有一个容器，就是 pod_sandbox 容器本身）</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="Stop"><a href="#Stop" class="headerlink" title="Stop"></a>Stop</h2><p><strong>关停 sandbox 与容器，并清理相关资源</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1687">source code</a></p><ol><li>如果 sandbox 状态已经为 stopped，则不做任何操作</li><li>校验 sandbox 状态是否为 ready、running 或者 paused</li><li>针对 sandbox 中的每一个容器，调用 VCContainer 的 <strong>stop</strong>，关停容器</li><li>调用 agent 的 <strong>stopSandbox</strong>，关停 sandbox</li><li>调用 hypervisor 的 <strong>StopVM</strong>，关停 VM</li><li>如果 [hypervisor]. enable_debug 启用，则关闭 VM console</li><li>设置 sandbox 状态为 stopped</li><li>调用 network 的 <strong>RemoveEndpoints</strong>，移除 VM 中的所有网卡</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li><li>调用 agent 的 <strong>disconnect</strong>，关闭与 agent 的连接</li><li>移除 host 上的 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;sandboxes&#x2F;swap&lt;ID&gt; 文件（sandbox 中的 SWAP 序号从 0 递增）</li></ol><h2 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h2><p><strong>销毁 sandbox 与容器，并清理相关资源</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L798">source code</a></p><ol><li>校验 sandbox 的状态是否为 ready、paused 和 stopped</li><li>针对 sandbox 中的每一个容器，调用 VCContainer 的 <strong>delete</strong>，删除容器</li><li>如果在 root 权限下，则调用 resCtrl 的 <strong>resourceControllerDelete</strong>，删除相关的 resourceController 以及 cgroup 资源</li><li>关停 sandbox 的 monitor</li><li>调用 hypervisor 的 <strong>Cleanup</strong>，清理 hypervisor 资源</li><li>调用 fsShare 的 <strong>Cleanup</strong>，清理 sandbox 的共享文件系统</li><li>调用 store 的 <strong>Destroy</strong>，删除状态数据目录</li></ol><h2 id="Status"><a href="#Status" class="headerlink" title="Status"></a>Status</h2><p><strong>获取 sandbox 与容器的详细信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L333">source code</a></p><ol><li>针对 sandbox 中的每一个容器，获取其状态信息（例如：ID、rootfs、状态、启动时间、annotation、PID 等）</li><li>结合 sandbox 的状态信息（例如 ID、状态、hypervisor 类别、hypervisor 配置、annotation 等）返回</li></ol><h2 id="CreateContainer"><a href="#CreateContainer" class="headerlink" title="CreateContainer"></a>CreateContainer</h2><p><strong>创建 pod_container 容器并热更新 sandbox 规格</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1300">source code</a></p><ol><li>初始化 VCContainer，准备容器环境，挂载设备等</li><li>根据 [hypervisor].disable_block_device_use、agent 是否具备使用块设备能力以及 hypervisor 是否允许块设备热插拔，判断是否当前支持块设备，并且容器的 rootfs 类型不是 fuse.nydus-overlayfs，也就是 rootfs 是基于块设备创建的<ol><li>通过 &#x2F;sys&#x2F;dev&#x2F;block&#x2F;&lt;major&gt;-&lt;minor&gt;&#x2F;dm 的存在性，判断是否为 devicemapper 块设备</li><li>如果是 devicemapper 块设备，则调用 devManager <strong>NewDevice</strong>，初始化设备，并调用 devManager 的 <strong>AttachDevice</strong>，热插到 VM 中 &lt;XDG_RUNTIME_DIR&gt;&#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;containers&#x2F;&lt;sandboxID&gt; 路径</li></ol></li><li>针对容器中的每一个设备，调用 devManager 的 <strong>AttachDevice</strong>，热插到 VM 中</li><li>调用 agent 的 <strong>createContainer</strong>，创建 pod_container 容器</li><li>设置容器状态为 ready</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li><li>更新维护在 sandbox 中的容器信息</li><li>调用 <strong>updateResources</strong>，热更新 VM 的资源规格</li><li>调用 resCtrl 的 <strong>resourceControllerUpdate</strong>，更新 sandbox 的 cgroup</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="DeleteContainer"><a href="#DeleteContainer" class="headerlink" title="DeleteContainer"></a>DeleteContainer</h2><p><strong>删除 sandbox 中的指定容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1431">source code</a></p><ol><li>获取 sandbox 中的指定容器，并调用 VCContainer 的 <strong>delete</strong>，删除维护的容器信息</li><li>调用 resCtrl 的 <strong>resourceControllerUpdate</strong>，更新 sandbox 的 cgroup</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="StartContainer"><a href="#StartContainer" class="headerlink" title="StartContainer"></a>StartContainer</h2><p><strong>启动 sandbox 中的 pod_container 容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1364">source code</a></p><ol><li>获取 sandbox 中的指定容器，并调用 VCContainer 的 <strong>start</strong>，启动容器</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li><li>调用 <strong>updateResources</strong>，热更新 VM 的资源信息</li></ol><h2 id="StopContainer"><a href="#StopContainer" class="headerlink" title="StopContainer"></a>StopContainer</h2><p><strong>关停 sandbox 中的指定容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1392">source code</a></p><ol><li>获取 sandbox 中的指定容器，并调用 VCContainer 的 <strong>stop</strong>，关停容器并清理相关资源</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="KillContainer"><a href="#KillContainer" class="headerlink" title="KillContainer"></a>KillContainer</h2><p><strong>杀死 sandbox 中的指定容器进程</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1411">source code</a></p><ol><li>获取 sandbox 中的指定容器，并调用 VCContainer 的 <strong>signalProcess</strong>，发送 kill 信号（理论上是这样，然而并未有真实调用）</li></ol><h2 id="StatusContainer"><a href="#StatusContainer" class="headerlink" title="StatusContainer"></a>StatusContainer</h2><p><strong>获取 sandbox 中指定容器的状态</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1467">source code</a></p><ol><li>获取 sandbox 中的指定容器，获取其状态信息（例如：ID、rootfs、状态、启动时间、annotation、PID 等）</li></ol><h2 id="StatsContainer"><a href="#StatsContainer" class="headerlink" title="StatsContainer"></a>StatsContainer</h2><p><strong>获取 sandbox 中指定容器的统计信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1532">source code</a></p><ol><li>获取 sandbox 中的指定容器，校验其状态是否为 running</li><li>调用 agent 的 <strong>statsContainer</strong>，获取容器状态信息</li></ol><h2 id="PauseContainer"><a href="#PauseContainer" class="headerlink" title="PauseContainer"></a>PauseContainer</h2><p><strong>暂停 sandbox 中的指定容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1576">source code</a></p><ol><li>获取 sandbox 中的指定容器，校验其状态是否为 running</li><li>调用 agent 的 <strong>pauseContainer</strong>，暂停容器</li><li>设置容器状态为 paused</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="ResumeContainer"><a href="#ResumeContainer" class="headerlink" title="ResumeContainer"></a>ResumeContainer</h2><p><strong>恢复 sandbox 中的指定容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1595">source code</a></p><ol><li>获取 sandbox 中的指定容器，校验其状态是否为 running</li><li>调用 agent 的 <strong>resumeContainer</strong>，恢复容器</li><li>设置容器状态为 running</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="EnterContainer"><a href="#EnterContainer" class="headerlink" title="EnterContainer"></a>EnterContainer</h2><p><strong>在 sandbox 中的指定容器中执行命令</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1493">source code</a></p><ol><li>获取 sandbox 中的指定容器，校验其状态是否为 running</li><li>调用 agent 的 <strong>exec</strong>，进入容器执行指定命令</li></ol><h2 id="UpdateContainer"><a href="#UpdateContainer" class="headerlink" title="UpdateContainer"></a>UpdateContainer</h2><p><strong>更新 sandbox 中的指定容器资源规格</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1510">source code</a></p><ol><li>获取 sandbox 中的指定容器，校验其状态是否为 running</li><li>调用 <strong>updateResources</strong>，热更新 VM 的资源规格</li><li>调用 agent 的 <strong>updateContainer</strong>，更新容器</li><li>调用 resCtrl 的 <strong>resourceControllerUpdate</strong>，更新 sandbox 的 cgroup</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="WaitProcess"><a href="#WaitProcess" class="headerlink" title="WaitProcess"></a>WaitProcess</h2><p><strong>等待 sandbox 中的指定容器进程返回退出码</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L377">source code</a></p><ol><li>校验 sandbox 的状态是否为 running</li><li>获取 sandbox 中的指定容器，校验其状态是否为 ready 或 running</li><li>调用 agent 的 <strong>waitProcess</strong>，等待进程返回退出码</li></ol><h2 id="SignalProcess"><a href="#SignalProcess" class="headerlink" title="SignalProcess"></a>SignalProcess</h2><p><strong>向 sandbox 中的指定容器进程发送指定信号</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L392">source code</a></p><ol><li>校验 sandbox 的状态是否为 running</li><li>获取 sandbox 中的指定容器，调用 VCContainer 的 <strong>signalProcess</strong>，向容器进程发送指定信号</li></ol><h2 id="WinsizeProcess"><a href="#WinsizeProcess" class="headerlink" title="WinsizeProcess"></a>WinsizeProcess</h2><p><strong>设置 sandbox 中的指定容器 tty 大小</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L406">source code</a></p><ol><li>校验 sandbox 的状态是否为 running</li><li>获取 sandbox 中的指定容器，校验其状态是否为 ready 或 running</li><li>调用 agent 的 <strong>winsizeProcess</strong>，设置进程的 tty 大小</li></ol><h2 id="IOStream"><a href="#IOStream" class="headerlink" title="IOStream"></a>IOStream</h2><p><strong>获取 sandbox 中的指定容器 IO 流</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L420">source code</a></p><ol><li>校验 sandbox 的状态是否为 running</li><li>获取 sandbox 中的指定容器，校验其状态是否为 ready 或 running</li><li>初始化 IO 流，返回其 stdin、stdout 和 stderr</li></ol><h2 id="AddDevice"><a href="#AddDevice" class="headerlink" title="AddDevice"></a>AddDevice</h2><p><strong>向 sandbox 中添加设备</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L1932">source code</a></p><ol><li>调用 devManager 的 <strong>NewDevice</strong>，初始化对应类型的设备</li><li>调用 devManager 的 <strong>AttachDevice</strong>，添加该设备</li></ol><h2 id="AddInterface"><a href="#AddInterface" class="headerlink" title="AddInterface"></a>AddInterface</h2><p><strong>向 sandbox 中添加网卡</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L918">source code</a></p><ol><li>将 rpc 请求体转换成网卡信息结构</li><li>调用 network 的 <strong>AddEndpoints</strong>，热添加该网卡</li><li>获取网卡 PCI 地址，调用 agent 的 <strong>updateInterface</strong>，更新网卡信息</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="RemoveInterface"><a href="#RemoveInterface" class="headerlink" title="RemoveInterface"></a>RemoveInterface</h2><p><strong>移除 sandbox 中的指定网卡</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L956">source code</a></p><ol><li>调用 network 的 <strong>Endpoints</strong>，根据 MAC 地址匹配所有网卡中待移除的网卡</li><li>调用 network 的 <strong>RemoveEndpoints</strong>，移除该网卡</li><li>调用 store 的 <strong>ToDisk</strong>，保存状态数据到文件中</li></ol><h2 id="ListInterfaces"><a href="#ListInterfaces" class="headerlink" title="ListInterfaces"></a>ListInterfaces</h2><p><strong>获取 sandbox 的所有网卡配置</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L975">source code</a></p><ol><li>调用 agent 的 <strong>listInterfaces</strong>，获取所有网卡配置</li></ol><h2 id="UpdateRoutes"><a href="#UpdateRoutes" class="headerlink" title="UpdateRoutes"></a>UpdateRoutes</h2><p><strong>更新 sandbox 的路由表</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L980">source code</a></p><ol><li>调用 agent 的 <strong>updateRoutes</strong>，更新路由表</li></ol><h2 id="ListRoutes"><a href="#ListRoutes" class="headerlink" title="ListRoutes"></a>ListRoutes</h2><p><strong>获取 sandbox 的所有路由配置</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L985">source code</a></p><ol><li>调用 agent 的 <strong>listRoutes</strong>，获取所有路由配置</li></ol><h2 id="GetOOMEvent"><a href="#GetOOMEvent" class="headerlink" title="GetOOMEvent"></a>GetOOMEvent</h2><p><strong>获取 sandbox 的 OOM 事件信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2320">source code</a></p><ol><li>调用 agent 的 <strong>getOOMEvent</strong>，获取 OOM 事件信息</li></ol><h2 id="GetHypervisorPid"><a href="#GetHypervisorPid" class="headerlink" title="GetHypervisorPid"></a>GetHypervisorPid</h2><p><strong>获取 sandbox 的 hypervisor PID</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L292">source code</a></p><ol><li>调用 hypervisor 的 <strong>GetPids</strong>，获取所有 PID 列表</li><li>返回 PID 列表首位（因为首位是 hypervisor PID，次位为 virtiofsd PID）</li></ol><h2 id="UpdateRuntimeMetrics"><a href="#UpdateRuntimeMetrics" class="headerlink" title="UpdateRuntimeMetrics"></a>UpdateRuntimeMetrics</h2><p><strong>更新 sandbox 的 hypervisor 相关指标</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox_metrics.go#L134">source code</a></p><ol><li>调用 hypervisor 的 <strong>GetPids</strong>，获取 hypervisor 的 PID</li><li>获取 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;fd 目录下的文件数量（进程打开的所有文件描述符，这些文件描述符是指向实际文件的一个符号链接，例如 0 表示 stdin、1 表示 stdout、2 表示 stderr 等等），上报 kata_hypervisor_fds 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;net&#x2F;dev 文件内容（网络设备状态信息，例如 eth0、lo、tap0_kata 和 tunl0 接受和发送的数据包、错误和冲突的数量以及其他基本统计，参考 ifconfig 命令结果），上报 kata_hypervisor_netdev 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;stat 文件内容（进程的状态信息，参考 ps 命令结果），上报 kata_hypervisor_proc_stat 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;status 文件内容（进程的状态信息，相较于 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;stat 更易读），上报 kata_hypervisor_proc_status 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;io 文件内容（进程的 IO 统计信息），上报 kata_hypervisor_io 指标</li><li>调用 hypervisor 的 <strong>GetVirtioFsPid</strong>，获取 virtiofsd 的 PID</li><li>获取 &#x2F;proc&#x2F;&lt;virtiofsdPID&gt;&#x2F;fd 目录下的文件数量，上报 kata_virtiofsd_fds 指标</li><li>解析 &#x2F;proc&#x2F;&lt;virtiofsdPID&gt;&#x2F;stat 文件内容，上报 kata_virtiofsd_proc_stat 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;status 文件内容，上报 kata_virtiofsd_proc_status 指标</li><li>解析 &#x2F;proc&#x2F;&lt;hypervisorPID&gt;&#x2F;io 文件内容，上报 kata_virtiofsd_io 指标</li></ol><h2 id="GetAgentMetrics"><a href="#GetAgentMetrics" class="headerlink" title="GetAgentMetrics"></a>GetAgentMetrics</h2><p><strong>获取 sandbox 的 agent 相关指标</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox_metrics.go#L221">source code</a></p><ol><li>调用 agent 的 <strong>getAgentMetrics</strong>，获取 agent 的指标信息</li></ol><h2 id="GetAgentURL"><a href="#GetAgentURL" class="headerlink" title="GetAgentURL"></a>GetAgentURL</h2><p><strong>获取 sandbox 的 agent URI 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2324">source code</a></p><ol><li>调用 agent 的 <strong>getAgentURl</strong>，获取 URI 信息</li></ol><h2 id="GuestVolumeStats"><a href="#GuestVolumeStats" class="headerlink" title="GuestVolumeStats"></a>GuestVolumeStats</h2><p><strong>获取 sandbox 中的指定挂载卷信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2339">source code</a></p><ol><li>校验卷路径是否存在</li><li>遍历所有容器的所有挂载点，获取挂载源为指定卷目录的 sandbox 内的挂载点</li><li>调用 agent 的 <strong>getGuestVolumeStats</strong>，获取卷信息</li></ol><h2 id="ResizeGuestVolume"><a href="#ResizeGuestVolume" class="headerlink" title="ResizeGuestVolume"></a>ResizeGuestVolume</h2><p><strong>调整 sandbox 中的指定挂载卷大小</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox.go#L2348">source code</a></p><ol><li>校验卷路径是否存在</li><li>遍历所有容器的所有挂载点，获取挂载源为指定卷目录的 sandbox 内的挂载点</li><li>调用 agent 的 <strong>resizeGuestVolume</strong>，调整卷大小</li></ol><h2 id="GetIPTables"><a href="#GetIPTables" class="headerlink" title="GetIPTables"></a>GetIPTables</h2><p><strong>获取 sandbox 的 iptables 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox_metrics.go#L2329">source code</a></p><ol><li>调用 agent 的 <strong>getIPTables</strong>，获取 iptables 信息</li></ol><h2 id="SetIPTables"><a href="#SetIPTables" class="headerlink" title="SetIPTables"></a>SetIPTables</h2><p><strong>设置 sandbox 的 iptables 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/sandbox_metrics.go#L2334">source code</a></p><ol><li>调用 agent 的 <strong>setIPTables</strong>，设置 iptables 信息</li></ol><h1 id="VCContainer"><a href="#VCContainer" class="headerlink" title="VCContainer"></a>VCContainer</h1><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;interfaces.go</u></em></p><p>virtcontainers 库中用于管理容器的模块。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Container is composed of a set of containers and a runtime environment.</span></span><br><span class="line"><span class="comment">// A Container can be created, deleted, started, stopped, listed, entered, paused and restored.</span></span><br><span class="line"><span class="keyword">type</span> Container <span class="keyword">struct</span> &#123;</span><br><span class="line">ctx           context.Context</span><br><span class="line">config        *ContainerConfig</span><br><span class="line">sandbox       *Sandbox</span><br><span class="line">id            <span class="type">string</span></span><br><span class="line">sandboxID     <span class="type">string</span></span><br><span class="line"><span class="comment">// &lt;sandboxID&gt;/&lt;id&gt;</span></span><br><span class="line">containerPath <span class="type">string</span></span><br><span class="line"><span class="comment">// 固定为 rootfs</span></span><br><span class="line">rootfsSuffix  <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器挂载信息，包括 source、destination、type、options 等。从 OCI spec 解析获得</span></span><br><span class="line">mounts []Mount</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器设备信息，包括设备 ID、容器中的设备路径、文件模式等信息</span></span><br><span class="line">devices []ContainerDevice</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器状态信息，包括运行状态（ready、running、paused、stopped 以及 creating）、rootfs 的块设备 ID（DeviceMapper 场景下，rootfs 为热添加的块设备）、rootfs 的文件系统类型（rootfs 为块设备时）以及 sandbox 进程所在的 cgroup 路径</span></span><br><span class="line">state types.ContainerState</span><br><span class="line"></span><br><span class="line"><span class="comment">// 容器进程信息，包括 PID（本质上就是 shimID）、Token 以及启动时间等</span></span><br><span class="line">process Process</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 容器 rootfs 基本信息，包括 source、target、type、options 等</span></span><br><span class="line">rootFs RootFs</span><br><span class="line"></span><br><span class="line"><span class="comment">// systemMountsInfo.BindMountDev 表示是否将 host 的 /dev 目录以 bind 形式挂载到容器的 /dev 中</span></span><br><span class="line"><span class="comment">// systemMountsInfo.DevShmSize 表示 host 的 /dev/shm 大小</span></span><br><span class="line">systemMountsInfo SystemMountsInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>工厂函数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/container.go#L714">source code</a></p><ol><li>检验 containerConfig 配置是否合法（containerConfig 取自于 sandboxConfig 中的相关配置）</li><li>校验 annotation 中 SWAP 资源声明是否合法（io.katacontainers.container.resource.swappiness 必须小于 200），并透传设置（区别于 CPU 和内存等资源，SWAP 无法通过 spec.Containers.Resources 的方式声明，而需要通过 annotation 声明）</li><li>调用 store 的 <strong>FromDisk</strong>，获取 sandbox 和容器的状态信息。如果成功获取则表明不是新创建的容器，无需后续动作，仅用于状态更新维护，直接返回容器实例即可</li><li>处理容器挂载信息，即 container.mounts<br><em>除了借助 virtcontainers&#x2F;kata-agent 的共享目录挂载之外，块设备类型的挂载还可以通过 hypervisor 热添加到 VM。这里仅处理挂载源为块设备类型的挂载信息，常规共享目录挂载仍然由 virtcontainers&#x2F;kata-agent 处理</em><ol><li>如果未禁用 [hypervisor].disable_block_device_use，则调用 agent 的 <strong>capabilities</strong> 和 hypervisor 的 <strong>Capabilities</strong>，根据 agent 是否具备使用块设备能力以及 hypervisor 是否允许块设备热插拔判断是否当前支持块设备<br><em>默认场景下，rootfs 由 virtio-fs 传递共享；在未禁用 [hypervisor].disable_block_device_use 时，rootfs 基于块设备创建，并热插到 VM 中使用，以提高性能。例如 devicemapper 场景下 rootfs 必须是基于块设备创建的</em></li><li>针对容器中的所有挂载信息<ol><li>如果 mounts.BlockDeviceID 已经存在，则表明已经有一个设备和挂载点相关联，因此不需要创建设备，跳过即可</li><li>如果挂载类型不是 bind，跳过即可</li><li>获取 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 mounts.Source&gt;&#x2F;mountInfo.json 文件，如果文件存在，表明当前挂载设备需要以直通卷的方式处理，即创建 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 mounts.Source&gt;&#x2F;&lt;sandboxID&gt; 文件，并替换原本 mounts 中 Source、Type、Options、ReadOnly、FSGroup（取自 mountInfo.Metadata[“FSGroup”]）、FSGroupChangePolicy（取自 mountInfo.Metadata[“FSGroupChangePolicy”]） 等信息为 mountInfo.json 的对应字段，后续支持直通卷的 CSI 会根据此文件与信息与 Kata 交互<br><em>mounts.Source 格式为 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;&lt;podUID&gt;&#x2F;volumes&#x2F;kubernetes.io~csi&#x2F;&lt;pvName&gt;&#x2F;mount；<br>mountInfo.json 中 device 字段的格式为 &#x2F;dev&#x2F;sda（取决于 host 上的具体设备）</em></li><li>如果挂载源为块设备类型或 PMEM 设备，则调用 devManager 的 <strong>NewDevice</strong>，初始化挂载块设备信息，回写 mounts.BlockDeviceID 字段信息<br><em>块设备 DeviceInfo 的 HostPath、ContainerPath 等信息均为 mounts 中信息；<br>PMEM 设备 DeviceInfo 的 HostPath 处理方式比较特殊：如果 DevType 为 c 或者 u，则 backingFile 路径为 &#x2F;sys&#x2F;dev&#x2F;char&#x2F;&lt;major:minor&gt;&#x2F;loop&#x2F;backing_file；如果 DevType 为 b，则 backingFile 路径为 &#x2F;sys&#x2F;dev&#x2F;block&#x2F;&lt;major:minor&gt;&#x2F;loop&#x2F;backing_file。读取 backingFile 文件内容作为 HostPath。此外，判断 HostPath 签名是否合法（当使用 PMEM 设备和 DAX 技术时，需要确保文件或设备路径具有正确的 PFN 签名，以便内核可以正确地管理 PMEM 设备和启用 DAX 技术）以及通过 &#x2F;proc&#x2F;mounts 获取 PMEM 的挂载源的文件系统类型 fstype</em></li></ol></li></ol></li><li>准备容器设备信息，即 container.devices<br><em>设备均通过 hypervisor 热添加到 VM 中</em><ol><li>针对容器中所有的设备信息，调用 devManager 的 <strong>NewDevice</strong>，初始化设备信息，并过滤类型为 CDROM 和 floppy 的设备</li></ol></li></ol><p>VCContainer 中声明的 <strong>GetAnnotations</strong>、<strong>GetPid</strong>、<strong>GetToken</strong>、<strong>ID</strong>、<strong>Sandbox</strong> 以及 <strong>Process</strong> 均为参数获取与赋值，无复杂逻辑，不作详述。</p><h2 id="start"><a href="#start" class="headerlink" title="start"></a>start</h2><p><strong>启动容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/container.go#L940">source code</a></p><ol><li>校验 sandbox 状态是否为 running</li><li>校验容器状态是否为 ready 或 stopped</li><li>调用 agent 的 <strong>startContainer</strong>，启动容器</li><li>如果启动失败，则调用 <strong>stop</strong>，执行回滚操作；否则，设置容器状态为 running，并调用 store 的 <strong>ToDisk</strong>，保存 sandbox 和容器的状态数据到文件中</li></ol><h2 id="stop"><a href="#stop" class="headerlink" title="stop"></a>stop</h2><p><strong>关停容器，并清理相关资源</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/container.go#L966">source code</a></p><ol><li>如果容器状态已经为 stopped，则不做任何操作</li><li>校验容器状态是否为 ready、running 或 paused</li><li>调用 <strong>signalProcess</strong>，向 sandbox 中的容器进程发送 kill 信号</li><li>调用 agent 的 <strong>waitProcess</strong>，确保容器进程已退出</li><li>调用 agent 的 <strong>stopContainer</strong>，关停容器</li><li>针对容器中每一个挂载信息，调用 fsShare 的 <strong>UnshareFile</strong>，移除 host 侧的 sandbox 共享文件</li><li>调用 fsShare 的 <strong>UnshareRootFilesystem</strong>，移除 sandbox 中的容器 rootfs 共享挂载</li><li>调用 devManager 的 <strong>DetachDevice</strong> 和 <strong>RemoveDevice</strong>，detach 并移除 sandbox 中的所有设备（含块设备）</li><li>如果容器的 rootfs 是块设备，则调用 devManager 的 <strong>DetachDevice</strong> 和 <strong>RemoveDevice</strong>，detach 并移除容器的 rootfs 块设备</li><li>设置容器状态为 stopped，并调用 store 的 <strong>ToDisk</strong>，保存 sandbox 和容器的状态数据到文件中</li></ol><h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h2><p><strong>删除容器信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/container.go#L896">source code</a></p><ol><li>校验容器状态是否为 ready 或 stopped</li><li>删除维护在 sandbox 中的容器信息</li><li>调用 store 的 <strong>ToDisk</strong>，保存 sandbox 和容器的状态数据到文件中</li></ol><h2 id="signalProcess"><a href="#signalProcess" class="headerlink" title="signalProcess"></a>signalProcess</h2><p><strong>向容器进程发送指定信号</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/virtcontainers/container.go#L1074">source code</a></p><ol><li>校验 sandbox 状态是否为 ready 或者 running</li><li>校验容器状态是否为 ready、running 或者 paused</li><li>调用 agent 的 <strong>signalProcess</strong>，向 sandbox 中的指定容器进程发送信号（由于 Containerd 和 CRIO 并不会处理 <code>ESRCH: No such process</code> 错误，因此 Kata runtime 在这里做了特殊操作，针对此报错仅输出 warning 日志，不作返回）</li></ol>]]></content>
    
    
    <summary type="html">virtcontainers 中与 VC、VCSandbox、VCContainer 等硬件虚拟化管理平面相关的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — kata-monitor</title>
    <link href="http://shenxianghong.github.io/2023/01/29/2023-01-29%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20kata-monitor/"/>
    <id>http://shenxianghong.github.io/2023/01/29/2023-01-29%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20kata-monitor/</id>
    <published>2023-01-28T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.269Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><p>Kata monitor 是一个守护进程，能够收集和暴露在同一 host 上运行的所有 Kata 容器工作负载相关的指标。一旦启动，它会检测 containerd-shim-kata-v2 系统中所有正在运行的 Kata Containers 运行时，并暴露一些 HTTP endpoints。主要 endpoint 是 &#x2F;metrics（用于聚合来自所有 Kata 工作负载的指标）。</p><p>可用指标包括：</p><ul><li>Kata 运行时指标</li><li>Kata agent 指标</li><li>Kata guestOS 指标</li><li>hypervisor 指标</li><li>Firecracker 指标</li><li>Kata monitor 指标</li></ul><p>Kata monitor 提供的指标均采用 Prometheus 格式。虽然 Kata monitor 可以在任何运行 Kata Containers 工作负载的主机上用作独立守护进程，并且可以用于从正在运行的 Kata 运行时检索分析数据，但它的主要预期用途是作为 DaemonSet 部署在 Kubernetes 集群上。</p><p><em><u>src&#x2F;runtime&#x2F;cmd&#x2F;kata-monitor&#x2F;main.go</u></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> KataMonitor <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 维护 /run/vc/sbs 目录下的 sandbox 的基础信息，包括 uid、name 和 namespace</span></span><br><span class="line">sandboxCache *sandboxCache</span><br><span class="line">    </span><br><span class="line"><span class="comment">// --runtime-endpoint 参数指定，默认为 /run/containerd/containerd.sock</span></span><br><span class="line">runtimeEndpoint <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>main 函数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-monitor/main.go#L69">source code</a></p><ol><li><p>如果指定的参数为 version 或者 –version，则展示其版本、架构、commit 等信息</p></li><li><p>解构命令行参数与初始化日志</p></li><li><p>初始化 monitor server</p><ol><li>校验 –runtime-endpoint 参数是否不为空，默认为 &#x2F;run&#x2F;containerd&#x2F;containerd.sock</li><li>注册指标至 Prometheus</li><li>启动 goroutine，实时处理 sandbox cache<ol><li>启动 fsnotify watcher，监听 &#x2F;run&#x2F;vc&#x2F;sbs 目录下的文件（文件名即为 sandboxID）</li><li>遍历目录内容，将 sandboxID 维护在 km.sandboxCache</li><li>根据 fsnotify watcher 监听到的创建或者删除事件，同步更新维护在 km.sandboxCache 中的 sandboxID</li><li>同时，默认每隔 5 秒，根据 –runtime-endpoint 参数构建 gRPC Client 调用 CRI 的 ListPodSandbox 获取到 CRI 中所有的 PodSandbox，将详细内容（即 sandboxCRIMetadata 对象，其中包含 UID、Name 和 Namespace 属性）更新至 km.sandboxCache 中</li></ol></li></ol></li><li><p>注册 &#x2F;metrics、&#x2F;sandboxes、&#x2F;agent-url 和一系列 Golang pprof 的 HTTP 端点；根服务请求（&#x2F;）会展示所有可用的 HTTP 端点</p></li><li><p>启动 monitor server 服务，监听地址通过 –listen-address 指定，默认为 127.0.0.1:8090</p></li></ol><h1 id="ProcessMetricsRequest"><a href="#ProcessMetricsRequest" class="headerlink" title="ProcessMetricsRequest"></a>ProcessMetricsRequest</h1><p><strong>处理 &#x2F;metrics 请求，获取 shim、hypervisor、vm 和 agent 指标</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/kata-monitor/metrics.go#L74">source code</a></p><ol><li>获取请求中的 sandbox 参数</li><li>如果指定了 sandbox 参数，则通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/metrics</code>，获取指定 sandbox 的指标信息并返回（等价于 kata-runtime metrics &lt;sandboxID&gt;）</li><li>如果没有指定 sandbox 参数，则通过 Prometheus 聚合所有 sandbox 的指标处理并返回</li></ol><h1 id="ListSandboxes"><a href="#ListSandboxes" class="headerlink" title="ListSandboxes"></a>ListSandboxes</h1><p><strong>处理 &#x2F;sandboxes 请求，获取所有运行的 sandbox</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/kata-monitor/monitor.go#L196">source code</a></p><ol><li>获取维护的所有 sandboxID</li><li>根据实际请求，具体展示 HTML 或者 Text 格式的内容</li></ol><h1 id="GetAgentURL"><a href="#GetAgentURL" class="headerlink" title="GetAgentURL"></a>GetAgentURL</h1><p><strong>处理 &#x2F;agent-url 请求，获取指定 sandboxID 的 agent 地址</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/kata-monitor/monitor.go#L179">source code</a></p><ol><li>检验请求中的 sandbox 参数是否不为空</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/agent-url</code>，解析内容获得 sandbox socket 地址</li></ol><h1 id="ExpvarHandler、PprofIndex、PprofCmdline、PprofProfile、PprofSymbol、PprofTrace"><a href="#ExpvarHandler、PprofIndex、PprofCmdline、PprofProfile、PprofSymbol、PprofTrace" class="headerlink" title="ExpvarHandler、PprofIndex、PprofCmdline、PprofProfile、PprofSymbol、PprofTrace"></a>ExpvarHandler、PprofIndex、PprofCmdline、PprofProfile、PprofSymbol、PprofTrace</h1><p><strong>处理 pprof 类请求，转发至 shim server</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/kata-monitor/pprof.go#L38">source code</a></p><ol><li>不同的 endpoint 在转发前会设置特定的请求头，例如 Content-Type 和 Content-Disposition</li><li>代理请求<ol><li>检验请求中的 sandbox 参数是否不为空</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 转发 HTTP GET 请求至 shim server 的 <code>http://shim/&lt;URL&gt;</code></li><li>根据调用传参中的请求处理方式加工数据并返回</li></ol></li></ol>]]></content>
    
    
    <summary type="html">Kata Containers 指标采集、聚合与上报的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — containerd-shim-kata-v2</title>
    <link href="http://shenxianghong.github.io/2023/01/21/2023-01-21%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20containerd-shim-kata-v2/"/>
    <id>http://shenxianghong.github.io/2023/01/21/2023-01-21%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20containerd-shim-kata-v2/</id>
    <published>2023-01-20T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.268Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><p>本质上，Kata agent 负责 VM（也称 sandbox、guest 等）中的容器等进程的生命周期的管理。而 containerd-shim-kata-v2 作为 Kata agent 唯一的服务入口（本身是一个可执行程序，运行后即为 shim server），一部分实现了 Containerd shimv2 接口，暴露 shim API 用于与 Containerd 的 gRPC 通信，一部分暴露 HTTP endpoints 用于命令行工具和 Kata monitor 的服务请求处理，内部调用 virtcontainers 的诸多子模块，提供了用户和 Containerd 对 VM 以及容器进程的生命周期管理的能力。</p><p><em><u>src&#x2F;runtime&#x2F;vendor&#x2F;github.com&#x2F;containerd&#x2F;containerd&#x2F;runtime&#x2F;v2&#x2F;task&#x2F;shim.pb.go</u></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// service is the shim implementation of a remote shim over GRPC</span></span><br><span class="line"><span class="keyword">type</span> service <span class="keyword">struct</span> &#123;</span><br><span class="line">ctx      context.Context</span><br><span class="line">rootCtx  context.Context <span class="comment">// root context for tracing</span></span><br><span class="line">rootSpan otelTrace.Span</span><br><span class="line">sandbox  vc.VCSandbox</span><br><span class="line">monitor  <span class="keyword">chan</span> <span class="type">error</span></span><br><span class="line">ec       <span class="keyword">chan</span> exit</span><br><span class="line">    mu       sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置文件信息</span></span><br><span class="line">config *oci.RuntimeConfig</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当前 shim service 中的容器信息</span></span><br><span class="line">containers <span class="keyword">map</span>[<span class="type">string</span>]*container</span><br><span class="line"></span><br><span class="line"><span class="comment">// 事件消费队列（TaskCreate、TaskStart、TaskDelete、TaskPaused、TaskResumed、TaskOOM、TaskExecAdded 和 TaskExecStarted）</span></span><br><span class="line">events      <span class="keyword">chan</span> <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">eventSendMu sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// 由 container engine 触发的关停函数</span></span><br><span class="line">cancel    <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line"><span class="comment">// 由 container engine 传入的信息</span></span><br><span class="line">namespace <span class="type">string</span></span><br><span class="line">id       <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 原语义为 VM 中的容器 PID，但是在 kata 模型中 shimv2 无法获得，因此这里为 hypervisor 的 PID</span></span><br><span class="line">hpid <span class="type">uint32</span></span><br><span class="line"><span class="comment">// shimv2 的 PID</span></span><br><span class="line">pid  <span class="type">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>main 函数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/containerd-shim-kata-v2/main.go#L24">source code</a></p><ol><li>如果指定的参数为 –version，则展示其版本、commit 等信息</li><li>通过 shim API，初始化并启动 shim server，注册名称为 containerd-shim-kata-v2，其中 NoReaper 和 NoSubreaper 均为 true<ol><li>初始化 containerd-kata-shim-v2 模块的 logger，如果没有开启 debug 日志级别，则默认设置为 warn 级别，以此 logger 为基准，设置 virtcontainers 与 katautils 模块的 logger</li><li>校验启动时是否指定了 –namespce 参数（在 Kubernetes 集群中为 k8s.io，Docker 中为 moby，默认为 default）</li><li>启动 goroutine，持续处理 service 中的 exit channel，构建 TaskExit 事件发送至 events channel 中</li><li>初始化 eventForwarder，并启动 goroutine 调用 eventForwarder 的 <strong>forward</strong> 持续上报事件</li><li>返回 service，交给 Containerd 负责针对每个容器启动 shim server</li></ol></li></ol><h1 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h1><p>shim server 对外暴露的 gRPC 服务。</p><h2 id="State"><a href="#State" class="headerlink" title="State"></a>State</h2><p><strong>获取进程的运行时状态</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L628">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StateRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>   </span><br><span class="line">ExecID               <span class="type">string</span>      </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StateResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>      </span><br><span class="line">Bundle               <span class="type">string</span>      </span><br><span class="line">Pid                  <span class="type">uint32</span>      </span><br><span class="line">Status               task.Status </span><br><span class="line">Stdin                <span class="type">string</span>      </span><br><span class="line">Stdout               <span class="type">string</span>     </span><br><span class="line">Stderr               <span class="type">string</span>      </span><br><span class="line">Terminal             <span class="type">bool</span>       </span><br><span class="line">ExitStatus           <span class="type">uint32</span>      </span><br><span class="line">ExitedAt             time.Time   </span><br><span class="line">ExecID               <span class="type">string</span>           </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>根据容器中的属性构建返回消息，如果 r.ExecID 不为空，则通过 r.ExecID 获取维护在 container.execs 中的 exec 中的属性为准</p></li></ol><h2 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h2><p><strong>使用底层 OCI 运行时创建一个新的容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L381">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CreateTaskRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>         </span><br><span class="line">Bundle               <span class="type">string</span>         </span><br><span class="line">Rootfs               []*types.Mount </span><br><span class="line">Terminal             <span class="type">bool</span></span><br><span class="line">Stdin                <span class="type">string</span></span><br><span class="line">Stdout               <span class="type">string</span></span><br><span class="line">Stderr               <span class="type">string</span></span><br><span class="line">Checkpoint           <span class="type">string</span></span><br><span class="line">ParentCheckpoint     <span class="type">string</span></span><br><span class="line">Options              *types1.Any    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CreateTaskResponse <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// shimv2 无法从 VM 获取容器进程 PID，因此后续对于需要 PID 的返回值，直接返回 hypervisor 的 PID 即可</span></span><br><span class="line">Pid                  <span class="type">uint32</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>校验 r.ID 是否不为空，且正则匹配满足 ^[a-zA-Z0-9][a-zA-Z0-9_.-]+$</p></li><li><p>调用 <strong>create</strong>，创建容器，将返回的容器状态设为 created，并维护在 service.containers 中</p></li><li><p>发送 TaskCreate 事件至 service.events 中</p></li></ol><h3 id="create"><a href="#create" class="headerlink" title="create"></a>create</h3><p><strong>基于 service 实例和请求消息创建容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/create.go#L51">source code</a></p><ol><li><p>初始化空的 rootfs 对象，如果请求中 r.Rootfs 已经提供了一个，则以此为准，丰富 rootfs 对象</p></li><li><p>将 r.Bundle 下的 config.json 文件（例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;config.json，该文件即为 <a href="https://github.com/opencontainers/runtime-spec/blob/main/config.md">OCI spec</a>，由 container manager 事先创建），解析为 OCI spec 结构</p><ol><li>校验 r.ID 与 r.Bundle 是否不为空，并且 r.Bundle 存在且为目录结构，获取 r.Bundle 符号链接（如果是）指向的路径名</li><li>获取 r.Bundle 目录下的 config.json，读取其内容，解构成 compatOCISpec 结构（为了兼容 v1.0.0-rc4 和 v1.0.0-rc5，参考：<a href="https://github.com/opencontainers/runtime-spec/commit/37391fb%EF%BC%89">https://github.com/opencontainers/runtime-spec/commit/37391fb）</a></li><li>不同版本下 spec.Process.Capabilities 字段属性不同，通过类型断言，将其以及 compatOCISpec 转换成对应的 OCI spec（实际上，容器运行后，spec 信息可以通过 crictl inspect xxx 或者 ctr c info xxx 查看到，也可以查看 config.json 文件），并返回</li></ol></li><li><p>根据 spec 中的 annotation 信息判断其容器类型，并转换成 virtcontainers 中定义的容器类型</p><ol><li>判断 spec.Annotations 中是否包含 io.kubernetes.cri.container-type、io.kubernetes.cri-o.ContainerType 和 io.kubernetes.docker.type 的 key（分别代表 Containerd、CRI-O 和 Dockershim 三种 CRI）</li><li>获得 key 对应的 value（value 即为容器的类型），分为两类，分别是 sandbox 和 container，区别于 CRI 的不同，具体的名称有所区别（Containerd 和 CRI-O 中称为 sandbox 和 container，而 Dockershim 中称为 podsandbox 和 container）</li><li>根据容器类型，映射出 virtcontainers 中的容器类别，例如 pod_sandbox 和 pod_container，当 spec.Annotations 中未识别到上述三种 key，则视为 single_container，即非 Pod 容器（如通过 ctr，podman 启动运行）</li><li>此外，匹配到 key，但是 value 不符合 sandbox 和 container 的，均视为 unknown_container_type</li></ol></li><li><p>构建 runtimeConfig（runtimeConfig 聚合了运行时所有的设置信息，后续的操作中不再解析配置文件），优先级依次从 spec.Annotations、shimv2 请求传参和环境变量中获取</p><ol><li>获取 spec.Annotations 中 key 为 io.katacontainers.config_path 的 value 作为 configPath（也就是 Kata Containers 的静态配置文件）</li><li>当 configPath 为空时，尝试从 r.Options 中获取（其中在类型断言时，优先使用 github.com&#x2F;containerd&#x2F;containerd&#x2F;pkg&#x2F;runtimeoptions&#x2F;v1 中的 Options 类型，为了兼容 1.4.3、1.4.4 版本的 Containerd，退而使用 github.com&#x2F;containerd&#x2F;cri-containerd&#x2F;pkg&#x2F;api&#x2F;runtimeoptions&#x2F;v1 中的 Options 类型）</li><li>如果此时 configPath 仍为空，则从环境变量 KATA_CONF_FILE 中获取</li><li>如果 configPath 为空，则按序优先读取 &#x2F;etc&#x2F;kata-containers&#x2F;configuration.toml 和 &#x2F;usr&#x2F;share&#x2F;defaults&#x2F;kata-containers&#x2F;configuration.toml 配置文件内容，构建 runtimeConfig</li></ol></li><li><p>校验部分配置项</p><ol><li>[runtime].experimental 特性是否支持</li><li>[runtime].sandbox_bind_mounts 挂载点是否嵌套（即挂载点的 base 目录存在重复）</li><li>当 [runtime].disable_new_netns 启用时，[runtime].internetworking_model 是否设置为 none</li><li>[hypervisor].default_memory 是否不为 0。当 guest 镜像采用 initrd 格式时，[hypervisor].default_memory 必须大于镜像大小（因为 initrd 会完全读到内存中）；当 guest 镜像采用 image 格式时，镜像大小大于 [hypervisor].default_memory 时，会输出警告信息（虽然 image 不会完全读到内存中，但是此情况并非正常现象）</li><li>当 [factory].enable_template 启用时，guest 镜像类型必须为 initrd 格式；当 [factory].vm_cache_number 大于 0 时，hypervisor 类型必须为 QEMU</li></ol></li><li><p>根据不同的容器类型，基于配置文件内容创建容器</p><p><em><strong>pod_sandbox 或 single_container</strong>（以下统称为 pod_sandbox）</em></p><ol><li><p>当 service.sandbox 不为空时，意味着当前容器环境已经存在一个 sandbox（只有在完成创建容器后才会回写该字段），是无法嵌套创建 sandbox 的</p></li><li><p>基于 [runtime].jaeger_endpoint、[runtime].jaeger_user 和 [runtime].jaeger_password 创建 jaeger tracer</p></li><li><p>如果容器类型为 pod_sandbox，则基于 spec.Annotations 中的 io.kubernetes.cri.sandbox-memory、io.kubernetes.cri.sandbox-cpu-period 和 io.kubernetes.cri.sandbox-cpu-quota，计算 VM 的资源大小；如果容器类型为 single_container，则基于 spec.Linux.Resources 中的 Memory.Limit、CPU.Quota 和 CPU.Period，计算 VM 的资源大小。两者公式一致：</p><blockquote><p>CPU &#x3D; (cpu-quota * 1000 &#x2F; cpu-period + 999) &#x2F; 1000</p><p>MEM &#x3D; memory &#x2F; 1024 &#x2F;1024</p></blockquote></li><li><p>检查容器的 rootfs 目录是否需要挂载</p><ol><li>如果请求中 r.Rootfs 指定了一个，则判断其是否为块设备，并且 [hypervisor].disable_block_device_use 为 false（disable_block_device_use 禁止块设备用于容器的 rootfs。 在像 devicemapper 这样的存储驱动程序中，容器的 rootfs 由块设备支持，出于性能原因，块设备直接传递给 hypervisor。 这个标志阻止块设备被传递给 hypervisor，而使用 virtio-fs 传递 rootfs）；或者，rootfs 的类型为 fuse.nydus-overlayfs。满足条件之一，即不需要挂载，而是走后续的热插流程</li><li>创建 rootfs 目录（如果不存在），遍历 r.Rootfs，挂载至 rootfs 目录下（即 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs）</li></ol></li><li><p>基于 factory 配置项，尝试获取现有 VM factory，如果获取失败且未启用 VM cache 特性时，会初始化新的 VM factory，并调用 vircontainers 的 <strong>SetFactory</strong>，透传 VM factory</p></li><li><p>基于 [hypervisor].rootless 设置 rootless（默认情况下，QEMU 以 root 身份运行。 当设置为 true 时，QEMU 将以非 root 的随机用户运行），如果启用 rootless，则额外执行以下流程</p><ol><li>创建一个用于运行 Kata Containers 的随机用户</li><li>根据用户名获取并设置 UID 和 GID</li><li>创建用户目录，并设置环境变量 XDG_RUNTIME_DIR</li><li>将 KVM GID 添加到 hypervisor 配置项中的补充组中，使 hypervisor 进程可以访问 &#x2F;dev&#x2F;kvm 设备</li></ol></li><li><p>基于上述构建的 OCI spec、runtimeConfig、rootfs、bundle、containerID 等信息创建 sandbox</p><ol><li>将 OCI spec 和 runtimeConfig 转为 virtcontainers 所需的配置结构（即 sandboxConfig）<br><br>额外注明：a. 部分参数当 OCI spec annotations 中有声明时，会以 annotations 为准，前提是 [hypervisor].enable_annotations 中声明了允许动态加载的配置项且该配置项合法；b. 当启用 [hypervisor].static_sandbox_resource_mgmt，VM 规格会被静态配置，而非启动后热插拔，因此 CPU 资源规格为 [hypervisor].default_vcpus + &lt;workloadCPUs&gt;，内存同理</li><li>当 host 启用 FIPS 时（即 &#x2F;proc&#x2F;sys&#x2F;crypto&#x2F;fips_enabled 为 1），sandboxConfig 中额外追加 kernel 参数</li><li>启动容器前优先创建 netns。当 [runtime].disable_new_netns 启用时（表示 shim 和 hypervisor 会运行在 host netns 中，而非创建新的），则直接跳过后续创建；否则，当 networkID（spec.Linux.Namespace 中 type 为 network 的 path）为空时（表示 netns 并非由 CNI 提前创建好，而是需要由 Kata Containers 创建，比如脱离 K8s 运行 Kata 的场景中），则根据具体是否为 rootless，执行对应的创建网络命名空间流程。如果为提前创建好的 netns，需要判断其是否与当前进程的 netns 不一致（当前进程可以代表 host 网络，而 Kata Containers 是不支持采用 host 网络作为容器网络的）</li><li>执行 spec.Hooks.Prestart（Prestart 是在执行容器进程之前要运行的 hook 列表，现已废弃） 中定义的动作</li><li>执行 spec.Hooks.CreateRuntime（CreateRuntime 是在创建容器之后但在调用 pivot_root 或任何等效操作之前要运行的 hook 列表） 中定义的动作</li><li>调用 VC 的 <strong>CreateSandbox</strong>，根据 sandboxConfig 信息创建 sandbox，并启动 pod_sandbox 容器</li><li>调用 VCSandbox 的 <strong>GetAllContainers</strong>，校验 sandbox 中的容器总数量是否为 1，返回 sandbox</li></ol></li><li><p>设置 service.sandbox 为上面返回的 sandbox，调用 VCSandbox 的 <strong>GetHypervisorPid</strong>，获取 hypervisor 的 PID，设置至 service.hpid 中</p></li><li><p>启动监听 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 地址的 shim server，注册服务有 &#x2F;metrics、&#x2F;agent-url、&#x2F;direct-volume&#x2F;stats、&#x2F;direct-volume&#x2F;resize、&#x2F;iptables、&#x2F;ip6tables 以及 Pprof，注册上报至 Prometheus 的 shim 相关指标以及 sandbox 相关指标</p></li></ol><p><em><strong>pod_container</strong></em></p><ol><li>校验 service.sandbox 是否不为空（因为 pod_container 的运行是要依托于 pod_sandbox）</li><li>检查容器的 rootfs 目录是否需要挂载<ol><li>如果请求中 r.Rootfs 指定了一个，则判断其是否为块设备，并且 [hypervisor].disable_block_device_use 为 false（disable_block_device_use 禁止块设备用于容器的 rootfs。 在像 devicemapper 这样的存储驱动程序中，容器的 rootfs 由块设备支持，出于性能原因，块设备直接传递给 hypervisor。 这个标志阻止块设备被传递给 hypervisor，而使用 virtio-fs 传递 rootfs）；或者，rootfs 的类型为 fuse.nydus-overlayfs。满足条件之一，即不需要挂载，而是走后续的热插流程</li><li>创建 rootfs 目录（如果不存在），遍历 r.Rootfs，挂载 rootfs 目录</li></ol></li><li>基于上述构建的 OCI spec、runtimeConfig、rootfs、bundle、containerID 等信息创建 container 类型容器<ol><li>遍历 spec.Mounts，如果挂载源路径由 K8s 临时存储（即路径中有 kubernetes.io~empty-dir 标识，且文件类型为 tmpfs），则将 spec.Mounts 中对应挂载点的类型设置为 ephemeral；如果挂载源路径由 K8s emptydir（即路径中有 kubernetes.io~empty-dir 标识，且文件类型不为 tmpfs） 且 runtimeConfig 没有禁用 disable_guest_empty_dir（如果启用，将不会在 guest 的文件系统中创建 emptydir 挂载，而是在 host 上创建，由 virtiofs 共享，性能较差，但是可以实现 host 和 guest 共享文件），则将 spec.Mounts 中对应挂载点的类型设置为 local （对于给定的 Pod，临时卷仅在 VM 内由 tmpfs 支持时创建一次。 对于同一 Pod 的连续容器，将重复使用已经存在的卷）</li><li>将 OCI spec 和 runtimeConfig 转为 virtcontainers 所需的配置结构（即 containerConfig）</li><li>根据 spec.Annotations 中的 io.kubernetes.cri.sandbox-id、io.kubernetes.cri-SandboxID 和 io.kubernetes.sandbox.id 的 key（分别代表 Containerd、CRI-O 和 Dockershim 三种 CRI），获取到 value（value 即为 sandboxID）</li><li>调用 VCSandbox 的 <strong>CreateContainer</strong>，创建容器</li><li>进入到 sandbox 的网络命名空间中（如果有），执行 spec.Hooks.Prestart（Prestart 是在执行容器进程之前要运行的 hook 列表，现已废弃） 中定义的动作</li></ol></li></ol></li><li><p>构建并返回容器</p></li></ol><h2 id="Start"><a href="#Start" class="headerlink" title="Start"></a>Start</h2><p><strong>启动容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L440">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StartRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">ExecID               <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StartResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">Pid                  <span class="type">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>如果 r.ExecID 为空，则调用 <strong>startContainer</strong>，启动容器，并发送 TaskStart 事件至 service.events 中；否则，调用 <strong>startExec</strong>，启动 exec 进程，并发送 TaskExecStart 事件至 service.events 中</p></li></ol><h3 id="startContainer"><a href="#startContainer" class="headerlink" title="startContainer"></a>startContainer</h3><p><strong>处理启动容器请求</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/start.go#L18">source code</a></p><ol><li>如果容器类型为 pod_sandbox<ol><li>调用 VCSandbox 的 <strong>Start</strong>，启动 sandbox</li><li>调用 VCSandbox 的 <strong>Monitor</strong>，启动 monitor，并设置在 service.monitor 中</li><li>启动 goroutine，监听 service.monitor 中的错误和退出信号。如果监听到（视为异常），则调用 VCSandbox 的 <strong>Stop</strong> 和 <strong>Delete</strong>，关停与销毁 sandbox 并清理相关资源</li><li>移除 rootfs 挂载点（注意：此处清理的为 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs，而共享目录下的 rootfs 在上述步骤 3 中已经清理）</li><li>启动 goroutine，调用 VCSandbox 的 <strong>GetOOMEvent</strong>（如果是由于 Kata agent 关停，返回类似 ttrpc: closed 或者 Dead agent 的错误时，则不再监听；其他异常情况，仍重新尝试调用接口），监听 OOM 事件。当收到 OOM 事件后，如果 container manager 为 CRI-O 时，则在例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt; 目录下，创建名为 oom 的文件，用于通知 CRI-O；如果 container manager 为 Containerd 时，则发送 TaskOOM 事件至 service.events 中</li></ol></li><li>如果容器的类型不为 pod_sandbox，则调用 VCSandbox 的 <strong>StartContainer</strong>，启动容器</li><li>进入到 sandbox 的网络命名空间中（如果有），执行 spec.Hooks.Poststart（Poststart 是在容器进程启动后要运行的 hook 列表） 中定义的动作</li><li>设置容器状态为 running</li><li>调用 VCSandbox 的 <strong>IOStream</strong>，启动 goroutine，实时处理容器中的标准输出等 IO 流</li><li>启动 goroutine，处理容器中的退出队列 ，即先等到容器 IO 退出事件后，再调用 VCSandbox 的 <strong>WaitProcess</strong>，进一步等待进程返回退出码后执行后续清理流程：如果容器类型为 pod_sandbox，则关停 monitor，调用 VCSandbox 的 <strong>Stop</strong> 和 <strong>Delete</strong>，关停与销毁 sandbox，并清理相关资源；否则，调用 VCSandbox 的 <strong>StopContainer</strong>，关停容器。设置容器状态为 stopped，记录退出时间，状态码等<br><em>例如，当 Pod 启动之后，pod_sandbox 容器会退出，此时可以收到 pod_sandbox 容器的 IO 退出事件，但是在 WaitProcess 时，不会有返回，因此不会执行 sandbox 的关停与销毁流程；而当 Pod 删除时，pod_sandbox 的 WaitProcess 收到结果，伴随着其余的业务容器一起关停并删除</em></li><li>启动 goroutine，发送退出消息至 service.ec 中</li></ol><h3 id="startExec"><a href="#startExec" class="headerlink" title="startExec"></a>startExec</h3><p><strong>处理进入容器请求</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/start.go#L100">source code</a></p><ol><li>通过 r.ID 获取维护在 service.containers 中的容器</li><li>通过 r.ExecID 获取维护在 container.execs 中的 exec</li><li>调用 VCSandbox 的 <strong>EnterContainer</strong>，进入容器内部</li><li>设置 exec 状态为 running</li><li>调用 VCSandbox 的 <strong>WinsizeProcess</strong>，调整 tty 大小</li><li>调用 VCSandbox 的 <strong>IOStream</strong>，启动 goroutine，实时处理容器中的标准输出等 IO 流</li><li>启动 goroutine，处理 exec 中的退出队列 ，即先等到容器 IO 退出事件后，再调用 VCSandbox 的 <strong>WaitProcess</strong>，进一步等待进程返回退出码后执行后续流程。设置 exec 状态为 stopped，记录退出时间，状态码等</li><li>启动 goroutine，发送退出消息至 service.ec 中</li></ol><h2 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h2><p><strong>删除容器或者 exec 进程</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L493">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DeleteRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">ExecID               <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DeleteResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">Pid                  <span class="type">uint32</span></span><br><span class="line">ExitStatus           <span class="type">uint32</span></span><br><span class="line">ExitedAt             time.Time </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>如果 r.ExecID 为空，则调用 <strong>deleteContainer</strong>，删除容器，并发送 TaskDelete 事件至 service.events 中；否则，直接删除 container.execs 中 key 为 r.ExecID 的 exec</p></li></ol><h3 id="deleteContainer"><a href="#deleteContainer" class="headerlink" title="deleteContainer"></a>deleteContainer</h3><p><strong>删除指定容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/delete.go#L17">source code</a></p><ol><li>如果容器的类型不是 pod_sandbox，则先调用 VCSandbox 的 <strong>StopContainer</strong>，关停容器（如果容器状态不为 stopped），并调用 VCSandbox 的 <strong>DeleteContainer</strong>，删除容器</li><li>执行 spec.Hooks.Poststop（Poststop 是在容器进程退出后要运行的 hook 列表）中定义的动作</li><li>如果容器文件系统已经挂载完成，则移除 rootfs 挂载点（例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs，其在 host 上以 overlay 挂载点形式存在）</li><li>删除 s.containers 中的 key 为 r.ID 的容器</li></ol><h2 id="Pids"><a href="#Pids" class="headerlink" title="Pids"></a>Pids</h2><p><strong>返回容器内的所有进程 ID，对于 Kata Containers 而言，无法从 VM 获取进程 PID，因此只返回 hypervisor 的 PID</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L829">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PidsRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PidsResponse <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// task.ProcessInfo&#123;</span></span><br><span class="line"><span class="comment">//   Pid: s.hpid,</span></span><br><span class="line"><span class="comment">// &#125;</span></span><br><span class="line">Processes            []*task.ProcessInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="Pause"><a href="#Pause" class="headerlink" title="Pause"></a>Pause</h2><p><strong>暂停容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L684">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PauseRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>设置容器状态为 pausing</p></li><li><p>调用 VCSandbox 的 <strong>PauseContainer</strong>，暂停容器</p></li><li><p>如果暂停成功，则设置容器状态为 paused，并发送 TaskPaused 事件至 service.events 中；否则，调用 VCSandbox 的 <strong>StatusContainer</strong>，查询容器状态（分为 ready、running、paused 和 stopped），如果查询失败，则实际状态视为 unknown，设置容器状态为查询到的实际结果</p></li></ol><h2 id="Resume"><a href="#Resume" class="headerlink" title="Resume"></a>Resume</h2><p><strong>恢复容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L725">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ResumeRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>调用 VCSandbox 的 <strong>ResumeContainer</strong>，恢复容器</p></li><li><p>如果恢复成功，则设置容器状态为 running，并发送 TaskResumed 事件至 service.events 中；否则，调用 VCSandbox 的 <strong>StatusContainer</strong>，查询容器状态（分为 ready、running、paused 和 stopped），如果查询失败，则实际状态视为 unknown，设置容器状态为查询到的实际结果</p></li></ol><h2 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h2><p><strong>创建容器检查点</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L897">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CheckpointTaskRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>      </span><br><span class="line">Path                 <span class="type">string</span>      </span><br><span class="line">Options              *types1.Any</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>截至 Kata 3.0，尚未实现该接口</p></li></ol><h2 id="Kill"><a href="#Kill" class="headerlink" title="Kill"></a>Kill</h2><p><strong>根据指定信号杀死进程</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L764">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> KillRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>   </span><br><span class="line">ExecID               <span class="type">string</span>  </span><br><span class="line">Signal               <span class="type">uint32</span>  </span><br><span class="line">All                  <span class="type">bool</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>以容器状态与 ID 作为待杀死进程的信息，如果 r.ExecID 不为空，则以通过 r.ExecID 获取维护在 container.execs 中的 exec 属性为准</p></li><li><p>如果信号为 SIGKILL 或者 SIGTERM，并且进程状态已经为 stopped，则不做处理，直接返回即可（根据 CRI 规范，Kubelet 在调用 RemovePodSandbox 之前至少会调用一次 StopPodSandbox ，此调用是幂等的，并且如果所有相关资源都已被回收则不得返回错误。 在调用中它会先发送一个 SIGKILL 信号来尝试停止容器，因此一旦容器终止，应该忽略这个信号并直接返回）；否则，调用 VCSandbox 的 <strong>SignalProcess</strong>，杀死进程</p></li></ol><h2 id="Exec"><a href="#Exec" class="headerlink" title="Exec"></a>Exec</h2><p><strong>在容器中追加一个额外的进程</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L547">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ExecProcessRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>  </span><br><span class="line">ExecID               <span class="type">string</span> </span><br><span class="line">Terminal             <span class="type">bool</span>        </span><br><span class="line">Stdin                <span class="type">string</span>      </span><br><span class="line">Stdout               <span class="type">string</span>      </span><br><span class="line">Stderr               <span class="type">string</span>   </span><br><span class="line">Spec                 *types1.Any</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>校验 r.ExecID 是否在 container.execs 不存在</p></li><li><p>基于 r.Stdin、r.Stdout、r.Stderr、r.Terminal 和 r.Spec 构建 exec，维护在 container.execs 中，并发送 TaskExecAdded 事件至 service.events 中</p></li></ol><h2 id="ResizePty"><a href="#ResizePty" class="headerlink" title="ResizePty"></a>ResizePty</h2><p><strong>调整进程的 pty 大小</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L587">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ResizePtyRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span> </span><br><span class="line">ExecID               <span class="type">string</span> </span><br><span class="line">Width                <span class="type">uint32</span>  </span><br><span class="line">Height               <span class="type">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>以 container.ID 作为待处理进程的 ID，如果 r.ExecID 不为空，则通过 r.ExecID 获取维护在 container.execs 中的 exec.ID 为准，并更新 r.Width 和 r.Height 至 exec 中</p></li><li><p>调用 VCSandbox 的 <strong>WinsizeProcess</strong>，调整待处理进程的 pty 大小</p></li></ol><h2 id="CloseIO"><a href="#CloseIO" class="headerlink" title="CloseIO"></a>CloseIO</h2><p><strong>关闭进程的 IO 流</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L854">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CloseIORequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">ExecID               <span class="type">string</span>   </span><br><span class="line">Stdin                <span class="type">bool</span>    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>以 container.stdinPipe 和 container.stdinCloser 作为待处理进程 IO 的信息，如果 r.ExecID 不为空，则以通过 r.ExecID 获取维护在 container.execs 中的 exec 信息为准</p></li><li><p>直至 stdinCloser channel 不再阻塞，调用 stdinPipe 的 Close 方法关闭 IO 流</p></li></ol><h2 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h2><p><strong>更新容器</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L1012">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> UpdateTaskRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span>            </span><br><span class="line">Resources            *types1.Any      </span><br><span class="line">Annotations          <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 VCSandbox 的 <strong>UpdateContainer</strong>，更新容器的资源规格</p></li></ol><h2 id="Wait"><a href="#Wait" class="headerlink" title="Wait"></a>Wait</h2><p><strong>等待进程退出</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L1046">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> WaitRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">ExecID               <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> WaitResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">ExitStatus           <span class="type">uint32</span>   </span><br><span class="line">ExitedAt             time.Time</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>从 container.exitCh 中获取退出状态码，并重新回填至 container.exitCh（用容器进程的退出代码重新填充 exitCh，以防此进程有其他等待），如果 r.ExecID 不为空，则以通过 r.ExecID 获取维护在 container.execs 中的 exec.exitCh 为准</p></li></ol><h2 id="Stats"><a href="#Stats" class="headerlink" title="Stats"></a>Stats</h2><p><strong>获取容器的统计信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L981">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StatsRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StatsResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">Stats                *types1.Any</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过 r.ID 获取维护在 service.containers 中的容器</p></li><li><p>调用 VCSandbox 的 <strong>StatsContainer</strong>，获取容器的 Hugetlb、Pids、CPU、Memory、Blkio 和 Network 统计信息</p></li></ol><h2 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h2><p><strong>返回 shim 相关信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L913">source code</a></p><ol><li><p>请求体和返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ConnectRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ConnectResponse <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 即 service.pid</span></span><br><span class="line">ShimPid              <span class="type">uint32</span></span><br><span class="line"><span class="comment">// 即 service.hpid</span></span><br><span class="line">TaskPid              <span class="type">uint32</span>   </span><br><span class="line">Version              <span class="type">string</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="Shutdown"><a href="#Shutdown" class="headerlink" title="Shutdown"></a>Shutdown</h2><p><strong>关闭 shim server</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L935">source code</a></p><ol><li><p>请求体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ShutdownRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">ID                   <span class="type">string</span></span><br><span class="line">Now                  <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>如果 service.containers 中仍有元素，代表 shim server 仍然管理容器中，因此仅关闭 tracing，不作其他处理，直接返回</p></li><li><p>调用 service.cancel 退出 shim server（cancel 由 Containerd 服务注册声明）</p></li><li><p>向 service.hpid 发送 SIGKILL 信号（由于只是在执行 stopSandbox 时向 QEMU 发送了一个 shutdown qmp 命令，并没有等到 QEMU 进程退出，这里最好确保它在 shim server 终止时已经退出。 因此，这里要对 hypervisor 进行最后的清理）</p></li><li><p>调用 os.Exit(0)，退出程序</p></li></ol><h2 id="Cleanup"><a href="#Cleanup" class="headerlink" title="Cleanup"></a>Cleanup</h2><p><strong>清理容器相关资源</strong></p><p><em>Cleanup 并未用于实现 shimv2 API，而是 Service 的功能扩展，用于在执行 containerd-shim-kata-v2 delete 操作时触发容器清理流程</em></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/service.go#L323">source code</a></p><ol><li><p>返回体结构如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DeleteResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">Pid                  <span class="type">uint32</span></span><br><span class="line">ExitStatus           <span class="type">uint32</span></span><br><span class="line">ExitedAt             time.Time</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>设置日志输出至 stderr 中（因此，日志信息并不会出现在 Kata 服务中）</p></li><li><p>获取当前目录下（例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt; 目录，流程需要在此路径下执行 ）的 config.json 文件，解析成 OCI spec 格式，判断其容器类型</p></li><li><p>如果容器类型是 pod_container，则通过 spec.Annotation 中获取到 sandboxID；如果容器类型是 pod_sandbox 或者 single_container，sandboxID 即为 service.id</p></li><li><p>调用 VC 的 <strong>CleanupContainer</strong>，清理容器</p></li><li><p>移除 rootfs 挂载点（例如 &#x2F;run&#x2F;containerd&#x2F;io.containerd.runtime.v2.task&#x2F;k8s.io&#x2F;&lt;containerID&gt;&#x2F;rootfs）</p></li></ol><h1 id="ShimManagement"><a href="#ShimManagement" class="headerlink" title="ShimManagement"></a>ShimManagement</h1><p>shim server 对外暴露的 HTTP 服务。</p><h2 id="agentURL"><a href="#agentURL" class="headerlink" title="agentURL"></a>agentURL</h2><p><strong>处理 &#x2F;agent-url 请求，返回 agent 的地址</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L56">source code</a></p><ol><li>调用 VCSandbox 的 <strong>GetAgentURL</strong>，获取 agent 地址并返回</li></ol><h2 id="serveMetrics"><a href="#serveMetrics" class="headerlink" title="serveMetrics"></a>serveMetrics</h2><p><strong>处理 &#x2F;metrics 请求，返回 guest、shim 和 agent 相关的指标</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L68">source code</a></p><ol><li>调用 VCSandbox 的 <strong>UpdateRuntimeMetrics</strong>，更新 guest 指标（更新就是重新获取指标，重新设置在 Prometheus 中）</li><li>更新当前进程（即 shimPID）的指标<ol><li>获取 &#x2F;proc&#x2F;&lt;shimPID&gt;&#x2F;fd 目录下的文件数量，上报 kata_shim_fds 指标</li><li>解析 &#x2F;proc&#x2F;&lt;shimPID&gt;&#x2F;stat 文件内容，上报 kata_shim_proc_stat 指标</li><li>解析 &#x2F;proc&#x2F;&lt;shimPID&gt;&#x2F;status 文件内容，上报 kata_shim_proc_status 指标</li><li>解析 &#x2F;proc&#x2F;&lt;shimPID&gt;&#x2F;io 文件内容，上报 kata_shim_io 指标</li></ol></li><li>如果使用旧版本的 agent（现阶段均为新版本），则不支持获取 agent 指标，直接返回 VM 和 shim 指标即可</li><li>调用 VCSandbox 的 <strong>GetAgentMetrics</strong>，获取 agent 指标（在这里，如果获取不到，则视为当前使用旧版本的 agent，后续则由步骤 3 直接返回）</li><li>启动 goroutine，上报 pod_overhead_cpu 和 pod_overhead_memory_in_bytes 至 Prometheus（收集 Pod overhead 指标需要 sleep 来获取 cpu&#x2F;memory 资源使用的变化，所以这里只触发 collect 操作，下次从 Prometheus server 收集请求时收集数据）<ol><li>调用 VCSandbox 的 <strong>Stats</strong>，获取 sandbox 的 cgroup 相关信息；调用 VCSandbox 的 <strong>GetAllContainers</strong>，获取所有容器，并逐一调用 VCSandbox 的 <strong>StatsContainer</strong>，获取容器的 cgroup 相关信息</li><li>间隔 1 秒钟，重复步骤 1，再次获取 sandbox 和容器的 cgroup 相关信息</li><li>根据两次数据信息以及总耗时，计算 overhead 指标</li></ol></li></ol><h2 id="serveVolumeStats"><a href="#serveVolumeStats" class="headerlink" title="serveVolumeStats"></a>serveVolumeStats</h2><p><strong>处理 &#x2F;direct-volume&#x2F;stats 请求，返回 guest 中指定卷的信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L147">source code</a></p><ol><li>校验请求中 path 参数是否不为空</li><li>调用 VCSandbox 的 <strong>GuestVolumeStats</strong>，获取 guest 中指定卷的信息并返回</li></ol><h2 id="serveVolumeResize"><a href="#serveVolumeResize" class="headerlink" title="serveVolumeResize"></a>serveVolumeResize</h2><p><strong>处理 &#x2F;direct-volume&#x2F;resize 请求，扩容 guest 中指定卷的大小</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L175">source code</a></p><ol><li>读取请求体，并解构成 VCSandbox 所需的格式</li><li>调用 VCSandbox 的 <strong>ResizeGuestVolume</strong>，扩容 guest 中指定卷的大小</li></ol><h2 id="ipTablesHandler、ip6TablesHandler"><a href="#ipTablesHandler、ip6TablesHandler" class="headerlink" title="ipTablesHandler、ip6TablesHandler"></a>ipTablesHandler、ip6TablesHandler</h2><p><strong>处理 &#x2F;iptables 和 &#x2F;ip6tables请求，操作 guest 中的 iptables 信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L206">source code (ipTablesHandler)</a><br><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/shim_management.go#L202">source code (ip6TablesHandler)</a></p><ol><li>两者本质相似，区别在于 ip6TablesHandler 的 isIPv6 参数为 true，后续调用接口时，会传递该参数</li><li>判断请求方法，目前仅支持 PUT 和 GET 两种，其余返回状态码 501。如果为 PUT 请求，则读取请求体，调用 VCSandbox 的 <strong>SetIPTables</strong>，设置 guest 中的 iptables 信息；如果为 GET 请求，调用 VCSandbox 的 <strong>GetIPTables</strong>，获取 guest 中的 iptables 信息</li></ol><h1 id="EventForwarder"><a href="#EventForwarder" class="headerlink" title="EventForwarder"></a>EventForwarder</h1><p><em><u>src&#x2F;runtime&#x2F;pkg&#x2F;containerd-shim-v2&#x2F;event_forwarder.go</u></em></p><p>EventForwarder 为事件上报模块，其中事件源自于 forwarder 中的 service.events。forwarder 包括两类：log 与 containerd，取决于事件最终上报的地点。每一个事件默认上报超时时间为 5 秒钟，超出会被取消上报。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> logForwarder <span class="keyword">struct</span> &#123;</span><br><span class="line">s *service</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> containerdForwarder <span class="keyword">struct</span> &#123;</span><br><span class="line">s         *service</span><br><span class="line">ctx       context.Context</span><br><span class="line">publisher events.Publisher</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，publisher 由 Containerd 调用时提供。</p><p><strong>工厂函数</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/event_forwarder.go#L71">source code</a></p><ol><li>如果环境变量中声明了 TTRPC_ADDRESS，则初始化 containerdForwarder，否则初始化 logForwarder</li></ol><h2 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h2><p><strong>处理事件上报</strong></p><h3 id="logForwarder"><a href="#logForwarder" class="headerlink" title="logForwarder"></a>logForwarder</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/event_forwarder.go#L40">source code</a></p><ol><li>监听 service.events 中的事件，断言其的类型，获得事件的 topic</li><li>在 containerd-kata-shim-v2 模块的日志中输出事件内容</li></ol><h3 id="containerdForwarder"><a href="#containerdForwarder" class="headerlink" title="containerdForwarder"></a>containerdForwarder</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/event_forwarder.go#L56">source code</a></p><ol><li>监听 service.events 中的事件，断言其的类型，获得事件的 topic</li><li>调用 Containerd 的 publisher 模块的 Publish（Containerd 负责实现），上报事件至 Containerd</li></ol><h2 id="forwarderType"><a href="#forwarderType" class="headerlink" title="forwarderType"></a>forwarderType</h2><p><strong>forwarder 的具体类型</strong></p><h3 id="logForwarder-1"><a href="#logForwarder-1" class="headerlink" title="logForwarder"></a>logForwarder</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/event_forwarder.go#L46">source code</a></p><ol><li>类型为 log</li></ol><h3 id="containerdForwarder-1"><a href="#containerdForwarder-1" class="headerlink" title="containerdForwarder"></a>containerdForwarder</h3><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/pkg/containerd-shim-v2/event_forwarder.go#L67">source code</a></p><ol><li>类型为 containerd</li></ol>]]></content>
    
    
    <summary type="html">Containerd Shimv2 API 的实现与 ShimManagement、EventForwarder 等管理相关流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码走读 — kata-runtime</title>
    <link href="http://shenxianghong.github.io/2022/11/26/2022-11-26%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20kata-runtime/"/>
    <id>http://shenxianghong.github.io/2022/11/26/2022-11-26%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20kata-runtime/</id>
    <published>2022-11-25T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.268Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><p>kata-runtime 是一个可执行程序，用于运行基于 OCI（Open Container Initiative）构建打包的应用。</p><p><em><u>src&#x2F;runtime&#x2F;cmd&#x2F;kata-runtime&#x2F;main.go</u></em></p><p>kata-runtime 本身是基于 <a href="https://github.com/urfave/cli">urfave&#x2F;cli</a> 库构建。kata-runtime 包括 7 个子命令：check（kata-check）、env（kata-env）、exec、metrics、factory、direct-volume 和 iptables。</p><p><strong>beforeSubcommands</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/main.go#L221">source code</a></p><ol><li>如果指定了 –show-default-config-paths 参数，则展示配置文件默认的路径（&#x2F;etc&#x2F;kata-containers&#x2F;configuration.toml 和 &#x2F;opt&#x2F;kata&#x2F;share&#x2F;defaults&#x2F;kata-containers&#x2F;configuration.toml）</li><li>判断用户的输入是否需要展示用法（例如 kata-runtime、kata-runtime help、kata-runtime –help 和 kata-runtime -h 等），如果满足条件，则直接展示用法文本，不执行后续流程</li><li>解析 –rootless 参数并设置</li><li>如果子命令为 check（kata-check），则设置日志级别为 warn；否则，根据 –log 参数创建日志文件（默认为 &#x2F;dev&#x2F;null），根据 –log-format 设置日志格式（支持 text 和 json，默认为 text），日志中新增 command 字段标识子命令，提取 context 设置给 logger</li><li>将配置文件内容解析并转为 OCI runtime 配置，设置在 context 中，后续的操作中不再解析配置文件</li></ol><h1 id="check（kata-check）"><a href="#check（kata-check）" class="headerlink" title="check（kata-check）"></a>check（kata-check）</h1><p><strong>Kata Containers 的运行环境要求检查</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-check.go#L313">source code</a></p><ol><li><p>如果指定了 –verbose 参数，则设置日志级别为 Info</p></li><li><p>如果没有指定 –no-network-checks 参数并且没有声明 KATA_CHECK_NO_NETWORK 环境变量，则借助网络尝试进行 release 版本检查：如果当前用户为 root 则输出 Not running network checks as super user，否则执行 release version 检查</p><ol><li>校验当前版本号是否符合 SemVer 版本规范</li><li>根据版本解析中的主版本号获取 release URL：如果为 0，则不合法；如果为 1 则获取 1.x 的 <a href="https://api.github.com/repos/kata-containers/runtime/releases">release URL</a>；如果为 2 则获取 2.x 的 <a href="https://api.github.com/repos/kata-containers/kata-containers/releases">release URL</a>；如果环境变量中声明了 KATA_RELEASE_URL 则以此为准</li><li>检验 release URL 的合法性，除了默认的 1.x 和 2.x 版本之外，其余的均为不合法，因此通过环境变量 KATA_RELEASE_URL 声明的 release URL 也必须为官方默认的</li><li>如果当前用户为 root 则返回 No network checks allowed running as super user 错误，否则请求 release URL，根据是否指定了 –include-all-releases 参数，解析符合要求的 release 详情信息</li><li>如果指定了 –only-list-releases 参数，则展示所有的 release 详情，不执行后续流程</li><li>获取最新的 release，并展示其详情信息</li></ol></li><li><p>如果指定了 –check-version-only 参数或者 –only-list-releases 参数则不执行后续流程</p></li><li><p>解析获得 OCI runtime 配置信息，根据使用的 hypervisor 的类别，设置 CPU 类别，获取运行所需的 CPU flags 和内核模块</p><p><em><strong>amd64</strong></em></p><ol><li>根据 &#x2F;proc&#x2F;cpuinfo 文件中字符串匹配 GenuineIntel 或 AuthenticAMD 获得其 CPU 类型，x86 架构下支持  Intel 和 AMD 类型</li><li>当 CPU 类型为 Intel 时：<ol><li>根据 CPU flags 中是否含有 “hypervisor” 判断是否运行在 VM 环境中，如果没运行在 VM 中，则需要支持 <a href="https://communities.vmware.com/t5/VMware-Workstation-Pro/What-is-VMX-Unrestricted-Guest/td-p/2748822">VMX Unrestricted</a> 模式（用于判断系统环境是否足够新，用以满足运行 Kata Containers，至少是 <a href="https://en.wikipedia.org/wiki/Westmere_(microarchitecture)">Westmere</a>）</li><li>如果 hypervisor 为 QEMU、Cloud hypervisor、Firecracker 和 Dragonball 时，则要求 CPU 具有 vmx、lm 和 sse4_1 的 flag 特性以及内核模块中 kvm、kvm_intel、vhost、vhost_net 和 vhost_vsock 应启动；如果 hypervisor 为 acrn 时，则要求 CPU 具有 lm 和 sse4_1 的 flag 特性以及内核模块中 vhm_dev、vhost 和 vhost_net 应启动；如果 hypervisor 为 mock 时，则要求 CPU 具有 vmx、lm 和 sse4_1 的 flag 特性</li></ol></li><li>当 CPU 类型为 AMD 时：<ol><li>无论 hypervisor 的类型，要求 CPU 具有 svm、lm、sse4_1 的 flag 特性以及内核模块中 kvm、kvm_amd、vhost、vhost_net 和 vhost_vsock 应启动</li><li>记录以上依赖要求至全局变量中，后续会作为运行环境监测的依据</li></ol></li></ol><p><em><strong>arm64</strong></em></p><ol><li>arm64 架构下，setCPUtype 不做任何处理，而是采取了相关全局变量硬编码方式</li><li>要求内核模块中 kvm、vhost、vhost_net 和 vhost_vsock 应启动，CPU flag 特性无特殊要求</li></ol></li><li><p>判断当前环境是否满足运行 Kata Containers 要求，满足要求时输出 System is capable of running Kata Containers</p></li><li><p>如果当前用户为 root，则通过系统调用创建一个最小化的 VM 之后并删除，用以检测当前环境是否能够满足创建 VM 的要求</p><p><em><strong>amd64</strong></em></p><ol><li>当 hypervisor 为 QEMU、Cloud Hypervisor、Firecracker 时，验证流程参考：<a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-check_amd64.go#L234">kvmIsUsable</a>；hypervisor 为 ACRN 时，验证流程参考：<a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-check_amd64.go#L240">acrnIsUsable</a>。满足要求时输出 System can currently create Kata Containers</li></ol><p><em><strong>arm64</strong></em></p><ol><li>不区分 hypervisor 类型，验证流程参考：<a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-check_arm64.go#L66">kvmIsUsable</a></li><li>验证是否支持 KVM Extension，验证流程参考：<a href="#https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-check_arm64.go#L70">checkKVMExtensions</a></li></ol></li></ol><h1 id="env（kata-env）"><a href="#env（kata-env）" class="headerlink" title="env（kata-env）"></a>env（kata-env）</h1><p><strong>展示 Kata Containers 的设置信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-env.go#L427">source code</a></p><ol><li>调用上述的 <strong>setCPUtype</strong>，根据 hypervisor 的类别，获取运行所需的 CPU flags 和内核模块</li><li>生成 meta 配置项内容，其中 version 固定为 1.0.26</li><li>通过配置文件和 OCI Runtime 的信息，生成 runtime、agent、 hypervisor、image、initrd、kernel  配置项内容</li><li>通过解析 &#x2F;proc&#x2F;version 获取内核版本信息；通过解析 &#x2F;etc&#x2F;os-release 或者 &#x2F;usr&#x2F;lib&#x2F;os-release 获取发行版名称和版本信息；通过解析 &#x2F;proc&#x2F;cpuinfo 获得 CPU 类别和型号；通过 &#x2F;dev&#x2F;vhost-vsock 的存在性，判断是否支持 vhost-sock。此外，汇合内存总量与使用量、CPU 是否满足运行要求等，生成 host 配置项内容</li><li>汇总以上配置项内容，根据是否指定 –json 参数（默认为 TOML 格式），格式化展示内容</li></ol><h1 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h1><p><strong>借助 debug console 进入到 VM 中</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-exec.go#L51">source code</a></p><ol><li><p>如果没有指定 –kata-debug-port 参数或者指定为 0，则 debug 端口设置为默认的 1026</p></li><li><p>校验指定的 sandboxID 参数是否不为空，且正则匹配满足 ^[a-zA-Z0-9][a-zA-Z0-9_.-]+$</p></li><li><p>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/agent-url</code>，解析内容获得 sandbox 的 console socket，示例如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl --unix-socket /run/vc/sbs/dd2aa45873a9c0f5e1e93fc38cc0e1fe561e79e33aa85be49487162c1ebc7f43/shim-monitor.sock http://shim/agent-url</span></span><br><span class="line">vsock://4138340623:1024</span><br></pre></td></tr></table></figure></li><li><p>如果 sandbox 的 console socket 协议为 vsock，则构建成类似 vsock:&#x2F;&#x2F;4138340623:1026 的格式；如果协议为 hvsock，则构建成 hvsock:&#x2F;&#x2F;&#x2F;run&#x2F;vc&#x2F;firecracker&#x2F;340b412c97bf1375cdda56bfa8f18c8a&#x2F;root&#x2F;kata.hvsock:1026 的格式。仅支持此两种协议，建立 grpc 请求链接，用于 VM 内外的通信交互</p></li><li><p>获取当前进程的 console，将 kata-runtime exec &lt;sandboxID&gt; 的输出流展示到当前 console 中</p></li></ol><h1 id="metrics"><a href="#metrics" class="headerlink" title="metrics"></a>metrics</h1><p><strong>获取 VM 中暴露的指标信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-metrics.go#L16">source code</a></p><ol><li>校验指定的 sandboxID 参数是否不为空，且正则匹配满足 ^[a-zA-Z0-9][a-zA-Z0-9_.-]+$</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/metrics</code>，展示请求返回内容</li></ol><h1 id="factory"><a href="#factory" class="headerlink" title="factory"></a>factory</h1><h2 id="init"><a href="#init" class="headerlink" title="init"></a>init</h2><p><strong>初始化 VM factory</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L148">source code</a></p><ol><li>如果启用 VM cache 特性（即 [factory].vm_cache_number 大于 0），则初始化一个新的 factory（即 fetchOnly 为 false）。启动 cache server，监听 [factory].vm_cache_endpoint（默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock）</li><li>如果启用 VM template 特性（即 [factory].enable_template 为 true），则初始化一个新的 factory（即 fetchOnly 为 false）；否则视为 VM cache 和 VM template 均未开启前提下调用 kata-runtime factory init，抛出相关报错</li></ol><h2 id="destory"><a href="#destory" class="headerlink" title="destory"></a>destory</h2><p><strong>销毁 VM factory</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L224">source code</a></p><ol><li>如果启用 VM cache 特性（即 [factory].vm_cache_number 大于 0），则通过 [factory].vm_cache_endpoint（默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock）gRPC 调用 cache server 的 <strong>Quit</strong>，请求关闭 cache server</li><li>如果启用 VM template 特性（即 [factory].enable_template 为 true），则获取现有的 factory （即 fetchOnly 为 true），调用 factory 的 <u>CloseFactory</u>，关闭 factory</li></ol><h2 id="status"><a href="#status" class="headerlink" title="status"></a>status</h2><p><strong>查询 VM factory 的状态</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/factory.go#L274">source code</a></p><ol><li>如果启用 VM cache 特性（即 [factory].vm_cache_number 大于 0），则通过 [factory].vm_cache_endpoint（默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock）gRPC 调用 cache server 的 <strong>Status</strong>，展示请求返回内容</li><li>如果启用 VM template 特性（即 [factory].enable_template 为 true），则获取现有的 factory （即 fetchOnly 为 true），输出其是否存在</li></ol><h1 id="direct-volume"><a href="#direct-volume" class="headerlink" title="direct-volume"></a>direct-volume</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MountInfo contains the information needed by Kata to consume a host block device and mount it as a filesystem inside the guest VM.</span></span><br><span class="line"><span class="keyword">type</span> MountInfo <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// The type of the volume (ie. block)</span></span><br><span class="line">VolumeType <span class="type">string</span> <span class="string">`json:&quot;volume-type&quot;`</span></span><br><span class="line"><span class="comment">// The device backing the volume.</span></span><br><span class="line">Device <span class="type">string</span> <span class="string">`json:&quot;device&quot;`</span></span><br><span class="line"><span class="comment">// The filesystem type to be mounted on the volume.</span></span><br><span class="line">FsType <span class="type">string</span> <span class="string">`json:&quot;fstype&quot;`</span></span><br><span class="line"><span class="comment">// Additional metadata to pass to the agent regarding this volume.</span></span><br><span class="line">Metadata <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span> <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line"><span class="comment">// Additional mount options.</span></span><br><span class="line">Options []<span class="type">string</span> <span class="string">`json:&quot;options,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直通卷的操作都是基于 MountInfo 结构，它描述了待直通至 VM 中的卷位于 host 侧的信息详情。</p><h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><p><strong>为指定的 VM 新增直通卷</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-volume.go#L42">source code</a></p><ol><li>对指定的 –volume-path 参数进行 URLEncoding 后，拼接成 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;volumePath (base64)&gt; 路径目录</li><li>如果该路径不存在，则创建目录层级；如果该路径存在，则判断其是否为目录</li><li>将 –mount-info 参数内容持久化到该目录下的 mountInfo.json 文件中</li></ol><h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><p><strong>删除指定 VM 的直通卷</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-volume.go#L65">source code</a></p><ol><li>对指定的 –volume-path 参数进行 URLEncoding 后，拼接成 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;volumePath (base64)&gt; 路径目录</li><li>移除该目录</li></ol><h2 id="stats"><a href="#stats" class="headerlink" title="stats"></a>stats</h2><p><strong>获取 VM 中直通卷的文件系统信息</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-volume.go#L83">source code</a></p><ol><li>对指定的 –volume-path 参数进行 URLEncoding 后，拼接成 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;volumePath (base64)&gt; 路径目录</li><li>遍历目录，获取到 sandboxID（直通卷模式下，该目录中仅有一个 sandboxID 目录与 mountInfo.json 文件，因此名称不为 mountInfo.json 即为 sandboxID）</li><li>获取并解析目录中的 mountInto.json 文件内容，得到 mountInfo.Device（即位于 host 上待直通至 VM 中的设备）</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/direct-volume/stats?path=&lt;device&gt;</code>，展示请求返回内容</li></ol><h2 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h2><p><strong>扩容 VM 的直通块设备的卷大小</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-volume.go#L104">source code</a></p><ol><li>对指定的 –volume-path 参数进行 URLEncoding 后，拼接成 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;volumePath (base64)&gt; 路径目录</li><li>遍历目录，获取到 sandboxID（直通卷模式下，该目录中仅有一个 sandboxID 目录与 mountInfo.json 文件，因此名称不为 mountInfo.json 的即为 sandboxID）</li><li>获取并解析目录中的 mountInto.json 文件内容，得到 mountInfo.Device（即位于 host 上待直通至 VM 中的设备）</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送格式为 application&#x2F;json 的 HTTP POST 请求至 shim server 的 <code>http://shim/direct-volume/resize</code>，其中请求体包含 mountInfo.Device 和卷扩容后的期望大小</li></ol><h1 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h1><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><p><strong>获取 VM 中的 iptables 规则</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-iptables.go#L36">source code</a></p><ol><li>校验指定的 sandboxID 参数是否不为空，且正则匹配满足 ^[a-zA-Z0-9][a-zA-Z0-9_.-]+$</li><li>如果额外指定了 –v6 参数，则 url 为 &#x2F;ip6tables，否则为 &#x2F;iptables</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送 HTTP GET 请求至 shim server 的 <code>http://shim/&lt;url&gt;</code>，展示请求返回内容</li></ol><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><p><strong>基于指定的文件内容，设置 VM 中的 iptables 规则</strong></p><p><a href="https://github.com/kata-containers/kata-containers/blob/3.0.0/src/runtime/cmd/kata-runtime/kata-iptables.go#L72">source code</a></p><ol><li>校验指定的 sandboxID 参数是否不为空，且正则匹配满足 ^[a-zA-Z0-9][a-zA-Z0-9_.-]+$</li><li>校验指定的 iptables 参数对应的文件是否存在，并读取 iptables 文件内容</li><li>如果额外指定了 –v6 参数，则 url 为 &#x2F;ip6tables，否则为 &#x2F;iptables</li><li>通过 &#x2F;run&#x2F;vc&#x2F;sbs&#x2F;&lt;sandboxID&gt;&#x2F;shim-monitor.sock 发送格式为 application&#x2F;octet-stream 的 HTTP PUT 请求至 shim server 的 <code>http://shim/&lt;url&gt;</code>，其中请求体包含 iptables 文件内容流</li></ol>]]></content>
    
    
    <summary type="html">Kata Containers 命令行工具的流程梳理</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Virtual Kubelet 」快速开始</title>
    <link href="http://shenxianghong.github.io/2022/11/22/2022-11-22%20Virtual%20Kubelet%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2022/11/22/2022-11-22%20Virtual%20Kubelet%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2022-11-21T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.267Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/virtual-kubelet/logo.svg"></div><hr><blockquote><p>based on <strong>v1.7.0</strong></p></blockquote><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>Kubernetes API on top, programmable back.</p></blockquote><p>Virtual Kubelet（VK） 是 Kubernetes 中 Kubelet 的典型特性实现，向上伪装成 Kubelet，从而模拟出 Node 对象，对接 Kubernetes 的原生资源对象。向下提供 API，可对接其他资源管理平台提供的 Provider，不同的平台通过实现 Virtual Kubelet 定义的方法，允许节点由其对应的 Provider 提供，如 ACI、AWS Fargate、IoT Edge、Tensile Kube 等。Virtual Kubelet 的主要场景是将 Kubernetes API 扩展到 Serverless 容器平台（如 ACI 和 Fargate）或者扩展到如 Docker Swarm、Openstack ZUN 等容器平台中，也可以通过 Provider 纳管其他 Kubernetes 集群，甚至是原生的 IAAS 平台（如 VMware、Openstack 等。在社区宗旨中，Virtual Kubelet 不是用来实现集群联邦的手段。</p><p>Virtual Kubelet 具有可插拔架构和直接使用 Kubernetes 原语的特点，更易于构建。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><div align=center><img width="800" style="border: 0px" src="/gallery/virtual-kubelet/diagram.svg"></div><p><strong>与传统 Kubelet 的区别</strong></p><ul><li>传统的 Kubelet 实现了所在节点的 Pod 和容器的操作行为</li><li>Virtual Kubelet 以节点的形式注册，允许开发者以自定义的行为部署 Pod 和容器</li></ul><p><strong>当前支持的 Kubernetes 特性</strong></p><ul><li>创建、删除和更新 Pod</li><li>容器日志、管理和指标</li><li>获取 Pod 以及状态</li><li>节点地址、节点容量、节点守护进程端点</li><li>管理操作系统</li><li>携带私有虚拟网络</li></ul><h1 id="Providers"><a href="#Providers" class="headerlink" title="Providers"></a>Providers</h1><p>Virtual Kubelet 专注于提供一个库，用户可以在项目中使用该库来构建自定义 Kubernetes 节点 agent。</p><p>该项目具有一个可插拔的 Provider 接口，开发者可以实现该接口来定义 Kubelet 的操作。</p><p>支持按需和与 Kubernetes 近乎即时的编排容器计算，无需管理 VM 基础设施，同时仍然利用可移植的 Kubernetes API。</p><p>每个 Provider 可能有自己的配置文件和所需的环境变量。</p><p>Provider 必须具备以下功能才能与 Virtual Kubelet 集成支持：</p><ul><li><p>提供必要的后端服务，用于支持 Kubernetes 的 Pod、容器和支持资源的生命周期管理</p></li><li><p>符合 Virtual Kubelet 的 API 规范</p></li><li><p>无法访问 Kubernetes API 服务器，并且具有定义明确的回调机制来获取 Secret 或 ConfigMap 等数据</p></li></ul><p><em>参考：<a href="https://pkg.go.dev/github.com/virtual-kubelet/virtual-kubelet#section-readme">virtual-kubelet godoc</a></em></p><h2 id="Admiralty-Multi-Cluster-Scheduler"><a href="#Admiralty-Multi-Cluster-Scheduler" class="headerlink" title="Admiralty Multi-Cluster Scheduler"></a>Admiralty Multi-Cluster Scheduler</h2><p>Admiralty Multi-Cluster Scheduler 将特定的 Pod 运行在 Virtual Kubelet 节点上，作为“代理 Pod”，并在远程集群（实际运行容器）中创建相应的”委托 Pod”。通过控制循环机制，更新代理 Pod 的信息用来反映委托 Pod 的状态。</p><p><em>参考：<a href="https://github.com/admiraltyio/multicluster-scheduler">Admiralty Multi-Cluster Scheduler documentation</a></em></p><h2 id="Alibaba-Cloud-Elastic-Container-Instance-ECI"><a href="#Alibaba-Cloud-Elastic-Container-Instance-ECI" class="headerlink" title="Alibaba Cloud Elastic Container Instance (ECI)"></a>Alibaba Cloud Elastic Container Instance (<strong>ECI</strong>)</h2><p>阿里云 ECI（弹性容器实例）是一种无需管理服务器或集群即可运行容器的服务。阿里云 ECI Provider 是连接 K8s和 ECI 服务之间的桥梁。</p><p><em>参考： <a href="https://github.com/virtual-kubelet/alibabacloud-eci/blob/master/README.md">Alibaba Cloud ECI documentation</a></em></p><h2 id="Azure-Container-Instances-ACI"><a href="#Azure-Container-Instances-ACI" class="headerlink" title="Azure Container Instances (ACI)"></a>Azure Container Instances (<strong>ACI</strong>)</h2><p>Azure 容器实例 Provider 允许在同一个 Kubernetes 集群中同时使用 VM 上的 Pod 和 Azure 容器实例。</p><div align=center><img width="600" style="border: 0px" src="/gallery/virtual-kubelet/aci.png"></div><p><em>参考：<a href="https://github.com/virtual-kubelet/azure-aci/blob/master/README.md">Azure Container Instances documentation</a></em></p><h2 id="AWS-Fargate"><a href="#AWS-Fargate" class="headerlink" title="AWS Fargate"></a>AWS Fargate</h2><p>AWS Fargate 是一种允许运行容器而无需管理服务器或集群的技术。</p><p>AWS Fargate 提供商允许将 Pod 部署到 AWS Fargate。在 AWS Fargate 上的 Pod 可以访问具有子网中专用 ENI 的 VPC 网络、连接到互联网的公共 IP 地址、连接到 Kubernetes 集群的私有 IP 地址、安全组、IAM 角色、CloudWatch Logs 和许多其他 AWS 服务。 Fargate 上的 Pod 可以与同一 Kubernetes 集群中常规工作节点上的 Pod 共存。</p><p><em>参考：<a href="https://github.com/virtual-kubelet/aws-fargate">AWS Fargate documentation</a></em></p><h2 id="Elotl-Kip"><a href="#Elotl-Kip" class="headerlink" title="Elotl Kip"></a>Elotl Kip</h2><p>Kip 是一个在云实例中运行 Pod 的提供商，允许 Kubernetes 集群透明地将工作负载扩展到云中。当一个 Pod 被调度到虚拟节点上时，Kip 会为 Pod 的工作负载启动一个大小合适的云实例，并将 Pod 调度到该实例上。当 Pod 完成运行时，云实例将终止。</p><p>当工作负载在 Kip 上运行时，集群大小自然会随着集群工作负载而扩展，Pod 彼此高度隔离，并且用户无需管理工作节点并将 Pod 战略性地调度到节点上。</p><p><em>参考：<a href="https://github.com/elotl/kip">Elotl Kip documentation</a></em></p><h2 id="Kubernetes-Container-Runtime-Interface-CRI"><a href="#Kubernetes-Container-Runtime-Interface-CRI" class="headerlink" title="Kubernetes Container Runtime Interface (CRI)"></a>Kubernetes Container Runtime Interface (<strong>CRI</strong>)</h2><p>CRI Provider 是基于 CRI 的容器运行时管理真实的 Pod 和容器。</p><p>CRI Provider 的目的仅用于测试和原型。不得用于任何其他目的！</p><p>Virtual Kubelet 项目的重点是为不符合标准节点模型的容器运行时提供接口。 而 Kubelet 代码库是全面的标准 CRI 节点代理，并且此 Provider 不会尝试重新创建它。</p><p>这个 Provider 实现是一个最基本的最小实现，它可以更容易地针对真实的 Pod 和容器测试 Virtual Kubelet 项目的核心功能 —— 换句话说，它比 MockProvider 更全面。</p><p><strong>已知限制</strong></p><ul><li>CRI Provider 实现了 Provider 接口全部操作，主要是管理 Pod 的生命周期、返回日志和其他内容</li><li>具备创建 emptyDir、configmap 和 secret volumes 的能力，但如果当发生变化时不会更新</li><li>不支持任何类型的持久卷</li><li>会在启动时尝试运行 kube-proxy，并且可以成功运行。但是，当将 Virtual Kubelet 转换为抽象地处理 Service 和路由的模型时，此功能将被重构为测试该功能的一种方式</li><li>网络目前是非功能性的</li></ul><h2 id="Huawei-Cloud-Container-Instance-CCI"><a href="#Huawei-Cloud-Container-Instance-CCI" class="headerlink" title="Huawei Cloud Container Instance (CCI)"></a>Huawei Cloud Container Instance (<strong>CCI</strong>)</h2><p>华为 CCI Virtual Kubelet Provider 将 CCI 项目配置成任何 Kubernetes 集群中的节点，例如华为 CCE（云容器引擎）。CCE 支持原生 Kubernetes 应用和工具作为私有集群，便于轻松搭建容器运行环境。被调度到 Virtual Kubelet Provider 的 Pod 将运行在 CCI 中，便于更好的利用 CCI 的高性能。</p><div align=center><img width="600" style="border: 0px" src="/gallery/virtual-kubelet/cci-provider.svg"></div><p><em>参考：<a href="https://github.com/virtual-kubelet/huawei-cci/blob/master/README.md#readme">Huawei CCI documentation</a></em></p><h2 id="HashiCorp-Nomad"><a href="#HashiCorp-Nomad" class="headerlink" title="HashiCorp Nomad"></a>HashiCorp Nomad</h2><p>Virtual Kubelet 的 HashiCorp Nomad Provider 通过将 Nomad 集群公开为 Kubernetes 中的一个节点，将Kubernetes 集群与 Nomad 集群连接起来。借助 Provider，在 Kubernetes 上注册的虚拟 Nomad 节点上调度的 Pod 将作为 Job 在 Nomad 客户端上运行，就像在 Kubernetes 节点上一样。</p><p><em>参考：<a href="https://github.com/virtual-kubelet/nomad/blob/master/README.md">HashiCorp Nomad documentation</a></em></p><h2 id="Liqo"><a href="#Liqo" class="headerlink" title="Liqo"></a>Liqo</h2><p>Liqo 为 Virtual Kubelet 实现了一个 Provider，旨在透明地将 Pod 和服务卸载到“对等”Kubernetes 远程集群。 Liqo 能够发现邻居集群（使用 DNS、mDNS）并与其“对等”，或者说建立关系以共享集群的部分资源。当集群建立对等连接时，会生成一个新的 Liqo Virtual Kubelet 实例，通过提供远程集群资源的抽象来无缝扩展集群的容量。该提供商与 Liqo 网络结构相结合，通过启用 Pod 到 Pod 流量和多集群东西向服务扩展集群网络，支持两个集群上的端点。</p><p><em>参考：<a href="https://github.com/liqotech/liqo/blob/master/README.md">Liqo documentation</a></em></p><h2 id="OpenStack-Zun"><a href="#OpenStack-Zun" class="headerlink" title="OpenStack Zun"></a>OpenStack Zun</h2><p>Virtual Kubelet 的 OpenStack Zun Provider 用于将 Kubernetes 集群与 OpenStack 集群打通，从而可以在 OpenStack 上运行 Kubernetes 的 Pod。借助子网中的 Neutron 端口，在 OpenStack 上的 Pod 可以访问 OpenStack 租户网络，每个 Pod 都有私有 IP 地址，可以连接到租户内的其他 OpenStack 资源（例如 VM），也可以借助浮动 IP 地址连接互联网，或者将 Cinder 卷绑定给 Pod 容器使用。</p><p><em>参考：<a href="https://github.com/virtual-kubelet/openstack-zun/blob/master/README.md">OpenStack Zun documentation</a></em></p><h2 id="Tencent-Games-Tensile-Kube"><a href="#Tencent-Games-Tensile-Kube" class="headerlink" title="Tencent Games Tensile Kube"></a>Tencent Games Tensile Kube</h2><p>Tensile Kube Provider 由腾讯游戏提供，可将 Kubernetes 集群与其他 Kubernetes 集群连接起来。该 Provider 能够将 Kubernetes 集群规模无限扩展。底层集群以虚拟节点的形态注册到上层集群中，借助 Provider，调度在虚拟节点上的 Pod 将在其他 Kubernetes 集群的节点上运行。</p><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><div align=center><img width="600" style="border: 0px" src="/gallery/virtual-kubelet/tensile-kube.png"></div><ul><li><p>virtual-node</p><p>基于 virtual-kubelet 实现的 Kubernetes Provider。在上层集群中创建的 Pod 将同步到底层集群。如果 Pod 依赖于 ConfigMaps 或 Secret，那么依赖关系也会在集群中创建</p></li><li><p>multi-cluster scheduler</p><p>基于 K8s schedule framework 实现。它会在调度 Pod 时根据所有底层集群的容量，并调用 filter 过滤器。如果可用节点数大于或等于 1，则 Pod 可以被调度。因此，这可能会消耗更多资源，因此添加了另一个实现（descheduler）</p></li><li><p>descheduler</p><p>descheduler 是基于 K8s descheduler 的二次优化，改变了一些逻辑。它会通过注入一些 nodeAffinity 重新创建一些不可调度的 Pod。可以选择部署上层集群中的 multi-scheduler 和 descheduler 之一，也可以同时选择两者</p><ul><li>大规模集群不建议使用 multi-scheduler，当节点总数超过 10000 时，descheduler 开销相对更小</li><li>当集群中的节点较少时，multi-scheduler 效果会更好，例如有 10 个集群，每个集群只有 100 个节点</li></ul></li><li><p>webhook</p><p>Webhook 是基于 K8s mutation webhook 设计的。用于转换一些可能影响上层集群中调度 Pod（不在 kube-system 中）的字段，例如 nodeSelector、nodeAffinity 和 tolerations。但是只有标签为 virtual-pod:true 的 Pod 才会被转换</p><p>强烈建议 Pod 运行在底层集群并添加标签 virtual-pod:true，除非那些 Pod 必须部署在上层集群的 kube-system 中</p><ul><li>对于 K8s &lt; 1.16，没有 label 的 pod 不会被转换。但仍会发送请求到 webhook</li><li>对于 K8s &gt;&#x3D; 1.16，可以使用 label selector 为一些指定的 pod 启用 webhook</li><li>总的来说，最初的想法是只在底层集群中运行 Pod</li></ul></li></ul><h3 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h3><ul><li>如果要使用 Server，必须保持 Pod 间通信正常。集群 A 中的 Pod A 可以被集群 B 中的 Pod B 通过 ip 访问。default 命名空间中的服务 Kubernetes 和 kube-system 中的其他服务将同步到较底层的集群</li><li>在 repo 中开发的 multi-scheduler 可能会花费更多资源，因为它会同步所有较底层集群中调度程序需要的所有对象</li><li>descheduler 不能绝对避免资源碎片化</li><li>PV&#x2F;PVC 只支持本地 PV 的 WaitForFirstConsumer，上层集群的调度器应该忽略 VolumeBindCheck</li></ul><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><div align=center><img width="800" style="border: 0px" src="/gallery/virtual-kubelet/multi.png"></div><p><em>参考：<a href="https://github.com/virtual-kubelet/tensile-kube/blob/master/README.md">Tensile Kube documentation</a></em></p><h1 id="Provider-接口实现"><a href="#Provider-接口实现" class="headerlink" title="Provider 接口实现"></a>Provider 接口实现</h1><p>Provider 实现了 Kubernetes 节点代理 （即 Kubelet）的核心逻辑。</p><h2 id="PodLifecylceHandler"><a href="#PodLifecylceHandler" class="headerlink" title="PodLifecylceHandler"></a>PodLifecylceHandler</h2><p>用于处理在 Kubernetes 中创建、更新或删除 Pod 的请求。</p><p><a href="https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#PodLifecycleHandler">godoc#PodLifecylceHandler</a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PodLifecycleHandler <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// CreatePod takes a Kubernetes Pod and deploys it within the provider.</span></span><br><span class="line">    CreatePod(ctx context.Context, pod *corev1.Pod) <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// UpdatePod takes a Kubernetes Pod and updates it within the provider.</span></span><br><span class="line">    UpdatePod(ctx context.Context, pod *corev1.Pod) <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// DeletePod takes a Kubernetes Pod and deletes it from the provider.</span></span><br><span class="line">    DeletePod(ctx context.Context, pod *corev1.Pod) <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// GetPod retrieves a pod by name from the provider (can be cached).</span></span><br><span class="line">    GetPod(ctx context.Context, namespace, name <span class="type">string</span>) (*corev1.Pod, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// GetPodStatus retrieves the status of a pod by name from the provider.</span></span><br><span class="line">    GetPodStatus(ctx context.Context, namespace, name <span class="type">string</span>) (*corev1.PodStatus, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// GetPods retrieves a list of all pods running on the provider (can be cached).</span></span><br><span class="line">    GetPods(context.Context) ([]*corev1.Pod, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有一个可选实现的接口 PodNotifiery，用于 Provider 异步通知 virtual-kubelet 有关 Pod 状态更改的信息。如果没有实现这个接口，virtual-kubelet 会周期性的检查所有 Pod 的状态。</p><p><em>强烈建议实现 PodNotifier，尤其是当运行大量 Pod 时。</em></p><p><a href="https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#PodNotifier">godoc#PodNotifier</a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PodNotifier <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// NotifyPods instructs the notifier to call the passed in function when</span></span><br><span class="line">    <span class="comment">// the pod status changes.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// NotifyPods should not block callers.</span></span><br><span class="line">    NotifyPods(context.Context, <span class="function"><span class="keyword">func</span><span class="params">(*corev1.Pod)</span></span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PodLifecycleHandler 由 PodController 维护，PodController 是管理分配给节点 Pod 的核心逻辑。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pc, _ := node.NewPodController(podControllerConfig) <span class="comment">// &lt;-- instatiates the pod controller</span></span><br><span class="line">pc.Run(ctx) <span class="comment">// &lt;-- starts watching for pods to be scheduled on the node</span></span><br></pre></td></tr></table></figure><h2 id="NodeProvider"><a href="#NodeProvider" class="headerlink" title="NodeProvider"></a>NodeProvider</h2><p>NodeProvider 负责通知 virtual-kubelet 节点状态更新。 virtual-kubelet 会定期检查节点的状态并相应地更新至 Kubernetes。</p><p><a href="https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#NodeProvider">godoc#NodeProvider</a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> NodeProvider <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// Ping checks if the node is still active.</span></span><br><span class="line">    <span class="comment">// This is intended to be lightweight as it will be called periodically as a</span></span><br><span class="line">    <span class="comment">// heartbeat to keep the node marked as ready in Kubernetes.</span></span><br><span class="line">    Ping(context.Context) <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// NotifyNodeStatus is used to asynchronously monitor the node.</span></span><br><span class="line">    <span class="comment">// The passed in callback should be called any time there is a change to the</span></span><br><span class="line">    <span class="comment">// node&#x27;s status.</span></span><br><span class="line">    <span class="comment">// This will generally trigger a call to the Kubernetes API server to update</span></span><br><span class="line">    <span class="comment">// the status.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// NotifyNodeStatus should not block callers.</span></span><br><span class="line">    NotifyNodeStatus(ctx context.Context, cb <span class="function"><span class="keyword">func</span><span class="params">(*corev1.Node)</span></span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NodeProvider 由 NodeController 维护，这是 Kubernetes 管理节点对象的核心逻辑。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nc, _ := node.NewNodeController(nodeProvider, nodeSpec) <span class="comment">// &lt;-- instantiate a node controller from a node provider and a kubernetes node spec</span></span><br><span class="line">nc.Run(ctx) <span class="comment">// &lt;-- creates the node in kubernetes and starts up he controller</span></span><br></pre></td></tr></table></figure><p><a href="https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#NaiveNodeProvider">godoc#NaiveNodeProvider</a></p><p>Virtual Kubelet 提供了一个 NaiveNodeProvider，用于不打算自定义节点行为时。</p><h2 id="API-endpoints"><a href="#API-endpoints" class="headerlink" title="API endpoints"></a>API endpoints</h2><p>Kubelet 的工作之一是接受来自 API Server 的请求，比如 kubectl logs 和 kubectl exec。</p><p>如果想在集群中使用 HPA（Horizontal Pod Autoscaler），Provider 应该实现 GetStatsSummary 函数。然后 metrics-server 将能够获取 virtual-kubelet 上的 Pod 的指标。否则，可能会在 metrics-server 上看到 No metrics for pod，这意味着不会收集 virtual-kubelet 上的 Pod 的指标。</p><h1 id="已知问题和解决方案"><a href="#已知问题和解决方案" class="headerlink" title="已知问题和解决方案"></a>已知问题和解决方案</h1><h2 id="Service-缺少-Load-Balancer-IP"><a href="#Service-缺少-Load-Balancer-IP" class="headerlink" title="Service 缺少 Load Balancer IP"></a>Service 缺少 Load Balancer IP</h2><p><strong>Provider 不支持服务发现</strong></p><p>Kubernetes 1.9 为控制平面的 Controller Manager 引入了一个新标识 ServiceNodeExclusion。在 Controller Manager 的配置文件中启用此标志允许 Kubernetes 将 Virtual Kubelet 节点排除在添加到负载均衡器池之外，创建具有外部 IP 的 Service。</p><p><strong>解决方案</strong></p><p>集群要求：Kubernetes 1.9或以上</p><p>Controller Manager 配置文件中新增 –feature-gates&#x3D;ServiceNodeExclusion&#x3D;true 参数启用 ServiceNodeExclusion 标识。</p><h1 id="实践操作"><a href="#实践操作" class="headerlink" title="实践操作"></a>实践操作</h1><p>以 Tensile Kube Provider 为例。</p><p><strong>准备工作</strong></p><p>Tensile Kube Provider 是将其他的 Kubernetes 集群以虚拟节点的形式加入到主集群，因此需要准备两个集群。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上层集群</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node</span></span><br><span class="line">NAME           STATUS   ROLES                  AGE   VERSION</span><br><span class="line">desktop-ca83   Ready    control-plane,master   16d   v1.22.9</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">底层集群</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node</span></span><br><span class="line">NAME              STATUS   ROLES    AGE    VERSION</span><br><span class="line">archcnstcm67370   Ready    master   2d5h   v1.18.15</span><br><span class="line">archcnstcm67371   Ready    master   2d5h   v1.18.15</span><br><span class="line">archcnstcm67372   Ready    master   2d5h   v1.18.15</span><br></pre></td></tr></table></figure><p><strong>编译 virtual-node</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/virtual-kubelet/tensile-kube.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> tensile-kube &amp;&amp; make</span></span><br></pre></td></tr></table></figure><p><strong>Provider 部署</strong></p><p>Tensile Kube Provider 运行在底层集群中，将其三节点集群以虚拟节点 vk-node 加入到上层集群中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">底层集群启动 Tensile Kube Provider，其中 kubeconfig 为上层集群的配置文件，client-kubeconfig 为底层集群的配置文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./virtual-node --nodename vk-node --kubeconfig ./config --client-kubeconfig /root/.kube/config</span></span><br><span class="line">I1124 16:47:19.501216 3727733 provider.go:158] Informer started</span><br><span class="line">I1124 16:47:19.902257 3727733 service_controller.go:114] Starting controller</span><br><span class="line">I1124 16:47:19.902298 3727733 common_controller.go:115] Starting controller</span><br><span class="line">I1124 16:47:19.902331 3727733 pv_controller.go:129] Starting controller</span><br><span class="line">ERRO[0000] TLS certificates not provided, not setting up pod http server  caPath= certPath= keyPath= node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">INFO[0000] Initialized                                   node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">I1124 16:47:19.902447 3727733 node.go:98] Called NotifyNodeStatus</span><br><span class="line">I1124 16:47:19.902455 3727733 pod.go:321] Called NotifyPods</span><br><span class="line">INFO[0000] Pod cache in-sync                             node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">INFO[0000] starting workers                              node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">INFO[0000] started workers                               node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">I1124 16:47:20.607794 3727733 service_controller.go:144] enqueue service addkey istio-system/istio-ingressgateway</span><br><span class="line">I1124 16:47:20.607839 3727733 service_controller.go:144] enqueue service addkey istio-system/istiod</span><br><span class="line">I1124 16:47:20.607855 3727733 service_controller.go:144] enqueue service addkey velero/minio</span><br><span class="line">I1124 16:47:20.607803 3727733 service_controller.go:176] enqueue endpoint add key velero/minio</span><br><span class="line">I1124 16:47:20.607878 3727733 service_controller.go:176] enqueue endpoint add key istio-system/istio-ingressgateway</span><br><span class="line">I1124 16:47:20.607887 3727733 service_controller.go:176] enqueue endpoint add key istio-system/istiod</span><br><span class="line">I1124 16:47:20.702816 3727733 pv_controller.go:135] Sync caches from master successfully</span><br><span class="line">I1124 16:47:20.702859 3727733 pv_controller.go:140] Sync caches from client successfully</span><br><span class="line">I1124 16:47:20.702816 3727733 service_controller.go:120] Sync caches from master successfully</span><br><span class="line">I1124 16:47:20.702903 3727733 service_controller.go:125] Sync caches from client successfully</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上层集群</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node</span></span><br><span class="line">NAME           STATUS   ROLES                  AGE   VERSION</span><br><span class="line">desktop-ca83   Ready    control-plane,master   16d   v1.22.9</span><br><span class="line">vk-node        Ready    agent                  9s    v1.18.15</span><br></pre></td></tr></table></figure><p>Provider 可以部署在任意集群中，通过 –kubeconfig 和 –client-kubeconfig 指定上层底层集群即可，也可以组成网状集群或者公用虚拟节点的集群。</p><p><strong>调度</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上层集群部署的负载信息</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myconfigmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">vk-demo</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">USER_NAME:</span> <span class="string">YWRtaW4=</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vk-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">100Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp/example</span></span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">vk-node</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vk-demo</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># Optional:</span></span><br><span class="line">  <span class="comment"># storageClassName: &lt;YOUR_STORAGE_CLASS_NAME&gt;</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">50Mi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vk-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">automountServiceAccountToken:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.27</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;tail -f /dev/null&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&quot;/etc/foo&quot;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">bar</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&quot;/etc/bar&quot;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/datadir</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">virtual-kubelet</span></span><br><span class="line">  <span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;virtual-kubelet.io/provider&quot;</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line">    <span class="attr">configMap:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">myconfigmap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">bar</span></span><br><span class="line">    <span class="attr">secret:</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">mysecret</span></span><br><span class="line">      <span class="attr">optional:</span> <span class="literal">false</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">local</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">vk-demo</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 底层集群预先准备可用的卷</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vk-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">100Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp/example</span></span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">archcnstcm67370</span></span><br></pre></td></tr></table></figure><p>创建负载之后可以看到，原本在上层的 configmap、secret 和 pvc，透传到对应的底层集群创建了一份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">底层集群</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get configmap</span></span><br><span class="line">NAME          DATA   AGE</span><br><span class="line">myconfigmap   1      15m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get secret</span></span><br><span class="line">NAME                  TYPE                                  DATA   AGE</span><br><span class="line">default-token-jxhcg   kubernetes.io/service-account-token   3      2d7h</span><br><span class="line">mysecret              Opaque                                1      15m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pvc</span></span><br><span class="line">NAME                 STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS             AGE</span><br><span class="line">vk-demo              Bound    vk-demo  100Gi      RWO                                     16m</span><br></pre></td></tr></table></figure><p>负载在上层集群和底层集群均可以查询到，但由于两个集群 Pod 网络未打通，因此无法通过上层集群 exec 或者 log 查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">I1124 17:52:59.931178 2460220 helper.go:57] pod vk-demo depends on secrets [mysecret]</span><br><span class="line">I1124 17:52:59.931202 2460220 helper.go:70] pod vk-demo depends on configMap [myconfigmap]</span><br><span class="line">I1124 17:52:59.931210 2460220 helper.go:83] pod vk-demo depends on pvc [vk-demo]</span><br><span class="line">I1124 17:52:59.936998 2460220 pod.go:457] Create myconfigmap in default success</span><br><span class="line">I1124 17:52:59.937019 2460220 pod.go:79] Create configmaps [myconfigmap] of default/vk-demo success</span><br><span class="line">INFO[0028] Created pod in provider                      </span><br><span class="line">INFO[0028] Event(v1.ObjectReference&#123;Kind:&quot;Pod&quot;, Namespace:&quot;default&quot;, Name:&quot;vk-demo&quot;, UID:&quot;1c52b390-29ab-40de-b892-860db9fe3418&quot;, APIVersion:&quot;v1&quot;, ResourceVersion:&quot;3395567&quot;, FieldPath:&quot;&quot;&#125;): type: &#x27;Normal&#x27; reason: &#x27;ProviderCreateSuccess&#x27; Create pod in provider successfully  node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">I1124 17:53:00.023488 2460220 pod.go:84] Create pvc [vk-demo] of default/vk-demo success</span><br><span class="line">INFO[0029] Updated pod in provider                      </span><br><span class="line">INFO[0029] Event(v1.ObjectReference&#123;Kind:&quot;Pod&quot;, Namespace:&quot;default&quot;, Name:&quot;vk-demo&quot;, UID:&quot;1c52b390-29ab-40de-b892-860db9fe3418&quot;, APIVersion:&quot;v1&quot;, ResourceVersion:&quot;3395570&quot;, FieldPath:&quot;&quot;&#125;): type: &#x27;Normal&#x27; reason: &#x27;ProviderUpdateSuccess&#x27; Update pod in provider successfully  node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line">INFO[0042] Updated pod in provider                      </span><br><span class="line">INFO[0042] Event(v1.ObjectReference&#123;Kind:&quot;Pod&quot;, Namespace:&quot;default&quot;, Name:&quot;vk-demo&quot;, UID:&quot;1c52b390-29ab-40de-b892-860db9fe3418&quot;, APIVersion:&quot;v1&quot;, ResourceVersion:&quot;3395617&quot;, FieldPath:&quot;&quot;&#125;): type: &#x27;Normal&#x27; reason: &#x27;ProviderUpdateSuccess&#x27; Update pod in provider successfully  node=vk-node operatingSystem=Linux provider=k8s watchedNamespace=</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide</span></span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP           NODE      NOMINATED NODE   READINESS GATES</span><br><span class="line">vk-demo   1/1     Running   0          16m   10.244.0.1   vk-node   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide</span></span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">vk-demo   1/1     Running   0          17m   10.244.0.1    archcnstcm67370   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><p>Tensile Kube Provider</p><ul><li>底层多节点集群是以一个单独的虚拟节点加入的上层集群中</li><li>在上层集群创建的负载，会通过 virtual-node 组件下发到底层集群对应的 api-server 中（可以支持 HA），会根据底层集群的情况进行实际调度</li><li>由于工作负载真实运行在底层集群中，其依赖的 Secret、Configmap 和 PVC 等资源同样的会透传给底层集群创建，其运行时的资源由底层集群分配并维护，例如 Pod 的网络、存储等</li></ul>]]></content>
    
    
    <summary type="html">以 Tensile Kube Provider 实践操作为例，理解 Virtual Kubelet 的设计理念、Provider 原语以及各厂商的探索实现</summary>
    
    
    
    <category term="Serverless" scheme="http://shenxianghong.github.io/categories/Serverless/"/>
    
    
    <category term="Virtual Kubelet" scheme="http://shenxianghong.github.io/tags/Virtual-Kubelet/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」架构演进</title>
    <link href="http://shenxianghong.github.io/2022/11/14/2022-11-14%20Kata%20Containers%20%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"/>
    <id>http://shenxianghong.github.io/2022/11/14/2022-11-14%20Kata%20Containers%20%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/</id>
    <published>2022-11-13T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.267Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>在云原生场景中，对容器启动速度、资源消耗、稳定性和安全性的需求不断增加，目前 Kata Containers 运行时相对于其他运行时面临挑战。为了解决这一点，社区提出了一个可靠的、经过现场测试的、安全的 Rust 版本的 kata-runtime。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li>Turn key solution with builtin <code>Dragonball</code> Sandbox</li><li>异步 I&#x2F;O 以减少资源消耗</li><li>用于多种服务、运行时和 hypervisor 的可扩展框架</li><li>sandbox 和容器相关联资源的生命周期管理</li></ul><h2 id="选择-Rust-的理由"><a href="#选择-Rust-的理由" class="headerlink" title="选择 Rust 的理由"></a>选择 Rust 的理由</h2><p>之所以选择 Rust，是因为它被设计为一种注重效率的系统语言。与 Go 相比，Rust 进行了各种设计权衡以获得良好的执行性能，其创新技术与 C 或 C++ 相比，提供了针对常见内存错误（缓冲区溢出、无效指针、范围错误）的合理保护、错误检查（确保错误得到处理）、线程安全、资源所有权等。</p><p>当 Kata agent 用 Rust 重写时，这些优点得到了验证。基于 Rust 的实现显着减少了内存使用量。</p><h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/architecture.png"></div><h2 id="内置的-VMM"><a href="#内置的-VMM" class="headerlink" title="内置的 VMM"></a>内置的 VMM</h2><h3 id="当前-Kata-2-x-架构"><a href="#当前-Kata-2-x-架构" class="headerlink" title="当前 Kata 2.x 架构"></a>当前 Kata 2.x 架构</h3><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/not_built_in_vmm.png"></div><p>如图所示，runtime 和 VMM 是独立的进程。runtime 进程 fork 出 VMM 进程并通过 RPC 进程间通信。通常，进程间交互比进程内交互开销更大且效率更低。同时，还要考虑资源维护成本。例如，在异常情况下进行资源回收时，任何进程的异常都必须被其他组件检测到，并触发相应的资源回收进程。如果有额外的过程，恢复变得更加困难。</p><h3 id="如何支持内置的-VMM"><a href="#如何支持内置的-VMM" class="headerlink" title="如何支持内置的 VMM"></a>如何支持内置的 VMM</h3><p>社区提供了 Dragonball Sandbox，通过将 VMM 的功能集成到 Rust 库中来启用内置的 VMM。可以通过使用该库来执行与 VMM 相关的功能。因为 runtime 和 VMM 在同一个进程中，所以在消息处理速度和 API 同步方面有所改善。还可以保证 runtime 和 VMM 生命周期的一致性，减少资源回收和异常处理维护的复杂度，如图所示：</p><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/built_in_vmm.png"></div><h2 id="支持异步"><a href="#支持异步" class="headerlink" title="支持异步"></a>支持异步</h2><h3 id="为什么需要异步"><a href="#为什么需要异步" class="headerlink" title="为什么需要异步"></a>为什么需要异步</h3><p><strong>Async 已经为稳定版 Rust 特性</strong></p><blockquote><p>参考：<a href="https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html">Why Async</a> 和 <a href="https://rust-lang.github.io/async-book/01_getting_started/03_state_of_async_rust.html">The State of Asynchronous Rust</a></p></blockquote><ul><li>Async 显著降低了 CPU 和内存开销，尤其是对于具有大量 I&#x2F;O 绑定类型的任务负载</li><li>Async 在 Rust 中是零成本的，这意味着只需应用层面开销，可以不用堆分配和动态调度，大大提高效率</li></ul><p><strong>如果使用 Sync Rust 实现 kata-runtime 可能会出现的几个问题</strong></p><ul><li>TTRPC 连接线程数太多（TTRPC threads: reaper thread(1) + listener thread(1) + client handler(2)）</li><li>每个容器有三个 I&#x2F;O 线程</li><li>在 Sync 模式下，实现超时机制具有挑战性。比如 TTRPC API 交互中，超时机制很难和 Golang 对齐</li></ul><p><strong>如何支持 Async</strong></p><p>kata-runtime 由 TOKIO_RUNTIME_WORKER_THREADS 控制运行 OS 线程，默认为 2 个线程。TTRPC 和容器相关的线程统一运行在tokio 线程中，Timer，File，Netlink 等相关的依赖调用需要切换到 Async。借助 Async，可以轻松支持无阻塞 I&#x2F;O 和定时器。目前，仅将 Async 用于 kata-runtime。内置的 VMM 保留了 OS 线程，因为它可以保证线程的可控性。</p><h2 id="可扩展框架"><a href="#可扩展框架" class="headerlink" title="可扩展框架"></a>可扩展框架</h2><p>Kata 3.x runtime 设计了 service、runtime、hypervisor 的扩展，结合配置满足不同场景的需求。目前服务提供注册机制，支持多种服务。服务可以通过消息与 runtime 交互。此外，runtime handler 处理来自服务的消息。为了满足二进制支持多个 runtime 和 hypervisor 的需求，启动必须通过配置获取 runtime handler 类型和 hypervisor 类型。</p><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/framework.png"></div><h2 id="资源管理器"><a href="#资源管理器" class="headerlink" title="资源管理器"></a>资源管理器</h2><p>在实际使用中，会有各种各样的资源，每个资源都有几个子类型。特别是对于 virtcontainers，资源的每个子类型都有不同的操作。并且可能存在依赖关系，例如 share-fs rootfs 和 share-fs volume 会使用 share-fs 资源将文件共享到 VM。目前，network、share-fs 被视为沙盒资源，rootfs、volume、cgroup 被视为容器资源。此外，社区为每个资源抽象出一个公共接口，并使用子类操作来评估不同子类型之间的差异。</p><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/resourceManager.png"></div><h1 id="路线图"><a href="#路线图" class="headerlink" title="路线图"></a>路线图</h1><ul><li>阶段 1（截至 2022.06）：提供基础特性</li><li>阶段 2（截至 2022.09）：提供常用特性</li><li>阶段 3：提供全量特性</li></ul><table><thead><tr><th><strong>Class</strong></th><th><strong>Sub-Class</strong></th><th><strong>Development Stage</strong></th><th><strong>Status</strong></th></tr></thead><tbody><tr><td>Service</td><td>task service</td><td>Stage 1</td><td>✅</td></tr><tr><td></td><td>extend service</td><td>Stage 3</td><td>🚫</td></tr><tr><td></td><td>image service</td><td>Stage 3</td><td>🚫</td></tr><tr><td>Runtime handler</td><td>Virt-Container</td><td>Stage 1</td><td>✅</td></tr><tr><td>Endpoint</td><td>VETH Endpoint</td><td>Stage 1</td><td>✅</td></tr><tr><td></td><td>Physical Endpoint</td><td>Stage 2</td><td>✅</td></tr><tr><td></td><td>Tap Endpoint</td><td>Stage 2</td><td>✅</td></tr><tr><td></td><td>Tuntap Endpoint</td><td>Stage 2</td><td>✅</td></tr><tr><td></td><td>IPVlan Endpoint</td><td>Stage 2</td><td>✅</td></tr><tr><td></td><td>MacVlan Endpoint</td><td>Stage 2</td><td>✅</td></tr><tr><td></td><td>MACVTAP Endpoint</td><td>Stage 3</td><td>🚫</td></tr><tr><td></td><td>VhostUserEndpoint</td><td>Stage 3</td><td>🚫</td></tr><tr><td>Network Interworking Model</td><td>Tc filter</td><td>Stage 1</td><td>✅</td></tr><tr><td></td><td>MacVtap</td><td>Stage 3</td><td>🚧</td></tr><tr><td>Storage</td><td>Virtio-fs</td><td>Stage 1</td><td>✅</td></tr><tr><td></td><td>nydus</td><td>Stage 2</td><td>🚧</td></tr><tr><td></td><td>device mapper</td><td>Stage 2</td><td>🚫</td></tr><tr><td>Cgroup V2</td><td></td><td>Stage 2</td><td>🚧</td></tr><tr><td>Hypervisor</td><td>Dragonball</td><td>Stage 1</td><td>🚧</td></tr><tr><td></td><td>QEMU</td><td>Stage 2</td><td>🚫</td></tr><tr><td></td><td>ACRN</td><td>Stage 3</td><td>🚫</td></tr><tr><td></td><td>Cloud Hypervisor</td><td>Stage 3</td><td>🚫</td></tr><tr><td></td><td>Firecracker</td><td>Stage 3</td><td>🚫</td></tr></tbody></table><h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><ul><li><p>service、message dispatcher 和 runtime handler 都是 Kata 3.x runtime 二进制的一部分吗？</p><p>是的。它们是 Kata 3.x 运行时中的组件。它们将被打包成一个二进制文件</p><ul><li>service 是一个接口，负责处理任务服务、镜像服务等多种服务</li><li>message dispatcher 用于匹配来自服务模块的多个请求</li><li>runtime handler 用于处理对沙箱和容器的操作</li></ul></li><li><p>Kata 3.x runtime 二进制的名称是什么？</p><p>由于 containerd-shim-v2-kata 已经被使用了，目前在内部，社区使用 containerd-shim-v2-rund</p></li><li><p>Kata 3.x 设计是否与 containerd shimv2 架构兼容？</p><p>是的。它旨在遵循 go 版本 kata 的功能。它实现了 containerd shim v2 接口&#x2F;协议</p></li><li><p>用户将如何迁移到 Kata 3.x 架构？</p><p>迁移计划将在 Kata 3.x 合并到主分支之前提供</p></li><li><p>Dragonball 是不是仅限于自己内置的 VMM？ Dragonball 系统是否可以配置为使用外部 Dragonball VMM&#x2F;hypervisor 工作？</p><p>Dragonball 可以用作外部管理程序。然而，在这种情况下，稳定性和性能具有挑战性。内置 VMM 可以优化容器开销，易于维护稳定性。runD 是 runC 的 containerd-shim-v2 对应物，可以运行 Pod&#x2F;容器。 Dragonball 是一种 microvm&#x2F;VMM，旨在运行容器工作负载。有时将其称为安全沙箱，而不是 microvm&#x2F;VMM</p></li><li><p>QEMU、Cloud Hypervisor 和 Firecracker 支持已在计划中，但如何运作。它们在不同的进程中工作吗？</p><p>是的。它们无法像 VMM 中内置的那样工作</p></li><li><p>upcall 是什么？</p><p>upcall 用于热插拔 CPU&#x2F;内存&#x2F;MMIO 设备，它解决了两个问题：</p><ul><li><p>避免依赖 PCI&#x2F;ACPI</p></li><li><p>避免在 guest 中依赖 udevd 并获得热插拔操作的确定性结果。所以 upcall 是基于 ACPI 的 CPU&#x2F;内存&#x2F;设备热插拔的替代方案。如果需要，Kata 社区会与相关社区合作添加对基于 ACPI 的 CPU&#x2F;内存&#x2F;设备热插拔的支持</p></li></ul><p>Dbs-upcall 是 VMM 和 guest 之间基于 vsock 的直接通信工具。 upcall 的服务器端是 guest 内核中的驱动程序（此功能需要内核补丁），一旦内核启动，它将开始为请求提供服务。而客户端在 VMM 中，它将是一个线程，通过 uds 与 VSOCK 通信。通过upcall 直接实现了设备的热插拔，避免了ACPI 的虚拟化，将虚拟机的开销降到最低。通过这种直接的通信手段，可能还有许多其他用途。现目前已经开源：<a href="https://github.com/openanolis/dragonball-sandbox/tree/main/crates/dbs-upcall">https://github.com/openanolis/dragonball-sandbox/tree/main/crates/dbs-upcall</a></p></li><li><p>内核补丁适用于 4.19，但它们也适用于 5.15+ 吗？</p><p>向前兼容应该是可以实现的，社区已经将它移植到基于 5.10 的内核</p></li><li><p>这些补丁是否特定于平台，或者它们是否适用于支持 VSOCK 的任何架构？</p><p>它几乎与平台无关，但一些与 CPU 热插拔相关的是与平台相关的</p></li><li><p>是否可以使用 loopback VSOCK 将内核驱动程序替换为 guest 中的用户态守护程序？</p><p>需要为热添加的 CPU&#x2F;内存&#x2F;设备创建设备节点，因此用户空间守护进程执行这些任务并不容易</p></li><li><p>upcall 允许 VMM 和 guest 之间进行通信的事实表明，此架构可能与 <a href="https://github.com/confidential-containers">https://github.com/confidential-containers</a> 不兼容，其中 VMM 应该不知道 VM 内部发生的事情</p><ul><li>TDX 还不支持 CPU&#x2F;内存热插拔</li><li>对于基于 ACPI 的设备热插拔，它依赖于 ACPI DSDT 表，guest 内核将在处理这些热插拔事件时执行 ASL 代码来处理。与 ACPI ASL 方法相比，审计基于 VSOCK 的通信应该更容易</li></ul></li><li><p>单体与内置 VMM 的安全边界是什么？</p><p>它具有虚拟化的安全边界。更多细节将在下一阶段提供</p></li></ul>]]></content>
    
    
    <summary type="html">Kata Containers 3.x 较 2.x 版本架构发展演进与设计初衷</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」中国移动分享</title>
    <link href="http://shenxianghong.github.io/2022/10/27/2022-10-27%20Kata%20Containers%20%E4%B8%AD%E5%9B%BD%E7%A7%BB%E5%8A%A8%E5%88%86%E4%BA%AB/"/>
    <id>http://shenxianghong.github.io/2022/10/27/2022-10-27%20Kata%20Containers%20%E4%B8%AD%E5%9B%BD%E7%A7%BB%E5%8A%A8%E5%88%86%E4%BA%AB/</id>
    <published>2022-10-26T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.266Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p><a href="/reference/kata-containers-chinamobile.pdf">Kata Containers Performance Exploration and Practice</a></p></blockquote>]]></content>
    
    
    <summary type="html">Kata Containers 性能调优探索与实践</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」蚂蚁金服分享</title>
    <link href="http://shenxianghong.github.io/2022/10/14/2022-10-14%20Kata%20Containers%20%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E5%88%86%E4%BA%AB/"/>
    <id>http://shenxianghong.github.io/2022/10/14/2022-10-14%20Kata%20Containers%20%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E5%88%86%E4%BA%AB/</id>
    <published>2022-10-13T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.266Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p><a href="/reference/kata-containers-antgroup.pdf">Kata Containers Best Practices  at Ant Group</a></p></blockquote>]]></content>
    
    
    <summary type="html">Kata Containers 在蚂蚁金服的最佳实践</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — Sidecar</title>
    <link href="http://shenxianghong.github.io/2022/09/16/2022-09-16%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Sidecar/"/>
    <id>http://shenxianghong.github.io/2022/09/16/2022-09-16%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Sidecar/</id>
    <published>2022-09-15T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.258Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>Sidecar 描述了 sidecar 代理的配置，该代理将入站和出站通信调解到它所连接的工作负载实例。默认情况下，Istio 将对网格中的所有代理进行编程，并使用必要的配置来访问网格中的每个工作负载实例，并接管与工作负载关联的所有端口上的流量。 Sidecar 配置提供了一种微调端口集的方法，代理在转发流量进出工作负载时将接受的协议。此外，可以限制代理在转发来自工作负载实例的出站流量时可以访问的服务集。</p><p>网格中的服务和配置被划分成一个或多个命名空间（例如，Kubernetes 命名空间或 CF org&#x2F;space）。命名空间中的 Sidecar 配置将应用于同一命名空间中的一个或多个工作负载实例，使用 workloadSelector 字段选择。在没有 workloadSelector 的情况下，它将应用于同一命名空间中的所有工作负载实例。在确定要应用于工作负载实例的 Sidecar 配置时，将优先考虑具有选择此工作负载实例的 workloadSelector 的资源，而不是没有任何 workloadSelector 的 Sidecar 配置。</p><p>注意点</p><ul><li>每个命名空间只能有一个没有 workloadSelector 的  Sidecar 配置，该配置为该命名空间中的所有 Pod 指定默认值。建议对命名空间范围的 sidecar 使用名称 default。如果给定命名空间中存在多个无选择器的 Sidecar 配置，则系统的行为是未定义的。如果具有 workloadSelector 的两个或多个 Sidecar 配置选择相同的工作负载实例，则系统的行为是未定义的</li><li>默认情况下，MeshConfig 根命名空间中的 Sidecar 配置将应用于所有没有 Sidecar 配置的命名空间。这个全局默认 Sidecar 配置不应该有任何 workloadSelector</li></ul><p>下面的示例在名为 istio-config 的命名空间中声明了一个全局默认 Sidecar 配置，该配置将所有命名空间中的 Sidecar 配置为仅允许出口流量到同一命名空间中的其他工作负载以及 istio-system 命名空间中的服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">istio-config</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;./*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;istio-system/*&quot;</span></span><br></pre></td></tr></table></figure><p>下面的示例在 prod-us1 命名空间中声明了一个 Sidecar 配置，它覆盖了上面定义的全局默认值，并在命名空间中配置了 Sidecar 以允许出口流量到 prod-us1、prod-apis 和 istio-system 中的命名空间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod-us1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;prod-us1/*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;prod-apis/*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;istio-system/*&quot;</span></span><br></pre></td></tr></table></figure><p>以下示例在 prod-us1 命名空间中为所有带有标签 app: rating 的 Pod 声明了 Sidecar 配置，属于 rating.prod-us1 服务。工作负载在端口 9080 上接受入站 HTTP 流量。然后将流量转发到在 Unix 域套接字上侦听的附加工作负载实例。在出口方向，除了 istio-system 命名空间，Sidecar 仅代理 prod-us1 命名空间中服务的 9080 端口的 HTTP 流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod-us1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">9080</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">somename</span></span><br><span class="line">    <span class="attr">defaultEndpoint:</span> <span class="string">unix:///var/run/someuds.sock</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">9080</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">egresshttp</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;prod-us1/*&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;istio-system/*&quot;</span></span><br></pre></td></tr></table></figure><p>如果在没有基于 IPTables 的流量捕获的情况下部署工作负载，则 Sidecar 配置是连接到工作负载实例的代理上的端口的唯一方法。</p><p>以下示例在 prod-us1 命名空间中为所有带有 app: productpage 标签的 Pod 声明了 Sidecar 配置，属于 productpage.prod-us1 服务。假设这些 Pod 部署时没有 IPtable 规则（即 istio-init 容器）并且代理中 metadata 的 ISTIO_META_INTERCEPTION_MODE 设置为 NONE，下面的规范允许这些 Pod 在端口 9080 上接收 HTTP 流量（包裹在 Istio 双向 TLS 中）和将其转发到监听 127.0.0.1:8080 的应用程序。它还允许应用程序与 127.0.0.1:3306 上的支持 MySQL 数据库通信，然后将其代理到 mysql.foo.com:3306 上的外部托管 MySQL 服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="literal">no</span><span class="string">-ip-tables</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod-us1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">productpage</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">9080</span> <span class="comment"># binds to proxy_instance_ip:9080 (0.0.0.0:9080, if no unicast IP is available for the instance)</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">somename</span></span><br><span class="line">    <span class="attr">defaultEndpoint:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8080</span></span><br><span class="line">    <span class="attr">captureMode:</span> <span class="string">NONE</span> <span class="comment"># not needed if metadata is set for entire proxy</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">MYSQL</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">egressmysql</span></span><br><span class="line">    <span class="attr">captureMode:</span> <span class="string">NONE</span> <span class="comment"># not needed if metadata is set for entire proxy</span></span><br><span class="line">    <span class="attr">bind:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;*/mysql.foo.com&quot;</span></span><br></pre></td></tr></table></figure><p>以及用于路由到 mysql.foo.com:3306 的关联 ServiceEntry：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ns1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mysql.foo.com</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">MYSQL</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br></pre></td></tr></table></figure><p>还可以在单个代理中混合和匹配流量捕获模式。例如，考虑内部服务位于 192.168.0.0&#x2F;16 子网上的设置。因此，在 VM 上设置 IP 表以捕获 192.168.0.0&#x2F;16 子网上的所有出站流量。假设 VM 在 172.16.0.0&#x2F;16 子网上有一个额外的网络接口用于入站流量。以下 Sidecar 配置允许 VM 在 172.16.1.32:80（VM 的 IP）上公开一个侦听器，以接收来自 172.16.0.0&#x2F;16 子网的流量。</p><p>注意：VM 中代理上的 ISTIO_META_INTERCEPTION_MODE 元数据可选值有 REDIRECT 或 TPROXY，这意味着当前是基于 IP 表的流量捕获。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">partial-ip-tables</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod-us1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">productpage</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">bind:</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.32</span></span><br><span class="line">    <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># binds to 172.16.1.32:80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">somename</span></span><br><span class="line">    <span class="attr">defaultEndpoint:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8080</span></span><br><span class="line">    <span class="attr">captureMode:</span> <span class="string">NONE</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">    <span class="comment"># use the system detected defaults</span></span><br><span class="line">    <span class="comment"># sets up configuration to handle outbound traffic to services</span></span><br><span class="line">    <span class="comment"># in 192.168.0.0/16 subnet, based on information provided by the</span></span><br><span class="line">    <span class="comment"># service registry</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">captureMode:</span> <span class="string">IPTABLES</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;*/*&quot;</span></span><br></pre></td></tr></table></figure><p>以下示例在 prod-us1 命名空间中为所有带有标签 app: rating 的 Pod 声明了 Sidecar 配置，属于 rating.prod-us1 服务。该服务在端口 8443 上接受入站 HTTPS 流量，并且 sidecar 代理使用给定的服务器证书以一种方式终止 TLS。然后将流量转发到在 Unix 域套接字上侦听的附加工作负载实例。预计将配置 PeerAuthentication 策略，以便在特定端口上将 mTLS 模式设置为“禁用”。在此示例中，在 PORT 80 上禁用了 mTLS 模式。此功能目前是实验性的。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">security.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PeerAuthentication</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-peer-auth</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod-us1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">mtls:</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">STRICT</span></span><br><span class="line">  <span class="attr">portLevelMtls:</span></span><br><span class="line">    <span class="attr">80:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">DISABLE</span></span><br></pre></td></tr></table></figure><h1 id="Sidecar"><a href="#Sidecar" class="headerlink" title="Sidecar"></a>Sidecar</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#WorkloadSelector">workloadSelector</a></td><td>用于选择应用此 Sidecar 配置的特定 Pod&#x2F;VM 集的标准。如果省略，Sidecar 配置将应用于同一命名空间中的所有工作负载实例</td></tr><tr><td><a href="#IstioIngressListener">ingress</a></td><td>Ingress 指定 Sidecar 的配置，用于处理附加工作负载实例的入站流量。如果省略，Istio 将根据从编排平台获得的工作负载信息（例如，暴露的端口、服务等）自动配置 sidecar。如果指定，当且仅当工作负载实例与服务关联时，才会配置入站端口</td></tr><tr><td><a href="#IstioEgressListener">egress</a></td><td>Egress 指定 sidecar 的配置，用于处理从附加工作负载实例到网格中其他服务的出站流量。如果未指定，则从命名空间范围或全局默认 Sidecar 继承系统检测到的默认值</td></tr><tr><td>outboundTrafficPolicy</td><td>出方向流量策略的配置。如果应用程序使用一个或多个未知的外部服务，将策略设置为 ALLOW_ANY 将导致 sidecar 将来自应用程序的任何未知流量路由到其请求的目的地。如果未指定，则从命名空间范围或全局默认 Sidecar 继承系统检测到的默认值</td></tr></tbody></table><h1 id="IstioIngressListener"><a href="#IstioIngressListener" class="headerlink" title="IstioIngressListener"></a><a name="IstioIngressListener">IstioIngressListener</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>port</td><td>与 listener 关联的端口</td></tr><tr><td>bind</td><td>listener 应绑定到的 IP（IPv4 或 IPv6）。入口 listener 的绑定字段中不允许使用 Unix 域套接字地址。如果省略，Istio 将根据导入的服务和应用此配置的工作负载实例自动配置默认值</td></tr><tr><td><a href="#CaptureMode">captureMode</a></td><td>表示如何捕获（或不捕获）到 listener 的流量</td></tr><tr><td>defaultEndpoint</td><td>应将流量转发到的 IP 端点或 Unix 域套接字。此配置可用于将到达 sidecar 上的绑定 IP:Port 的流量重定向到应用程序工作负载实例正在侦听连接的 localhost:port 或 Unix 域套接字。不支持任意 IP。格式应该是 127.0.0.1:PORT、[::1]:PORT（转发到 localhost）、0.0.0.0:PORT、[::]:PORT（转发到实例 IP）或 unix:&#x2F;&#x2F;&#x2F; 之一path&#x2F;to&#x2F;socket（转发到 Unix 域套接字）</td></tr><tr><td>tls</td><td>一组 TLS 相关选项，将在 sidecar 上为来自网格外部的请求启用 TLS 终止。目前仅支持 SIMPLE 和 MUTUAL TLS 模式</td></tr></tbody></table><h1 id="IstioEgressListener"><a href="#IstioEgressListener" class="headerlink" title="IstioEgressListener"></a><a name="IstioEgressListener">IstioEgressListener</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>port</td><td>与 listener 关联的端口。如果使用 Unix 域套接字，请使用 0 作为端口号，并使用有效的协议。如果指定了端口，将用作与导入主机关联的默认目标端口。如果省略端口，Istio 将根据导入的主机推断 listener 端口。请注意，当指定多个出口 listener 时，其中一个或多个侦听器具有特定端口而其他 listener 没有端口，则在 listener 端口上暴露的主机将基于具有最特定端口的 listener</td></tr><tr><td>bind</td><td>listener 应绑定到的 IP（IPv4 或 IPv6）或 Unix 域套接字。如果 bind 不为空，则必须指定端口。格式：IPv4 或 IPv6 地址格式或 unix:&#x2F;&#x2F;&#x2F;path&#x2F;to&#x2F;uds 或 unix:&#x2F;&#x2F;@foobar（Linux 抽象命名空间）。如果省略，Istio 将根据导入的服务、应用此配置的工作负载实例和 captureMode 自动配置默认值。如果 captureMode 为 NONE，bind 将默认为 127.0.0.1</td></tr><tr><td><a href="#CaptureMode">captureMode</a></td><td>当绑定地址是 IP 时，captureMode 选项指示如何捕获（或不捕获）到 listener 的流量。对于 Unix 域套接字绑定，captureMode 必须为 DEFAULT 或 NONE</td></tr><tr><td>hosts</td><td>listener 以 namespace&#x2F;dnsName 格式暴露一个或多个服务主机。与 dnsName 匹配的指定命名空间中的服务将被暴露。相应的服务可以是服务注册表中的服务（例如，Kubernetes 或云服务）或使用 ServiceEntry 或 VirtualService 配置指定的服务。还将使用同一命名空间中的任何关联 DestinationRule。<br />应使用 FQDN 格式指定 dnsName，可选择在最左侧的组件中包含通配符（例如 prod&#x2F;*.example.com）。将 dnsName 设置为 * 以选择指定命名空间中的所有服务（例如 prod&#x2F;*）。<br />命名空间可以设置为 <em>、. 或 ~，分别表示任何命名空间、当前命名空间或无命名空间。例如，</em>&#x2F;foo.example.com 从任何可用的命名空间中选择服务，而 .&#x2F;foo.example.com 仅从 sidecar 的命名空间中选择服务。如果主机设置为 *&#x2F;<em>，Istio 将配置 sidecar 以便能够访问网格中导出到 sidecar 命名空间的每个服务。值 ~&#x2F;</em> 可用于完全修剪 Sidecar 的配置，这些 Sidecar 仅接收流量并响应，但不建立自己的出站连接。<br />只能引用导出到 sidecar 命名空间的服务和配置工件（例如，exportTo 的 * 值）。私有配置（例如，exportTo 设置为 .）</td></tr></tbody></table><h1 id="WorkloadSelector"><a href="#WorkloadSelector" class="headerlink" title="WorkloadSelector"></a><a name="WorkloadSelector">WorkloadSelector</a></h1><p>WorkloadSelector 指定用于确定是否可以将 Gateway、Sidecar、EnvoyFilter、ServiceEntry 或 DestinationRule 配置应用于代理的标准。匹配条件包括与代理关联的元数据、工作负载实例信息（例如附加到 pod&#x2F;VM 的标签）或代理在初始握手期间提供给 Istio 的任何其他信息。如果指定了多个条件，则需要匹配所有条件才能选择工作负载实例。目前，仅支持基于标签的选择机制。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>labels</td><td>一个或多个标签，指示应用配置的一组特定 Pod&#x2F;VM。标签搜索的范围仅限于资源所在的配置命名空间</td></tr></tbody></table><h1 id="OutboundTrafficPolicy"><a href="#OutboundTrafficPolicy" class="headerlink" title="OutboundTrafficPolicy"></a><a name="OutboundTrafficPolicy">OutboundTrafficPolicy</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#OutboundTrafficPolicy.Mode">mode</a></td><td>设置 sidecar 的默认行为以处理来自应用程序的出站流量。如果应用程序使用一个或多个先验未知的外部服务，将策略设置为 ALLOW_ANY 将导致边车将来自应用程序的任何未知流量路由到其请求的目的地。强烈建议用户使用 ServiceEntry 配置来显式声明任何外部依赖项，而不是使用 ALLOW_ANY，以便可以监控到这些服务的流量</td></tr></tbody></table><h1 id="OutboundTrafficPolicy-Mode"><a href="#OutboundTrafficPolicy-Mode" class="headerlink" title="OutboundTrafficPolicy.Mode"></a><a name="OutboundTrafficPolicy.Mode">OutboundTrafficPolicy.Mode</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>REGISTRY_ONLY</td><td>出站流量将仅限于服务注册表中定义的服务以及通过 ServiceEntry 配置定义的服务</td></tr><tr><td>ALLOW_ANY</td><td>如果目标端口没有服务或 ServiceEntry 配置，则将允许到未知目标的出站流量</td></tr></tbody></table><h1 id="CaptureMode"><a href="#CaptureMode" class="headerlink" title="CaptureMode"></a><a name="CaptureMode">CaptureMode</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>DEFAULT</td><td>环境定义的默认捕获模式</td></tr><tr><td>IPTABLES</td><td>使用 IPtables 重定向捕获流量</td></tr><tr><td>NONE</td><td>没有流量捕获。当在出口 listener 中使用时，应用程序应与 listener 端口或 Unix 域套接字显式通信。在入口 listener 中使用时，需要注意确保 listener 端口没有被主机上的其他进程使用</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 Sidecar 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — ProxyConfig</title>
    <link href="http://shenxianghong.github.io/2022/09/15/2022-09-15%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20ProxyConfig/"/>
    <id>http://shenxianghong.github.io/2022/09/15/2022-09-15%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20ProxyConfig/</id>
    <published>2022-09-14T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.258Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>ProxyConfig 暴露代理级别的配置选项。 ProxyConfig 可以基于每个工作负载、每个命名空间或网格范围进行配置。 ProxyConfig 不是必需的资源。</p><p><em>注意：ProxyConfig 中的字段不是动态配置的，更改配置需要重启工作负载才能生效。</em></p><p>对于任何命名空间，包括根配置命名空间，仅对只有一个无 workloadSelector 的 ProxyConfig 资源生效。</p><p>对于具有 workloadSelector 的资源，仅对只有一个资源选择任何给定工作负载生效。</p><p>对于网格级别配置，ProxyConfig 需部署在 Istio 安装的根配置命名空间 istio-system 中，并且无需设置 workloadSelector。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ProxyConfig</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-proxyconfig</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">istio-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">concurrency:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">image:</span></span><br><span class="line">    <span class="attr">imageType:</span> <span class="string">distroless</span></span><br></pre></td></tr></table></figure><p>对于命名空间级别的配置，ProxyConfig 需部署在该命名空间 user-namespace 中，并且无需设置 workloadSelector。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ProxyConfig</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-ns-proxyconfig</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">user-namespace</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">concurrency:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>对于工作负载级别配置，在 ProxyConfig 资源上设置 selector 字段：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ProxyConfig</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">per-workload-proxyconfig</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">concurrency:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">image:</span></span><br><span class="line">    <span class="attr">imageType:</span> <span class="string">debug</span></span><br></pre></td></tr></table></figure><p>如果定义了与工作负载匹配的 ProxyConfig CR，它将与其 proxy.istio.io&#x2F;config 注释（如果存在）合并，重复字段内容以 ProxyConfig CR 为准。同样，如果定义了网格范围的 ProxyConfig CR 并设置了 meshConfig.DefaultConfig，则两个资源将合并，重复字段内容以 ProxyConfig CR 为准。</p><h1 id="ProxyConfig"><a href="#ProxyConfig" class="headerlink" title="ProxyConfig"></a>ProxyConfig</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>selector</td><td>selector 指定待应用此 ProxyConfig 的一组 Pod&#x2F;VM。如果未设置，ProxyConfig 资源将应用于其所在命名空间中的所有工作负载</td></tr><tr><td>concurrency</td><td>要运行的工作线程数。如果未设置，则默认为 2。如果设置为 0，这将被配置为使用机器上的所有内核使用 CPU 请求和限制来选择一个值，限制优先于请求</td></tr><tr><td>environmentVariables</td><td>代理的其他环境变量。以 ISTIO_META_ 开头的名称将包含在生成的引导配置中并发送到 XDS 服务器</td></tr><tr><td><a href="#ProxyImage">image</a></td><td>指定代理的镜像</td></tr></tbody></table><h1 id="ProxyImage"><a href="#ProxyImage" class="headerlink" title="ProxyImage"></a><a name="ProxyImage">ProxyImage</a></h1><p>用于构造代理镜像 url。格式：${hub}&#x2F;${image_name}&#x2F;${tag}-${image_type}，例如：docker.io&#x2F;istio&#x2F;proxyv2:1.11.1 或 docker.io&#x2F;istio&#x2F;proxyv2:1.11.1-distroless。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>imageType</td><td>镜像的类型。可选的有：default、debug、distroless。如果 image 类型已经（例如：centos）发布到指定的 hub，则允许使用其他值。</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 ProxyConfig 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — WorkloadGroup</title>
    <link href="http://shenxianghong.github.io/2022/09/08/2022-09-08%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Workload%20Group/"/>
    <id>http://shenxianghong.github.io/2022/09/08/2022-09-08%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Workload%20Group/</id>
    <published>2022-09-07T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.258Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>WorkloadGroup 描述工作负载实例的集合。提供了工作负载实例可用于引导其代理的规范，包括元数据和标识。它仅适用于虚拟机等非 Kubernetes 工作负载，旨在模仿用于 Kubernetes 工作负载的现有 Sidecar 注入和部署规范模型以引导 Istio 代理。</p><p>以下示例声明了一个 WorkloadGroup，代表了一组在 bookinfo 命名空间中 reviews 下注册的工作负载集合。标签集将在初始化过程中与每个工作负载实例相关联，端口 3550 和 8080 将与 WorkloadGroup 相关联并使用名为 default Service Account。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">WorkloadGroup</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">reviews</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/version:</span> <span class="string">&quot;1.3.4&quot;</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="attr">grpc:</span> <span class="number">3550</span></span><br><span class="line">      <span class="attr">http:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">serviceAccount:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">probe:</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">timeoutSeconds:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">4</span></span><br><span class="line">    <span class="attr">successThreshold:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">     <span class="attr">path:</span> <span class="string">/foo/bar</span></span><br><span class="line">     <span class="attr">host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">     <span class="attr">port:</span> <span class="number">3100</span></span><br><span class="line">     <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">     <span class="attr">httpHeaders:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Lit-Header</span></span><br><span class="line">       <span class="attr">value:</span> <span class="string">Im-The-Best</span></span><br></pre></td></tr></table></figure><h1 id="WorkloadGroup"><a href="#WorkloadGroup" class="headerlink" title="WorkloadGroup"></a>WorkloadGroup</h1><p>WorkloadGroup 可以为 bootstrap 指定单个工作负载的属性，并为 WorkloadEntry 提供模板，类似于 Deployment 通过 Pod 模板指定工作负载的属性。一个 WorkloadGroup 可以有多个 WorkloadEntry。 WorkloadGroup 与控制 ServiceEntry 等服务注册表的资源没有关系，因此不会为这些工作负载配置主机名。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#WorkloadGroup.ObjectMeta">metadata</a></td><td>metadata 会作用于对应的所有 WorkloadEntry 中，WorkloadGroup 的 label 设置应位于 metadata 中，而不是 template</td></tr><tr><td>template</td><td>用于生成属于此 WorkloadGroup 的 WorkloadEntry 资源的模板。注意，不应在模板中设置地址和标签字段，空的 serviceAccount 应默认为 default。工作负载身份（mTLS 证书）将使用指定 Service Account 的令牌进行初始化。该组中的 WorkloadEntry 将与工作负载组位于同一命名空间中，并从上述 metadata 字段继承标签和注释</td></tr><tr><td><a href="#ReadinessProbe">probe</a></td><td>ReadinessProbe 描述了用户对其工作负载进行健康检查提供的配置。具体参考 Kubernetes 的语法与逻辑</td></tr></tbody></table><h1 id="ReadinessProbe"><a href="#ReadinessProbe" class="headerlink" title="ReadinessProbe"></a><a name="ReadinessProbe">ReadinessProbe</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>initialDelaySeconds</td><td>容器启动后，进行就绪探测之前的秒数</td></tr><tr><td>timeoutSeconds</td><td>探测超时的秒数。默认为 1 秒。最小值为 1 秒</td></tr><tr><td>periodSeconds</td><td>执行探测的频率（以秒为单位）。默认为 10 秒。最小值为 1 秒</td></tr><tr><td>successThreshold</td><td>探测失败后被视为成功的最小连续成功次数。默认为 1</td></tr><tr><td>failureThreshold</td><td>探测成功后被视为失败的最小连续失败次数。默认为 3</td></tr><tr><td><a href="#HTTPHealthCheckConfig">httpGet</a></td><td>基于 http get 的健康检查</td></tr><tr><td><a href="#TCPHealthCheckConfig">tcpSocket</a></td><td>基于代理是否能够连接的健康检查</td></tr><tr><td><a href="#ExecHealthCheckConfig">exec</a></td><td>基于执行的命令如何退出的健康检查</td></tr></tbody></table><h1 id="HTTPHealthCheckConfig"><a href="#HTTPHealthCheckConfig" class="headerlink" title="HTTPHealthCheckConfig"></a><a name="HTTPHealthCheckConfig">HTTPHealthCheckConfig</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>path</td><td>HTTP 服务器上的访问路径</td></tr><tr><td>port</td><td>endpoint 所在的端口</td></tr><tr><td>host</td><td>要连接的主机名，默认为 Pod IP</td></tr><tr><td>scheme</td><td>HTTP 或者 HTTPS，默认为 HTTP</td></tr><tr><td>httpHeaders</td><td>请求的 header。允许重复的请求头</td></tr></tbody></table><h1 id="HTTPHeader"><a href="#HTTPHeader" class="headerlink" title="HTTPHeader"></a><a name="HTTPHeader">HTTPHeader</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>header 的键</td></tr><tr><td>value</td><td>header 的值</td></tr></tbody></table><h1 id="TCPHealthCheckConfig"><a href="#TCPHealthCheckConfig" class="headerlink" title="TCPHealthCheckConfig"></a><a name="TCPHealthCheckConfig">TCPHealthCheckConfig</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>host</td><td>待连接的主机，默认为 localhost</td></tr><tr><td>port</td><td>主机端口</td></tr></tbody></table><h1 id="ExecHealthCheckConfig"><a href="#ExecHealthCheckConfig" class="headerlink" title="ExecHealthCheckConfig"></a><a name="ExecHealthCheckConfig">ExecHealthCheckConfig</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>command</td><td>待运行的命令。退出状态为 0 被视为活动&#x2F;健康，非零表示不健康</td></tr></tbody></table><h1 id="WorkloadGroup-ObjectMeta"><a href="#WorkloadGroup-ObjectMeta" class="headerlink" title="WorkloadGroup.ObjectMeta"></a><a name="WorkloadGroup.ObjectMeta">WorkloadGroup.ObjectMeta</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>labels</td><td>标签信息</td></tr><tr><td>annotations</td><td>注解信息</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 WorkloadGroup 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — WorkloadEntry</title>
    <link href="http://shenxianghong.github.io/2022/08/23/2022-08-23%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Workload%20Entry/"/>
    <id>http://shenxianghong.github.io/2022/08/23/2022-08-23%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Workload%20Entry/</id>
    <published>2022-08-22T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.257Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>WorkloadEntry 描述单个非 Kubernetes 工作负载的属性，例如 VM 或裸机服务器，因为它被载入到网格中。 WorkloadEntry 必须伴随着 Istio ServiceEntry，它通过适当的标签选择工作负载并为 MESH_INTERNAL 服务（主机名、端口属性等）提供服务定义。 ServiceEntry 对象可以根据服务条目中指定的标签选择器选择多个工作负载条目以及 Kubernetes pod。</p><p>当工作负载连接到 istiod 时，自定义资源中的 Status 字段将更新，表示工作负载的健康状况以及其他详细信息，类似于 Kubernetes 更新 Pod 状态的方式。</p><p>以下示例为 details.bookinfo.com 服务声明一个表示 VM 的 Workload Entry。此 VM 已使用 details-legacy Service Account 安装和引导 Sidecar。该服务在端口 80 上暴露给网格中的应用程序。到该服务的 HTTP 流量被封装在 Istio 双向 TLS 中，并发送到目标端口 8080 上 VM 上的 sidecar，然后将其转发到同一端口上 localhost 上的应用程序。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">WorkloadEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># use of the service account indicates that the workload has a</span></span><br><span class="line">  <span class="comment"># sidecar proxy bootstrapped with this service account. Pods with</span></span><br><span class="line">  <span class="comment"># sidecars will automatically communicate with the workload using</span></span><br><span class="line">  <span class="comment"># istio mutual TLS.</span></span><br><span class="line">  <span class="attr">serviceAccount:</span> <span class="string">details-legacy</span></span><br><span class="line">  <span class="attr">address:</span> <span class="number">2.2</span><span class="number">.2</span><span class="number">.2</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">details-legacy</span></span><br><span class="line">    <span class="attr">instance-id:</span> <span class="string">vm1</span></span><br></pre></td></tr></table></figure><p>相关联的 Service Entry：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">details.bookinfo.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">details-legacy</span></span><br></pre></td></tr></table></figure><p>以下示例使用其完全限定的 DNS 名称声明相同的 VM 工作负载。服务条目的解析模式应更改为 DNS，表示客户端 Sidecar 应在运行时动态解析 DNS 名称，然后再转发请求。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">WorkloadEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># use of the service account indicates that the workload has a</span></span><br><span class="line">  <span class="comment"># sidecar proxy bootstrapped with this service account. Pods with</span></span><br><span class="line">  <span class="comment"># sidecars will automatically communicate with the workload using</span></span><br><span class="line">  <span class="comment"># istio mutual TLS.</span></span><br><span class="line">  <span class="attr">serviceAccount:</span> <span class="string">details-legacy</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">vm1.vpc01.corp.net</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">details-legacy</span></span><br><span class="line">    <span class="attr">instance-id:</span> <span class="string">vm1</span></span><br></pre></td></tr></table></figure><p>相关联的 Service Entry：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">details.bookinfo.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">details-legacy</span></span><br></pre></td></tr></table></figure><h1 id="WorkloadEntry"><a href="#WorkloadEntry" class="headerlink" title="WorkloadEntry"></a>WorkloadEntry</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>address</td><td>不带端口的网络 endpoint 地址。当且仅当 resolution 设置为 DNS 时，才能使用域名，并且必须是完全限定的，没有通配符。Unix 域套接字 endpoint 使用格式：unix:&#x2F;&#x2F;&#x2F;absolute&#x2F;path&#x2F;to&#x2F;socket。</td></tr><tr><td>ports</td><td>与 endpoint 关联的 endpoint 集。如果指定了端口映射，则它必须是 servicePortName 到此 endpoint 端口的映射，这样到服务端口的流量将被转发到映射到服务端口名称的 endpoint 端口。如果省略，并且 targetPort 被指定为服务端口规范的一部分，则到服务端口的流量将被转发到指定 targetPort 上的 endpoint 之一。如果未指定 targetPort 和 endpoint 的端口映射，则到服务端口的流量将被转发到同一端口上的 endpoint 之一</td></tr><tr><td>labels</td><td>与 endpoint 关联的一个或多个标签</td></tr><tr><td>network</td><td>使 Istio 能够对驻留在同一 L3 域&#x2F;网络中的 endpoint 进行分组。假定同一网络中的所有 endpoint 彼此可直接访问。当不同网络中的 endpoint 无法直接相互访问时，可以使用 Istio Gateway 建立连接（通常在 Gateway Server 中使用 AUTO_PASSTHROUGH 模式）。这是一种高级配置，通常用于跨越多个集群的 Istio 网格</td></tr><tr><td>locality</td><td>与 endpoint 关联的位置信息。位置对应于故障域（例如，国家&#x2F;地区&#x2F;区域）。任意故障域层次结构可以通过用 &#x2F; 分隔每个封装故障域来表示。例如，endpoint 在 US、US-East-1 区域、可用区 az-1 内、数据中心机架 r11 中的位置可以表示为 us&#x2F;us-east-1&#x2F;az-1&#x2F;r11。 Istio 将配置 sidecar 以路由到与 sidecar 相同位置的 endpoint。如果本地没有可用的 endpoint，则将选择 endpoint 父本地（但在同一网络 ID 内）。例如，如果同一网络中有两个 endpoint（networkID “n1”），例如 e1 的位置为 us&#x2F;us-east-1&#x2F;az-1&#x2F;r11 和 e2 的位置为 us&#x2F;us-east-1&#x2F;az-2 &#x2F;r12，来自 us&#x2F;us-east-1&#x2F;az-1&#x2F;r11 地区的 Sidecar 将更倾向于来自同一地区的 e1 而不是来自不同地区的 e2。endpoint e2 可以是与 Gateway 关联的 IP（桥接网络 n1 和 n2），也可以是与标准服务 endpoint 关联的 IP</td></tr><tr><td>weight</td><td>与 endpoint 关联的负载平衡权重。具有较高权重的 endpoint 将按比例获得较高的流量</td></tr><tr><td>serviceAccount</td><td>如果工作负载中存在 Sidecar，则与工作负载关联的 Service Account。Service Account 必须存在于与配置相同的命名空间中（WorkloadEntry 或 ServiceEntry）</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 WorkloadEntry 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — ServiceEntry</title>
    <link href="http://shenxianghong.github.io/2022/08/16/2022-08-16%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Service%20Entry/"/>
    <id>http://shenxianghong.github.io/2022/08/16/2022-08-16%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Service%20Entry/</id>
    <published>2022-08-15T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.257Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>ServiceEntry 允许将外部的服务添加到 Istio 的内部服务注册表中，以便网格中的服务可以访问&#x2F;路由到这些手动指定的服务。ServiceEntry 描述了服务的属性（DNS 名称、VIP、端口、协议、端点）。这些服务可能在网格外部（例如，Web API）或网格内部服务，它们不属于平台的服务注册表（例如，一组与 Kubernetes 中的服务通信的 VM）。此外，还可以使用 workloadSelector 字段动态选择 ServiceEntry  的 endpoint。这些 endpoint 可以是使用 WorkloadEntry 对象或 Kubernetes Pod 声明的 VM 工作负载。在单个服务下同时选择 Pod 和 VM 的能力允许将服务从 VM 迁移到 Kubernetes，而无需更改与服务关联的现有 DNS 名称。</p><p>以下示例中声明了一些由内部应用程序通过 HTTPS 访问的外部 API。 Sidecar 检查 ClientHello 消息中的 SNI 值以路由到适当的外部服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-https</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">api.dropboxapi.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">www.googleapis.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">api.facebook.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TLS</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br></pre></td></tr></table></figure><p>以下配置将一组运行在非托管 VM 上的 MongoDB 实例添加到 Istio 的注册表中，以便可以将这些服务视为网格中的服务。关联的 DestinationRule 用于启动与数据库实例的 mTLS 连接。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-mongocluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mymongodb.somedomain</span> <span class="comment"># not used</span></span><br><span class="line">  <span class="attr">addresses:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">192.192</span><span class="number">.192</span><span class="number">.192</span><span class="string">/24</span> <span class="comment"># VIPs</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">27018</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">MONGO</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">2.2</span><span class="number">.2</span><span class="number">.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">3.3</span><span class="number">.3</span><span class="number">.3</span></span><br></pre></td></tr></table></figure><p>相关联的 DestinationRule。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mtls-mongocluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">mymongodb.somedomain</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">MUTUAL</span></span><br><span class="line">      <span class="attr">clientCertificate:</span> <span class="string">/etc/certs/myclientcert.pem</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/etc/certs/client_private_key.pem</span></span><br><span class="line">      <span class="attr">caCertificates:</span> <span class="string">/etc/certs/rootcacerts.pem</span></span><br></pre></td></tr></table></figure><p>以下示例结合使用 VirtualService 中的 ServiceEntry 和 TLS 路由，根据 SNI 值将流量引导至内部出口防火墙。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-redirect</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">wikipedia.org</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;*.wikipedia.org&quot;</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TLS</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">NONE</span></span><br></pre></td></tr></table></figure><p>基于 SNI 值路由的相关联的 VirtualService。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tls-routing</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">wikipedia.org</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;*.wikipedia.org&quot;</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">sniHosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">wikipedia.org</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;*.wikipedia.org&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">internal-egress-firewall.ns1.svc.cluster.local</span></span><br></pre></td></tr></table></figure><p>具有 TLS 匹配的 Virtual Service 用于覆盖默认的 SNI 匹配。在没有 Virtual Service 的情况下，流量将被转发到 wikipedia 。</p><p>以下示例中演示了使用专用出口网关，通过该网关转发所有外部服务流量。 “exportTo” 字段允许控制服务声明对网格中其他命名空间的可见性。默认情况下，服务会导出到所有命名空间。下面的例子限制了当前命名空间的可见性，用 “.” 表示，所以它不能被其他命名空间使用。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-httpbin</span></span><br><span class="line">  <span class="attr">namespace :</span> <span class="string">egress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">example.com</span></span><br><span class="line">  <span class="attr">exportTo:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;.&quot;</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br></pre></td></tr></table></figure><p>定义一个 Gateway 来处理所有出口流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">istio-egressgateway</span></span><br><span class="line"> <span class="attr">namespace:</span> <span class="string">istio-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"> <span class="attr">selector:</span></span><br><span class="line">   <span class="attr">istio:</span> <span class="string">egressgateway</span></span><br><span class="line"> <span class="attr">servers:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">     <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">     <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">     <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">   <span class="attr">hosts:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">&quot;*&quot;</span></span><br></pre></td></tr></table></figure><p>关联的 VirtualService 从 Sidecar 路由到网关服务（istio-egressgateway.istio-system.svc.cluster.local），同样的从 Gateway 路由到外部服务。VirtualService 被导出到所有命名空间，使它们能够通过 Gateway 将流量路由到外部服务。像这样强制流量通过托管中间代理是一种常见做法。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gateway-routing</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">egress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">example.com</span></span><br><span class="line">  <span class="attr">exportTo:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;*&quot;</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mesh</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">istio-egressgateway</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">gateways:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mesh</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">istio-egressgateway.istio-system.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">gateways:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">istio-egressgateway</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">example.com</span></span><br></pre></td></tr></table></figure><p>以下示例演示了在主机中为外部服务使用通配符。如果必须将连接路由到应用程序请求的 IP 地址（即应用程序解析 DNS 并尝试连接到特定 IP），则必须将 resolution 设置为 NONE。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-wildcard-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;*.bar.com&quot;</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">NONE</span></span><br></pre></td></tr></table></figure><p>以下示例演示了可通过客户端主机上的 Unix 域套接字获得的服务。resolution 必须设置为 STATIC 才能使用 Unix 地址 endpoint。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">unix-domain-socket-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;example.unix.local&quot;</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="string">unix:///var/run/example/socket</span></span><br></pre></td></tr></table></figure><p>对于基于 HTTP 的服务，可以创建一个由多个 DNS 可寻址 endpoint 支持的 VirtualService。在这种情况下，应用程序可以使用 HTTP_PROXY 环境变量透明地将 VirtualService 的 API 调用重新路由到选定的后端。</p><p>例如，以下配置创建了一个名为 foo.bar.com 的不存在的外部服务，后端：us.foo.bar.com:8080、uk.foo.bar.com:9080 和 in.foo.bar.com:7080。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-dns</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">foo.bar.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="string">us.foo.bar.com</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="attr">http:</span> <span class="number">8080</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="string">uk.foo.bar.com</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="attr">http:</span> <span class="number">9080</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="string">in.foo.bar.com</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="attr">http:</span> <span class="number">7080</span></span><br></pre></td></tr></table></figure><p>使用 HTTP_PROXY&#x3D;<a href="http://localhost/%EF%BC%8C%E4%BB%8E%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%88%B0">http://localhost/，从应用程序到</a> <a href="http://foo.bar.com/">http://foo.bar.com</a> 的调用将在上面指定的三个域之间进行负载平衡。换句话说，对 <a href="http://foo.bar.com/baz">http://foo.bar.com/baz</a> 的调用将被转换为 <a href="http://uk.foo.bar.com/baz%E3%80%82">http://uk.foo.bar.com/baz。</a></p><p>以下示例说明了包含 subjectAltNames 的 ServiceEntry 的用法，该名称的格式符合 SPIFFE 标准。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">httpbin</span></span><br><span class="line">  <span class="attr">namespace :</span> <span class="string">httpbin-ns</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">example.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">2.2</span><span class="number">.2</span><span class="number">.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">3.3</span><span class="number">.3</span><span class="number">.3</span></span><br><span class="line">  <span class="attr">subjectAltNames:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;spiffe://cluster.local/ns/httpbin-ns/sa/httpbin-service-account&quot;</span></span><br></pre></td></tr></table></figure><p>以下示例演示了使用 ServiceEntry 和 workloadSelector 来处理服务 details.bookinfo.com 从 VM 到 Kubernetes 的迁移。该服务有两个基于 VM 的实例和 Sidecar，以及一组由标准部署对象管理的 Kubernetes Pod。网格中此服务的使用者将在 VM 和 Kubernetes 之间自动进行负载平衡。用于 details.bookinfo.com 服务的 VM。此 VM 已使用 details-legacy Service Account 安装和引导 Sidecar。 Sidecar 在端口 80 上接收 HTTP 流量（包装在 istio 双向 TLS 中）并将其转发到同一端口上 localhost 上的应用程序。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">WorkloadEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-vm-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceAccount:</span> <span class="string">details</span></span><br><span class="line">  <span class="attr">address:</span> <span class="number">2.2</span><span class="number">.2</span><span class="number">.2</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">details</span></span><br><span class="line">    <span class="attr">instance-id:</span> <span class="string">vm1</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">WorkloadEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-vm-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceAccount:</span> <span class="string">details</span></span><br><span class="line">  <span class="attr">address:</span> <span class="number">3.3</span><span class="number">.3</span><span class="number">.3</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">details</span></span><br><span class="line">    <span class="attr">instance-id:</span> <span class="string">vm2</span></span><br></pre></td></tr></table></figure><p>假设还有一个 Deployment 带有 Pod 标签 app: details 使用相同的 ServiceAccount（即 details），以下 ServiceEntry 声明了一个跨 VM 和 Kubernetes 的服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">details-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">details.bookinfo.com</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">details</span></span><br></pre></td></tr></table></figure><h1 id="ServiceEntry"><a href="#ServiceEntry" class="headerlink" title="ServiceEntry"></a>ServiceEntry</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>hosts</td><td>与 ServiceEntry 关联的主机。可以是带有通配符前缀的 DNS 名称。<br />- hosts 字段用于在 VirtualServices 和 DestinationRules 中选择匹配的主机<br />- 对于 HTTP 流量，HTTP Host&#x2F;Authority 标头将与 hosts 字段匹配<br />- 对于包含服务器名称指示（SNI） 的 HTTPs 或 TLS 流量，SNI 值将与 hosts 字段匹配<br /><br />NOTE：<br />- 当解析设置为 DNS 类型且未指定 endpoint 时，主机字段将用作将流量路由到的 endpoint 的 DNS 名称<br />- 如果主机名与另一个服务注册中心的服务名称匹配，例如 Kubernetes，它也提供自己的一组 endpoint，则 ServiceEntry 将被视为现有 Kubernetes 服务的装饰器。如果适用，Service Entry 中的属性将添加到 Kubernetes 服务中。目前，istiod 只会考虑以下附加属性：<br />- subjectAltNames：除了验证与服务的 pod 关联的服务帐户的 SAN 之外，还将验证此处指定的 SAN</td></tr><tr><td>addresses</td><td>与服务关联的虚拟 IP 地址。可能是 CIDR 前缀。对于 HTTP 流量，生成的路由配置将包括地址和主机字段值的 http 路由域，并且将根据 HTTP Host&#x2F;Authority 标头识别目标。如果指定了一个或多个 IP 地址，如果目标 IP 与地址字段中指定的 IP&#x2F;CIDR 匹配，则传入流量将被标识为属于此服务。如果地址字段为空，则将仅根据目标端口识别流量。在这种情况下，服务被访问的端口不能被网格中的任何其他服务共享。换句话说，Sidecar 将充当简单的 TCP 代理，将指定端口上的传入流量转发到指定的目标 endpoint IP&#x2F;主机。此字段不支持 Unix 域套接字地址</td></tr><tr><td>ports</td><td>与外部服务关联的端口。如果 endpoint 是 Unix 域套接字地址，则必须只有一个端口</td></tr><tr><td><a href="#ServiceEntry.Location">location</a></td><td>指定是否应将服务视为网格外部或网格的一部分</td></tr><tr><td><a href="#ServiceEntry.Resolution">resolution</a></td><td>主机的服务发现模式。为没有附带 IP 地址的 TCP 端口设置解析模式为 NONE 时需要注意，在这种情况下，将允许到所述端口上的任何 IP 的流量（即 0.0.0.0:&lt;port&gt;）</td></tr><tr><td>endpoints</td><td>与服务关联的一个或多个 endpoint。只能指定 endpoints 或 workloadSelector 之一</td></tr><tr><td>workloadSelector</td><td>仅适用于 MESH_INTERNAL 服务。只能指定 endpoint 或工作负载选择器之一。根据标签选择一个或多个 Kubernetes Pod 或 VM 工作负载（使用 WorkloadEntry 指定）。表示 VM 的 WorkloadEntry 对象应与 ServiceEntry 定义在相同的命名空间中</td></tr><tr><td>exportTo</td><td>此服务导出到的命名空间列表。导出服务允许它被其他命名空间中定义的 Sidecar、Gateway 和 VirtualService 使用。此功能为服务所有者和网格管理员提供了一种机制来控制跨命名空间边界的服务的可见性。<br />如果未指定命名空间，则默认将服务导出到所有命名空间。<br /> ”.” 保留语义表示导出到声明服务的同一命名空间。类似地，“*” 保留语义定义导出到所有命名空间。<br />对于 Kubernetes Service，可以通过将注解 networking.istio.io&#x2F;exportTo 设置为以逗号分隔的命名空间名称列表来实现等效效果</td></tr><tr><td>subjectAltNames</td><td>如果指定，代理将验证服务器证书的 subject alternate name 是否与指定值之一匹配。<br />注意：将 workloadEntry  与 workloadSelector 一起使用时，workloadEntry 中指定的 ServiceAccount 也将用于派生应验证的其他 subject alternate name</td></tr></tbody></table><h1 id="ServiceEntry-Location"><a href="#ServiceEntry-Location" class="headerlink" title="ServiceEntry.Location"></a><a name="ServiceEntry.Location">ServiceEntry.Location</a></h1><p>location 指定服务是 Istio 网格的一部分还是网格之外。location 决定了几个特性的行为，例如服务到服务的 mTLS 身份验证、策略执行等。当与网格外的服务通信时，Istio 的 mTLS 身份验证被禁用，并且策略执行在客户端执行，而不是在服务端。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>MESH_EXTERNAL</td><td>表示服务在网格外部。通常用于指示通过 API 使用的外部服务</td></tr><tr><td>MESH_INTERNAL</td><td>表示服务是网格的一部分。通常用于指示作为扩展服务网格以包括非托管基础设施的一部分而显式添加的服务（例如，添加到基于 Kubernetes 的服务网格的虚拟机）</td></tr></tbody></table><h1 id="ServiceEntry-Resolution"><a href="#ServiceEntry-Resolution" class="headerlink" title="ServiceEntry.Resolution"></a><a name="ServiceEntry.Resolution">ServiceEntry.Resolution</a></h1><p>resolution 决定代理将如何解析与服务关联的网络 endpoint 的 IP 地址，以便它可以路由到其中一个。此处指定的解析模式对应用程序如何解析与服务关联的 IP 地址没有影响。应用程序可能仍需要使用 DNS 将服务解析为 IP，以便代理可以捕获出站流量。或者，对于 HTTP 服务，应用程序可以直接与代理通信（例如，通过设置 HTTP_PROXY）来与这些服务通信。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>NONE</td><td>假设传入的连接已经被解析（到特定的目标 IP 地址）。此类连接通常使用 IP 表 REDIRECT&#x2F;eBPF 等机制通过代理进行路由。在执行任何与路由相关的转换后，代理会将连接转发到连接绑定的 IP 地址</td></tr><tr><td>STATIC</td><td>使用 endpoint 中指定的静态 IP 地址（见下文）作为与服务关联的支持实例</td></tr><tr><td>DNS</td><td>尝试通过异步查询环境 DNS 来解析 IP 地址。如果未指定 endpoint，则代理将解析主机字段中指定的 DNS 地址（如果未使用通配符）。如果指定了 endpoint，则将解析 endpoint 中指定的 DNS 地址以确定目标 IP 地址。 DNS 解析不能与 Unix 域套接字 endpoint 一起使用</td></tr><tr><td>DNS_ROUND_ROBIN</td><td>尝试通过异步查询环境 DNS 来解析 IP 地址。与 DNS 不同，DNS_ROUND_ROBIN 仅在需要启动新连接时使用返回的第一个 IP 地址，而不依赖于 DNS 解析的完整结果，即使 DNS 记录频繁更改，与主机建立的连接也将被保留，从而消除了耗尽连接池和连接循环。这最适合必须通过 DNS 访问的大型 Web 规模服务。如果不使用通配符，代理将解析主机字段中指定的 DNS 地址。 DNS 解析不能与 Unix 域套接字 endpoint 一起使用</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 ServiceEntry 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — DestinationRule</title>
    <link href="http://shenxianghong.github.io/2022/08/09/2022-08-09%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Destination%20Rule/"/>
    <id>http://shenxianghong.github.io/2022/08/09/2022-08-09%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Destination%20Rule/</id>
    <published>2022-08-08T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.256Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>DestinationRule 定义了在路由发生后应用于服务的流量的策略。这些规则指定负载均衡的配置、sidecar 的连接池大小以及异常值检测设置，用来检测、驱逐负载均衡池中不健康的后端。</p><p>例如，review 服务的简单负载均衡策略如下。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">LEAST_REQUEST</span></span><br></pre></td></tr></table></figure><p>可以通过定义 subset 覆盖在服务级别指定的设置来指定版本特定策略。</p><p>以下规则对流向名为 testversion 的子集的所有流量使用 ROUND_ROBIN 负载均衡策略。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">LEAST_REQUEST</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">testversion</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3</span></span><br><span class="line">    <span class="attr">trafficPolicy:</span></span><br><span class="line">      <span class="attr">loadBalancer:</span></span><br><span class="line">        <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br></pre></td></tr></table></figure><p><em>注意：为子集指定的策略在路由规则明确向该子集发送流量之前不会生效。</em></p><p>流量策略也可以针对特定端口进行定制。以下规则对流向端口 80 的所有流量使用 LEAST_REQUEST 负载均衡策略，而对流向端口 9080 的流量使用 ROUND_ROBIN  负载均衡策略。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-ratings-port</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span> <span class="comment"># Apply to all ports</span></span><br><span class="line">    <span class="attr">portLevelSettings:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">        <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">loadBalancer:</span></span><br><span class="line">        <span class="attr">simple:</span> <span class="string">LEAST_REQUEST</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">        <span class="attr">number:</span> <span class="number">9080</span></span><br><span class="line">      <span class="attr">loadBalancer:</span></span><br><span class="line">        <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br></pre></td></tr></table></figure><p>目标规则也可以针对特定的工作负载进行定制。以下示例显示了如何使用工作负载选择器将目标规则应用于特定工作负载。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configure-client-mtls-dr-with-workloadselector</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">workloadSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">    <span class="attr">portLevelSettings:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">        <span class="attr">number:</span> <span class="number">31443</span></span><br><span class="line">      <span class="attr">tls:</span></span><br><span class="line">        <span class="attr">credentialName:</span> <span class="string">client-credential</span></span><br><span class="line">        <span class="attr">mode:</span> <span class="string">MUTUAL</span></span><br></pre></td></tr></table></figure><h1 id="DestinationRule"><a href="#DestinationRule" class="headerlink" title="DestinationRule"></a>DestinationRule</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>host</td><td>服务注册表中的服务名称。服务名称从平台的服务注册表（例如，Kubernetes 服务、Consul 服务等）和 ServiceEntry 声明的 host 中查找。两者都找不到的流量将被丢弃。<br /><em>同样的，推荐使用完全限定域名，host 字段适用于 HTTP 和 TCP 的服务</em></td></tr><tr><td><a href="#TrafficPolicy">trafficPolicy</a></td><td>要应用的流量策略（负载均衡策略、连接池大小、异常值检测）</td></tr><tr><td><a href="#Subset">subsets</a></td><td>一个或多个命名集，代表服务的各个版本。流量策略可以在子集级别被覆盖</td></tr><tr><td>exportTo</td><td>此 VirtualService 暴露到的命名空间列表。暴露 VirtualService 允许它被其他命名空间中定义的 sidecar 和 Gateway 使用。此功能为服务所有者和网格管理员提供了一种机制来控制跨命名空间边界的 VirtualService 的可见性<br />如果未指定命名空间，则默认情况下将 VirtualService 暴露到所有命名空间<br /> . 为保留标识代表暴露到 VirtualService 的同一命名空间中。类似地，* 代表暴露到所有命名空间</td></tr><tr><td>workloadSelector</td><td>用于选择应用此 DestinationRule 配置的特定 pod&#x2F;VM 集的条件。如果指定，则 DestinationRule 配置将仅应用于与同一命名空间中的选择器标签匹配的工作负载实例。工作负载选择器不适用于跨命名空间。如果省略，DestinationRule 将回退到其默认行为。例如，如果特定的 sidecar 需要为网格外的服务设置出口 TLS 设置，而不是网格中的每个 sidecar 都需要配置（这是默认行为），则可以指定工作负载选择器</td></tr></tbody></table><h1 id="TrafficPolicy"><a href="#TrafficPolicy" class="headerlink" title="TrafficPolicy"></a><a name="TrafficPolicy">TrafficPolicy</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#LoadBalancerSettings">loadBalancer</a></td><td>负载均衡器算法的设置</td></tr><tr><td><a href="#ConnectionPoolSettings">connectionPool</a></td><td>与上游服务的连接池的设置</td></tr><tr><td><a href="#OutlierDetection">outlierDetection</a></td><td>负载均衡池中逐出不健康后端的设置</td></tr><tr><td><a href="#ClientTLSSettings">tls</a></td><td>与上游服务连接的 TLS 相关设置</td></tr><tr><td><a href="#TrafficPolicy.PortTrafficPolicy">portLevelSettings</a></td><td>各个端口的流量策略。<br /><em>注意，portLevelSettings 将覆盖 destinationLevel 设置。portLevelSettings 未设置的部分，会以 destinationLevel  级别为准</em></td></tr><tr><td><a href="#TrafficPolicy.TunnelSettings">tunnel</a></td><td>在 DestinationRule 中配置的 host 的其他传输层或应用层上的隧道 TCP 配置。隧道设置可以应用于 TCP 或 TLS 路由，但不能应用于 HTTP 路由</td></tr></tbody></table><h1 id="Subset"><a href="#Subset" class="headerlink" title="Subset"></a><a name="Subset">Subset</a></h1><p>Service 的 endpoint 的子集。子集可用于 A&#x2F;B 测试或路由到特定服务版本等场景。此外，在 VirtualService 级别定义的流量策略可以被子集级别覆盖。</p><p>通常需要一个或多个标签来标识子集目的地，但是，当相应的 DestinationRule 表示支持多个 SNI 主机的主机（例如，出口网关）时，没有标签的子集可能是有意义的。在这种情况下，可以使用带有 ClientTLSSettings 的流量策略来识别与命名子集相对应的特定 SNI 主机。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>子集的名称。服务名称和子集名称可用于路由规则中的流量拆分</td></tr><tr><td>labels</td><td>服务注册表中的服务 endpoint 上应用过滤器</td></tr><tr><td><a href="#TrafficPolicy">trafficPolicy</a></td><td>子集的流量策略。子集会继承在 DestinationRule 级别指定的流量策略，同时会被子集级别指定的设置覆盖</td></tr></tbody></table><h1 id="LoadBalancerSettings"><a href="#LoadBalancerSettings" class="headerlink" title="LoadBalancerSettings"></a><a name="LoadBalancerSettings">LoadBalancerSettings</a></h1><p>应用到特定目的地的负载均衡策略。有关更多详细信息，参阅 <a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/load_balancing">Envoy 的负载均衡文档</a>。</p><p>例如，以下规则对流向 ratings 服务的所有流量使用 ROUND_ROBIN 负载均衡策略。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br></pre></td></tr></table></figure><p>以下示例对于使用 User cookie 作为哈希键访问 rating 服务设置粘性会话。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">consistentHash:</span></span><br><span class="line">        <span class="attr">httpCookie:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">user</span></span><br><span class="line">          <span class="attr">ttl:</span> <span class="string">0s</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#LoadBalancerSettings.SimpleLB">simple</a></td><td>参考 LoadBalancerSettings.SimpleLB 说明</td></tr><tr><td><a href="#LoadBalancerSettings.ConsistentHashLB">consistentHash</a></td><td>参考 LoadBalancerSettings.ConsistentHashLB 说明</td></tr><tr><td><a href="#LocalityLoadBalancerSetting">localityLbSetting</a></td><td>本地负载均衡器设置，这将完全覆盖网格范围的设置，这意味着不会在此对象和 MeshConfig 之间执行合并</td></tr><tr><td>warmupDurationSecs</td><td>表示 Service 的预热持续时间。如果设置，则新创建的 service endpoint 在此窗口期间从其创建时间开始保持预热模式，并且 Istio 逐渐增加该 endpoint 的流量，而不是发送成比例的流量。应该为需要预热时间的合理延迟服务完整生产负载的服务启用此功能。目前只支持 ROUND_ROBIN 和 LEAST_CONN 负载均衡器</td></tr></tbody></table><h1 id="ConnectionPoolSettings"><a href="#ConnectionPoolSettings" class="headerlink" title="ConnectionPoolSettings"></a><a name="ConnectionPoolSettings">ConnectionPoolSettings</a></h1><p>上游主机的连接池设置。这些设置适用于上游服务中的每个单独的主机。有关更多详细信息，参阅 <a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/circuit_breaking">Envoy 的断路器</a>。连接池设置可以应用于 TCP 级别以及 HTTP 级别。</p><p>例如，以下规则设置了 100 个连接到名为 myredissrv 的 redis 服务的限制，连接超时为 30 毫秒。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">myredissrv.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">connectionPool:</span></span><br><span class="line">      <span class="attr">tcp:</span></span><br><span class="line">        <span class="attr">maxConnections:</span> <span class="number">100</span></span><br><span class="line">        <span class="attr">connectTimeout:</span> <span class="string">30ms</span></span><br><span class="line">        <span class="attr">tcpKeepalive:</span></span><br><span class="line">          <span class="attr">time:</span> <span class="string">7200s</span></span><br><span class="line">          <span class="attr">interval:</span> <span class="string">75s</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ConnectionPoolSettings.TCPSettings">tcp</a></td><td>HTTP 和 TCP 上游连接通用的设置</td></tr><tr><td><a href="#ConnectionPoolSettings.HTTPSettings">http</a></td><td>HTTP 连接池设置</td></tr></tbody></table><h1 id="OutlierDetection"><a href="#OutlierDetection" class="headerlink" title="OutlierDetection"></a><a name="OutlierDetection">OutlierDetection</a></h1><p>一种断路器实现，用于跟踪上游服务中每个单独主机的状态。</p><p>适用于 HTTP 和 TCP 服务。</p><ul><li>对于 HTTP 服务，对于 API 调用持续返回 5xx 错误的主机将在预定义的时间段内从池中弹出</li><li>对于 TCP 服务，在测量连续错误指标时，与给定主机的连接超时或连接失败将计为错误</li></ul><p>有关更多详细信息，参阅 <a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/outlier">Envoy 的异常值检测</a>。</p><p>以下规则将连接池大小设置为 100 个 HTTP1 连接，其中 reviews 服务的单连接的请求最大不超过 10 个。此外，它设置了 1000 个并发 HTTP2 请求的限制，并将上游 host 配置为每 5 分钟扫描一次，任何连续 7 次失败并出现 502、503 或 504 错误代码的 host 将被弹出 15 分钟。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-cb-policy</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">connectionPool:</span></span><br><span class="line">      <span class="attr">tcp:</span></span><br><span class="line">        <span class="attr">maxConnections:</span> <span class="number">100</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">http2MaxRequests:</span> <span class="number">1000</span></span><br><span class="line">        <span class="attr">maxRequestsPerConnection:</span> <span class="number">10</span></span><br><span class="line">    <span class="attr">outlierDetection:</span></span><br><span class="line">      <span class="attr">consecutive5xxErrors:</span> <span class="number">7</span></span><br><span class="line">      <span class="attr">interval:</span> <span class="string">5m</span></span><br><span class="line">      <span class="attr">baseEjectionTime:</span> <span class="string">15m</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>splitExternalLocalOriginErrors</td><td>确定是否区分本地源故障和外部错误。如果设置为 true，则连续_local_origin_failure 被考虑用于异常值检测计算。当您希望根据本地看到的错误（例如连接失败、连接超时等）而不是上游服务重新调整的状态码来推导异常检测状态时，应该使用此选项。当上游服务为某些请求显式返回 5xx 并且您希望在确定主机的异常检测状态时忽略来自上游服务的这些响应时，这尤其有用。默认为假</td></tr><tr><td>consecutiveLocalOriginFailures</td><td>在弹出发生之前连续发生的本地故障数。默认为 5。参数仅在 splitExternalLocalOriginErrors 设置为 true 时生效</td></tr><tr><td>consecutiveGatewayErrors</td><td>主机从连接池中弹出之前的网关错误数。当通过 HTTP 访问上游主机时，502、503 或 504 返回码被视为网关错误。当通过不透明的 TCP 连接访问上游主机时，连接超时和连接错误&#x2F;失败事件符合网关错误。默认为 0，即禁用此功能</td></tr><tr><td>consecutive5xxErrors</td><td>主机从连接池中弹出之前的 5xx 错误数。当通过不透明的 TCP 连接访问上游主机时，连接超时、连接错误&#x2F;失败和请求失败事件被视为 5xx 错误。默认为 5，可以通过将值设置为 0 来禁用<br /><em>注意， consecutiveGatewayErrors 和  consecutive5xxErrors 可以单独使用，也可以一起使用。因为 consecutiveGatewayErrors 统计的错误也包含在 consecutive5xxErrors 中，如果 consecutiveGatewayErrors 的值大于或等于 consecutive5xxErrors 的值，则 consecutiveGatewayErrors 将不起作用</em></td></tr><tr><td>interval</td><td>弹出分析的时间间隔。格式：1h&#x2F;1m&#x2F;1s&#x2F;1ms。必须 &gt;&#x3D;1 ms。默认为 10 s</td></tr><tr><td>baseEjectionTime</td><td>最短弹出时间。被弹出的时间等于最小弹出持续时间与主机被弹出次数的乘积。这种方式下系统将自动增加不健康的上游服务器的弹出周期。格式：1h&#x2F;1m&#x2F;1s&#x2F;1ms。必须 &gt;&#x3D;1 ms。默认为 30 s</td></tr><tr><td>maxEjectionPercent</td><td>上游服务的负载均衡池中可以弹出的后端的最大百分比。默认为 10%</td></tr><tr><td>minHealthPercent</td><td>只要关联的负载均衡池至少有 minHealthPercent 主机处于健康模式，就会启用异常值检测。当负载均衡池中健康主机的百分比低于此阈值时，将禁用异常值检测，并且代理将在池中的所有主机（健康和不健康）之间进行负载均衡。可以通过将阈值设置为 0% 来禁用该阈值。默认值为 0%，因为它通常不适用于每个服务的 pod 很少的 k8s 环境</td></tr></tbody></table><h1 id="ClientTLSSettings"><a href="#ClientTLSSettings" class="headerlink" title="ClientTLSSettings"></a><a name="ClientTLSSettings">ClientTLSSettings</a></h1><p>上游连接的 SSL&#x2F;TLS 相关设置。有关更多详细信息，参阅 <a href="https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/transport_sockets/tls/v3/common.proto.html#common-tls-configuration">Envoy 的 TLS 上下文</a>。对 HTTP 和 TCP 上游都是通用的。</p><p>例如，以下规则将客户端配置为使用双向 TLS（MUTUAL）连接到上游数据库集群。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">db-mtls</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">mydbserver.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">MUTUAL</span></span><br><span class="line">      <span class="attr">clientCertificate:</span> <span class="string">/etc/certs/myclientcert.pem</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/etc/certs/client_private_key.pem</span></span><br><span class="line">      <span class="attr">caCertificates:</span> <span class="string">/etc/certs/rootcacerts.pem</span></span><br></pre></td></tr></table></figure><p>以下规则将客户端配置为在与 rating 服务通信时使用 Istio 双向 TLS。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-istio-mtls</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">ISTIO_MUTUAL</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ClientTLSSettings.TLSmode">mode</a></td><td>是否应使用 TLS 保护与此端口的连接。该字段的值决定了 TLS 的行为方式</td></tr><tr><td>clientCertificate</td><td>如果 mode 为 MUTUAL 时，则为必需。表示使用的客户端 TLS 证书的文件的路径。如果模式为 ISTIO_MUTUAL，则应为空</td></tr><tr><td>privateKey</td><td>如果 mode 为 MUTUAL 时，则为必需。保存客户端私钥的文件的路径。如果模式为 ISTIO_MUTUAL，则应为空</td></tr><tr><td>caCertificates</td><td>用于验证提供的服务器证书的证书颁发机构证书的文件的路径。如果省略，代理将不会验证服务器的证书。如果模式为 ISTIO_MUTUAL，则应为空</td></tr><tr><td>credentialName</td><td>保存客户端 TLS 证书的密钥的名称，包括 CA 证书。 Secret 必须与使用证书的代理存在于同一命名空间中。密钥（通用类型）应包含以下键和值：key：&lt;privateKey&gt;、cert：&lt;clientCert&gt;、cacert：&lt;CACertificate&gt;。这里 CACertificate 用于验证服务器证书。还支持用于客户端证书的 tls 类型的密钥以及用于 CA 证书的 ca.crt 密钥。只能指定客户端证书和 CA 证书或 credentialName 中的一个<br />注意：仅当 DestinationRule 指定了工作负载选择器时，此字段才适用于 sidecar。否则该字段将仅适用于网关，sidecar 将继续使用证书路径</td></tr><tr><td>subjectAltNames</td><td>用于验证证书中主体身份的备用名称列表。如果指定，代理将验证服务器证书的主题 alt 名称是否与指定值之一匹配。如果指定，此列表将覆盖 ServiceEntry 中的 subject_alt_names 的值。如果未指定，则将根据下游 HTTP 主机&#x2F;授权标头自动验证新上游连接的上游证书，前提是 VERIFY_CERT_AT_CLIENT 和 ENABLE_AUTO_SNI 环境变量设置为 true</td></tr><tr><td>sni</td><td>在 TLS 握手期间呈现给服务器的 SNI 字符串。如果未指定，则 SNI 将根据 SIMPLE 和 MUTUAL TLS 模式的下游 HTTP host&#x2F;authority header 自动设置，前提是 ENABLE_AUTO_SNI 环境变量设置为 true</td></tr><tr><td>insecureSkipVerify</td><td>InsecureSkipVerify 指定代理是否应该跳过验证主机对应的服务器证书的 CA 签名和 SAN。仅当启用全局 CA 签名验证，VerifyCertAtClient 环境变量设置为 true，但不需要对特定主机进行验证时，才应设置此标志。无论是否启用了 VerifyCertAtClient，都将跳过 CA 签名和 SAN 的验证<br />InsecureSkipVerify 默认为 false。在 Istio 1.9 版本中，VerifyCertAtClient 默认为 false，但在以后的版本中默认为 true</td></tr></tbody></table><h1 id="LocalityLoadBalancerSetting"><a href="#LocalityLoadBalancerSetting" class="headerlink" title="LocalityLoadBalancerSetting"></a><a name="LocalityLoadBalancerSetting">LocalityLoadBalancerSetting</a></h1><p>位置加权负载均衡允许根据流量的来源和终止位置来控制到 endpoint 的流量分配。这些地区是使用任意标签指定的，这些标签以 {region}&#x2F;{zone}&#x2F;{sub-zone} 形式指定地区层次结构。有关更多详细信息，参阅<a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/locality_weight">局部权重</a>。</p><p>以下示例显示如何在网格范围内设置局部权重：在一个网格中，其工作负载中的服务部署到了 us-west&#x2F;zone1&#x2F; 和 us-west&#x2F;zone2&#x2F; 中。当访问服务的流量源自 us-west&#x2F;zone1&#x2F; 中时，80% 的流量将发送到 us-west&#x2F;zone1&#x2F; 的 endpoint，即同一区域，其余的 20% 将进入 us-west&#x2F;zone2&#x2F; 的 endpoint。此设置旨在将流量路由到同一位置的 endpoint。为源自 us-west&#x2F;zone2&#x2F; 的流量指定了类似的设置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">distribute:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span> <span class="string">us-west/zone1/*</span></span><br><span class="line">    <span class="attr">to:</span></span><br><span class="line">      <span class="string">&quot;us-west/zone1/*&quot;</span><span class="string">:</span> <span class="number">80</span></span><br><span class="line">      <span class="string">&quot;us-west/zone2/*&quot;</span><span class="string">:</span> <span class="number">20</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span> <span class="string">us-west/zone2/*</span></span><br><span class="line">    <span class="attr">to:</span></span><br><span class="line">      <span class="string">&quot;us-west/zone1/*&quot;</span><span class="string">:</span> <span class="number">20</span></span><br><span class="line">      <span class="string">&quot;us-west/zone2/*&quot;</span><span class="string">:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>如果运营商的目标不是跨区域和区域分配负载，而是限制故障转移的区域性以满足其他运营要求，则运营商可以设置“故障转移”策略而不是“分布”策略。</p><p>以下示例为区域设置本地故障转移策略。假设服务驻留在 us-east、us-west 和 eu-west 内的区域中，此示例指定当 us-east 内的 endpoint 变得不健康时，流量应故障转移到 eu-west 内的 endpoint，类似地 us-west 应该故障转移到 us-east。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">failover:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span> <span class="string">us-east</span></span><br><span class="line">    <span class="attr">to:</span> <span class="string">eu-west</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span> <span class="string">us-west</span></span><br><span class="line">    <span class="attr">to:</span> <span class="string">us-east</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#LocalityLoadBalancerSetting.Distribute">distribute</a></td><td>只能设置 distribute、failover 或 failoverPriority 中的其一。指定跨不同区域和地理位置的负载平衡权重。参考 <a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/locality_weight">Locality weighted load balancing</a>。如果为空，则根据其中的 endpoints 数量设置 locality 权重</td></tr><tr><td><a href="#LocalityLoadBalancerSetting.Failover">failover</a></td><td>只能设置 distribute、failover 或 failoverPriority 中的其一。当本地区域的 endpoint 变得不健康时，显式指定待转移流量的区域。应与 OutlierDetection 一起使用以检测不健康的 endpoint<br /><em>注意：生效的前提是指定了 OutlierDetection</em></td></tr><tr><td>failoverPriority</td><td>failoverPriority 是标签的有序列表，用于对 endpoint 进行排序以进行基于优先级的负载平衡。这是为了支持跨不同 endpoint 组的流量故障转移。假设总共指定了 N 个标签：<br />- 与客户端代理匹配所有 N 个标签的 endpoint 具有优先级 P(0)，即最高优先级<br />- 将前 N-1 个标签与客户端代理匹配的 endpoint 具有优先级 P(1)，即第二高优先级<br />- 通过扩展此逻辑，仅与客户端代理匹配第一个标签的 endpoint 具有优先级 P(N-1)，即第二低优先级<br />- 所有其他 endpoint 具有优先级 P(N)，即最低优先级<br />注意：对于要考虑匹配的标签，之前的标签必须匹配，即仅当前 n-1 个标签匹配时，才会认为第 n 个标签匹配<br />它可以是在客户端和服务器工作负载上指定的任何标签。还支持以下具有特殊语义含义的标签<br />- topology.istio.io&#x2F;network 用于匹配 endpoint 的网络元数据，可以通过 pod&#x2F;namespace 标签 topology.istio.io&#x2F;network、sidecar env ISTIO_META_NETWORK 或 MeshNetworks 指定<br />- topology.istio.io&#x2F;cluster 用于匹配一个 endpoint 的clusterID，可以通过 pod label topology.istio.io&#x2F;cluster 或pod env ISTIO_META_CLUSTER_ID 指定<br />- topology.kubernetes.io&#x2F;region 用于匹配 endpoint 的区域元数据，映射到 Kubernetes 节点标签 topology.kubernetes.io&#x2F;region 或 failure-domain.beta.kubernetes.io&#x2F;region（已弃用）<br />- topology.kubernetes.io&#x2F;zone 用于匹配 endpoint 的 zone 元数据，映射到 Kubernetes 节点标签 topology.kubernetes.io&#x2F;zone 或 failure-domain.beta.kubernetes.io&#x2F;zone（已弃用）<br />- topology.istio.io&#x2F;subzone 用于匹配 endpoint 的子区域元数据，映射到 Istio 节点标签 topology.istio.io&#x2F;subzone<br />拓扑配置遵循以下优先级：<br />failoverPriority<br/>- topology.istio.io&#x2F;network<br/>- topology.kubernetes.io&#x2F;region<br/>- topology.kubernetes.io&#x2F;zone<br/>- topology.istio.io&#x2F;subzone<br />即 endpoint 和客户端代理的 [network, region, zone, subzone] label 的匹配度越高，则优先级越高<br />只能设置 distribute、failover 或 failoverPriority 中的其一。并且应该和 OutlierDetection 一起使用来检测不健康的 endpoint，否则没有效果</td></tr><tr><td>enabled</td><td>是否启用局部负载平衡，为 DestinationRule 级别，将完全覆盖网格范围的设置<br /><em>例如 true 表示无论网格范围的设置是什么，都为此 DestinationRule 打开局部负载平衡</em></td></tr></tbody></table><h1 id="TrafficPolicy-PortTrafficPolicy"><a href="#TrafficPolicy-PortTrafficPolicy" class="headerlink" title="TrafficPolicy.PortTrafficPolicy"></a><a name="TrafficPolicy.PortTrafficPolicy">TrafficPolicy.PortTrafficPolicy</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>port</td><td>指定应用此策略的目标服务上的端口号</td></tr><tr><td><a href="#LoadBalancerSettings">loadBalancer</a></td><td>控制负载均衡器算法的设置</td></tr><tr><td><a href="#ConnectionPoolSettings">connectionPool</a></td><td>控制与上游服务的连接量的设置</td></tr><tr><td><a href="#OutlierDetection">outlierDetection</a></td><td>控制从负载均衡池中逐出不健康主机的设置</td></tr><tr><td><a href="#ClientTLSSettings">tls</a></td><td>与上游服务连接的 TLS 相关设置</td></tr></tbody></table><h1 id="TrafficPolicy-TunnelSettings"><a href="#TrafficPolicy-TunnelSettings" class="headerlink" title="TrafficPolicy.TunnelSettings"></a><a name="TrafficPolicy.TunnelSettings">TrafficPolicy.TunnelSettings</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>protocol</td><td>指定用于隧道下行连接的协议。支持的协议有：connect - 使用 HTTP CONNECT； post - 使用 HTTP POST。上游请求的 HTTP 版本由为代理定义的服务协议确定</td></tr><tr><td>targetHost</td><td>指定下游连接通过隧道连接到的主机。目标主机必须是 FQDN 或 IP 地址</td></tr><tr><td>targetPort</td><td>指定下游连接通过隧道连接到的端口</td></tr></tbody></table><h1 id="LoadBalancerSettings-ConsistentHashLB"><a href="#LoadBalancerSettings-ConsistentHashLB" class="headerlink" title="LoadBalancerSettings.ConsistentHashLB"></a><a name="LoadBalancerSettings.ConsistentHashLB">LoadBalancerSettings.ConsistentHashLB</a></h1><p>一致的基于哈希的负载均衡可用于提供基于 HTTP 标头、cookie 或其他属性的软会话亲和性。当从目标服务中添加&#x2F;删除一个或多个主机时，与特定目标主机的关联将被移除。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>httpHeaderName</td><td>基于特定 HTTP 标头的 hash</td></tr><tr><td><a href="#LoadBalancerSettings.ConsistentHashLB.HTTPCookie">httpCookie</a></td><td>基于 HTTP cookie 的 hash</td></tr><tr><td>useSourceIp</td><td>基于源 IP 地址的 hash。适用于 TCP 和 HTTP 连接</td></tr><tr><td>httpQueryParameterName</td><td>基于特定 HTTP query 参数的 hash</td></tr><tr><td>minimumRingSize</td><td>用于哈希环的最小虚拟节点数。默认为 1024。较大的环尺寸会产生更精细的负载分布。如果负载均衡池中的主机数量大于环大小，则每个主机将被分配一个虚拟节点</td></tr></tbody></table><h1 id="LoadBalancerSettings-ConsistentHashLB-HTTPCookie"><a href="#LoadBalancerSettings-ConsistentHashLB-HTTPCookie" class="headerlink" title="LoadBalancerSettings.ConsistentHashLB.HTTPCookie"></a><a name="LoadBalancerSettings.ConsistentHashLB.HTTPCookie">LoadBalancerSettings.ConsistentHashLB.HTTPCookie</a></h1><p>描述将用作一致哈希负载均衡器的哈希键的 HTTP cookie。如果 cookie 不存在，则会自动生成</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>cookie 的名称</td></tr><tr><td>path</td><td>为 cookie 设置的路径</td></tr><tr><td>ttl</td><td>cookie 的生命周期</td></tr></tbody></table><h1 id="ConnectionPoolSettings-TCPSettings"><a href="#ConnectionPoolSettings-TCPSettings" class="headerlink" title="ConnectionPoolSettings.TCPSettings"></a><a name="ConnectionPoolSettings.TCPSettings">ConnectionPoolSettings.TCPSettings</a></h1><p>HTTP 和 TCP 上游连接通用的设置。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>maxConnections</td><td>到目标主机的最大 HTTP1 &#x2F;TCP 连接数。默认 2^32-1</td></tr><tr><td>connectTimeout</td><td>TCP 连接超时。格式：1h&#x2F;1m&#x2F;1s&#x2F;1ms。必须 &gt;&#x3D;1ms。默认为 10s</td></tr><tr><td><a href="#ConnectionPoolSettings.TCPSettings.TcpKeepalive">tcpKeepalive</a></td><td>如果设置，则在套接字上设置 SO_KEEPALIVE 以启用 TCP Keepalive</td></tr></tbody></table><h1 id="ConnectionPoolSettings-HTTPSettings"><a href="#ConnectionPoolSettings-HTTPSettings" class="headerlink" title="ConnectionPoolSettings.HTTPSettings"></a><a name="ConnectionPoolSettings.HTTPSettings">ConnectionPoolSettings.HTTPSettings</a></h1><p>适用于 HTTP1.1&#x2F;HTTP2&#x2F;GRPC 连接的设置。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>http1MaxPendingRequests</td><td>目标的最大挂起 HTTP 请求数。默认 2^32-1</td></tr><tr><td>http2MaxRequests</td><td>后端的最大请求数。默认 2^32-1</td></tr><tr><td>maxRequestsPerConnection</td><td>每个连接到后端的最大请求数。将此参数设置为 1 将禁用 alive。默认为 0，表示无限制，最大为 2^29</td></tr><tr><td>maxRetries</td><td>在给定时间可以对集群中的所有主机进行的最大重试次数。默认为 2^32-1</td></tr><tr><td>idleTimeout</td><td>上游连接池连接的空闲超时。空闲超时定义为没有 alive 请求的时间段。如果未设置，则默认为 1 小时。当达到空闲超时时，连接将被关闭。如果连接是 HTTP&#x2F;2 连接，则会在关闭连接之前发生耗尽序列。请注意，基于请求的超时意味着 HTTP&#x2F;2 PING 不会使连接保持活动状态。适用于 HTTP1.1 和 HTTP2 连接</td></tr><tr><td><a href="#ConnectionPoolSettings.HTTPSettings.H2UpgradePolicy">h2UpgradePolicy</a></td><td>指定是否应将关联目标的 http1.1 连接升级到 http2</td></tr><tr><td>useClientProtocol</td><td>如果设置为 true，则启动与后端的连接时将保留客户端协议。请注意，当设置为 true 时，h2UpgradePolicy 将无效，即客户端连接不会升级到 http2</td></tr></tbody></table><h1 id="ConnectionPoolSettings-TCPSettings-TcpKeepalive"><a href="#ConnectionPoolSettings-TCPSettings-TcpKeepalive" class="headerlink" title="ConnectionPoolSettings.TCPSettings.TcpKeepalive"></a><a name="ConnectionPoolSettings.TCPSettings.TcpKeepalive">ConnectionPoolSettings.TCPSettings.TcpKeepalive</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>probes</td><td>在确定连接已死之前，要发送且无响应的最大保活探测数。默认是使用操作系统级别的配置（除非被覆盖，Linux 默认为 9)</td></tr><tr><td>time</td><td>在开始发送 keep-alive 探测之前，连接需要空闲的持续时间。默认是使用操作系统级别的配置（除非被覆盖，Linux 默认为 7200s）</td></tr><tr><td>interval</td><td>保持活动探测之间的持续时间。默认是使用操作系统级别的配置（除非被覆盖，Linux 默认为 75s）</td></tr></tbody></table><h1 id="LocalityLoadBalancerSetting-Distribute"><a href="#LocalityLoadBalancerSetting-Distribute" class="headerlink" title="LocalityLoadBalancerSetting.Distribute"></a><a name="LocalityLoadBalancerSetting.Distribute">LocalityLoadBalancerSetting.Distribute</a></h1><p>描述源自 from 区域或子区域的流量如何分布在一组 to 区域上。指定区域的语法是 {region}&#x2F;{zone}&#x2F;{sub-zone} 并且规范的任何部分都允许使用终端通配符。例如：</p><ul><li>* 匹配所有的地区</li><li>us-west&#x2F;* 匹配 us-west 区域内的所有区域和子区域</li><li>us-west&#x2F;zone-1&#x2F;* 匹配 us-west&#x2F;zone-1 中的所有子区域</li></ul><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>from</td><td>源位置，用 &#x2F; 分隔，例如 region&#x2F;zone&#x2F;sub_zone</td></tr><tr><td>to</td><td>上游地区到流量分布权重的地图。所有权重的总和应为 100。任何不存在的位置都不会收到流量</td></tr></tbody></table><h1 id="LocalityLoadBalancerSetting-Failover"><a href="#LocalityLoadBalancerSetting-Failover" class="headerlink" title="LocalityLoadBalancerSetting.Failover"></a><a name="LocalityLoadBalancerSetting.Failover">LocalityLoadBalancerSetting.Failover</a></h1><p>指定跨区域的流量故障转移策略。由于默认情况下支持区域和子区域故障转移，因此仅当运营商需要限制流量故障转移时才需要为区域指定，以便全局故障转移到任何 endpoint 的默认行为不适用。这在跨区域故障转移流量不会改善服务健康或可能需要因监管控制等其他原因而受到限制时非常有用。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>from</td><td>源区域</td></tr><tr><td>to</td><td>当 from 区域中的 endpoint 变得不健康时，流量将故障转移到目标区域</td></tr></tbody></table><h1 id="LoadBalancerSettings-SimpleLB"><a href="#LoadBalancerSettings-SimpleLB" class="headerlink" title="LoadBalancerSettings.SimpleLB"></a><a name="SimpleLB">LoadBalancerSettings.SimpleLB</a></h1><p>无需调整的标准负载均衡算法。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>UNSPECIFIED</td><td>用户未指定负载均衡算法。 Istio 将选择适当的默认值</td></tr><tr><td>RANDOM</td><td>随机负载均衡器选择一个随机的健康主机。如果没有配置健康检查策略，随机负载均衡器的性能通常比轮询更好</td></tr><tr><td>PASSTHROUGH</td><td>此选项会将连接转发到调用者请求的原始 IP 地址，而不进行任何形式的负载平衡。慎重使用。它适用于高级用例。有关更多详细信息，参阅 Envoy 中的原始目标负载均衡器</td></tr><tr><td>ROUND_ROBIN</td><td>一个基本的循环负载均衡策略。这对于许多场景（例如，使用 endpoint 加权时）通常是不安全的，因为它可能会使 endpoint 负担过重。一般来说，倾向于使用 LEAST_REQUEST 替代 ROUND_ROBIN</td></tr><tr><td>LEAST_REQUEST</td><td>最少请求负载均衡器将负载分散到各个 endpoint，倾向于具有最少未完成请求的 endpoint。这通常更安全，并且几乎在所有情况下都优于 ROUND_ROBIN。倾向于使用 LEAST_REQUEST 替代 ROUND_ROBIN</td></tr><tr><td>LEAST_CONN</td><td>已弃用。改用 LEAST_REQUEST</td></tr></tbody></table><h1 id="ConnectionPoolSettings-HTTPSettings-H2UpgradePolicy"><a href="#ConnectionPoolSettings-HTTPSettings-H2UpgradePolicy" class="headerlink" title="ConnectionPoolSettings.HTTPSettings.H2UpgradePolicy"></a><a name="ConnectionPoolSettings.HTTPSettings.H2UpgradePolicy">ConnectionPoolSettings.HTTPSettings.H2UpgradePolicy</a></h1><p>将 http1.1 连接升级到 http2 的策略。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>DEFAULT</td><td>使用全局默认值</td></tr><tr><td>DO_NOT_UPGRADE</td><td>不将连接升级到 http2。会覆盖默认值</td></tr><tr><td>UPGRADE</td><td>将连接升级到 http2。会覆盖默认值</td></tr></tbody></table><h1 id="ClientTLSSettings-TLSmode"><a href="#ClientTLSSettings-TLSmode" class="headerlink" title="ClientTLSSettings.TLSmode"></a><a name="ClientTLSSettings.TLSmode">ClientTLSSettings.TLSmode</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>DISABLE</td><td>不设置到上游 endpoint 的 TLS 连接</td></tr><tr><td>SIMPLE</td><td>发起到上游 endpoint 的 TLS 连接</td></tr><tr><td>MUTUAL</td><td>通过提供客户端证书进行身份验证，使用双向 TLS 保护与上游的连接</td></tr><tr><td>ISTIO_MUTUAL</td><td>通过提供客户端证书进行身份验证，使用双向 TLS 保护与上游的连接。与 MUTUAL 模式相比，该模式使用 Istio 自动生成的证书进行 mTLS 身份验证。使用此模式时，ClientTLSSettings 中的所有其他字段都应为空</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 DestinationRule 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — VirtualService</title>
    <link href="http://shenxianghong.github.io/2022/08/05/2022-08-05%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Virtual%20Service/"/>
    <id>http://shenxianghong.github.io/2022/08/05/2022-08-05%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Virtual%20Service/</id>
    <published>2022-08-04T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.255Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>VirtualService 定义了一组流量路由规则，以在 host 被寻址时应用。每个路由规则都为特定协议的流量定义了匹配标准。如果流量匹配，则将其发送到注册表中定义的命名目标服务（或其子集&#x2F;版本）</p><p>流量来源也可以在路由规则中匹配。这允许为特定的客户端上下文定制路由。</p><p><strong>Service</strong></p><p>绑定到 service registry 中唯一名称的应用程序行为单元。Service 由多个 endpoints 组成，这些 endpoints 也就是运行在 Pod、容器、VM 等上的工作负载实例。</p><p><strong>Service versions（subsets）</strong></p><p>在持续部署场景中，一个服务可以有不同的实例子集的不同变体，这些变体不一定是不同的 API 版本，它们可能是对同一服务的迭代更改，部署在不同的环境（prod, staging, dev 等）中。常见场景包括 A&#x2F;B 测试、金丝雀发布等。不同版本的选择可以根据各种标准（headers, url 等）的权重来决定。每个服务都有一个由其所有实例组成的默认版本。</p><p><strong>Source</strong></p><p>调用服务的下游客户端。</p><p><strong>Host</strong></p><p>客户端尝试连接到服务时使用的地址。</p><p><strong>Access model</strong></p><p>应用程序仅处理目标服务（Host），而不知道各个服务版本（subsets）。版本的实际选择由代理或者 sidecar 决定，这样应用程序代码能够将自身与依赖服务的解耦。</p><p>例如，以下示例默认将所有 HTTP 流量路由到标签为 review：v1 的 review 服务的 Pod。此外，路径以 &#x2F;wpcatalog&#x2F; 或 &#x2F;consumercatalog&#x2F; 开头的 HTTP 请求将被重写为 &#x2F;newcatalog 并发送到标签为 version: v2 的 Pod。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;reviews-v2-routes&quot;</span></span><br><span class="line">    <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/wpcatalog&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/consumercatalog&quot;</span></span><br><span class="line">    <span class="attr">rewrite:</span></span><br><span class="line">      <span class="attr">uri:</span> <span class="string">&quot;/newcatalog&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;reviews-v1-route&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure><p>路由目的地的子集或者版本通过对必须在相应 DestinationRule 中声明的命名服务子集的引用来标识。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-destination</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br></pre></td></tr></table></figure><h1 id="VirtualService"><a href="#VirtualService" class="headerlink" title="VirtualService"></a>VirtualService</h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>hosts</td><td>向其发送流量的目标主机（只有访问客户端的 Host 字段为 hosts 配置的地址才能路由到后端服务）。可以是带有通配符前缀的 DNS 名称或 IP 地址。根据平台的不同，也可以使用短名称代替 FQDN（即名称中没有点）。在这种情况下，主机的 FQDN 将基于底层平台派生<br />单个 VirtualService 可用于描述相应 host 的所有流量属性，包括多个 HTTP 和 TCP 端口的流量属性。或者，可以使用多个 VirtualService 定义 host 的流量属性，但有一些注意事项，参阅<a href="https://istio.io/latest/docs/ops/best-practices/traffic-management/#split-virtual-services">操作指南</a><br />Kubernetes 用户注意事项：当使用短名称时（例如 reviews 而不是 reviews.default.svc.cluster.local），Istio 将根据规则的命名空间而不是服务来解析短名称。名为 reviews 的 host 在 default 命名空间中的规则将被解析为 reviews.default.svc.cluster.local，而与 reviews 服务关联的实际命名空间无关。为避免潜在的错误配置，建议始终使用完全限定域名而不是短名称<br />hosts 字段适用于 HTTP 和 TCP 服务。网格内的服务，即服务注册表中的服务，必须始终使用它们的字母数字名称来引用。 IP 地址仅允许用于通过 Gateway 定义的服务<br />注意：对于 delegate VirtualService 而言，必须为空。</td></tr><tr><td>gateways</td><td>应用这些路由规则的 Gateway 和 sidecar 的名称。 其他命名空间中的 Gateway 的引用方式为&lt;gateway namespace&gt;&#x2F;&lt;gateway name&gt;；指定没有显式的指定命名空间则与 VirtualService 的命名空间相同。单个 VirtualService 用于网格内的 sidecar 以及一个或多个 Gateway。可以使用协议特定路由的匹配条件中的源字段覆盖该字段强加的选择条件。保留字 mesh 用于表述网格中的所有 sidecar。当省略该字段时，将使用默认 Gateway 即 mesh，这会将规则应用于网格中的所有 sidecar。如果提供了 Gateway 名称列表，则规则将仅适用该相关的 Gateway。要将规则应用于 Gateway 和 sidecar，请将 mesh 指定为 gateways 之一</td></tr><tr><td><a href="#HTTPRoute">http</a></td><td>HTTP 流量的路由规则的有序列表。 使用匹配传入请求的第一个规则</td></tr><tr><td><a href="#TLSRoute">tls</a></td><td>An ordered list of route rule for non-terminated TLS &amp; HTTPS traffic. Routing is typically performed using the SNI value presented by the ClientHello message. TLS routes will be applied to platform service ports named ‘https-*’, ‘tls-*’, unterminated gateway ports using HTTPS&#x2F;TLS protocols (i.e. with “passthrough” TLS mode) and service entry ports using HTTPS&#x2F;TLS protocols. The first rule matching an incoming request is used. NOTE: Traffic ‘https-*’ or ‘tls-*’ ports without associated virtual service will be treated as opaque TCP traffic.</td></tr><tr><td><a href="#TCPRoute">tcp</a></td><td>不透明 TCP 流量的路由规则的有序列表。 TCP 路由将应用于不是 HTTP 或 TLS 端口的任何端口。使用匹配传入请求的第一个规则</td></tr><tr><td>exportTo</td><td>此 VirtualService 暴露到的命名空间列表。暴露 VirtualService 允许它被其他命名空间中定义的 sidecar 和 Gateway 使用。此功能为服务所有者和网格管理员提供了一种机制来控制跨命名空间边界的 VirtualService 的可见性<br />如果未指定命名空间，则默认情况下将 VirtualService 暴露到所有命名空间<br /> . 为保留标识代表暴露到 VirtualService 的同一命名空间中。类似地，* 代表暴露到所有命名空间</td></tr></tbody></table><h1 id="Destination"><a href="#Destination" class="headerlink" title="Destination"></a>Destination</h1><p>Destination 表示在处理路由规则后将请求（连接）发送到的网络可寻址服务。 destination.host 应该明确引用服务注册表中的服务。 Istio 的服务注册表由平台服务注册表中的所有服务（例如 Kubernetes 服务、Consul 服务）以及通过 ServiceEntry 资源声明的服务组成。</p><p>以下示例中默认将所有流量路由到带有标签 version：v1（即 subset v1）的 review 服务的 Pod，并将符合条件的路由到 subset v2。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">foo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span> <span class="comment"># interpreted as reviews.foo.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/wpcatalog&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/consumercatalog&quot;</span></span><br><span class="line">    <span class="attr">rewrite:</span></span><br><span class="line">      <span class="attr">uri:</span> <span class="string">&quot;/newcatalog&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span> <span class="comment"># interpreted as reviews.foo.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span> <span class="comment"># interpreted as reviews.foo.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure><p>以下 VirtualService 为 productpage.prod.svc.cluster.local 服务的设置了 5s 的超时时间。此规则中没有定义子集，Istio 将从服务注册表中获取 productpage.prod.svc.cluster.local 服务的所有实例，并填充 sidecar 的负载均衡池。另外，此规则设置在 istio-system 命名空间中，但使用的是 productpage 服务的完全限定域名 productpage.prod.svc.cluster.local。因此，规则的命名空间对解析 productpage 服务的名称没有影响。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-productpage-rule</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">istio-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">productpage.prod.svc.cluster.local</span> <span class="comment"># ignores rule namespace</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">timeout:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">productpage.prod.svc.cluster.local</span></span><br></pre></td></tr></table></figure><p>为了路由到网格外服务的流量，必须首先使用 ServiceEntry 资源将外部服务添加到 Istio 的内部服务注册表中。然后可以定义 VirtualServices 来控制绑定到这些外部服务的流量。例如，以下规则为 wikipedia.org 定义了一个 Service，并为 HTTP 请求设置了 5s 的超时时间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-wikipedia</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">wikipedia.org</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">example-http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-wiki-rule</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">wikipedia.org</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">timeout:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">wikipedia.org</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>host</td><td>服务注册表中的服务名称。服务名称从平台的服务注册表（例如，Kubernetes 服务、Consul 服务等）和 ServiceEntry 声明的 host 中查找。两者都找不到的流量将被丢弃。<br /><em>同样的，推荐使用完全限定域名</em></td></tr><tr><td>subset</td><td>服务中子集的名称。仅适用于网格内的服务。子集必须在相应的 DestinationRule 中定义</td></tr><tr><td><a href="#PortSelector">port</a></td><td>指定寻址目标主机上的端口。如果服务只公开一个端口，则不需要显式选择端口</td></tr></tbody></table><h1 id="HTTPRoute"><a href="#HTTPRoute" class="headerlink" title="HTTPRoute"></a><a name="HTTPRoute">HTTPRoute</a></h1><p>描述路由 HTTP&#x2F;1.1、HTTP2 和 gRPC 流量的匹配条件和行为。有关使用示例，请参阅 VirtualService。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>分配给路由的名称，用作调试。该名称将与匹配的路由结果一起记录在访问日志</td></tr><tr><td><a href="#HTTPMatchRequest">match</a></td><td>应用规则需要满足的匹配条件。单个匹配块内的所有条件都具有 AND 语义，而匹配块列表具有 OR 语义。如果任何一个匹配块匹配成功，则应用该规则</td></tr><tr><td><a href="#HTTPRouteDestination">route</a></td><td>HTTP 规则可以重定向或转发（默认）流量。转发目标可以是服务的多个版本之一（subset）。与服务版本相关的权重决定了它接收的流量比例</td></tr><tr><td><a href="#HTTPRedirect">redirect</a></td><td>HTTP 规则可以重定向或转发（默认）流量。如果在规则中指定了流量直通选项，则重定向将被忽略。重定向可用于将 HTTP 301 重定向发送到不同的 URI</td></tr><tr><td><a href="#Delegate">delegate</a></td><td>委托是指定可用于定义委托 HTTPRoute 的特定 VirtualService。只有Route和Redirect都为空时才可以设置，并且delegate VirtualService的路由规则会与当前的路由规则合并。<br /><em>注意：仅支持一级委派，delegate 的 HTTPMatchRequest 必须是 root 的严格子集，否则会发生冲突，HTTPRoute 不会生效</em></td></tr><tr><td><a href="#HTTPRewrite">rewrite</a></td><td>重写 HTTP URI 和 Authority header。 Rewrite 不能与 Redirect 原语一起使用。转发前会进行重写</td></tr><tr><td>timeout</td><td>HTTP 请求超时，默认禁用</td></tr><tr><td><a href="#HTTPRetry">retries</a></td><td>HTTP 请求的重试策略</td></tr><tr><td><a href="#HTTPFaultInjection">fault</a></td><td>故障注入策略应用于客户端的 HTTP 流量。<br /><em>注意，在客户端启用故障时，将不会启用超时或重试</em></td></tr><tr><td><a href="#Destination">mirror</a></td><td>除了将请求转发到预期目标之外，还将 HTTP 流量镜像到另一个目标。镜像流量是在尽力而为的基础上，sidercar &#x2F; gateway 在从原始目的地返回响应之前不会等待镜像集群响应。会为镜像目的地生成统计信息。</td></tr><tr><td><a href="#Percent">mirrorPercentage</a></td><td>要镜像的流量百分比。默认为所有的流量（100%）都会被镜像。最大值为 100%。</td></tr><tr><td><a href="#CorsPolicy">corsPolicy</a></td><td>跨域资源共享策略 (CORS)。有关跨源资源共享的更多详细信息，参阅 <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS</a></td></tr><tr><td><a href="#Headers">headers</a></td><td>Header 操作规则</td></tr></tbody></table><h1 id="Delegate"><a href="#Delegate" class="headerlink" title="Delegate"></a><a name="Delegate">Delegate</a></h1><p>在 Istio 1.5 中，VirtualService 资源之间是无法进行转发的，在 Istio 1.6 版本中规划了 VirtualService Chain 机制，也就是说，我们可以通过 delegate 配置项将一个 VirtualService 代理到另外一个 VirtualService 中进行规则匹配。</p><p>例如，路由规则通过名为 productpage 的委托 VirtualService 将流量转发到 &#x2F;productpage，通过名为 reviews 的委托 VirtualService 将流量转发到 &#x2F;reviews。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;bookinfo.com&quot;</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mygateway</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/productpage&quot;</span></span><br><span class="line">    <span class="attr">delegate:</span></span><br><span class="line">       <span class="attr">name:</span> <span class="string">productpage</span></span><br><span class="line">       <span class="attr">namespace:</span> <span class="string">nsA</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/reviews&quot;</span></span><br><span class="line">    <span class="attr">delegate:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">nsB</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">productpage</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">nsA</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/productpage/v1/&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">productpage-v1.nsA.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">productpage.nsA.svc.cluster.local</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">nsB</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.nsB.svc.cluster.local</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>委托 VirtualService 的名称</td></tr><tr><td>namespace</td><td>委托 VirtualService 所在的命名空间。默认情况下，它与根的相同</td></tr></tbody></table><h1 id="Headers"><a href="#Headers" class="headerlink" title="Headers"></a><a name="Headers">Headers</a></h1><p>当 Envoy 将请求转发到目标服务或从目标服务转发响应时，可以操作 header 信息。可以为特定路由目的地或所有目的地指定 header 操作规则。以下 VirtualService 将值为 test: true 的请求头添加到路由到任何 reviews 服务目标的请求中。同时，删除了仅来自 reviews 服务的 v1 版本的响应头中的 foo。 </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">      <span class="attr">request:</span></span><br><span class="line">        <span class="attr">set:</span></span><br><span class="line">          <span class="attr">test:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">25</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">      <span class="attr">headers:</span></span><br><span class="line">        <span class="attr">response:</span></span><br><span class="line">          <span class="attr">remove:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">foo</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">75</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#HeaderOperations">request</a></td><td>在将请求转发到目标服务之前应用的标头操作规则</td></tr><tr><td><a href="#HeaderOperations">response</a></td><td>在向调用者返回响应之前应用的标头操作规则</td></tr></tbody></table><h1 id="TLSRoute"><a href="#TLSRoute" class="headerlink" title="TLSRoute"></a><a name="TLSRoute">TLSRoute</a></h1><p>描述路由未终止的 TLS 流量 (TLS&#x2F;HTTPS) 的匹配条件和操作。</p><p>以下路由规则根据 SNI 值将到达名为 mygateway 的 Gateway 的端口 443 的未终止 TLS 流量转发到网格中的内部服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-sni</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;*.bookinfo.com&quot;</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mygateway</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">sniHosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">login.bookinfo.com</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">login.prod.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">sniHosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">reviews.bookinfo.com</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#TLSMatchAttributes%5B%5D">match</a></td><td>应用规则需要满足的匹配条件。单个匹配块内的所有条件都具有 AND 语义，而匹配块列表具有 OR 语义。如果任何一个匹配块匹配成功，则应用该规则</td></tr><tr><td><a href="#RouteDestination">route</a></td><td>连接应转发到的目的地</td></tr></tbody></table><h1 id="TCPRoute"><a href="#TCPRoute" class="headerlink" title="TCPRoute"></a><a name="TCPRoute">TCPRoute</a></h1><p>描述路由 TCP 流量的匹配条件和操作。</p><p>以下路由规则将到达端口 27017 的 mongo.prod.svc.cluster.local 的流量转发到端口 5555 上的另一个 Mongo 服务器。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-mongo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mongo.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">tcp:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">27017</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">mongo.backup.svc.cluster.local</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">5555</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#L4MatchAttributes%5B%5D">match</a></td><td>应用规则需要满足的匹配条件。单个匹配块内的所有条件都具有 AND 语义，而匹配块列表具有 OR 语义。如果任何一个匹配块匹配成功，则应用该规则</td></tr><tr><td><a href="#RouteDestination%5B%5D">route</a></td><td>连接应转发到的目的地</td></tr></tbody></table><h1 id="HTTPMatchRequest"><a href="#HTTPMatchRequest" class="headerlink" title="HTTPMatchRequest"></a><a name="HTTPMatchRequest">HTTPMatchRequest</a></h1><p>HttpMatchRequest 指定要满足的一组标准，以便将规则应用于 HTTP 请求。</p><p>例如，以下内容将规则限制为仅匹配 URL 路径以 &#x2F;ratings&#x2F;v2&#x2F; 开头的请求，并且请求包含具有值 jason 的自定义最终用户标头。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">        <span class="attr">end-user:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">jason</span></span><br><span class="line">      <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">&quot;/ratings/v2/&quot;</span></span><br><span class="line">      <span class="attr">ignoreUriCase:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br></pre></td></tr></table></figure><p>HTTPMatchRequest 不能为空。注意：指定委托 VirtualService 时，不能设置正则表达式字符串匹配。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>name</td><td>分配给匹配项的名称。匹配的名称将与父路由的名称一同记录在与该路由匹配的请求的访问日志中</td></tr><tr><td><a href="#StringMatch">uri</a></td><td>区分大小写，格式包括 exact（精准匹配）、prefix（前缀匹配）和 regex（正则）<br /><em>注意：可以通过 ignore_uri_case 标志启用不区分大小写的匹配</em></td></tr><tr><td><a href="#StringMatch">scheme</a></td><td>区分大小写，格式包括 exact（精准匹配）、prefix（前缀匹配）和 regex（正则）</td></tr><tr><td><a href="#StringMatch">method</a></td><td>区分大小写，格式包括 exact（精准匹配）、prefix（前缀匹配）和 regex（正则）</td></tr><tr><td><a href="#StringMatch">authority</a></td><td>区分大小写，格式包括 exact（精准匹配）、prefix（前缀匹配）和 regex（正则）</td></tr><tr><td><a href="#StringMatch">headers</a></td><td>header 的 key 必须为小写并使用连字符作为分隔符，例如 x-request-id。区分大小写，格式包括 exact（精准匹配）、prefix（前缀匹配）和 regex（正则）。如果该值为空并且仅指定了 header 的名称，则检查标头的存在<br /><em>注意：键 uri、scheme、method 和 authority 将被忽略</em></td></tr><tr><td>port</td><td>指定正在寻址的 host 上的端口。许多服务只公开单个端口或使用它们支持的协议标记端口，在这些情况下，不需要显式选择端口</td></tr><tr><td>sourceLabels</td><td>一个或多个标签，用于限制规则对具有给定标签的源（客户端）工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr><tr><td>gateways</td><td>待应用规则的网关的名称。 VirtualService 的顶级 gateways 字段中的网关名称（如果有）被覆盖。Gateway 匹配独立于 sourceLabels</td></tr><tr><td><a href="#StringMatch">queryParams</a></td><td>用于匹配的查询参数，例如 exact: “true”，extact: “” 和 regex: “\d+$”<br /><em>注意：目前不支持前缀匹配</em></td></tr><tr><td>ignoreUriCase</td><td>用于指定 URI 匹配是否不区分大小写的标志。<br /><em>注意：只有在完全和前缀 URI 匹配的情况下才会忽略大小写</em></td></tr><tr><td><a href="#StringMatch">withoutHeaders</a></td><td>withoutHeaders 与 header 的语法相同，但含义相反。如果 header 与 withoutHeaders 中的匹配规则匹配，则流量变为不匹配</td></tr><tr><td>sourceNamespace</td><td>源命名空间限制规则对该命名空间中工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr></tbody></table><h1 id="HTTPRouteDestination"><a href="#HTTPRouteDestination" class="headerlink" title="HTTPRouteDestination"></a><a name="HTTPRouteDestination">HTTPRouteDestination</a></h1><p>每个路由规则都与一个或多个服务版本相关联。与版本相关的权重决定了它接收的流量比例。</p><p>例如，以下规则会将 reviews 服务的 25% 流量路由到 v2 版本的实例中，而剩余流量（即 75%）将路由到 v1 版本。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">25</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">75</span></span><br></pre></td></tr></table></figure><p>流量也可以分成两个完全不同的服务，而无需定义新的子集（也就是内部分流）。</p><p>例如，以下规则将 25% 的流量从 reviews.com 转发到 dev.reviews.com。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route-two-domains</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.com</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">dev.reviews.com</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">25</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.com</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">75</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#Destination">destination</a></td><td>请求&#x2F;连接应转发到的服务实例</td></tr><tr><td>weight</td><td>要转发到目的地的流量的相对比例（即权重&#x2F;所有权重的总和）。如果规则中只有一个目的地，它将接收所有流量。如果权重为 0，则目的地将不会收到任何流量</td></tr><tr><td><a href="#Headers">headers</a></td><td>header 操作规则</td></tr></tbody></table><h1 id="RouteDestination"><a href="#RouteDestination" class="headerlink" title="RouteDestination"></a><a name="RouteDestination">RouteDestination</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#Destination">destination</a></td><td>请求&#x2F;连接应转发到的服务实例</td></tr><tr><td>weight</td><td>要转发到目的地的流量的相对比例（即权重&#x2F;所有权重的总和）。如果规则中只有一个目的地，它将接收所有流量。如果权重为 0，则目的地将不会收到任何流量</td></tr></tbody></table><h1 id="L4MatchAttributes"><a href="#L4MatchAttributes" class="headerlink" title="L4MatchAttributes"></a><a name="L4MatchAttributes">L4MatchAttributes</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>destinationSubnets</td><td>带有可选子网的目标 IPv4 或 IPv6 IP 地址。例如，a.b.c.d&#x2F;xx  或只是 a.b.c.d</td></tr><tr><td>port</td><td>指定正在寻址的 host 上的端口。许多服务只公开单个端口或使用它们支持的协议标记端口，在这些情况下，不需要显式选择端口</td></tr><tr><td>sourceLabels</td><td>一个或多个标签，用于限制规则对具有给定标签的源（客户端）工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr><tr><td>gateways</td><td>待应用规则的网关的名称。 VirtualService 的顶级 gateways 字段中的网关名称（如果有）被覆盖。Gateway 匹配独立于 sourceLabels</td></tr><tr><td>sourceNamespace</td><td>源命名空间限制规则对该命名空间中工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr></tbody></table><h1 id="TLSMatchAttributes"><a href="#TLSMatchAttributes" class="headerlink" title="TLSMatchAttributes"></a><a name="TLSMatchAttributes">TLSMatchAttributes</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>sniHosts</td><td>要匹配的 SNI（server name indicator）。通配符前缀可用于 SNI 值，例如，*.com 将匹配 foo.example.com 以及 example.com。 SNI 值必须是相应虚拟服务主机的子集（即属于域内）</td></tr><tr><td>destinationSubnets</td><td>带有可选子网的目标 IPv4 或 IPv6 IP 地址。例如，a.b.c.d&#x2F;xx  或只是 a.b.c.d</td></tr><tr><td>port</td><td>指定正在寻址的 host 上的端口。许多服务只公开单个端口或使用它们支持的协议标记端口，在这些情况下，不需要显式选择端口</td></tr><tr><td>sourceLabels</td><td>一个或多个标签，用于限制规则对具有给定标签的源（客户端）工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr><tr><td>gateways</td><td>待应用规则的网关的名称。 VirtualService 的顶级 gateways 字段中的网关名称（如果有）被覆盖。Gateway 匹配独立于 sourceLabels</td></tr><tr><td>sourceNamespace</td><td>源命名空间限制规则对该命名空间中工作负载的适用性。如果 VirtualService 在顶级 gateways 字段中指定了网关列表，仅当列表中包含保留的 gateway — mesh 时，该字段才生效</td></tr></tbody></table><h1 id="HTTPRedirect"><a href="#HTTPRedirect" class="headerlink" title="HTTPRedirect"></a><a name="HTTPRedirect">HTTPRedirect</a></h1><p>HTTPRedirect 可用于向调用者发送 301 重定向响应。例如，以下规则将 review 服务上的 &#x2F;v1&#x2F;getProductRatings API 请求重定向到 bookratings 服务提供的 &#x2F;v1&#x2F;bookRatings。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">/v1/getProductRatings</span></span><br><span class="line">    <span class="attr">redirect:</span></span><br><span class="line">      <span class="attr">uri:</span> <span class="string">/v1/bookRatings</span></span><br><span class="line">      <span class="attr">authority:</span> <span class="string">newratings.default.svc.cluster.local</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>uri</td><td>在重定向时，使用此值覆盖 URL 的 path 部分。<br /><em>无论请求 URI 是否匹配为确切路径或前缀，都将替换整个路径</em></td></tr><tr><td>authority</td><td>在重定向时，使用此值覆盖 URL 的 Authority&#x2F;Host 部分</td></tr><tr><td>port</td><td>在重定向时，使用此值覆盖 URL 的 Port 部分</td></tr><tr><td><a href="#HTTPRedirect.RedirectPortSelection">derivePort</a></td><td>在重定向时，动态设置端口</td></tr><tr><td>scheme</td><td>在重定向时，使用此值覆盖 URL 的 Scheme 部分。例如，http 或 https。如果未设置，将使用原 Scheme。如果 derivePort 设置为 FROM_PROTOCOL_DEFAULT，这也会影响该端口</td></tr><tr><td>redirectCode</td><td>在重定向时，指定要在重定向响应中使用的 HTTP 状态代码。默认响应代码为 MOVED_PERMANENTLY (301)</td></tr></tbody></table><h1 id="HTTPRewrite"><a href="#HTTPRewrite" class="headerlink" title="HTTPRewrite"></a><a name="HTTPRewrite">HTTPRewrite</a></h1><p>HTTPRewrite 可用于在将请求转发到目标之前重写 HTTP 请求的特定部分。HTTPRewrite 只能与 HTTPRouteDestination 一起使用。</p><p>以下示例演示如何在实际调用之前将 &#x2F;ratings 前缀重写为 rating 服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/ratings</span></span><br><span class="line">    <span class="attr">rewrite:</span></span><br><span class="line">      <span class="attr">uri:</span> <span class="string">/v1/bookRatings</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>uri</td><td>用这个值重写 URI 的 Path 或 Prefix 部分。如果原始 URI 是根据前缀匹配的，则此字段中提供的值将替换相应匹配的前缀</td></tr><tr><td>authority</td><td>用这个值重写  Authority&#x2F;Host header</td></tr></tbody></table><h1 id="StringMatch"><a href="#StringMatch" class="headerlink" title="StringMatch"></a><a name="StringMatch">StringMatch</a></h1><p>匹配 HTTP header 中的特定字符串的策略。匹配区分大小写。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>exact</td><td>精准匹配</td></tr><tr><td>prefix</td><td>前缀匹配</td></tr><tr><td>regex</td><td>正则匹配 （参阅：<a href="https://github.com/google/re2/wiki/Syntax%EF%BC%89">https://github.com/google/re2/wiki/Syntax）</a></td></tr></tbody></table><h1 id="HTTPRetry"><a href="#HTTPRetry" class="headerlink" title="HTTPRetry"></a><a name="HTTPRetry">HTTPRetry</a></h1><p>HTTP 请求失败时的重试策略。</p><p>例如，以下规则将调用 rating 服务 v1 版本时的最大重试次数设置为 3，每次重试超时为 2 秒。如果出现 gateway-error，connect-failure 和 refused-stream 的错误将重试。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">retries:</span></span><br><span class="line">      <span class="attr">attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">perTryTimeout:</span> <span class="string">2s</span></span><br><span class="line">      <span class="attr">retryOn:</span> <span class="string">gateway-error,connect-failure,refused-stream</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>attempts</td><td>请求允许的重试次数。重试间隔将自动确定（25ms+）。当配置了 HTTP 路由的请求超时或 perTryTimeout 时，实际尝试的重试次数还取决于指定的请求超时和 perTryTimeout 值</td></tr><tr><td>perTryTimeout</td><td>给定请求的每次尝试超时，包括初始调用和任何重试。格式：1h&#x2F;1m&#x2F;1s&#x2F;1ms。必须 &gt;&#x3D;1 ms。默认值与 HTTP 路由的请求超时相同，即没有超时</td></tr><tr><td>retryOn</td><td>指定重试发生的条件。可以使用 , 分隔列表指定一个或多个策略。如果 retryOn 指定了一个有效的 HTTP 状态，它将被添加到 retriable_status_codes 重试策略中。<br /><em>有关更多详细信息，参阅<a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#x-envoy-retry-on">重试策略</a>和 <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#x-envoy-retry-grpc-on">gRPC 重试策略</a></em></td></tr><tr><td>retryRemoteLocalities</td><td>是否应重试到其他位置。<br /><em>有关更多详细信息，参阅<a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/http_connection_management#retry-plugin-configuration">重试插件配置</a></em></td></tr></tbody></table><h1 id="CorsPolicy"><a href="#CorsPolicy" class="headerlink" title="CorsPolicy"></a><a name="CorsPolicy">CorsPolicy</a></h1><p>描述给定服务的跨域资源共享（CORS）策略。有关跨源资源共享的更多详细信息，参阅 <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">CORS</a>。</p><p>例如，以下规则使用 HTTP POST&#x2F;GET 将跨源请求限制为来自 example.com 域的请求，并将 Access-Control-Allow-Credentials header 设置为 false。此外，它只暴露 X-Foo-bar header 并设置 1 天的有效期。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">corsPolicy:</span></span><br><span class="line">      <span class="attr">allowOrigins:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">exact:</span> <span class="string">https://example.com</span></span><br><span class="line">      <span class="attr">allowMethods:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">POST</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">GET</span></span><br><span class="line">      <span class="attr">allowCredentials:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">allowHeaders:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">X-Foo-Bar</span></span><br><span class="line">      <span class="attr">maxAge:</span> <span class="string">&quot;24h&quot;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#StringMatch">allowOrigins</a></td><td>匹配允许的来源的字符串模式。如果任何字符串匹配器匹配，则允许来源。如果找到匹配项，则传出的 Access-Control-Allow-Origin 将设置为客户端提供的源</td></tr><tr><td>allowMethods</td><td>允许访问资源的 HTTP 方法列表。内容将被序列化到 Access-Control-Allow-Methods header 中</td></tr><tr><td>allowHeaders</td><td>请求资源时可以使用的 HTTP header 列表。序列化为 Access-Control-Allow-Headers header</td></tr><tr><td>exposeHeaders</td><td>允许浏览器访问的 HTTP header 列表。序列化为 Access-Control-Expose-Headers header</td></tr><tr><td>maxAge</td><td>指定预检请求的结果可以缓存多长时间。转换为 Access-Control-Max-Age header</td></tr><tr><td>allowCredentials</td><td>是否允许调用者使用凭据发送实际请求（而不是预检）。转换为 Access-Control-Allow-Credentials header</td></tr></tbody></table><h1 id="HTTPFaultInjection"><a href="#HTTPFaultInjection" class="headerlink" title="HTTPFaultInjection"></a><a name="HTTPFaultInjection">HTTPFaultInjection</a></h1><p>HTTPFaultInjection 可用于在将 HTTP 请求转发到路由中注入故障。故障规范是 VirtualService 规则的一部分。错误包括从下游服务中止 HTTP 请求、延迟请求代理等。故障规则中至少有 delay 或者 abort。<br /><em>注意：delay 和 abort 故障相互独立，即使两者同时指定。</em></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#HTTPFaultInjection.Delay">delay</a></td><td>在转发之前延迟请求，模拟网络问题、上游服务过载等各种故障</td></tr><tr><td><a href="#HTTPFaultInjection.Abort">abort</a></td><td>中止 HTTP 请求尝试并将错误代码返回给下游服务，模拟上游服务故障</td></tr></tbody></table><h1 id="PortSelector"><a href="#PortSelector" class="headerlink" title="PortSelector"></a><a name="PortSelector">PortSelector</a></h1><p>PortSelector 指定用于匹配或选择最终路由的端口号。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>number</td><td>有效的端口号</td></tr></tbody></table><h1 id="Percent"><a href="#Percent" class="headerlink" title="Percent"></a><a name="Percent">Percent</a></h1><p>百分比范围 0 ~ 100。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>value</td><td>百分比范围</td></tr></tbody></table><h1 id="Headers-HeaderOperations"><a href="#Headers-HeaderOperations" class="headerlink" title="Headers.HeaderOperations"></a><a name="Headers.HeaderOperations">Headers.HeaderOperations</a></h1><p>header 操作方式。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>set</td><td>用给定的值覆盖原 header 中的 Key</td></tr><tr><td>add</td><td>讲给定的值追加到 header 中的 Key 中</td></tr><tr><td>remove</td><td>移除指定的 header</td></tr></tbody></table><h1 id="HTTPFaultInjection-Delay"><a href="#HTTPFaultInjection-Delay" class="headerlink" title="HTTPFaultInjection.Delay"></a><a name="HTTPFaultInjection.Delay">HTTPFaultInjection.Delay</a></h1><p>延迟类故障注入。</p><p>例如，在所有标签为 env: prod 的 Pod 中对 reviews 服务的 v1 版本的发起的每 1000 个请求中引入 1 个延迟 5 秒的故障。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">sourceLabels:</span></span><br><span class="line">        <span class="attr">env:</span> <span class="string">prod</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">fault:</span></span><br><span class="line">      <span class="attr">delay:</span></span><br><span class="line">        <span class="attr">percentage:</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">0.1</span></span><br><span class="line">        <span class="attr">fixedDelay:</span> <span class="string">5s</span></span><br></pre></td></tr></table></figure><p>fixedDelay 字段用于指示延迟量（以秒为单位）。可选的百分比字段可用于仅延迟一定百分比的请求。如果未指定，所有请求都将被延迟。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>fixedDelay</td><td>在转发请求之前添加一个固定的延迟。格式：1h&#x2F;1m&#x2F;1s&#x2F;1ms。必须 &gt;&#x3D; 1 ms</td></tr><tr><td>percentage</td><td>注入延迟的请求的百分比</td></tr><tr><td>percent</td><td>注入延迟的请求的百分比（0-100）。不推荐使用整数百分比值。请改用 percentage 字段</td></tr></tbody></table><h1 id="HTTPFaultInjection-Abort"><a href="#HTTPFaultInjection-Abort" class="headerlink" title="HTTPFaultInjection.Abort"></a><a name="HTTPFaultInjection.Abort">HTTPFaultInjection.Abort</a></h1><p>中止类故障注入。</p><p>例如，为 ratings 服务 v1 版本的每 1000 个请求中的 1 个返回 HTTP 400 错误代码。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">fault:</span></span><br><span class="line">      <span class="attr">abort:</span></span><br><span class="line">        <span class="attr">percentage:</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">0.1</span></span><br><span class="line">        <span class="attr">httpStatus:</span> <span class="number">400</span></span><br></pre></td></tr></table></figure><p>httpStatus 字段表示返回给调用者的 HTTP 状态码。可选的百分比字段只能用于中止一定百分比的请求。如果未指定，则中止所有请求。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>httpStatus</td><td>用于中止 HTTP 请求的 HTTP 状态码</td></tr><tr><td><a href="#Percent">percentage</a></td><td>中止请求的百分比</td></tr></tbody></table><h1 id="HTTPRedirect-RedirectPortSelection"><a href="#HTTPRedirect-RedirectPortSelection" class="headerlink" title="HTTPRedirect.RedirectPortSelection"></a><a name="HTTPRedirect.RedirectPortSelection">HTTPRedirect.RedirectPortSelection</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>FROM_PROTOCOL_DEFAULT</td><td>对于 HTTP 自动设置为 80，对于 HTTPS 自动设置为 443</td></tr><tr><td>FROM_REQUEST_PORT</td><td>自动使用请求的端口</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 VirtualService 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」Block Volume 直通</title>
    <link href="http://shenxianghong.github.io/2022/08/01/2022-08-01%20Kata%20Containers%20Block%20Volume%20%E7%9B%B4%E9%80%9A/"/>
    <id>http://shenxianghong.github.io/2022/08/01/2022-08-01%20Kata%20Containers%20Block%20Volume%20%E7%9B%B4%E9%80%9A/</id>
    <published>2022-07-31T16:00:00.000Z</published>
    <updated>2023-07-10T09:47:25.802Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>2.4.3</strong></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Kubernetes 设计之初对基于 VM 的容器运行时考虑较少，很多场景都默认容器运行时能直接访问宿主机资源，这也使得 Kata Containers 在和 Kubernetes 集成时对某些 Kubernetes 特性的支持存在一些不足或限制，尤其是在存储方面。</p><p>Kubernetes 提供了 PV （persistent volume）资源来管理存储卷，制定了 CSI （Container Storage Interface）规范在存储提供者和容器运行时之间来管理存储设备。通常来说，CSI 会将不同类型的存储设备，比如云盘、本地存储、网络文件系统等，以文件系统的方式挂载到宿主机，然后再从宿主机将此文件系统挂载到容器中。在 Kata Containers 中，这个挂载是通过 virtiofs 协议，在宿主机和 guest OS 中实现了该存储卷的文件共享。虽然 virtiofs 在性能上比之前的 9p 有很大提升，但是和直接在宿主机上使用相比，性能损耗成为在生产环境中使用 Kata Containers 的阻碍因素之一。</p><p>其次，使用 Kata Containers 在线调整 PV 的大小是很困难的。虽然 PV 可以在 host 上扩展，但更新后的元数据需要传递到 guest OS 中，以便应用程序容器使用扩展的卷。目前，没有办法在不重新启动 Pod sandbox 的情况下将 PV 元数据从 host OS 传递到 guest OS。</p><p>一个理想的长期解决方案是 Kubelet 协调 CSI Driver 和 Container Runtime 之间的通信，如 <a href="https://github.com/kubernetes/enhancements/pull/2893/files">KEP-2857</a> 讨论，但是目前而言，KEP 仍在审查中，并且提议的解决方案有两个弊端：</p><ul><li>将 csiPlugin.json 文件写入卷的根路径会带来安全隐患。恶意用户可以将自己的 csiPlugin.json 写入上述位置，从而获得对块设备的未经授权的访问</li><li>提案中并没有描述如何在卷和 Kata Containers 中如何建立映射关系，然而这是 CSI 调整卷大小和信息所需的必备 API</li></ul><p>对此 Kata Containers 社区提出一个短期&#x2F;中期的解决方案 — Block Volume 直通。</p><p><strong>当前 CSI 挂载方式</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/CurrentMounts.png"></div><p><strong>CSI 与 Runtime 协调挂载</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/RuntimeAssistedMounts.png"></div><h1 id="现阶段缺陷"><a href="#现阶段缺陷" class="headerlink" title="现阶段缺陷"></a>现阶段缺陷</h1><ul><li>一个块设备卷一次只能由一个节点上的一个 Pod 使用，其实这是 Kata Containers 用例中最常见的模式。将同一个块设备连接到多个 Kata Pod 也是不安全的。在 Kubernetes 中，需要将 PersistentVolumeClaim (PVC) 的 accessMode 设置为 ReadWriteOncePod</li><li>不支持更高级的 Kubernetes 卷功能，例如 fsGroup、fsGroupChangePolicy 和 subPath</li></ul><h1 id="实现方案"><a href="#实现方案" class="headerlink" title="实现方案"></a>实现方案</h1><p>传统 CSI 都会将存储设备挂载到宿主机上，在 Kata Containers 中，由于 VM 的存在，挂载操作需要移动到 guest 中，由 Kata agent 来完成存储卷的挂载。如下所示：</p><p><strong>原挂载方案</strong></p><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/kata-mount-current.png"></div><p><strong>直通挂载方案</strong></p><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/kata-mount-direct.png"></div><p>因此，需要 CSI 具备直通卷的挂载能力，Kata Containers 社区提供了一些参考方案</p><ul><li>StorageClass 参数中指定直通卷的相关标识，这样可以免去 CSI 查询 PVC 或者 Pod 的信息，但是基于该 StorageClass 供应的 PV 均会视为直通卷</li><li>PVC annotation 中注明，需要 CSI Plugin 支持 –extra-create-metadata </li><li>RuntimeClass 中注明，CSI Driver 在 node publish 阶段通过 Runtime 来获得 Volume 是否需要直接挂载到 guest 中，参考<a href="https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/pkg/disk/nodeserver.go#L248">阿里云实现</a></li></ul><p>当 CSI Driver 并不会直接将直通卷挂载给 Kata Containers 使用，而是需要在 CSI 的不同阶段调用 Kata Containers 在 2.4 新增的 direct-volume 命令向 Kata Containers 运行时传递并收集卷信息。</p><ul><li>NodePublishVolume<br>调用 kata-runtime direct-volume add –volume-path [volumePath] –mount-info [mountInfo] 将卷挂载信息传递到 Kata Containers 用来执行文件系统挂载操作。 volumePath 是 CSI NodePublishVolumeRequest 中的 target_path。 mountInfo 是一个序列化的 JSON 字符串</li><li>NodeGetVolumeStats<br>调用 kata-runtime direct-volume stats –volume-path [volumePath] 获取直通卷的信息</li><li>NodeExpandVolume<br>调用 kata-runtime direct-volume resize –volume-path [volumePath] –size [size] 请求 Kata Containers 调整直通卷的大小</li><li>NodeStageVolume&#x2F;NodeUnStageVolume<br>调用 kata-runtime direct-volume remove –volume-path [volumePath] 删除直通卷的元数据信息</li></ul><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><h2 id="kata-runtime-direct-volume"><a href="#kata-runtime-direct-volume" class="headerlink" title="kata-runtime direct-volume"></a>kata-runtime direct-volume</h2><p><em><u>src&#x2F;runtime&#x2F;cmd&#x2F;kata-runtime&#x2F;kata-volume.go</u></em></p><p>Kata Containers 在 2.4 版本时，新增了 kata-runtime direct-volume 的命令，用于管理 Kata Containers 所使用的直通卷。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MountInfo contains the information needed by Kata to consume a host block device and mount it as a filesystem inside the guest VM.</span></span><br><span class="line"><span class="keyword">type</span> MountInfo <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// The type of the volume (ie. block)</span></span><br><span class="line">VolumeType <span class="type">string</span> <span class="string">`json:&quot;volume-type&quot;`</span></span><br><span class="line"><span class="comment">// The device backing the volume.</span></span><br><span class="line">Device <span class="type">string</span> <span class="string">`json:&quot;device&quot;`</span></span><br><span class="line"><span class="comment">// The filesystem type to be mounted on the volume.</span></span><br><span class="line">FsType <span class="type">string</span> <span class="string">`json:&quot;fstype&quot;`</span></span><br><span class="line"><span class="comment">// Additional metadata to pass to the agent regarding this volume.</span></span><br><span class="line">Metadata <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span> <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line"><span class="comment">// Additional mount options.</span></span><br><span class="line">Options []<span class="type">string</span> <span class="string">`json:&quot;options,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="add"><a href="#add" class="headerlink" title="add"></a>add</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume add</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr><tr><td>–mount-info</td><td>管理卷挂载的详情信息</td></tr></tbody></table><p><strong>主体流程</strong></p><ol><li>校验合法性，创建 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt; 目录</li><li>将 mount info 序列化为 json，以名为 mountInfo.json 的文件形式保存在该目录下</li></ol><h3 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume remove</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr></tbody></table><p><strong>主体流程</strong></p><ol><li>移除 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt; 目录</li></ol><h3 id="stats"><a href="#stats" class="headerlink" title="stats"></a>stats</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume stats</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr></tbody></table><p><strong>主体流程</strong></p><ol><li>获取 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt; 目录下的 sandbox id 名称<br><em>预期是一个直通卷仅有一个相关联的 sanbox，因此，该目录下，仅有两个文件，一个名为 sandbox id，一个名为 mountInfo.json</em></li><li>解析 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt;&#x2F;mountInfo.json 文件，构建 mountInfo 对象，获取 volume 的源 device 信息</li><li>向 containerd-shim-kata-v2 的 &#x2F;direct-volume&#x2F;stats 接口发起 HTTP Get 请求</li><li>判断 host 上的该 device 是否存在，根据 sandbox 中的 container 卷挂载的映射信息，获取到位于 guest OS 中的对应的挂载点</li><li>向 Kata agent 发起 rpc 请求，获取 guest OS 中的卷信息</li></ol><h3 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume resize</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr><tr><td>–size</td><td>调整后的卷大小，默认为 0</td></tr></tbody></table><p><strong>主体流程</strong></p><ol><li>获取 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt; 目录下的 sandbox id 名称<br><em>预期是一个直通卷仅有一个相关联的 sandbox，因此，该目录下，仅有两个文件，一个名为 sandbox id，一个名为 mountInfo.json</em></li><li>解析 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt;&#x2F;mountInfo.json 文件，构建 mountInfo 对象</li><li>向 containerd-shim-kata-v2 的 &#x2F;direct-volume&#x2F;resize 接口发起 HTTP Post 请求</li><li>判断 host 上的该 device 是否存在，根据 sandbox 中的 container 卷挂载的映射信息，获取到位于 guest OS 中的对应的挂载点</li><li>向 Kata agent 发起 rpc 请求，对 guest OS 中指定的卷进行大小调整</li></ol><h2 id="containerd-shim-kata-v2"><a href="#containerd-shim-kata-v2" class="headerlink" title="containerd-shim-kata-v2"></a>containerd-shim-kata-v2</h2><h3 id="createBlockDevices"><a href="#createBlockDevices" class="headerlink" title="createBlockDevices"></a>createBlockDevices</h3><p><em><u>src&#x2F;runtime&#x2F;virtcontainers&#x2F;container.go</u></em></p><p><strong>部分流程</strong></p><ol><li>如果不支持块设备的挂载特性，则直接返回错误信息</li><li>针对每一个 container spec 中记录的挂载点 mount，进行以下操作<ol><li>判断是否已经有 BlockDeviceID 信息，如果有代表已经有设备关联挂载点，后续不需要为其创建新的设备</li><li>判断 mount 类型是否是 bind</li><li>根据 mount source 获取到 mount info 信息，如果获取不到，则不是直通卷</li><li>在 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;direct-volumes&#x2F;&lt;base64 volume path&gt; 目录下，写入以 sandbox ID 为名的文件，用于后续 CSI 与 runtime 通信</li><li>根据 mount info 信息，设置 container mount 的所需信息</li></ol></li><li>……</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Mount describes a container mount.</span></span><br><span class="line"><span class="comment">// nolint: govet</span></span><br><span class="line"><span class="keyword">type</span> Mount <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Source is the source of the mount.</span></span><br><span class="line">Source <span class="type">string</span></span><br><span class="line"><span class="comment">// Destination is the destination of the mount (within the container).</span></span><br><span class="line">Destination <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Type specifies the type of filesystem to mount.</span></span><br><span class="line">Type <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// HostPath used to store host side bind mount path</span></span><br><span class="line">HostPath <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// GuestDeviceMount represents the path within the VM that the device</span></span><br><span class="line"><span class="comment">// is mounted. Only relevant for block devices. This is tracked in the event</span></span><br><span class="line"><span class="comment">// runtime wants to query the agent for mount stats.</span></span><br><span class="line">GuestDeviceMount <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// BlockDeviceID represents block device that is attached to the</span></span><br><span class="line"><span class="comment">// VM in case this mount is a block device file or a directory</span></span><br><span class="line"><span class="comment">// backed by a block device.</span></span><br><span class="line">BlockDeviceID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Options list all the mount options of the filesystem.</span></span><br><span class="line">Options []<span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ReadOnly specifies if the mount should be read only or not</span></span><br><span class="line">ReadOnly <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// FSGroup a group ID that the group ownership of the files for the mounted volume</span></span><br><span class="line"><span class="comment">// will need to be changed when set.</span></span><br><span class="line">FSGroup *<span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// FSGroupChangePolicy specifies the policy that will be used when applying</span></span><br><span class="line"><span class="comment">// group id ownership change for a volume.</span></span><br><span class="line">FSGroupChangePolicy volume.FSGroupChangePolicy</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="实践操作"><a href="#实践操作" class="headerlink" title="实践操作"></a>实践操作</h1><h2 id="准备操作"><a href="#准备操作" class="headerlink" title="准备操作"></a>准备操作</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">准备两个 runtime 为 Kata Containers 的 Pod，分别为 direct 和 Virtiofs 的模式</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod</span></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE</span><br><span class="line">local-kata-direct   1/1     Running   0          2m7s</span><br><span class="line">local-kata-virt     1/1     Running   0          2m3s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl pods --no-trunc</span></span><br><span class="line">POD ID                                                             CREATED             STATE               NAME                                                      NAMESPACE           ATTEMPT</span><br><span class="line">3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9   11 minutes ago      Ready               local-kata-virt                                           default             0</span><br><span class="line">3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7   11 minutes ago      Ready               local-kata-direct                                         default             0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pvc</span></span><br><span class="line">NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">local-kata-direct   Bound    pvc-23dc3ecf-37fb-44ee-b8a6-7667a98aeb05   20Mi       RWO            local-kata-direct   20m</span><br><span class="line">local-kata-virt     Bound    pvc-0878818c-5d93-4ed4-b034-5bf37a657a6e   20Mi       RWO            local-kata-virt     20m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分别在持久卷种写入测试数据</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it local-kata-direct <span class="built_in">touch</span> /datadir/direct-data</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it local-kata-virt <span class="built_in">touch</span> /datadir/virt-data</span></span><br></pre></td></tr></table></figure><h2 id="host-端进程"><a href="#host-端进程" class="headerlink" title="host 端进程"></a>host 端进程</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef | grep 3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9</span></span><br><span class="line">root       889 10374  0 17:23 pts/34   00:00:00 grep --color=auto 3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9</span><br><span class="line">root     42721     1  0 17:10 ?        00:00:00 /usr/local/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9 -debug</span><br><span class="line">root     42744 42721  0 17:10 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts</span><br><span class="line">root     42751     1  0 17:10 ?        00:00:01 /opt/kata/bin/qemu-system-x86_64 -name sandbox-3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9 -uuid 26864a9b-ad50-43ab-9d41-2b6f4c7e34c3 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/qmp.sock,server=on,wait=off -m 256M,slots=10,maxmem=129389M -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-containers.img,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-3588796381,guest-cid=3588796381 -chardev socket,id=char-597c9c629356cf41,path=/run/vc/vm/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-597c9c629356cf41,tag=kataShared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=6e:ae:f6:c6:82:0a,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=256M,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux.container -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=48 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026 -pidfile /run/vc/vm/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/pid -smp 1,cores=1,threads=1,sockets=48,maxcpus=48</span><br><span class="line">root     42758 42744  0 17:10 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef | grep 3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7</span></span><br><span class="line">root     25155 10374  0 17:26 pts/34   00:00:00 grep --color=auto 3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7</span><br><span class="line">root     38975     1  0 17:10 ?        00:00:00 /usr/local/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7 -debug</span><br><span class="line">root     39008 38975  0 17:10 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts</span><br><span class="line">root     39312     1  0 17:10 ?        00:00:01 /opt/kata/bin/qemu-system-x86_64 -name sandbox-3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7 -uuid c3fccd7b-f344-4819-a894-80f5e1c5606d -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/qmp.sock,server=on,wait=off -m 256M,slots=10,maxmem=129389M -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-containers.img,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-2091051760,guest-cid=2091051760 -chardev socket,id=char-2c14db67d9a8d23c,path=/run/vc/vm/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-2c14db67d9a8d23c,tag=kataShared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=86:3f:52:0e:93:29,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=256M,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux.container -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=48 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026 -pidfile /run/vc/vm/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/pid -smp 1,cores=1,threads=1,sockets=48,maxcpus=48</span><br><span class="line">root     39547 39008  0 17:10 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到无论是哪种持久卷挂载方式，host 上的进程信息均为：两个 virtiofsd 进程，一个 qemu-system 进程，一个 containerd-shim-kata-v2 进程</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之所以卷直通模式也会有 virtiofsd 进程启动是因为卷直通仅限于持久卷的部分，对于 sandbox rootfs 仍以 virtiofs 协议挂载至 guest 中</span></span><br></pre></td></tr></table></figure><h2 id="host-端卷目录结构"><a href="#host-端卷目录结构" class="headerlink" title="host 端卷目录结构"></a>host 端卷目录结构</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> /var/lib/kubelet/pods/6cccbed3-45eb-4925-92af-aa2313f1e3f8/volumes/kubernetes.io~csi/pvc-0878818c-5d93-4ed4-b034-5bf37a657a6e/mount</span></span><br><span class="line">lost+found  virt-data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> /var/lib/kubelet/pods/7c974c3d-865a-4684-87ce-25d01a48d89e/volumes/kubernetes.io~csi/pvc-23dc3ecf-37fb-44ee-b8a6-7667a98aeb05/mount/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的卷目录存在，但是没有相应的数据</span></span><br></pre></td></tr></table></figure><h2 id="host-端挂载点"><a href="#host-端挂载点" class="headerlink" title="host 端挂载点"></a>host 端挂载点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsblk</span></span><br><span class="line">...</span><br><span class="line">sdt                                                            65:48   0   200G  0 disk  </span><br><span class="line">└─mpathb                                                      253:11   0   200G  0 mpath </span><br><span class="line">  ├─i1666574565-lvmlock                                       253:13   0    10G  0 lvm   </span><br><span class="line">  ├─i1666574565-pvc--23dc3ecf--37fb--44ee--b8a6--7667a98aeb05 253:15   0    20M  0 lvm   </span><br><span class="line">  └─i1666574565-pvc--0878818c--5d93--4ed4--b034--5bf37a657a6e 253:16   0    20M  0 lvm   /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-b00bec5dd6f4958e-datadir</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount | grep 3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9</span></span><br><span class="line">shm on /run/containerd/io.containerd.grpc.v1.cri/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</span><br><span class="line">overlay on /run/containerd/io.containerd.runtime.v2.task/k8s.io/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/work)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared type tmpfs (ro,mode=755)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/work)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254839/work)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9-2c4e4dce04926bea-resolv.conf type xfs (ro,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9-2c4e4dce04926bea-resolv.conf type xfs (ro,relatime,attr2,inode64,noquota)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/251248/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254840/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254840/work)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/251248/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254840/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254840/work)</span><br><span class="line">/dev/mapper/i1666574565-pvc--0878818c--5d93--4ed4--b034--5bf37a657a6e on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-b00bec5dd6f4958e-datadir type ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/mapper/i1666574565-pvc--0878818c--5d93--4ed4--b034--5bf37a657a6e on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-b00bec5dd6f4958e-datadir type ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-d10c2427b7cfd382-hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-d10c2427b7cfd382-hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-aec3c5c428ab0e89-termination-log type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-aec3c5c428ab0e89-termination-log type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-0a63282c5f8f4163-hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-0a63282c5f8f4163-hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-a9d3c3e132ce299b-resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-a9d3c3e132ce299b-resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/mounts/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-30db53e3c43cb09f-serviceaccount type tmpfs (ro,relatime,size=32675592k)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/shared/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-30db53e3c43cb09f-serviceaccount type tmpfs (ro,relatime,size=32675592k)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount | grep 3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7</span></span><br><span class="line">shm on /run/containerd/io.containerd.grpc.v1.cri/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</span><br><span class="line">overlay on /run/containerd/io.containerd.runtime.v2.task/k8s.io/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/work)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared type tmpfs (ro,mode=755)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/work)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/1/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254837/work)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7-27977320e8b95e05-resolv.conf type xfs (ro,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7-27977320e8b95e05-resolv.conf type xfs (ro,relatime,attr2,inode64,noquota)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/251248/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254838/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254838/work)</span><br><span class="line">overlay on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379/rootfs type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/251248/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254838/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/254838/work)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-b03e8081dab8db44-hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-b03e8081dab8db44-hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-fc067734b16d5aec-termination-log type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-fc067734b16d5aec-termination-log type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-9578923c5ca9be73-hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-9578923c5ca9be73-hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-19d449c66d9d623d-resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/sda2 on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-19d449c66d9d623d-resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/mounts/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-fd37e76da5e2d86d-serviceaccount type tmpfs (ro,relatime,size=32675592k)</span><br><span class="line">tmpfs on /run/kata-containers/shared/sandboxes/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/shared/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-fd37e76da5e2d86d-serviceaccount type tmpfs (ro,relatime,size=32675592k)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">卷直通场景下，持久卷的块设备由 CSI 格式化后 attach 到节点后，不会执行 mount 到节点的操作，而是由 Kata Agent 触发 mount 操作，挂载到 VM 中，因此 host 端看不到挂载点信息，所以写在直通卷中的数据不会出现在 host 中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">两种模式下，rootfs 的挂载点一致</span></span><br></pre></td></tr></table></figure><h2 id="容器端挂载点"><a href="#容器端挂载点" class="headerlink" title="容器端挂载点"></a>容器端挂载点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it local-kata-virt sh</span></span><br><span class="line">/ # df -Th</span><br><span class="line">Filesystem           Type            Size      Used Available Use% Mounted on</span><br><span class="line">none                 virtiofs       80.0G     65.3G     14.7G  82% /</span><br><span class="line">tmpfs                tmpfs          64.0M         0     64.0M   0% /dev</span><br><span class="line">tmpfs                tmpfs         111.9M         0    111.9M   0% /sys/fs/cgroup</span><br><span class="line">none                 virtiofs       18.4M    332.0K     17.6M   2% /datadir</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/hosts</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /dev/termination-log</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/hostname</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/resolv.conf</span><br><span class="line">shm                  tmpfs         111.9M         0    111.9M   0% /dev/shm</span><br><span class="line">none                 virtiofs       31.2G     12.0K     31.2G   0% /var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                tmpfs          64.0M         0     64.0M   0% /proc/timer_list</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it local-kata-direct sh</span></span><br><span class="line">/ # df -Th</span><br><span class="line">Filesystem           Type            Size      Used Available Use% Mounted on</span><br><span class="line">none                 virtiofs       80.0G     65.3G     14.7G  82% /</span><br><span class="line">tmpfs                tmpfs          64.0M         0     64.0M   0% /dev</span><br><span class="line">tmpfs                tmpfs         111.9M         0    111.9M   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda             ext4           18.4M    332.0K     17.6M   2% /datadir</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/hosts</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /dev/termination-log</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/hostname</span><br><span class="line">kataShared           virtiofs       80.0G     65.3G     14.7G  82% /etc/resolv.conf</span><br><span class="line">shm                  tmpfs         111.9M         0    111.9M   0% /dev/shm</span><br><span class="line">none                 virtiofs       31.2G     12.0K     31.2G   0% /var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                tmpfs          64.0M         0     64.0M   0% /proc/timer_list</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 的场景下的持久卷以 virtiofs 类型挂载到容器中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 的场景下的持久卷以 ext4 类型挂载到容器中，其中 ext4 和 /dev/sda 均可通过直通时指定</span></span><br></pre></td></tr></table></figure><h2 id="VM-端挂载点"><a href="#VM-端挂载点" class="headerlink" title="VM 端挂载点"></a>VM 端挂载点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">exec</span> 3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9</span></span><br><span class="line">root@clr-bab03a69f32d46fa9bfa8f735f0a4036 / $ df -Th</span><br><span class="line">Filesystem     Type      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root      ext4      117M   95M   16M  87% /</span><br><span class="line">devtmpfs       devtmpfs  111M     0  111M   0% /dev</span><br><span class="line">tmpfs          tmpfs     112M     0  112M   0% /dev/shm</span><br><span class="line">tmpfs          tmpfs      45M   28K   45M   1% /run</span><br><span class="line">tmpfs          tmpfs     4.0M     0  4.0M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs          tmpfs     112M     0  112M   0% /tmp</span><br><span class="line">kataShared     virtiofs   63G  147M   63G   1% /run/kata-containers/shared/containers</span><br><span class="line">shm            tmpfs     112M     0  112M   0% /run/kata-containers/sandbox/shm</span><br><span class="line">none           virtiofs   80G   66G   15G  83% /run/kata-containers/3f1316b887ba0cf7b0144a095fb543a262ae0c2b32a94c7658e1dbb3707c5ea9/rootfs</span><br><span class="line">none           virtiofs   80G   66G   15G  83% /run/kata-containers/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce/rootfs</span><br><span class="line">none           virtiofs   32G   12K   32G   1% /run/kata-containers/shared/containers/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-30db53e3c43cb09f-serviceaccount</span><br><span class="line">none           virtiofs   19M  332K   18M   2% /run/kata-containers/shared/containers/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-b00bec5dd6f4958e-datadir</span><br><span class="line">root@clr-bab03a69f32d46fa9bfa8f735f0a4036 / $ lsblk</span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">pmem0     259:0    0  126M  1 disk </span><br><span class="line">`-pmem0p1 259:1    0  124M  1 part /</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">exec</span> 3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7</span></span><br><span class="line">root@clr-e5fe15d519854877912b7c4556e71299 / $ df -Th</span><br><span class="line">Filesystem     Type      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root      ext4      117M   95M   16M  87% /</span><br><span class="line">devtmpfs       devtmpfs  111M     0  111M   0% /dev</span><br><span class="line">tmpfs          tmpfs     112M     0  112M   0% /dev/shm</span><br><span class="line">tmpfs          tmpfs      45M   28K   45M   1% /run</span><br><span class="line">tmpfs          tmpfs     4.0M     0  4.0M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs          tmpfs     112M     0  112M   0% /tmp</span><br><span class="line">kataShared     virtiofs   63G  147M   63G   1% /run/kata-containers/shared/containers</span><br><span class="line">shm            tmpfs     112M     0  112M   0% /run/kata-containers/sandbox/shm</span><br><span class="line">none           virtiofs   80G   66G   15G  83% /run/kata-containers/3763faeb5fc0aa25265b751123b63fbbae1c8aa35bec202c42a4d569c0ef63a7/rootfs</span><br><span class="line">/dev/sda       ext4       19M  332K   18M   2% /run/kata-containers/sandbox/storage/MDow</span><br><span class="line">none           virtiofs   80G   66G   15G  83% /run/kata-containers/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379/rootfs</span><br><span class="line">none           virtiofs   32G   12K   32G   1% /run/kata-containers/shared/containers/6da9c84109d97ce2895b3e5b38631ebdf7185fc7b915cf4766572803ce4df379-fd37e76da5e2d86d-serviceaccount</span><br><span class="line">root@clr-e5fe15d519854877912b7c4556e71299 / $ lsblk                            </span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sda         8:0    0   20M  0 disk /run/kata-containers/sandbox/storage/MDow</span><br><span class="line">pmem0     259:0    0  126M  1 disk </span><br><span class="line">`-pmem0p1 259:1    0  124M  1 part /</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">direct 类型的 Pod 会较 virtiofs 多一个挂载点，/dev/sda -&gt; /run/kata-containers/sandbox/storage/MDow</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">virtiofs 类型的 Pod 会较 direct 多一个挂载点，/run/kata-containers/shared/containers/cc3782d5f7aef968f640a0c161ee027efec8054c9860cae9d7254f8fe0659cce-b00bec5dd6f4958e-datadir</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Kata Containers stable-2.4 版本中 Block Volume 直通特性的实践验证</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kubernetes 」源码走读 - CPU Manager</title>
    <link href="http://shenxianghong.github.io/2022/07/11/2022-07-11%20Kubernetes%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20CPU%20Manager/"/>
    <id>http://shenxianghong.github.io/2022/07/11/2022-07-11%20Kubernetes%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20CPU%20Manager/</id>
    <published>2022-07-10T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.247Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src=/gallery/kubernetes/logo.svg></div><hr><blockquote><p>based on <strong>v1.20.12</strong></p></blockquote><h1 id="state"><a href="#state" class="headerlink" title="state"></a>state</h1><p><em><u>pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;state&#x2F;state_checkpoint.go</u></em></p><p>基于内存，用于记录 CPU Manager 的状态，后续 Policy 获取 CPU 以及分配情况等均从 state 对象中获得</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// map[pod]map[container]CPU Set</span></span><br><span class="line"><span class="keyword">type</span> ContainerCPUAssignments <span class="keyword">map</span>[<span class="type">string</span>]<span class="keyword">map</span>[<span class="type">string</span>]cpuset.CPUSet</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> stateMemory <span class="keyword">struct</span> &#123;</span><br><span class="line">sync.RWMutex</span><br><span class="line"><span class="comment">// 记录 CPU 分配情况</span></span><br><span class="line">assignments   ContainerCPUAssignments</span><br><span class="line"><span class="comment">// 记录 CPU 信息</span></span><br><span class="line">defaultCPUSet cpuset.CPUSet</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="storeState"><a href="#storeState" class="headerlink" title="storeState"></a>storeState</h2><p>当有 CPU 分配或者回收时，会调用该函数，将 state 对象持久化为 checkpoint 文件</p><h2 id="restoreState"><a href="#restoreState" class="headerlink" title="restoreState"></a>restoreState</h2><p>当 CPU Manager 启动时，会调用该函数，将节点上的 checkpoint 文件恢复为 state 对象</p><h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>基于文件（位于 host 上的 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;cpu_manager_state），用于记录 CPU Manager 的状态，为了避免 state 对象在 Kubelet 重启后内存丢失的问题</p><h1 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h1><p><em><u>pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;policy.go</u></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Policy <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// 返回策略名称</span></span><br><span class="line">Name() <span class="type">string</span></span><br><span class="line"><span class="comment">// 针对 State 的校验流程</span></span><br><span class="line">Start(s state.State) <span class="type">error</span></span><br><span class="line"><span class="comment">// 容器 CPU 的分配流程</span></span><br><span class="line">Allocate(s state.State, pod *v1.Pod, container *v1.Container) <span class="type">error</span></span><br><span class="line"><span class="comment">// 容器移除后的回收流程</span></span><br><span class="line">RemoveContainer(s state.State, podUID <span class="type">string</span>, containerName <span class="type">string</span>) <span class="type">error</span></span><br><span class="line"><span class="comment">// 调用 Policy 中的 topologymanager.HintProvider 的实现</span></span><br><span class="line">GetTopologyHints(s state.State, pod *v1.Pod, container *v1.Container) <span class="keyword">map</span>[<span class="type">string</span>][]topologymanager.TopologyHint</span><br><span class="line"><span class="comment">// 调用 Policy 中的 topologymanager.HintProvider 的实现</span></span><br><span class="line">GetPodTopologyHints(s state.State, pod *v1.Pod) <span class="keyword">map</span>[<span class="type">string</span>][]topologymanager.TopologyHint</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="none"><a href="#none" class="headerlink" title="none"></a>none</h2><p><em><u>pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;policy_none.go</u></em></p><p>默认策略。</p><p>CPU Manager 的 none 策略并未做任何实际的逻辑处理，不提供任何系统调度器默认行为之外的亲和性策略。通过 CFS 配额来实现 Guaranteed Pods 和 Burstable Pods 的 CPU 使用限制。因此，共享池的 CPU 也会包含 Kubelet 预留的部分。</p><h2 id="static"><a href="#static" class="headerlink" title="static"></a>static</h2><p><em><u>pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;policy_static.go</u></em></p><p>仅针对 QoS 为 Guaranteed 且 CPU 申请量为正整数的 Pod 赋予增强的 CPU 亲和性和独占性。</p><h3 id="Start"><a href="#Start" class="headerlink" title="Start"></a>Start</h3><ol><li>初始化可分配的 CPU 信息，即获取所有可分配的 CPU（如果开启了 strictReserved，则取全量 CPU 和预留 CPU 的差集）</li><li>如果开启了 strictReserved，则校验全量 CPU 和预留 CPU 是否没有重叠；如果未开启，则校验预留 CPU 是否全在全量 CPU 中</li><li>校验已分配的 CPU 和可分配的 CPU 是否不重叠</li><li>校验可分配的 CPU + 已分配的 CPU 是否等于所有的 CPU - 预留的 CPU（如果开启了 strictReserved，否则忽视预留的 CPU）</li></ol><h3 id="Allocate"><a href="#Allocate" class="headerlink" title="Allocate"></a>Allocate</h3><ol><li>判断 Pod QoS 是否是 Guaranteed 级别，并且 Container 的 CPU request 为整数，如果不满足条件，直接返回，不做处理</li><li>从已分配的 CPU 信息中判断该 Pod 是否已经分配过，如果分配过，则本地更新</li><li>调用 Topology Manager 获取所有的 hint providers 返回的 hint</li><li>获取可申领的 CPU（即可分配 CPU + 步骤二中可复用的 CPU）</li><li>如果开启了 NUMA 亲和特性，则获取到涉及到的  NUMA 中的所有 CPU，取 NUMA CPU 之和和申请 CPU 中的最小值作为待对齐分配的 CPU 数量，校验申请的 CPU 数量是否大于 1 且小于所有可用的 CPU，</li><li>执行拓扑感知 best-fit 算法，优先对齐能满足 NUMA 的部分<br><em>参考 pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;cpu_assignment_test.go 单元测试示例</em><ol><li>如果请求的 CPU 数量不小于单块 CPU Socket 中 Thread 数量，那么会优先将整块 CPU Socket 中的Thread 分配<br><em>acc.freeSockets()，返回单 Socket 中所有 Thread 均可用的 Socket 列表</em></li><li>如果剩余请求的 CPU 数量不小于单块物理 CPU Core 提供的 Thread 数量，那么会优先将整块物理 CPU Core 上的 Thread 分配<br><em>acc.freeCores()，返回单 Core 中所有 Thread 均可用的 Core 列表，按照 SocketID 做升序排列</em></li><li>剩余请求的 CPU 数量则从按照如下规则排好序的 Thread 列表中选择<br><em>acc.freeCPUs()，返回所有可用的 Thread 列表，按照 SocketID 和 CoreID 做升序排列</em><ol><li>相同 Socket 上可用的 Thread</li><li>相同 Core 上可用的 Thread</li><li>CPU ID 升序排列</li></ol></li></ol></li><li>对于剩余的 CPU，进行如上拓扑感知 best-fit 算法，合并以上两部分，作为最终的 CPU 绑定结果</li><li>从共享池 CPU 中去除待分配的 CPU</li></ol><h3 id="RemoveContainer"><a href="#RemoveContainer" class="headerlink" title="RemoveContainer"></a>RemoveContainer</h3><ol><li>获取到容器的 CPU 分配信息，删除掉分配的记录信息，共享池 CPU 中添加 CPU</li></ol><h3 id="GetTopologyHints"><a href="#GetTopologyHints" class="headerlink" title="GetTopologyHints"></a>GetTopologyHints</h3><ol><li>获取容器申请的 CPU 数量</li><li>如果容器已经分配了申请 CPU，那么判断申请的和已分配的是否相等，不相等则不给出 hint，直接返回；相等则用已分配的生成 hint</li><li>获取可用的 CPU 和可复用的 CPU 信息，两者的合集作为可复用的 CPU，生成 hint</li></ol><h3 id="GetPodTopologyHints"><a href="#GetPodTopologyHints" class="headerlink" title="GetPodTopologyHints"></a>GetPodTopologyHints</h3><ol><li>获取 Pod 申请的 CPU 数量（获取 Init Container 最大值和 Container 之和，取两者最大为 CPU 数量）</li><li>遍历 Pod 的每个容器，如果容器已经分配了申请 CPU，那么判断申请的和已分配的是否相等，不相等则不给出 hint，直接返回；如果所有容器的已分配的 CPU 之和等于 Pod 的申请 CPU 数量，则用已分配的生成 hint</li><li>获取可用的 CPU 和可复用的 CPU 信息，两者的合集作为可复用的 CPU，生成 hint</li></ol><h3 id="generateCPUTopologyHints"><a href="#generateCPUTopologyHints" class="headerlink" title="generateCPUTopologyHints"></a>generateCPUTopologyHints</h3><p>生成 CPU TopologyHint 信息，假设有两个 NUMA 节点（编号为 0 和 1），NUMA0 上有 CPU1 和 CPU2，NUMA1上有 CPU3 和 CPU4，某个 Pod 请求两个 CPU。那么 CPU Manager 这个 HintProvider 会调用 generateCPUTopologyHints 产生如下的 TopologyHint：</p><ul><li>{01: True} 代表从 NUMA0 取 2 个 CPU，并且是“优先考虑的”</li><li>{10: True} 代表从 NUMA1 取 2 个 CPU，并且是“优先考虑的”</li><li>{11: False} 代表从 NUMA0 和 NUMA1 各取一个 CPU，不是“优先考虑的”</li></ul><ol><li>获取集群中的所有 NUMA 节点</li><li>获取 NUMA 节点组合中涉及到的 CPU</li><li>如果 NUMA 节点组合中所涉及到的 CPU 个数比请求的 CPU 数大，并且这个组合所涉及的 NUMA 节点个数是目前为止所有组合中最小的，那么就更新步骤 1 的获取结果</li><li>循环统计当前节点可用的 CPU 中，有哪些是属于当前正在处理的 NUMA 节点组合</li><li>如果当前 NUMA 组合中可用的 CPU 数比请求的 CPU 小，那么就直接返回，否则就创建一个 TopologyHint，并把它加入到 hints 中</li><li>遍历每一个 hint，涉及到的 NUMA 节点个数最少（即步骤 3 中获取的结果）的组合，会标注 preferred 为 true</li></ol><h1 id="CPU-Manager"><a href="#CPU-Manager" class="headerlink" title="CPU Manager"></a>CPU Manager</h1><p><em><u>pkg&#x2F;kubelet&#x2F;cm&#x2F;cpumanager&#x2F;cpu_manager.go</u></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Manager <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Kubelet 初始化时调用，启动 CPU Manager</span></span><br><span class="line">Start(activePods ActivePodsFunc, sourcesReady config.SourcesReady, podStatusProvider status.PodStatusProvider, containerRuntime runtimeService, initialContainers containermap.ContainerMap) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 CPU 分配给容器，必须在 AddContainer() 之前的某个时间点调用，例如在 Pod Admission 时</span></span><br><span class="line">Allocate(pod *v1.Pod, container *v1.Container) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在容器创建和容器启动之间调用，以便可以将初始 CPU 亲和性设置写入第一个进程开始执行之前的容器运行时中</span></span><br><span class="line">AddContainer(p *v1.Pod, c *v1.Container, containerID <span class="type">string</span>) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Kubelet 决定杀死或删除一个对象后调用，在此调用之后，CPU Manager 停止尝试协调该容器并且释放绑定于该容器的任何 CPU</span></span><br><span class="line"><span class="comment">// 目前未发现调用处</span></span><br><span class="line">RemoveContainer(containerID <span class="type">string</span>) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回内部 CPU Manager 的状态</span></span><br><span class="line">State() state.Reader</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 topologymanager.HintProvider 的实现，处理 NUMA 资源对齐等逻辑</span></span><br><span class="line">GetTopologyHints(*v1.Pod, *v1.Container) <span class="keyword">map</span>[<span class="type">string</span>][]topologymanager.TopologyHint</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取分配给 Pod 容器的 CPU 信息</span></span><br><span class="line">GetCPUs(podUID, containerName <span class="type">string</span>) []<span class="type">int64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 topologymanager.HintProvider 的实现，处理 NUMA 资源对齐等逻辑</span></span><br><span class="line">GetPodTopologyHints(pod *v1.Pod) <span class="keyword">map</span>[<span class="type">string</span>][]topologymanager.TopologyHint</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Start-1"><a href="#Start-1" class="headerlink" title="Start"></a>Start</h2><ol><li>初始化 checkpoint 文件，并基于该文件初始化 state 对象</li><li>调用 Policy 的 Start 接口，传入 state</li><li>如果策略是 none，则直接返回，否则启动 goroutine 定时调和 state</li></ol><h2 id="Allocate-1"><a href="#Allocate-1" class="headerlink" title="Allocate"></a>Allocate</h2><ol><li>清理搁浅的资源，也就是获取 state 中记录的 CPU 信息，但是实际上使用的容器已经不是 active 状态</li><li>调用 Policy 的 Allocate 接口</li></ol><h2 id="AddContainer"><a href="#AddContainer" class="headerlink" title="AddContainer"></a>AddContainer</h2><ol><li>从 state 中获取 Pod 容器的 CPU 信息，如果为空直接返回</li><li>调用 CRI 的 UpdateContainerResources 接口，更新容器的 CPU Set 信息，如果更新失败调用 Policy 的 RemoveContainer 接口回滚状态，从 containerMap 中移除容器信息</li></ol><h2 id="RemoveContainer-1"><a href="#RemoveContainer-1" class="headerlink" title="RemoveContainer"></a>RemoveContainer</h2><ol><li>调用 Policy 的 RemoveContainer 接口</li><li>从 containerMap 中移除 Container 信息</li></ol><h2 id="State"><a href="#State" class="headerlink" title="State"></a>State</h2><ol><li>返回 state 对象</li></ol><h2 id="GetTopologyHints-1"><a href="#GetTopologyHints-1" class="headerlink" title="GetTopologyHints"></a>GetTopologyHints</h2><ol><li>清理搁浅的资源，也就是获取 state 中记录的 CPU 信息，但是实际上使用的容器已经不是 active 状态</li><li>调用 Policy 的 GetTopologyHints 接口</li></ol><h2 id="GetCPUs"><a href="#GetCPUs" class="headerlink" title="GetCPUs"></a>GetCPUs</h2><ol><li>获取 state 中记录有给定 Pod 和容器的 CPU 分配情况，并返回</li></ol><h2 id="GetPodTopologyHints-1"><a href="#GetPodTopologyHints-1" class="headerlink" title="GetPodTopologyHints"></a>GetPodTopologyHints</h2><ol><li>清理搁浅的资源，也就是获取 state 中记录的 CPU 信息，但是实际上使用的容器已经不是 active 状态</li><li>调用 Policy 的 GetPodTopologyHints 接口</li></ol><h2 id="reconcileState"><a href="#reconcileState" class="headerlink" title="reconcileState"></a>reconcileState</h2><p>针对非 none 类型的 Policy 周期性调和</p><ol><li>清理搁浅的资源，也就是获取 state 中记录的 CPU 信息，但是实际上使用的容器已经不是 active 状态</li><li>遍历所有的 active 状态的 Pod 的容器</li><li>检查该 ContainerID 是否在 CPU Manager 维护的 state 中，然后检查对应的 Pod.Status.Phase 是否为 Running 且 DeletionTimestamp 为 nil，如果是，则调用 CPU Manager 的 AddContainer 对该 Container&#x2F;Pod 进行 QoS 和 CPU request 检查，如果满足 static Policy 的条件，则调用 takeByTopology 为该 Container 分配最佳的 CPU Set，并写入到 state 和 checkpoint 文件中</li><li>然后从 State 中获取该 ContainerID 对应的 CPU Set，调用 CRI UpdateContainerResources 接口更新容器的 CPU Set 信息</li></ol>]]></content>
    
    
    <summary type="html">Kubelet 中 CPU Manager 模块的流程梳理</summary>
    
    
    
    <category term="Scheduling &amp; Orchestration" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/"/>
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — Gateway</title>
    <link href="http://shenxianghong.github.io/2022/07/10/2022-07-10%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Gateway/"/>
    <id>http://shenxianghong.github.io/2022/07/10/2022-07-10%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20Gateway/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.212Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>Gateway 描述了在网格边缘运行的负载均衡器，用于接收传入或传出的 HTTP&#x2F;TCP 连接。该规范描述了一组应该公开的端口、要使用的协议类型、负载均衡器的 SNI 配置等。</p><p>例如，以下 Gateway 配置设置代理以充当负载均衡器，将端口 80 和 9080 (http)、443 (https)、9443 (https) 和端口 2379 (TCP) 用于入口。Gateway 会应用在带有标签 app: my-gateway-controller 的 Pod 上。<br><em>虽然 Istio 配置代理侦听这些端口，但用户有责任确保允许到这些端口的外部流量进入网格。</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-gateway</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">some-config-namespace</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">my-gateway-controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">uk.bookinfo.com</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">eu.bookinfo.com</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">httpsRedirect:</span> <span class="literal">true</span> <span class="comment"># sends 301 redirect for http requests</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">https-443</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">uk.bookinfo.com</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">eu.bookinfo.com</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">SIMPLE</span> <span class="comment"># enables HTTPS on this port</span></span><br><span class="line">      <span class="attr">serverCertificate:</span> <span class="string">/etc/certs/servercert.pem</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/etc/certs/privatekey.pem</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">9443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">https-9443</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;bookinfo-namespace/*.bookinfo.com&quot;</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">SIMPLE</span> <span class="comment"># enables HTTPS on this port</span></span><br><span class="line">      <span class="attr">credentialName:</span> <span class="string">bookinfo-secret</span> <span class="comment"># fetches certs from Kubernetes secret</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">9080</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http-wildcard</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;*&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">2379</span> <span class="comment"># to expose internal service via external port 2379</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">MONGO</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;*&quot;</span></span><br></pre></td></tr></table></figure><p>Gateway 描述了负载均衡器的 L4 - L6 属性。然后，可以将 VirtualService 绑定到 Gateway 控制到达特定 host 或 Gateway 端口的流量的转发。</p><p>例如，下面的 VirtualService 把流量路径  <a href="https://uk.bookinfo.com/reviews%E3%80%81https://eu.bookinfo.com/reviews%E3%80%81http://uk.bookinfo.com:9080/reviews%E3%80%81http://eu.bookinfo.com:9080/reviews">https://uk.bookinfo.com/reviews、https://eu.bookinfo.com/reviews、http://uk.bookinfo.com:9080/reviews、http://eu.bookinfo.com:9080/reviews</a> 分为了两个版本（prod 和 qa）。另外，包含 user: dev-123 cookie 的请求将发送到 7777 端口的 qa 版本。The same rule is also applicable inside the mesh for requests to the “reviews.prod.svc.cluster.local” service. This rule is applicable across ports 443, 9080. Note that <a href="http://uk.bookinfo.com/">http://uk.bookinfo.com</a> gets redirected to <a href="https://uk.bookinfo.com/">https://uk.bookinfo.com</a> (i.e. 80 redirects to 443).</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-rule</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bookinfo-namespace</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">uk.bookinfo.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">eu.bookinfo.com</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">some-config-namespace/my-gateway</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mesh</span> <span class="comment"># applies to all the sidecars in the mesh</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">        <span class="attr">cookie:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">&quot;user=dev-123&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">7777</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.qa.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/reviews/</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">9080</span> <span class="comment"># can be omitted if it&#x27;s the only port for reviews</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">80</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.qa.svc.cluster.local</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">20</span></span><br></pre></td></tr></table></figure><p>以下 VirtualService 将到达（外部）端口 27017 的流量转发到端口 5555 上的内部 Mongo 服务器。此规则在网格内部不适用，因为 gateways 中省略了保留名称网格（mesh）。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-mongo</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bookinfo-namespace</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mongosvr.prod.svc.cluster.local</span> <span class="comment"># name of internal Mongo service</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">some-config-namespace/my-gateway</span> <span class="comment"># can omit the namespace if gateway is in same namespace as virtual service.</span></span><br><span class="line">  <span class="attr">tcp:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">27017</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">mongo.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">5555</span></span><br></pre></td></tr></table></figure><p>可以使用 hosts 字段中的 namespace&#x2F;host 语法来限制可以绑定到 Gateway 服务器的 VirtualService。例如，下面的 Gateway 允许 ns1 命名空间中的任何 VirtualService 绑定到它，同时限制只有 ns2 命名空间中具有 foo.bar.com host 的 VirtualService 绑定。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-gateway</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">some-config-namespace</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">my-gateway-controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;ns1/*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;ns2/foo.bar.com&quot;</span></span><br></pre></td></tr></table></figure><h1 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h1><p>Gateway 描述了在网格边缘运行的负载均衡器，用于接收传入或传出的 HTTP&#x2F;TCP 连接。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#Server">servers</a></td><td>Server 集合</td></tr><tr><td>selector</td><td>一个或多个标签，用以匹配一组特定 pod&#x2F;VM 上应用此 Gateway。默认情况下，工作负载会根据标签选择器在所有命名空间中进行搜索。这意味着 Namespace foo 中的 Gateway 资源可以根据标签选择 Namespace bar 中的 Pod。这种行为可以通过 Istiod 中的 PILOT_SCOPE_GATEWAY_TO_NAMESPACE 环境变量来控制。如果此变量设置为 true，则标签搜索的范围仅限于 Gateway 资源所在的 Namespace。换言之，Gateway 资源必须与 Gateway 工作负载实例位于相同的 Namespace 中。如果选择器为 nil，则 Gateway 将应用于所有工作负载</td></tr></tbody></table><h1 id="Server"><a href="#Server" class="headerlink" title="Server"></a><a name="Server">Server</a></h1><p>Server 描述特定负载均衡端口上的代理属性。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><a href="#Port">port</a></td><td>代理监听的请求链接端口信息</td></tr><tr><td>bind</td><td>绑定到的 IP 或 Unix 域套接字。格式为 x.x.x.x、unix:&#x2F;&#x2F;&#x2F;path&#x2F;to&#x2F;uds 或 unix:&#x2F;&#x2F;@foobar（Linux 抽象命名空间）。使用 Unix 域套接字时，端口号应为 0。用于将此 server 的可达性限制为仅限 Gateway 内部。这通常在 Gateway 需要与另一个网格 server 通信时使用，例如发布指标。在这种情况下，使用指定绑定创建的 server 将不可用于外部 Gateway 客户端</td></tr><tr><td>hosts</td><td>Gateway 暴露的 host 信息。虽然通常适用于 HTTP 服务，但它也表述带有 SNI 的 TLS 的 TCP 服务。host 为带有 &lt;namespace&gt;&#x2F; 可选前缀的 dnsName（FQDN 格式，也可以类似如 prod&#x2F;*.example.com）。将 dnsName 设置为 * 表示从指定的命名空间（例如 prod&#x2F;*）中选择所有 VirtualService host。<br />namespace 可以设置为 * 或 .，分别代表任何或当前命名空间。例如，*&#x2F;foo.example.com 从任何可用的命名空间中选择 server，而 .&#x2F;foo.example.com 仅从 sidecar 的命名空间中选择服务。如果未指定 namespace&#x2F; 前缀部分，则默认为 *&#x2F;。所选命名空间中的任何关联 DestinationRule 也将被使用。<br />VirtualService 必须绑定到 Gateway，并且必须有一个或多个与 server 中匹配的 host。匹配可以是完全匹配或后缀匹配。<br /><em>例如，如果 server 的 host 指定 .example.com，则具有 host dev.example.com 或 prod.example.com 的 VirtualService 将匹配。但是，host example.com 或 newexample.com 的 VirtualService 将不匹配</em></td></tr><tr><td><a href="#ServerTLSSettings">tls</a></td><td>一组控制 server 行为的 TLS 相关选项。使用这些选项来控制是否应将所有 HTTP 请求重定向到 HTTPS，以及要使用的 TLS 模式</td></tr><tr><td>name</td><td>server 的可选名称，设置后在所有 server 中必须是唯一的。可用于例如为使用此名称生成的统计信息添加前缀等</td></tr></tbody></table><h1 id="Port"><a href="#Port" class="headerlink" title="Port"></a><a name="Port">Port</a></h1><p>Port 描述了 server 的特定端口的属性。</p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>number</td><td>端口号</td></tr><tr><td>protocol</td><td>端口协议。可选值 HTTP、HTTPS、GRPC、HTTP2、MONGO、TCP、TLS。TLS 意味着连接将根据 SNI 标头路由到目的地，而不会终止 TLS 连接</td></tr><tr><td>name</td><td>分配给端口的标签</td></tr><tr><td>targetPort</td><td>接收流量的 endpoint 上的端口号。仅在与 ServiceEntries 一起使用时适用</td></tr></tbody></table><h1 id="ServerTLSSettings"><a href="#ServerTLSSettings" class="headerlink" title="ServerTLSSettings"></a><a name="ServerTLSSettings">ServerTLSSettings</a></h1><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>httpsRedirect</td><td>如果设置为 true，负载均衡器将为所有 HTTP 连接发送 301 重定向，要求客户端使用 HTTPS</td></tr><tr><td><a href="#ServerTLSSettings.TLSmode">mode</a></td><td>可选：表明是否应使用 TLS 保护与此端口的连接。该字段的值决定了 TLS 的实施方式</td></tr><tr><td>serverCertificate</td><td>如果 mode 是 SIMPLE 或 MUTUAL，则为必需字段。保存使用的服务器端 TLS 证书的文件的路径</td></tr><tr><td>privateKey</td><td>如果 mode 是 SIMPLE 或 MUTUAL，则为必需字段。保存服务器私钥的文件的路径</td></tr><tr><td>caCertificates</td><td>如果 mode 是 MUTUAL，则为必需字段。包含证书颁发机构证书的文件的路径，用于验证提供的客户端证书</td></tr><tr><td>credentialName</td><td>对于在 Kubernetes 上运行的网关，包含 TLS 证书（包括 CA 证书）的密钥的名称。仅适用于 Kubernetes。密钥（通用类型）应包含以下键和值：键：&lt;privateKey&gt; 和证书：&lt;serverCert&gt;。对于双向 TLS，cacert: &lt;CACertificate&gt; 可以在同一个密钥或名为 &lt;secret&gt;-cacert 的单独密钥中提供。还支持用于服务器证书的 tls 类型的密钥以及用于 CA 证书的 ca.crt 密钥。只能指定服务器证书和 CA 证书或 credentialName 之一</td></tr><tr><td>subjectAltNames</td><td>用于验证客户端提供的证书中的主体身份的备用名称列表</td></tr><tr><td>verifyCertificateSpki</td><td>授权客户端证书的 SKPI 的 base64 编码 SHA-256 哈希的可选列表。注意：当同时指定 verify_certificate_hash 和 verify_certificate_spki 时，匹配任一值的哈希将导致证书被接受</td></tr><tr><td>verifyCertificateHash</td><td>授权客户端证书的十六进制编码 SHA-256 哈希的可选列表。简单格式和冒号分隔格式都可以接受。注意：当同时指定 verify_certificate_hash 和 verify_certificate_spki 时，匹配任一值的哈希将导致证书被接受</td></tr><tr><td><a href="#ServerTLSSettings.TLSProtocol">minProtocolVersion</a></td><td>最低 TLS 协议版本</td></tr><tr><td><a href="#ServerTLSSettings.TLSProtocol">maxProtocolVersion</a></td><td>最高 TLS 协议版本</td></tr><tr><td>cipherSuites</td><td>如果指定，只支持指定的密码列表。否则默认为 Envoy 支持的默认密码列表</td></tr></tbody></table><h1 id="ServerTLSSettings-TLSmode"><a href="#ServerTLSSettings-TLSmode" class="headerlink" title="ServerTLSSettings.TLSmode"></a><a name="ServerTLSSettings.TLSmode">ServerTLSSettings.TLSmode</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>PASSTHROUGH</td><td>客户端提供的 SNI 字符串将用作 VirtualService TLS 路由中的匹配标准，以确定服务注册表中的目标服务</td></tr><tr><td>SIMPLE</td><td>使用标准 TLS 语义的安全连接</td></tr><tr><td>MUTUAL</td><td>通过提供服务器证书进行身份验证，使用双向 TLS 保护与下游的连接</td></tr><tr><td>AUTO_PASSTHROUGH</td><td>与直通模式类似，除了具有此 TLS 模式的服务器不需要关联的 VirtualService 从 SNI 值映射到注册表中的服务。诸如服务&#x2F;子集&#x2F;端口之类的目标详细信息在 SNI 值中进行编码。代理将转发到 SNI 值指定的上游（Envoy）集群（一组端点）。此服务器通常用于在不同的 L3 网络中提供服务之间的连接，否则它们各自的端点之间没有直接连接。使用此模式假定源和目标都使用 Istio mTLS 来保护流量</td></tr><tr><td>ISTIO_MUTUAL</td><td>通过提供服务器证书进行身份验证，使用双向 TLS 保护来自下游的连接。与 Mutual 模式相比，该模式使用 Istio 自动生成的代表网关工作负载身份的证书进行 mTLS 身份验证。使用此模式时，TLSOptions 中的所有其他字段都应为空</td></tr></tbody></table><h1 id="ServerTLSSettings-TLSProtocol"><a href="#ServerTLSSettings-TLSProtocol" class="headerlink" title="ServerTLSSettings.TLSProtocol"></a><a name="ServerTLSSettings.TLSProtocol">ServerTLSSettings.TLSProtocol</a></h1><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>TLS_AUTO</td><td>自动选择最佳 TLS 版本</td></tr><tr><td>TLSV1_0</td><td>TLS 1.0 版本</td></tr><tr><td>TLSV1_1</td><td>TLS 1.1 版本</td></tr><tr><td>TLSV1_2</td><td>TLS 1.2 版本</td></tr><tr><td>TLSV1_3</td><td>TLS 1.3 版本</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Istio 流量管理场景下的 Gateway 资源对象使用范例与 API 结构概览</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」流量管理 — 整体概述</title>
    <link href="http://shenxianghong.github.io/2022/07/04/2022-07-04%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20%E6%95%B4%E4%BD%93%E6%A6%82%E8%BF%B0/"/>
    <id>http://shenxianghong.github.io/2022/07/04/2022-07-04%20Istio%20%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%20-%20%E6%95%B4%E4%BD%93%E6%A6%82%E8%BF%B0/</id>
    <published>2022-07-03T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.172Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><p>Istio 的流量路由规则可以很容易的控制服务之间的流量和 API 调用。Istio 简化了服务级别属性的配置，比如熔断器、超时和重试，并且能轻松的设置重要的任务，如 A&#x2F;B 测试、金丝雀发布、基于流量百分比切分的概率发布等。它还提供了开箱即用的故障恢复特性，有助于增强应用的健壮性，从而更好地应对被依赖的服务或网络发生故障的情况。</p><p>Istio 的流量管理模型源于和服务一起部署的 Envoy 代理。网格内服务发送和接收的所有流量（data plane 流量）都经由 Envoy 代理，这让控制网格内的流量变得异常简单，而且不需要对服务做任何的更改。</p><h1 id="整体概述"><a href="#整体概述" class="headerlink" title="整体概述"></a>整体概述</h1><p>为了在网格中导流，Istio 需要知道所有的 endpoint 在哪和属于哪个服务。为了定位到 Service Registry（服务注册中心），Istio 会连接到一个服务发现系统。例如，如果在 Kubernetes 集群上安装了 Istio，那么它将自动检测该集群中的服务和 endpoint。</p><p>使用此服务注册中心，Envoy 代理可以将流量定向到相关服务。大多数基于微服务的应用程序，每个服务的工作负载都有多个实例来处理流量，称为负载均衡池。默认情况下，Envoy 代理基于轮询调度模型在服务的负载均衡池内分发流量，按顺序将请求发送给池中每个成员，一旦所有服务实例均接收过一次请求后，重新回到第一个池成员。</p><p>Istio 基本的服务发现和负载均衡能力提供了一个可用的服务网格，但它能做到的远比这多的多。在许多情况下，可能希望对网格的流量情况进行更细粒度的控制。作为 A&#x2F;B 测试的一部分，可能想将特定百分比的流量定向到新版本的服务，或者为特定的服务实例子集应用不同的负载均衡策略。可能还想对进出网格的流量应用特殊的规则，或者将网格的外部依赖项添加到服务注册中心。通过使用 Istio 的流量管理 API 将流量配置添加到 Istio，就可以完成所有这些甚至更多的工作。</p><p>和其他 Istio 配置一样，这些 API 也使用 Kubernetes CRD 来声明，可以像示例中看到的那样使用 YAML 进行配置。</p><p>核心 API 包括：Virtual Services，Destination Rules，Gateways，Service Entries 和 Sidecars。</p><h1 id="Virtual-Service"><a href="#Virtual-Service" class="headerlink" title="Virtual Service"></a>Virtual Service</h1><p>Virtual Service 和 Destination Rule 是 Istio 流量路由功能的关键拼图。Virtual Service 配置如何在服务网格内将请求路由到服务，这基于 Istio 和平台提供的基本的连通性和服务发现能力。每个 Virtual Service 包含一组路由规则，Istio 按顺序评估它们，Istio 将每个给定的请求匹配到 Virtual Service 指定的实际目标地址。网格可以有多个 Virtual Service，也可以没有，取决于使用场景。</p><h2 id="为什么要使用-Virtual-Service"><a href="#为什么要使用-Virtual-Service" class="headerlink" title="为什么要使用 Virtual Service"></a>为什么要使用 Virtual Service</h2><p>Virtual Service 在增强 Istio 流量管理的灵活性和有效性方面，发挥着至关重要的作用，通过对客户端请求的目标地址与真实响应请求的目标工作负载进行解耦来实现。Virtual Service 同时提供了丰富的方式，为发送至这些工作负载的流量指定不同的路由规则。</p><p>如果没有 Virtual Service，Envoy 会在所有的服务实例中使用轮询的负载均衡策略分发请求，而有些场景下有着不同的分发需求。例如，有些可能代表不同的版本（A&#x2F;B 测试），希望在其中配置基于不同服务版本的流量百分比路由，或者路由内部用户到特定实例集的流量。</p><p>使用 Virtual Service，可以为一个或多个主机名指定流量行为。在 Virtual Service 中使用路由规则，告诉 Envoy 如何发送 Virtual Service 的流量到适当的目标。路由目标地址可以是同一服务的不同版本，也可以是完全不同的服务。</p><p>一个典型的用例是将流量发送到指定服务子集的不同版本。客户端将 Virtual Service 视为一个单一实体，将请求发送至  Virtual Service 主机，然后 Envoy 根据 Virtual Service 规则把流量路由到不同的版本。例如，将 20% 的调用转到新版本或者将这些用户的调用转到版本 2。例如，创建一个金丝雀发布，逐步增加发送到新版本服务的流量百分比。流量路由完全独立于实例部署，这意味着实现新版本服务的实例可以根据流量的负载来伸缩，完全不影响流量路由。</p><p>Virtual Service 可以</p><ul><li>通过单个 Virtual Service 处理多个应用程序服务。如果网格使用 Kubernetes，可以配置一个 Virtual Service 处理特定命名空间中的所有服务。映射单一的 Virtual Service 到多个真实 Service，可以在不需要客户适应转换的情况下，将单体应用转换为微服务构建的复合应用系统</li><li>和 Gateway 整合并配置流量规则来控制出入流量</li></ul><p>在某些情况下，还需要配置 Destination Rule（用于指定服务子集）来使用这些特性。在一个单独的对象中指定服务子集和其它特定目标策略，有利于在 Virtual Service 之间更简洁地重用这些规则。</p><h2 id="Virtual-Service-示例"><a href="#Virtual-Service-示例" class="headerlink" title="Virtual Service 示例"></a>Virtual Service 示例</h2><p>下面的 Virtual Service 根据请求是否来自特定的用户，把它们路由到服务的不同版本。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">        <span class="attr">end-user:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">jason</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><h3 id="hosts"><a href="#hosts" class="headerlink" title="hosts"></a>hosts</h3><p>使用 hosts 字段列举 Virtual Service 的主机——即用户指定的目标或是路由规则设定的目标。这是客户端向服务发送请求时使用的一个或多个地址。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hosts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">reviews</span></span><br></pre></td></tr></table></figure><p>Virtual Service 主机名可以是 IP 地址、DNS 名称，或者依赖于平台的一个简称（例如 Kubernetes 服务的短名称），隐式或显式地指向一个完全限定域名（FQDN）。也可以使用通配符（“*”）前缀，创建一组匹配所有服务的路由规则。Virtual Service 的 hosts 字段实际上不必是 Istio 服务注册的一部分，它只是虚拟的目标地址。可以为没有路由到网格内部的虚拟主机建模。</p><h3 id="路由规则"><a href="#路由规则" class="headerlink" title="路由规则"></a>路由规则</h3><p>在 http 字段包含了 Virtual Service 的路由规则，用来描述匹配条件和路由行为，它们把 HTTP&#x2F;1.1、HTTP2 和 gRPC 等流量发送到 hosts 字段指定的目标（也可以用 tcp 和 tls 为 TCP 和未终止的 TLS 流量设置路由规则）。一个路由规则包含了指定的请求要流向哪个目标地址，具有 0 或多个匹配条件，取决于使用场景。</p><h4 id="匹配条件"><a href="#匹配条件" class="headerlink" title="匹配条件"></a>匹配条件</h4><p>示例中的第一个路由规则有一个条件，因此以 match 字段开始。在本例中，希望此路由应用于来自 jason 用户的所有请求，所以使用 headers、end-user 和 exact 字段匹配相关请求。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">       <span class="attr">end-user:</span></span><br><span class="line">         <span class="attr">exact:</span> <span class="string">jason</span></span><br></pre></td></tr></table></figure><h4 id="目的地"><a href="#目的地" class="headerlink" title="目的地"></a>目的地</h4><p>route 部分的 destination 字段指定了符合此条件的流量的实际目标地址。与 Virtual Service 的 hosts 不同，destination 的 host 必须是存在于 Istio 服务注册中心的实际目标地址，否则 Envoy 不知道该将请求发送到哪里。可以是一个有代理的服务网格，或者是一个通过 Service Entry 被添加进来的非网格服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">route:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">    <span class="attr">subset:</span> <span class="string">v2</span></span><br></pre></td></tr></table></figure><p>在示例中，为了简单，使用 Kubernetes 的短名称设置 destination 的 host。在评估此规则时，Istio 会添加一个基于 Virtual Service 命名空间的域后缀，这个 Virtual Service 包含要获取主机的完全限定名的路由规则。在示例中使用短名称也意味着可以复制并在任何命名空间中尝试它们。</p><p><em>只有在目标主机和 Virtual Service 位于相同的 Kubernetes 命名空间时才可以使用这样的短名称。因为使用 Kubernetes 的短名称容易导致配置出错，建议在生产环境中指定完全限定的主机名</em></p><p>destination 还指定了 Kubernetes 服务的子集，将符合此规则条件的请求转入其中。在本例中子集名称是 v2。</p><h4 id="路由规则优先级"><a href="#路由规则优先级" class="headerlink" title="路由规则优先级"></a>路由规则优先级</h4><p>路由规则按从上到下的顺序选择，Virtual Service 中定义的第一条规则有最高优先级。本示例中，不满足第一个路由规则的流量均流向一个默认的目标（即 v2 子集），该目标在第二条规则中指定。因此，第二条规则没有 match 条件，直接将流量导向 v3 子集。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">      <span class="attr">subset:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>建议提供一个默认的”无条件”或基于权重的规则作为每一个 Virtual Service 的最后一条规则，从而确保流经 Virtual Service 的流量至少能够匹配一条路由规则。</p><h3 id="路由规则的更多内容"><a href="#路由规则的更多内容" class="headerlink" title="路由规则的更多内容"></a>路由规则的更多内容</h3><p>路由规则是将特定流量子集路由到指定目标地址的强大工具。可以在流量端口、header 字段、URI 等内容上设置匹配条件。例如，这个 Virtual Service 让用户发送请求到两个独立的服务：ratings 和 reviews。Virtual Service 规则根据请求的 URI 和指向适当服务的请求匹配流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bookinfo.com</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/reviews</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/ratings</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">      <span class="attr">sourceLabels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">reviews</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>有些匹配条件可以使用精确的值，如前缀或正则。</p><p>可以使用 AND 向同一个 match 块添加多个匹配条件，或者使用 OR 向同一个规则添加多个 match 块。对于任何给定的 Virtual Service 也可以有多个路由规则。</p><p>另外，使用匹配条件可以按百分比”权重“分发请求。这在 A&#x2F;B 测试和金丝雀发布中非常有用。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">75</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">25</span></span><br></pre></td></tr></table></figure><p>也可以使用路由规则在流量上执行一些操作，例如：</p><ul><li>添加或删除 header</li><li>重写 URL</li><li>为调用这一目标地址的请求设置重试策略</li></ul><h1 id="Destination-Rule"><a href="#Destination-Rule" class="headerlink" title="Destination Rule"></a>Destination Rule</h1><p>与 Virtual Service 一样，Destination Rule 也是 Istio 流量路由功能的关键部分。可以将 Virtual Service 视为将流量如何路由到给定目标地址，然后使用 Destination Rule 来配置该目标的流量。在评估 Virtual Service 路由规则之后，Destination Rule 将应用于流量的真实目标地址。</p><p>可以使用 Destination Rule 来指定命名的服务子集，例如按版本为所有给定服务的实例分组。然后可以在 Virtual Service 的路由规则中使用这些服务子集来控制到服务不同实例的流量。</p><p>Destination Rule 还允许在调用整个目的地服务或特定服务子集时定制 Envoy 的流量策略，比如负载均衡模型、TLS 安全模式或熔断器设置。</p><h2 id="负载均衡选项"><a href="#负载均衡选项" class="headerlink" title="负载均衡选项"></a>负载均衡选项</h2><p>默认情况下，Istio 使用轮询的负载均衡策略，实例池中的每个实例依次获取请求。Istio 同时支持如下的负载均衡模型，可以在 DestinationRule 中为流向某个特定服务或服务子集的流量指定这些模型。</p><ul><li>Random：请求以随机的方式转到池中的实例</li><li>Weighted：请求根据指定的百分比转到实例</li><li>Least requests：请求被转到最少被访问的实例</li></ul><h2 id="Destination-Rule-示例"><a href="#Destination-Rule-示例" class="headerlink" title="Destination Rule 示例"></a>Destination Rule 示例</h2><p>下面的示例为 my-svc 目标服务配置了 3 个具有不同负载均衡策略的子集：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-destination-rule</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">my-svc</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">RANDOM</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">trafficPolicy:</span></span><br><span class="line">      <span class="attr">loadBalancer:</span></span><br><span class="line">        <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v3</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>每个子集都是基于一个或多个 labels 定义的，在 Kubernetes 中它是附加到像 Pod 这种对象上的键&#x2F;值对。这些标签应用于 Kubernetes 服务的 Deployment 并作为 metadata 来识别不同的版本。</p><p>除了定义子集之外，Destination Rule 对于所有子集都有默认的流量策略，而对于该子集，则有特定于子集的策略覆盖它。定义在 subsets 上的默认策略，为 v1 和 v3 子集设置了一个简单的随机负载均衡器。为  v2 子集设置了一个轮询负载均衡器。</p><h1 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h1><p>使用 Gateway 为网格来管理入站和出站流量，可以指定要进入或离开网格的流量。网关配置被用于运行在网格边界的独立 Envoy 代理，而不是服务工作负载的 sidecar 代理。</p><p>与 Kubernetes Ingress API 这种控制进入系统流量的其他机制不同，Istio Gateway 充分利用流量路由的强大能力和灵活性。可以这么做的原因是 Istio 的 Gateway 资源可以配置 4-6 层的负载均衡属性，如对外暴露的端口、TLS 设置等。作为替代应用层流量路由（L7）到相同的 API 资源，绑定了一个常规的 Istio Virtual Service 到 Gateway 。可以像管理网格中其他数据平面的流量一样去管理网关流量。</p><p>Gateway 主要用于管理进入的流量，但也可以配置出口 Gateway 。出口 Gateway 为离开网格的流量配置一个专用的出口节点，这可以限制哪些服务可以或应该访问外部网络，或者启用出口流量安全控制为网格添加安全性。也可以使用 Gateway 配置一个纯粹的内部代理。</p><p>Istio 提供了一些预先配置好的 Gateway 代理服务（istio-ingressgateway 和 istio-egressgateway）。</p><h2 id="Gateway-示例"><a href="#Gateway-示例" class="headerlink" title="Gateway 示例"></a>Gateway 示例</h2><p>下面的示例展示了一个外部 HTTPS 入口流量的网关配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ext-host-gwy</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">my-gateway-controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ext-host.example.com</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">SIMPLE</span></span><br><span class="line">      <span class="attr">serverCertificate:</span> <span class="string">/tmp/tls.crt</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/tmp/tls.key</span></span><br></pre></td></tr></table></figure><p>这个 Gateway 配置让 HTTPS 流量从 ext-host.example.com 通过 443 端口流入网格，但没有为请求指定任何路由规则。</p><p>为想要生效的 Gateway 指定路由，必须把 Gateway 绑定到 Virtual Service 上。然后就可以为出口流量配置带有路由规则的 Virtual Service。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">virtual-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ext-host.example.com</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ext-host-gwy</span></span><br></pre></td></tr></table></figure><h1 id="Service-Entry"><a href="#Service-Entry" class="headerlink" title="Service Entry"></a>Service Entry</h1><p>使用 Service Entry 来添加一个入口到 Istio 内部维护的服务注册中心。添加了 Service Entry 后，Envoy 代理可以向服务发送流量，就好像它是网格内部的服务一样。配置 Service Entry 允许管理运行在网格外的服务的流量，它包括以下几种能力：</p><ul><li>为外部目标 redirect 和转发请求，例如来自 web 端的 API 调用，或者流向遗留老系统的服务</li><li>为外部目标定义重试、超时和故障注入策略</li><li>添加一个运行在虚拟机的服务来扩展您的网格</li></ul><p>不需要为网格服务要使用的每个外部服务都添加 Service Entry。默认情况下，Istio 配置 Envoy 代理将请求传递给未知服务。但是，不能使用 Istio 的特性来控制没有在网格中注册的目标流量。</p><h2 id="Service-Entry-示例"><a href="#Service-Entry-示例" class="headerlink" title="Service Entry 示例"></a>Service Entry 示例</h2><p>下面的 Service Entry 将外部服务 ext-svc.example.com 添加到 Istio 的服务注册中心：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-entry</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ext-svc.example.com</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br></pre></td></tr></table></figure><p>指定的外部资源使用 hosts 字段。可以使用完全限定名或通配符作为前缀域名。</p><p>可以配置 Virtual Service 和 Destination Rule，以更细粒度的方式控制到 Service Entry 的流量，这与网格中的任何其他服务配置流量的方式相同。</p><p>例如，下面的 Destination Rule 调整了使用 Service Entry 配置的 ext-svc.example.com  外部服务的连接超时：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ext-res-dr</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">ext-svc.example.com</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">connectionPool:</span></span><br><span class="line">      <span class="attr">tcp:</span></span><br><span class="line">        <span class="attr">connectTimeout:</span> <span class="string">1s</span></span><br></pre></td></tr></table></figure><h1 id="Sidecar"><a href="#Sidecar" class="headerlink" title="Sidecar"></a>Sidecar</h1><p>默认情况下，Istio 让每个 Envoy 代理都可以访问来自和它关联的工作负载的所有端口的请求，然后转发到对应的工作负载。可以使用 Sidecar 配置去做下面的事情：</p><ul><li>微调 Envoy 代理接受的端口和协议集</li><li>限制 Envoy 代理可以访问的服务集合</li></ul><p>可能希望在较庞大的应用程序中限制这样的 Sidecar 可达性，配置每个代理能访问网格中的任意服务可能会因为高内存使用量而影响网格的性能。</p><p>可以指定将 Sidecar 配置应用于特定命名空间中的所有工作负载，或者使用 workloadSelector 选择特定的工作负载。</p><p>例如，下面的 Sidecar 配置将 bookinfo 命名空间中的所有服务配置为仅能访问运行在相同命名空间和 istio-system 服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;./*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;istio-system/*&quot;</span></span><br></pre></td></tr></table></figure><h1 id="网络弹性和测试"><a href="#网络弹性和测试" class="headerlink" title="网络弹性和测试"></a>网络弹性和测试</h1><p>除了为网格导流之外，Istio 还提供了可选的故障恢复和故障注入功能，可以在运行时动态配置这些功能。使用这些特性可以让应用程序运行稳定，确保服务网格能够容忍故障节点，并防止局部故障级联影响到其他节点。</p><h2 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h2><p>超时是 Envoy 代理等待来自给定服务的答复的时间量，以确保服务不会因为等待答复而无限期的挂起，并在可预测的时间范围内调用成功或失败。HTTP 请求的默认超时时间是 15 秒，这意味着如果服务在 15 秒内没有响应，调用将失败。</p><p>对于某些应用程序和服务，Istio 的缺省超时可能不合适。例如，超时太长可能会由于等待失败服务的回复而导致过度的延迟；而超时过短则可能在等待涉及多个服务返回的操作时触发不必要地失败。为了找到并使用最佳超时设置，Istio 允许使用 Virtual Service 按服务轻松地动态调整超时，而不必修改业务代码。</p><p>例如，下面的 Virtual Service 配置对 ratings 服务的 v1 子集的调用指定 10 秒超时：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">10s</span></span><br></pre></td></tr></table></figure><h2 id="重试"><a href="#重试" class="headerlink" title="重试"></a>重试</h2><p>重试设置指定如果初始调用失败，Envoy 代理尝试连接服务的最大次数。通过确保调用不会因为临时过载的服务或网络等问题而永久失败，重试可以提高服务可用性和应用程序的性能。重试之间的间隔（25ms+）是可变的，并由 Istio 自动确定，从而防止被调用服务被请求淹没。HTTP 请求的默认重试行为是在返回错误之前重试两次。</p><p>与超时一样，Istio 默认的重试行为在延迟方面可能不适合应用程序需求（对失败的服务进行过多的重试会降低速度）或可用性。可以在 Virtual Service 中按服务调整重试设置，而不必修改业务代码。还可以通过添加每次重试的超时来进一步细化重试行为，并指定每次重试都试图成功连接到服务所等待的时间量。</p><p>例如，下面的 Virtual Service 配置在初始调用失败后最多重试 3 次来连接到服务子集，每个重试都有 2 秒的超时：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">retries:</span></span><br><span class="line">      <span class="attr">attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">perTryTimeout:</span> <span class="string">2s</span></span><br></pre></td></tr></table></figure><h2 id="熔断器"><a href="#熔断器" class="headerlink" title="熔断器"></a>熔断器</h2><p>熔断器是 Istio 为创建具有弹性的微服务应用提供的另一个有用的机制。在熔断器中，设置一个对服务中的单个主机调用的限制，例如并发连接的数量或对该主机调用失败的次数。一旦限制被触发，熔断器就会“跳闸”并停止连接到该主机。使用熔断模式可以快速失败而不必让客户端尝试连接到过载或有故障的主机。</p><p>熔断适用于在负载均衡池中的真实网格目标地址，可以在 Destination Rule 中配置熔断器阈值，让配置适用于服务中的每个主机。</p><p>例如，下面的 Destination Rule 配置将 v1 子集的 reviews 服务工作负载的并发连接数限制为 100：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">trafficPolicy:</span></span><br><span class="line">      <span class="attr">connectionPool:</span></span><br><span class="line">        <span class="attr">tcp:</span></span><br><span class="line">          <span class="attr">maxConnections:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="故障注入"><a href="#故障注入" class="headerlink" title="故障注入"></a>故障注入</h2><p>在配置了网络，包括故障恢复策略之后，可以使用 Istio 的故障注入机制来为整个应用程序测试故障恢复能力。故障注入是一种将错误引入系统以确保系统能够承受并从错误条件中恢复的测试方法。使用故障注入特别有用，能确保故障恢复策略不至于不兼容或者太严格，这会导致关键服务不可用。</p><p><em>目前，故障注入配置不能与同一个 Virtual Service 上的重试或超时配置相结合</em></p><p>与其他错误注入机制（如延迟数据包或在网络层杀掉 Pod）不同，Istio 允许在应用层注入错误。这可以注入更多相关的故障，例如 HTTP 错误码，以获得更多相关的结果。</p><p>可以注入两种故障，它们都使用 Virtual Service 配置：</p><ul><li>延迟：延迟是时间故障。它们模拟增加的网络延迟或一个超载的上游服务</li><li>终止：终止是崩溃失败。它们模仿上游服务的失败。终止通常以 HTTP 错误码或 TCP 连接失败的形式出现</li></ul><p>例如，下面的 Virtual Service 示例为千分之一的访问 ratings 服务的请求配置了一个 5 秒的延迟：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">fault:</span></span><br><span class="line">      <span class="attr">delay:</span></span><br><span class="line">        <span class="attr">percentage:</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">0.1</span></span><br><span class="line">        <span class="attr">fixedDelay:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure><h2 id="与应用程序协同工作"><a href="#与应用程序协同工作" class="headerlink" title="与应用程序协同工作"></a>与应用程序协同工作</h2><p>Istio 故障恢复功能对应用程序来说是完全透明的。在返回响应之前，应用程序不知道 Envoy Sidecar 代理是否正在处理被调用服务的故障。这意味着，如果在应用程序代码中设置了故障恢复策略，那么需要记住这两个策略都是独立工作的，否则会发生冲突。例如，假设设置了两个超时，一个在 Virtual Service 中配置，另一个在应用程序中配置。应用程序为服务的 API 调用设置了 2 秒超时。而在 Virtual Service 中配置了一个 3 秒超时和重试。在这种情况下，应用程序的超时会先生效，因此 Envoy 的超时和重试尝试会失效。</p><p>虽然 Istio 故障恢复特性提高了网格中服务的可靠性和可用性，但应用程序必须处理故障或错误并采取适当的回退操作。例如，当负载均衡中的所有实例都失败时，Envoy 返回一个 HTTP 503 状态码。应用程序必须实现回退逻辑来处理 HTTP 503 错误代码。</p>]]></content>
    
    
    <summary type="html">Istio 流量管理的设计概述与使用范例</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Istio 」快速开始</title>
    <link href="http://shenxianghong.github.io/2022/05/04/2022-05-04%20Istio%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2022/05/04/2022-05-04%20Istio%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2022-05-03T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.171Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="120" style="border: 0px" src="/gallery/istio/logo.svg"></div><hr><blockquote><p>based on <strong>1.15.0</strong></p></blockquote><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Istio 是一个开源服务网格，它透明地分层到现有的分布式应用程序上。 Istio 强大的特性提供了一种统一和更有效的方式来保护、连接和监视服务。 Istio 是实现负载平衡、服务到服务身份验证和监视的路径——只需要很少或不需要更改服务代码。它强大的控制平面带来了重要的特点，包括：</p><ul><li>使用 TLS 加密、强身份认证和授权的集群内服务到服务的安全通信</li><li>自动负载均衡的 HTTP、gRPC、WebSocket，和 TCP 流量</li><li>通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制</li><li>一个可插入的策略层和配置 API，支持访问控制、速率限制和配额</li><li>对集群内的所有流量（包括集群入口和出口）进行自动度量、日志和跟踪</li></ul><p>Istio 是为可扩展性而设计的，可以处理不同范围的部署需求。Istio 的控制平面运行在 Kubernetes 上，您可以将部署在该集群中的应用程序添加到您的网格中，将网格扩展到其他集群，甚至连接 VM 或运行在 Kubernetes 之外的其他端点。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="Istio-与-Kubernetes-版本映射关系"><a href="#Istio-与-Kubernetes-版本映射关系" class="headerlink" title="Istio 与 Kubernetes 版本映射关系"></a>Istio 与 Kubernetes 版本映射关系</h3><p>参考：<a href="https://istio.io/latest/docs/setup/platform-setup/">https://istio.io/latest/docs/setup/platform-setup/</a></p><table><thead><tr><th>Version</th><th>Currently Supported</th><th>Release Date</th><th>End of Life</th><th>Supported Kubernetes Versions</th><th>Tested, but not supported</th></tr></thead><tbody><tr><td>master</td><td>No, development only</td><td></td><td></td><td></td><td></td></tr><tr><td>1.15</td><td>Yes</td><td>August 31, 2022</td><td>~March 2023 (Expected)</td><td>1.22, 1.23, 1.24, 1.25</td><td>1.16, 1.17, 1.18, 1.19, 1.20, 1.21</td></tr><tr><td>1.14</td><td>Yes</td><td>May 24, 2022</td><td>~January 2023 (Expected)</td><td>1.21, 1.22, 1.23, 1.24</td><td>1.16, 1.17, 1.18, 1.19, 1.20</td></tr><tr><td>1.13</td><td>Yes</td><td>February 11, 2022</td><td>~October 2022 (Expected)</td><td>1.20, 1.21, 1.22, 1.23</td><td>1.16, 1.17, 1.18, 1.19</td></tr><tr><td>1.12</td><td>Yes</td><td>November 18, 2021</td><td>~June 2022 (Expected)</td><td>1.19, 1.20, 1.21, 1.22</td><td>1.16, 1.17, 1.18</td></tr><tr><td>1.11</td><td>Yes</td><td>August 12, 2021</td><td>~Mar 2022 (Expected)</td><td>1.18, 1.19, 1.20, 1.21, 1.22</td><td>1.16, 1.17</td></tr><tr><td>1.10</td><td>No</td><td>May 18, 2021</td><td>Jan 7, 2022</td><td>1.18, 1.19, 1.20, 1.21</td><td>1.16, 1.17, 1.22</td></tr><tr><td>1.9</td><td>No</td><td>February 9, 2021</td><td>Oct 8, 2021</td><td>1.17, 1.18, 1.19, 1.20</td><td>1.15, 1.16</td></tr><tr><td>1.8</td><td>No</td><td>November 10, 2020</td><td>May 12, 2021</td><td>1.16, 1.17, 1.18, 1.19</td><td>1.15</td></tr><tr><td>1.7</td><td>No</td><td>August 21, 2020</td><td>Feb 25, 2021</td><td>1.16, 1.17, 1.18</td><td>1.15</td></tr><tr><td>1.6 and earlier</td><td>No</td><td></td><td></td><td></td><td></td></tr></tbody></table><h3 id="profile-概念"><a href="#profile-概念" class="headerlink" title="profile 概念"></a>profile 概念</h3><p>参考：<a href="https://istio.io/latest/docs/setup/additional-setup/config-profiles/">https://istio.io/latest/docs/setup/additional-setup/config-profiles/</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl profile list</span></span><br><span class="line">Istio configuration profiles:</span><br><span class="line">    default</span><br><span class="line">    demo</span><br><span class="line">    empty</span><br><span class="line">    external</span><br><span class="line">    minimal</span><br><span class="line">    openshift</span><br><span class="line">    preview</span><br></pre></td></tr></table></figure><p>profile 描述了 Istio 控制平面与数据平面的配置信息，以下为 Istio 内建的 profile 类别，同时也支持自定义的 profile。</p><ul><li>default<br><em>根据 <a href="https://istio.io/latest/zh/docs/reference/config/istio.operator.v1alpha1/">IstioOperator API</a> 的默认设置启动组件。 建议用于生产部署和 <a href="https://istio.io/latest/zh/docs/ops/deployment/deployment-models/#multiple-clusters">Multicluster Mesh</a> 中的 Primary Cluster</em></li><li>demo<br><em>这一配置具有适度的资源需求，旨在展示 Istio 功能的配置。它适合运行 <a href="https://istio.io/latest/docs/examples/bookinfo/">Bookinfo</a> 应用程序和相关任务</em></li><li>empty<br><em>什么都不部署。可以作为自定义配置的基本配置文件</em></li><li>external<br><em>用于配置远程集群由一个外部控制平面或者通过控制平面主要集群<a href="https://istio.io/latest/docs/ops/deployment/deployment-models/#multiple-clusters">多集群网格</a></em></li><li>minimal<br><em>与默认配置文件相同，但仅安装控制平面组件。这允许您使用<a href="https://istio.io/latest/docs/setup/additional-setup/gateway/#deploying-a-gateway">单独的配置文件</a>配置控制平面和数据平面组件（例如网关）</em></li><li>openshift</li><li>preview<br><em>包含实验性功能。旨在探索 Istio 的新功能。不能保证稳定性、安全性和性能</em></li></ul><p><strong>不同的 profile 包含的核心组件</strong></p><table><thead><tr><th></th><th>default</th><th>demo</th><th>minimal</th><th>external</th><th>empty</th><th>preview</th></tr></thead><tbody><tr><td>Core components</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>istio-egressgateway</td><td></td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td>istio-ingressgateway</td><td>✔</td><td>✔</td><td></td><td></td><td></td><td>✔</td></tr><tr><td>istiod</td><td>✔</td><td>✔</td><td>✔</td><td></td><td></td><td>✔</td></tr></tbody></table><p><strong>展示 profile 具体内容</strong></p><p>可以将 profile dump 出来，便于浏览和修改配置信息，可以看到 profile 的本质就是 IstioOperator 资源（详见下文）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl profile dump demo</span></span><br><span class="line">apiVersion: install.istio.io/v1alpha1</span><br><span class="line">kind: IstioOperator</span><br><span class="line">spec:</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>也可以进一步通过 <code>--config-path</code> 参数（更多配置参考：<a href="https://istio.io/latest/docs/reference/config/%EF%BC%89%EF%BC%8C%E9%80%89%E6%8B%A9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E6%8C%87%E5%AE%9A%E8%B7%AF%E5%BE%84%E7%9A%84%E5%B1%80%E9%83%A8%E5%86%85%E5%AE%B9">https://istio.io/latest/docs/reference/config/），选择配置文件中指定路径的局部内容</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl profile dump --config-path components.pilot demo</span></span><br><span class="line">enabled: true</span><br><span class="line">k8s:</span><br><span class="line">  env:</span><br><span class="line">  - name: PILOT_TRACE_SAMPLING</span><br><span class="line">    value: &quot;100&quot;</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 10m</span><br><span class="line">      memory: 100Mi</span><br></pre></td></tr></table></figure><p><strong>展示 profile 之间差别</strong></p><p>可以看到 default 和 demo profile 之间的差别之一是，default 不会部署 istio-egressgateway 组件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl profile diff default demo</span></span><br><span class="line">spec:</span><br><span class="line">   components:</span><br><span class="line">     base:</span><br><span class="line">       enabled: true</span><br><span class="line">     cni:</span><br><span class="line">       enabled: false</span><br><span class="line">     egressGateways:</span><br><span class="line">-    - enabled: false</span><br><span class="line">+    - enabled: true</span><br><span class="line">+      k8s:</span><br><span class="line">+        resources:</span><br><span class="line">+          requests:</span><br><span class="line">+            cpu: 10m</span><br><span class="line">+            memory: 40Mi</span><br><span class="line">       name: istio-egressgateway</span><br></pre></td></tr></table></figure><h3 id="Istio-准备"><a href="#Istio-准备" class="headerlink" title="Istio 准备"></a>Istio 准备</h3><p>Istio 可以通过 <a href="https://github.com/istio/istio/releases/tag/1.15.0">release</a> 下载，也可以通过 Istio 官方提供的 downloadIstio 脚本下载，两者等价</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -L https://istio.io/downloadIstio | sh -</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">脚本本身也提供了诸多参数，例如指定版本、指定架构下载</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.15.0 TARGET_ARCH=x86_64 sh -</span></span><br></pre></td></tr></table></figure><p>下载后包括以下内容，其中 istioctl 位于 bin 目录中，示例位于 samples 目录中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">bin  LICENSE  manifests  manifest.yaml  README.md  samples  tools</span><br></pre></td></tr></table></figure><h3 id="环境预检"><a href="#环境预检" class="headerlink" title="环境预检"></a>环境预检</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl x precheck</span></span><br><span class="line">✔ No issues found when checking the cluster. Istio is safe to install or upgrade!</span><br><span class="line">  To get started, check out https://istio.io/latest/docs/setup/getting-started/</span><br></pre></td></tr></table></figure><h2 id="通过-Istioctl-安装"><a href="#通过-Istioctl-安装" class="headerlink" title="通过 Istioctl 安装"></a>通过 Istioctl 安装</h2><p>安装默认的 Istio（即 profile 为 default），该 profile 常用于生产环境。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl install</span></span><br></pre></td></tr></table></figure><p>也可以进行一些定制化（–set），例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl install --<span class="built_in">set</span> meshConfig.accessLogFile=/dev/stdout</span></span><br></pre></td></tr></table></figure><p>该效果等价于（-f），使用 Istio Operator API 的方式更适用于生产环境。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl install -f - &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">apiVersion: install.istio.io/v1alpha1</span><br><span class="line">kind: IstioOperator</span><br><span class="line">spec:</span><br><span class="line">  meshConfig:</span><br><span class="line">    accessLogFile: /dev/stdout</span><br><span class="line">EOF    </span><br></pre></td></tr></table></figure><p>为了更好的演示 Istio 的特性，因此使用 demo 的 profile 安装 Istio。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl install --<span class="built_in">set</span> profile=demo -y</span></span><br><span class="line">✔ Istio core installed</span><br><span class="line">✔ Istiod installed</span><br><span class="line">✔ Egress gateways installed</span><br><span class="line">✔ Ingress gateways installed</span><br><span class="line">✔ Installation complete</span><br></pre></td></tr></table></figure><h2 id="通过-Istio-Operator-安装"><a href="#通过-Istio-Operator-安装" class="headerlink" title="通过 Istio Operator 安装"></a>通过 Istio Operator 安装</h2><p>类似于 Prometheus Operator，Istio 提供了通过 Operator 安装 Istio 的方式，只需要简单的更新 Istio Operator 声明的 API 对象，便可以非常便捷地处理多版本 Istio。</p><h3 id="部署-Istio-Operator"><a href="#部署-Istio-Operator" class="headerlink" title="部署 Istio Operator"></a>部署 Istio Operator</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl operator init</span></span><br><span class="line">Installing operator controller in namespace: istio-operator using image: docker.io/istio/operator:1.15.0</span><br><span class="line">Operator controller will watch namespaces: istio-system</span><br><span class="line">✔ Istio operator installed</span><br><span class="line">✔ Installation complete</span><br></pre></td></tr></table></figure><p>在部署 Istio Operator 时，支持指定详细规格（更多配置参考：<a href="https://istio.io/latest/docs/reference/config/%EF%BC%89%E3%80%82%E4%BE%8B%E5%A6%82%EF%BC%8C%E5%9C%A8%E6%8C%87%E5%AE%9A%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E8%A7%82%E6%B5%8B%E8%B5%84%E6%BA%90%E3%80%82">https://istio.io/latest/docs/reference/config/）。例如，在指定命名空间观测资源。</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl operator init --watchedNamespaces=istio-namespace1,istio-namespace2</span></span><br></pre></td></tr></table></figure><p>部署 Istio Operator 后会产生以下资源</p><ul><li><p>CRD</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get crd | grep istio</span></span><br><span class="line">istiooperators.install.istio.io                       2022-05-14T03:11:20Z</span><br></pre></td></tr></table></figure></li><li><p>Deployment</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deploy -n istio-operator</span></span><br><span class="line">NAME             READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">istio-operator   1/1     1            1           6m20s</span><br></pre></td></tr></table></figure></li><li><p>Service（用于暴露 Istio Operator 指标）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n istio-operator</span></span><br><span class="line">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">istio-operator   ClusterIP   10.96.212.28   &lt;none&gt;        8383/TCP   6m47s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 10.96.212.28:8383/metrics</span></span><br></pre></td></tr></table></figure></li><li><p>RBAC（细节不做展示）</p></li></ul><h3 id="创建-IstioOperator-资源"><a href="#创建-IstioOperator-资源" class="headerlink" title="创建 IstioOperator 资源"></a>创建 IstioOperator 资源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f - &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">apiVersion: install.istio.io/v1alpha1</span><br><span class="line">kind: IstioOperator</span><br><span class="line">metadata:</span><br><span class="line">  namespace: istio-system</span><br><span class="line">  name: example-istiocontrolplane</span><br><span class="line">spec:</span><br><span class="line">  profile: demo</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>Istio Operator watch 到 IstioOperator 资源，然后根据 spec 中声明的详细规格（具体参考：更多配置参考：<a href="https://istio.io/latest/docs/reference/config/%EF%BC%89%EF%BC%8C%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2">https://istio.io/latest/docs/reference/config/），安装部署</a> Istio 服务。</p><h2 id="安装内容"><a href="#安装内容" class="headerlink" title="安装内容"></a>安装内容</h2><p>安装 Istio（profile 为 demo）后会产生以下资源</p><ul><li><p>Deployment</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deploy -n istio-system</span></span><br><span class="line">NAME                   READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">istio-egressgateway    1/1     1            1           4m14s</span><br><span class="line">istio-ingressgateway   1/1     1            1           4m14s</span><br><span class="line">istiod                 1/1     1            1           4m23s</span><br></pre></td></tr></table></figure></li><li><p>Service</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n istio-system</span></span><br><span class="line">NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE</span><br><span class="line">istio-egressgateway    ClusterIP      10.96.206.121   &lt;none&gt;        80/TCP,443/TCP                                                               85s</span><br><span class="line">istio-ingressgateway   LoadBalancer   10.96.159.246   &lt;pending&gt;     15021:31641/TCP,80:31235/TCP,443:30268/TCP,31400:32741/TCP,15443:31149/TCP   85s</span><br><span class="line">istiod                 ClusterIP      10.96.2.143     &lt;none&gt;        15010/TCP,15012/TCP,443/TCP,15014/TCP                                        2m24s</span><br></pre></td></tr></table></figure></li><li><p>CRD</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get crd | grep istio</span></span><br><span class="line">authorizationpolicies.security.istio.io               2022-09-13T05:55:57Z</span><br><span class="line">destinationrules.networking.istio.io                  2022-09-13T05:55:57Z</span><br><span class="line">envoyfilters.networking.istio.io                      2022-09-13T05:55:57Z</span><br><span class="line">gateways.networking.istio.io                          2022-09-13T05:55:57Z</span><br><span class="line">istiooperators.install.istio.io                       2022-09-13T05:55:57Z</span><br><span class="line">peerauthentications.security.istio.io                 2022-09-13T05:55:57Z</span><br><span class="line">proxyconfigs.networking.istio.io                      2022-09-13T05:55:57Z</span><br><span class="line">requestauthentications.security.istio.io              2022-09-13T05:55:58Z</span><br><span class="line">serviceentries.networking.istio.io                    2022-09-13T05:55:58Z</span><br><span class="line">sidecars.networking.istio.io                          2022-09-13T05:55:58Z</span><br><span class="line">telemetries.telemetry.istio.io                        2022-09-13T05:55:58Z</span><br><span class="line">virtualservices.networking.istio.io                   2022-09-13T05:55:58Z</span><br><span class="line">wasmplugins.extensions.istio.io                       2022-09-13T05:55:58Z</span><br><span class="line">workloadentries.networking.istio.io                   2022-09-13T05:55:58Z</span><br><span class="line">workloadgroups.networking.istio.io                    2022-09-13T05:55:58Z</span><br></pre></td></tr></table></figure></li><li><p>webhook</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get mutatingwebhookconfigurations</span></span><br><span class="line">NAME                         WEBHOOKS   AGE</span><br><span class="line">istio-revision-tag-default   4          8m57s</span><br><span class="line">istio-sidecar-injector       4          9m19s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get validatingwebhookconfigurations</span></span><br><span class="line">NAME                           WEBHOOKS   AGE</span><br><span class="line">istio-validator-istio-system   1          9m27s</span><br><span class="line">istiod-default-validator       1          9m4s</span><br></pre></td></tr></table></figure></li><li><p>RBAC，PodDisruptionBudget，ConfigMap，EnvoyFilter（细节不做展示）</p></li></ul><p>也可以查看 IstioOperator 对象来获取安装细节，installed-state 为 istioctl 安装的默认名称。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get istiooperator -n istio-system</span></span><br><span class="line">NAME              REVISION   STATUS   AGE</span><br><span class="line">installed-state                       10m</span><br></pre></td></tr></table></figure><p>如果 Istio 集群由 Istio Operator 创建，那么 Istio Operator 会维护 IstioOperator 对象。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get istiooperator -n istio-system</span></span><br><span class="line">NAMESPACE      NAME                        REVISION   STATUS    AGE</span><br><span class="line">istio-system   example-istiocontrolplane              HEALTHY   2m59s</span><br></pre></td></tr></table></figure><p>此外，也可以生成安装的资源清单，并校验安装是否完整。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl manifest generate --<span class="built_in">set</span> profile=demo | istioctl verify-install -f -</span></span><br><span class="line">...</span><br><span class="line">✔ Service: istio-ingressgateway.istio-system checked successfully</span><br><span class="line">✔ Service: istiod.istio-system checked successfully</span><br><span class="line">Checked 15 custom resource definitions</span><br><span class="line">Checked 3 Istio Deployments</span><br><span class="line">✔ Istio is installed and verified successfully</span><br></pre></td></tr></table></figure><h2 id="配置校验"><a href="#配置校验" class="headerlink" title="配置校验"></a>配置校验</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl analyze --all-namespaces</span></span><br><span class="line"></span><br><span class="line">✔ No validation issues found when analyzing all namespaces.</span><br></pre></td></tr></table></figure><p>例如，当 VirtualService 指向的 Gateway 不存在时：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl analyze --all-namespaces</span></span><br><span class="line">Error [IST0101] (VirtualService default/bookinfo) Referenced gateway not found: &quot;bookinfo-gateway-error&quot;</span><br><span class="line">Warning [IST0132] (VirtualService default/bookinfo) one or more host [*] defined in VirtualService default/bookinfo not found in Gateway default/bookinfo-gateway-error.</span><br><span class="line">Error: Analyzers found issues when analyzing all namespaces.</span><br><span class="line">See https://istio.io/v1.15/docs/reference/config/analysis for more information about causes and resolutions.</span><br></pre></td></tr></table></figure><h1 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h1><h2 id="卸载-Istio-Operator"><a href="#卸载-Istio-Operator" class="headerlink" title="卸载 Istio Operator"></a>卸载 Istio Operator</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl operator remove</span></span><br><span class="line">Removing Istio operator...</span><br><span class="line">  Removed Deployment:istio-operator:istio-operator.</span><br><span class="line">  Removed Service:istio-operator:istio-operator.</span><br><span class="line">  Removed ServiceAccount:istio-operator:istio-operator.</span><br><span class="line">  Removed ClusterRole::istio-operator.</span><br><span class="line">  Removed ClusterRoleBinding::istio-operator.</span><br><span class="line">✔ Removal complete</span><br></pre></td></tr></table></figure><h2 id="卸载-Istio"><a href="#卸载-Istio" class="headerlink" title="卸载 Istio"></a>卸载 Istio</h2><p><code>--purge</code> 会移除所有 Istio 资源，包括集群级别的（会对其他共享资源的 Istio 集群造成破坏），更多配置参考：<a href="https://istio.io/latest/docs/reference/config/">https://istio.io/latest/docs/reference/config/</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl uninstall --purge</span></span><br></pre></td></tr></table></figure><p>也可以通过安装的资源清单，执行卸载操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">istioctl manifest generate --<span class="built_in">set</span> profile=demo | kubectl delete -f -</span></span><br></pre></td></tr></table></figure><p>默认情况下，istio-system namespace 不会被删除，需要手动删除。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete ns istio-system</span></span><br></pre></td></tr></table></figure><h1 id="BookInfo-示例"><a href="#BookInfo-示例" class="headerlink" title="BookInfo 示例"></a>BookInfo 示例</h1><p>这个示例部署了一个用于演示多种 Istio 特性的应用，该应用由四个单独的微服务构成。这个应用模仿在线书店的一个分类，显示一本书的信息。 页面上会显示一本书的描述，书籍的细节（ISBN、页数等），以及关于这本书的一些评论。</p><p>BookInfo 应用分为四个单独的微服务</p><ul><li>productpage 会调用 details 和 reviews 两个微服务，用来生成页面</li><li>details 包含了书籍的信息</li><li>reviews 包含了书籍相关的评论。它还会调用 ratings 微服务</li><li>ratings 包含了由书籍评价组成的评级信息</li></ul><p>reviews 微服务有 3 个版本</p><ul><li>v1 版本不会调用 ratings 服务</li><li>v2 版本会调用 ratings 服务，并使用 1 到 5 个黑色星形图标来显示评分信息</li><li>v3 版本会调用 ratings 服务，并使用 1 到 5 个红色星形图标来显示评分信息</li></ul><p>该应用的端到端架构如下</p><div align=center><img width="600" style="border: 0px" src="/gallery/istio/withistio.svg"></div><p>BookInfo 应用中的几个微服务是由不同的语言编写的。 这些服务对 Istio 并无依赖，但是构成了一个有代表性的服务网格的例子：它由多个服务、多个语言构成，并且 reviews 服务具有多个版本。</p><p>所有的微服务都和 Envoy sidecar 集成在一起，被集成服务所有的出入流量都被 sidecar 所劫持，这样就为外部控制准备了所需的 Hook，然后就可以利用 Istio 控制平面为应用提供服务路由、遥测数据收集以及策略实施等功能。</p><p>根据名为 istio-ingressgateway 的 Service 的信息，可以明确 http 的访问地址为 <code>http://178.104.162.69:31235</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n istio-system istio-ingressgateway</span></span><br><span class="line">NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE</span><br><span class="line">istio-ingressgateway   LoadBalancer   10.96.159.246   &lt;pending&gt;     15021:31641/TCP,80:31235/TCP,443:30268/TCP,31400:32741/TCP,15443:31149/TCP   3m34s</span><br></pre></td></tr></table></figure><h2 id="注入-Sidecar"><a href="#注入-Sidecar" class="headerlink" title="注入 Sidecar"></a>注入 Sidecar</h2><p>Istio 默认自动注入 Sidecar，目前为 default 命名空间打上标签 istio-injection&#x3D;enabled。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl label namespace default istio-injection=enabled</span></span><br></pre></td></tr></table></figure><h2 id="部署测试应用"><a href="#部署测试应用" class="headerlink" title="部署测试应用"></a>部署测试应用</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</span></span><br><span class="line">service/details created</span><br><span class="line">serviceaccount/bookinfo-details created</span><br><span class="line">deployment.apps/details-v1 created</span><br><span class="line">service/ratings created</span><br><span class="line">serviceaccount/bookinfo-ratings created</span><br><span class="line">deployment.apps/ratings-v1 created</span><br><span class="line">service/reviews created</span><br><span class="line">serviceaccount/bookinfo-reviews created</span><br><span class="line">deployment.apps/reviews-v1 created</span><br><span class="line">deployment.apps/reviews-v2 created</span><br><span class="line">deployment.apps/reviews-v3 created</span><br><span class="line">service/productpage created</span><br><span class="line">serviceaccount/bookinfo-productpage created</span><br><span class="line">deployment.apps/productpage-v1 created</span><br></pre></td></tr></table></figure><p>状态检查，可以看到所有的 Pod 均为 2 容器，其中就包含了 Sidecar 容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod</span></span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">details-v1-79f774bdb9-m9njc       2/2     Running   2          20m</span><br><span class="line">productpage-v1-6b746f74dc-8xps7   2/2     Running   2          20m</span><br><span class="line">ratings-v1-b6994bb9-54w28         2/2     Running   2          20m</span><br><span class="line">reviews-v1-545db77b95-57wkb       2/2     Running   2          20m</span><br><span class="line">reviews-v2-7bf8c9648f-qj7zg       2/2     Running   2          20m</span><br><span class="line">reviews-v3-84779c7bbc-fl2mx       2/2     Running   1          20m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc</span></span><br><span class="line">NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">details       ClusterIP   10.96.15.22     &lt;none&gt;        9080/TCP   13m</span><br><span class="line">kubernetes    ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    43d</span><br><span class="line">productpage   ClusterIP   10.96.59.210    &lt;none&gt;        9080/TCP   13m</span><br><span class="line">ratings       ClusterIP   10.96.136.207   &lt;none&gt;        9080/TCP   13m</span><br><span class="line">reviews       ClusterIP   10.96.254.165   &lt;none&gt;        9080/TCP   13m</span><br></pre></td></tr></table></figure><p>通过访问可以看到，Bookinfo 服务正在运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it $(kubectl get pod -l app=ratings -o jsonpath=<span class="string">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) -c ratings -- curl productpage:9080/productpage | grep -o <span class="string">&quot;&lt;title&gt;.*&lt;/title&gt;&quot;</span></span></span><br><span class="line">&lt;title&gt;Simple Bookstore App&lt;/title&gt;</span><br></pre></td></tr></table></figure><h2 id="创建-Gateway-与默认的-VirtualService"><a href="#创建-Gateway-与默认的-VirtualService" class="headerlink" title="创建 Gateway 与默认的 VirtualService"></a>创建 Gateway 与默认的 VirtualService</h2><p> 为了保证服务流量可以进入到服务网格，需要创建 Gateway 资源，同时创建一个默认的 VirtualService。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get gateway</span></span><br><span class="line">NAME               AGE</span><br><span class="line">bookinfo-gateway   9s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get virtualservice</span></span><br><span class="line">NAME       GATEWAYS               HOSTS   AGE</span><br><span class="line">bookinfo   [&quot;bookinfo-gateway&quot;]   [&quot;*&quot;]   23m</span><br></pre></td></tr></table></figure><p>创建的 Gateway，本质上是将入站流量交给满足标签 istio&#x3D;ingressgateway 的 Pod 的流量接管。</p><p><em>也就是说流量从 istio-ingressgateway 的 Service 80 端口入站，转发到后端的 istio-ingressgateway 的 Pod。创建 Gateway 之后 istio-ingressgateway 会动态绑定 Gateway 中声明的 port 端口，因此需要保证流量可以从路由至该端口（即 istio-ingressgateway Service 的 Endpoint 端口中也同样为 80）</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">selector:</span></span><br><span class="line">      <span class="attr">istio:</span> <span class="string">ingressgateway</span></span><br><span class="line">    <span class="attr">servers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">      <span class="attr">port:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">        <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br></pre></td></tr></table></figure><p>创建的 VirtualService，绑定了上面创建的 Gateway，本质上是将匹配到的路由定向到 productpage Service 的 9080 端口。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">gateways:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bookinfo-gateway</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">/productpage</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">          <span class="attr">prefix:</span> <span class="string">/static</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">/login</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">/logout</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">          <span class="attr">prefix:</span> <span class="string">/api/v1/products</span></span><br><span class="line">      <span class="attr">route:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">          <span class="attr">host:</span> <span class="string">productpage</span></span><br><span class="line">          <span class="attr">port:</span></span><br><span class="line">            <span class="attr">number:</span> <span class="number">9080</span></span><br></pre></td></tr></table></figure><p>此时访问 <code>http://178.104.162.69:31235/productpage</code>，review 部分在 v1, v2, v3 版本平均切换</p><p><em>其实可以看到 VirtualService 将流量路由到 productpage 的 Service 后，此后的流量的路径还是 K8s 原生的路由方式</em></p><h2 id="创建-DestinationRule"><a href="#创建-DestinationRule" class="headerlink" title="创建 DestinationRule"></a>创建 DestinationRule</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get destinationrule</span></span><br><span class="line">NAME          HOST          AGE</span><br><span class="line">details       details       4m41s</span><br><span class="line">productpage   productpage   4m42s</span><br><span class="line">ratings       ratings       4m41s</span><br><span class="line">reviews       reviews       4m41s</span><br></pre></td></tr></table></figure><p>此时 BookInfo 的 VirtualService 只是将流量转发到 productpage 上，而 productpage 只有 v1 版本，其他 DestinationRule 只是创建，未被引用，可以理解成 DestinationRule 注册了 productpage 的 v1 版本以及 reviews 的 v1，v2 和 v3 版本，如果后续需要使用，需要创建 VirtualService 路由流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">productpage</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">productpage</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v3</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>由于没有 VirtualService 路由访问 Service 的流量，因此，此时访问页面，页面中 Review 微服务还是会三个版本平均切换的。</p><h2 id="创建智能路由的-VirtualService"><a href="#创建智能路由的-VirtualService" class="headerlink" title="创建智能路由的 VirtualService"></a>创建智能路由的 VirtualService</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get virtualservice</span></span><br><span class="line">NAME          GATEWAYS               HOSTS             AGE</span><br><span class="line">bookinfo      [&quot;bookinfo-gateway&quot;]   [&quot;*&quot;]             5d22h</span><br><span class="line">details                              [&quot;details&quot;]       114s</span><br><span class="line">productpage                          [&quot;productpage&quot;]   114s</span><br><span class="line">ratings                              [&quot;ratings&quot;]       114s</span><br><span class="line">reviews                              [&quot;reviews&quot;]       114s</span><br></pre></td></tr></table></figure><p>创建的 VirtualService 的本质上是将访问各组件的所有的流量路由至对应的 v1 版本。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">productpage</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">productpage</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">productpage</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure><p>此时访问页面，页面中的 Review 只会有 v1 版本样式，即没有任何星星。</p>]]></content>
    
    
    <summary type="html">初识 Service Mesh，借助 Bookinfo 示例，简单上手 Istio 使用</summary>
    
    
    
    <category term="Service Mesh" scheme="http://shenxianghong.github.io/categories/Service-Mesh/"/>
    
    
    <category term="Istio" scheme="http://shenxianghong.github.io/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>「 Golang 」优雅处理枚举类型</title>
    <link href="http://shenxianghong.github.io/2022/04/21/2022-04-21%20Golang%20%E4%BC%98%E9%9B%85%E5%A4%84%E7%90%86%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B/"/>
    <id>http://shenxianghong.github.io/2022/04/21/2022-04-21%20Golang%20%E4%BC%98%E9%9B%85%E5%A4%84%E7%90%86%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B/</id>
    <published>2022-04-20T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.171Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="100" style="border: 0px" src="/gallery/golang/logo.svg"></div><hr><h1 id="Open-Source"><a href="#Open-Source" class="headerlink" title="Open Source"></a>Open Source</h1><p><a href="https://github.com/vmware-tanzu/velero%EF%BC%88Backup">https://github.com/vmware-tanzu/velero（Backup</a> and migrate Kubernetes applications and their persistent volumes）。是用于备份与恢复集群资源的工具，支持命令行操作。其中关于命令行传入的枚举参数作了优雅校验。</p><h1 id="Sample"><a href="#Sample" class="headerlink" title="Sample"></a>Sample</h1><p><a href="https://github.com/shenxianghong/shenxianghong.github.io/tree/main/elegant-coding/enum">https://github.com/shenxianghong/shenxianghong.github.io/tree/main/elegant-coding/enum</a></p><h1 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h1><h2 id="enum-go"><a href="#enum-go" class="headerlink" title="enum.go"></a>enum.go</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> flag</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/pkg/errors&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Enum is a Cobra-compatible wrapper for defining a string flag that can be one of a specified set of values.</span></span><br><span class="line"><span class="keyword">type</span> Enum <span class="keyword">struct</span> &#123;</span><br><span class="line">allowedValues []<span class="type">string</span></span><br><span class="line">value         <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewEnum returns a new enum flag with the specified list of allowed values, and the specified default value if none is set.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewEnum</span><span class="params">(defaultValue <span class="type">string</span>, allowedValues ...<span class="type">string</span>)</span></span> *Enum &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Enum&#123;</span><br><span class="line">allowedValues: allowedValues,</span><br><span class="line">value:         defaultValue,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// String returns a string representation of the enum flag.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Enum)</span></span> String() <span class="type">string</span> &#123;</span><br><span class="line"><span class="keyword">return</span> e.value</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set assigns the provided string to the enum receiver. It returns an error if the string is not an allowed value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Enum)</span></span> Set(s <span class="type">string</span>) <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, val := <span class="keyword">range</span> e.allowedValues &#123;</span><br><span class="line"><span class="keyword">if</span> val == s &#123;</span><br><span class="line">e.value = s</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> errors.Errorf(<span class="string">&quot;invalid value: %q&quot;</span>, s)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Type returns a string representation of the Enum type.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Enum)</span></span> Type() <span class="type">string</span> &#123;</span><br><span class="line"><span class="comment">// we don&#x27;t want the help text to display anything regarding</span></span><br><span class="line"><span class="comment">// the type because the usage text for the flag should capture</span></span><br><span class="line"><span class="comment">// the possible options.</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// AllowedValues returns a slice of the flag&#x27;s valid values.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Enum)</span></span> AllowedValues() []<span class="type">string</span> &#123;</span><br><span class="line"><span class="keyword">return</span> e.allowedValues</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>封装了枚举类型，包含默认值以及允许的枚举值，Enum 结构体实现了 pflag 的 Value 接口（String()，Set()，Type()），在执行 flags.StringSliceVar 等操作时，pflag 会调用 Set 函数设置值，因此 Set 可以用于校验枚举值的合法性。</p><h2 id="format-flag-go"><a href="#format-flag-go" class="headerlink" title="format_flag.go"></a>format_flag.go</h2><p>定义了日志格式的枚举值、默认值以及对外的工厂函数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="comment">// Format is a string representation of the desired output format for logs</span></span><br><span class="line"><span class="keyword">type</span> Format <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">FormatText   Format = <span class="string">&quot;text&quot;</span></span><br><span class="line">FormatJSON   Format = <span class="string">&quot;json&quot;</span></span><br><span class="line">defaultValue Format = FormatText</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// FormatFlag is a command-line flag for setting the logrus</span></span><br><span class="line"><span class="comment">// log format.</span></span><br><span class="line"><span class="keyword">type</span> FormatFlag <span class="keyword">struct</span> &#123;</span><br><span class="line">*Enum</span><br><span class="line">defaultValue Format</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewFormatFlag constructs a new log level flag.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFormatFlag</span><span class="params">()</span></span> *FormatFlag &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;FormatFlag&#123;</span><br><span class="line">Enum: NewEnum(</span><br><span class="line"><span class="type">string</span>(defaultValue),</span><br><span class="line"><span class="type">string</span>(FormatText),</span><br><span class="line"><span class="type">string</span>(FormatJSON),</span><br><span class="line">),</span><br><span class="line">defaultValue: defaultValue,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Parse returns the flag&#x27;s value as a Format.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *FormatFlag)</span></span> Parse() Format &#123;</span><br><span class="line"><span class="keyword">return</span> Format(f.String())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="level-flags-go"><a href="#level-flags-go" class="headerlink" title="level_flags.go"></a>level_flags.go</h2><p>原理类似 format_flag.go。</p><h2 id="default-logger-go"><a href="#default-logger-go" class="headerlink" title="default_logger.go"></a>default_logger.go</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/sirupsen/logrus&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// DefaultLogger returns a Logger with the default properties.</span></span><br><span class="line"><span class="comment">// The desired output format is passed as a LogFormat Enum.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DefaultLogger</span><span class="params">(level logrus.Level, format Format)</span></span> *logrus.Logger &#123;</span><br><span class="line">logger := logrus.New()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> format == FormatJSON &#123;</span><br><span class="line">logger.Formatter = <span class="built_in">new</span>(logrus.JSONFormatter)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Make sure the output is set to stdout so log messages don&#x27;t show up as errors in cloud log dashboards.</span></span><br><span class="line">logger.Out = os.Stdout</span><br><span class="line"></span><br><span class="line">logger.Level = level</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> logger</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>根据传入的枚举值，初始化一些上层使用的对象。</p><h2 id="main-go"><a href="#main-go" class="headerlink" title="main.go"></a>main.go</h2><p>上层用法参考。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;strings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">logLevelFlag := LogLevelFlag()</span><br><span class="line">formatFlag := NewFormatFlag()</span><br><span class="line"></span><br><span class="line">fmt.Printf(<span class="string">&quot;The level at which to log. Valid values are %s.\n&quot;</span>, strings.Join(logLevelFlag.AllowedValues(), <span class="string">&quot;, &quot;</span>))</span><br><span class="line">fmt.Printf(<span class="string">&quot;The format for log output. Valid values are %s.\n&quot;</span>, strings.Join(formatFlag.AllowedValues(), <span class="string">&quot;, &quot;</span>))</span><br><span class="line"></span><br><span class="line">logLevel := logLevelFlag.Parse()</span><br><span class="line">format := FormatJSON</span><br><span class="line"></span><br><span class="line">logger := DefaultLogger(logLevel, format)</span><br><span class="line">logger.Infof(<span class="string">&quot;Hello World&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">记一次在 Velero 项目中学到的结合 Cobra 与 Pflag 处理枚举类型参数的方式</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Golang" scheme="http://shenxianghong.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>「 Kubebuilder 」快速开始</title>
    <link href="http://shenxianghong.github.io/2022/04/13/2022-04-13%20Kubebuilder%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2022/04/13/2022-04-13%20Kubebuilder%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2022-04-12T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.170Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/kubebuilder/logo.png"></div><hr><blockquote><p>based on <strong>v3.3.0</strong></p></blockquote><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p><a href="https://github.com/kubernetes-sigs/kubebuilder">Kubebuilder</a> 是一个基于 CRD 来构建 Kubernetes API 的框架，可以使用 CRD 来构建 API、Controller 和 Admission Webhook。类似于 Ruby on Rails 和 SpringBoot 之类的 Web 开发框架，Kubebuilder 可以提高速度并降低开发人员管理的复杂性，以便在 Golang 中快速构建和发布 Kubernetes API。它建立在用于构建核心 Kubernetes API 的规范技术的基础之上，以提供减少样板和麻烦的简单抽象。</p><p>与 Kubebuilder 类似的项目还有 <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a>，两者的区别可以参考 <a href="https://github.com/operator-framework/operator-sdk/issues/1758%EF%BC%8C%E7%9B%AE%E5%89%8D%E4%B8%A4%E4%B8%AA%E7%A4%BE%E5%8C%BA%E7%9A%84%E5%9C%A8%E5%81%9A%E5%8A%9F%E8%83%BD%E6%95%B4%E5%90%88%E3%80%82">https://github.com/operator-framework/operator-sdk/issues/1758，目前两个社区的在做功能整合。</a></p><p>Where they differ is:</p><ul><li>Operator SDK also has support for Ansible and Helm operators, which make it easy to write operators without having to learn Go and if you already have experience with Ansible or Helm</li><li>Operator SDK includes integrations with the Operator Lifecycle Manager (OLM), which is a key component of the Operator Framework that is important to Day 2 cluster operations, like managing a live upgrade of your operator.</li><li>Operator SDK includes a scorecard subcommand that helps you understand if your operator follows best practices.</li><li>Operator SDK includes an e2e testing framework that simplifies testing your operator against an actual cluster.</li><li>Kubebuilder includes an envtest package that allows operator developers to run simple tests with a standalone etcd and apiserver.</li><li>Kubebuilder scaffolds a Makefile to assist users in operator tasks (build, test, run, code generation, etc.); Operator SDK is currently using built-in subcommands. Each has pros and cons. The SDK team will likely be migrating to a Makefile-based approach in the future.</li><li>Kubebuilder uses Kustomize to build deployment manifests; Operator SDK uses static files with placeholders.</li><li>Kubebuilder has recently improved its support for admission and CRD conversion webhooks, which has not yet made it into SDK.</li></ul><p><a href="https://github.com/kubernetes/code-generator">Code Generator</a> 是用于实现 Kubernetes 风格 API 类型的 Golang 代码生成器。可以利用该工程自动生成指定K8s 资源的 clientset、informers 和 listers API 接口，本身是位于 Kubernetes 项目中的工具，内部包含了大量的生成器，例如 client-gen，deepcopy-gen，informer-gen，lister-gen 等等。</p><ul><li><p>deepcopy-gen</p><p>生成深度拷贝对象方法，例如 DeepCopy，DeepCopyObject，DeepCopyInto 等</p></li><li><p>client-gen</p><p>生成 clientSet 对象，为资源生成标准的操作方法，如 get，list，watch，create，update，patch 和 delete</p></li><li><p>informer-gen</p><p>生成 informer 对象，提供事件监听机制，如 AddFunc，UpdateFunc，DeleteFunc</p></li><li><p>lister-gen</p><p>生成 lister 对象，为 get 和 list 方法提供只读缓存层</p></li></ul><p>Kubebuilder 与 Code Generator 都可以为 CRD 生成 Kubernetes API 相关代码，从代码生成层面来讲， 两者的区别在于：</p><ul><li>Kubebuilder 不会生成 informers、listers、clientsets，而 Code Generator 会</li><li>Kubebuilder 会生成 Controller、Admission Webhooks，而 Code Generator 不会</li><li>Kubebuilder 会生成 manifests yaml，而 Code Generator 不会</li><li>Kubebuilder 还带有一些其他便利性设施</li></ul><h1 id="Kubebuilder"><a href="#Kubebuilder" class="headerlink" title="Kubebuilder"></a>Kubebuilder</h1><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><ul><li><a href="https://golang.org/dl/">go</a> version v1.15+ (kubebuilder v3.0 &lt; v3.1).</li><li><a href="https://golang.org/dl/">go</a> version v1.16+ (kubebuilder v3.1 &lt; v3.3).</li><li><a href="https://golang.org/dl/">go</a> version v1.17+ (kubebuilder v3.3+).</li><li><a href="https://docs.docker.com/install/">docker</a> version 17.03+.</li><li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">kubectl</a> version v1.11.3+.</li><li>Access to a Kubernetes v1.11.3+ cluster.</li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go <span class="built_in">env</span> GOOS)/$(go <span class="built_in">env</span> GOARCH)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x kubebuilder &amp;&amp; <span class="built_in">mv</span> kubebuilder /usr/local/bin/</span></span><br></pre></td></tr></table></figure><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>首先借助 Kubebuilder 初始化一个项目。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubebuilder init --domain huayun.io --repo huayun.io/ake/android-operator --owner AKE --project-name android-operator</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree</span></span><br><span class="line">.</span><br><span class="line">├── config</span><br><span class="line">│   ├── default</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   ├── manager_auth_proxy_patch.yaml</span><br><span class="line">│   │   └── manager_config_patch.yaml</span><br><span class="line">│   ├── manager</span><br><span class="line">│   │   ├── controller_manager_config.yaml</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   └── manager.yaml</span><br><span class="line">│   ├── prometheus</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   └── monitor.yaml</span><br><span class="line">│   └── rbac</span><br><span class="line">│       ├── auth_proxy_client_clusterrole.yaml</span><br><span class="line">│       ├── auth_proxy_role_binding.yaml</span><br><span class="line">│       ├── auth_proxy_role.yaml</span><br><span class="line">│       ├── auth_proxy_service.yaml</span><br><span class="line">│       ├── kustomization.yaml</span><br><span class="line">│       ├── leader_election_role_binding.yaml</span><br><span class="line">│       ├── leader_election_role.yaml</span><br><span class="line">│       ├── role_binding.yaml</span><br><span class="line">│       └── service_account.yaml</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── hack</span><br><span class="line">│   └── boilerplate.go.txt</span><br><span class="line">├── main.go</span><br><span class="line">├── Makefile</span><br><span class="line">└── PROJECT</span><br><span class="line"></span><br><span class="line">6 directories, 24 files</span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–component-config</td><td></td></tr><tr><td>–domain</td><td>group 的 domain 信息，默认为 my.domain</td></tr><tr><td>–fetch-deps</td><td>确保依赖已下载，默认为 true</td></tr><tr><td>–license</td><td>boilerplate.txt 中使用的 license，可选的有 apache2 和 none，默认为 apache2</td></tr><tr><td>–owner</td><td>copyright 中的所有者名称</td></tr><tr><td>–project-name</td><td>项目名称</td></tr><tr><td>–project-version</td><td>项目版本，默认为 3</td></tr><tr><td>–repo</td><td>go module 中的 module 名称</td></tr><tr><td>–skip-go-version-check</td><td>如果指定，则跳过 Golang 版本检查</td></tr></tbody></table><h2 id="生成-API"><a href="#生成-API" class="headerlink" title="生成 API"></a>生成 API</h2><p>设置 Kubebuilder 开启 multigroup，即 api 支持多 group，例如 apps&#x2F;policy，apps&#x2F;admission 等。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubebuilder edit --multigroup=<span class="literal">true</span></span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–multigroup</td><td>是否启用多 api group 组</td></tr></tbody></table><p>生成 CRD API 对象。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubebuilder create api --group android --version v1 --kind AnFile --controller --resource --namespaced --plural anfiles</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubebuilder create api --group android --version v1 --kind AnImage --controller --resource --namespaced --plural animages</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–controller</td><td>是否不询问默认生成 controller，默认为 true</td></tr><tr><td>–force</td><td>强制生成资源</td></tr><tr><td>–group</td><td>资源 group 组，例如 storage，events 等，最终会和 domain 一起作为 api group 信息</td></tr><tr><td>–kind</td><td>资源 kind 信息，即资源名称，如 Pod，Service 等</td></tr><tr><td>–make</td><td>生成文件后，是否执行一次 make generate，默认为 true</td></tr><tr><td>–namespaced</td><td>是否是命名空间级别的资源</td></tr><tr><td>–plural</td><td>资源的复数信息</td></tr><tr><td>–resource</td><td>是否不询问默认生成 resource，默认为 true</td></tr><tr><td>–version</td><td>资源版本信息，如 v1，v1beta1</td></tr></tbody></table><p>最终的资源结构为</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">android.huayun.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">AnImage</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">animage-sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># TODO(user): Add fields here</span></span><br></pre></td></tr></table></figure><p>make manifest 会在 .&#x2F;config&#x2F;crd&#x2F;bases 下根据 API 声明信息生成 CRD 的基础模板，在 API 变动后需要更新。</p><h2 id="生成-webhook"><a href="#生成-webhook" class="headerlink" title="生成 webhook"></a>生成 webhook</h2><p>TODO</p><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree</span></span><br><span class="line"></span><br><span class="line">.</span><br><span class="line">├── apis</span><br><span class="line">│   └── android</span><br><span class="line">│       └── v1</span><br><span class="line">│           ├── anfile_types.go</span><br><span class="line">│           ├── animage_types.go</span><br><span class="line">│           ├── groupversion_info.go</span><br><span class="line">│           └── zz_generated.deepcopy.go</span><br><span class="line">├── bin</span><br><span class="line">│   └── controller-gen</span><br><span class="line">├── config</span><br><span class="line">│   ├── crd</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   ├── kustomizeconfig.yaml</span><br><span class="line">│   │   └── patches</span><br><span class="line">│   │       ├── cainjection_in_anfiles.yaml</span><br><span class="line">│   │       ├── cainjection_in_animages.yaml</span><br><span class="line">│   │       ├── webhook_in_anfiles.yaml</span><br><span class="line">│   │       └── webhook_in_animages.yaml</span><br><span class="line">│   ├── default</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   ├── manager_auth_proxy_patch.yaml</span><br><span class="line">│   │   └── manager_config_patch.yaml</span><br><span class="line">│   ├── manager</span><br><span class="line">│   │   ├── controller_manager_config.yaml</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   └── manager.yaml</span><br><span class="line">│   ├── prometheus</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   └── monitor.yaml</span><br><span class="line">│   ├── rbac</span><br><span class="line">│   │   ├── anfile_editor_role.yaml</span><br><span class="line">│   │   ├── anfile_viewer_role.yaml</span><br><span class="line">│   │   ├── animage_editor_role.yaml</span><br><span class="line">│   │   ├── animage_viewer_role.yaml</span><br><span class="line">│   │   ├── auth_proxy_client_clusterrole.yaml</span><br><span class="line">│   │   ├── auth_proxy_role_binding.yaml</span><br><span class="line">│   │   ├── auth_proxy_role.yaml</span><br><span class="line">│   │   ├── auth_proxy_service.yaml</span><br><span class="line">│   │   ├── kustomization.yaml</span><br><span class="line">│   │   ├── leader_election_role_binding.yaml</span><br><span class="line">│   │   ├── leader_election_role.yaml</span><br><span class="line">│   │   ├── role_binding.yaml</span><br><span class="line">│   │   └── service_account.yaml</span><br><span class="line">│   └── samples</span><br><span class="line">│       ├── android_v1_anfile.yaml</span><br><span class="line">│       └── android_v1_animage.yaml</span><br><span class="line">├── controllers</span><br><span class="line">│   └── android</span><br><span class="line">│       ├── anfile_controller.go</span><br><span class="line">│       ├── animage_controller.go</span><br><span class="line">│       └── suite_test.go</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── hack</span><br><span class="line">│   └── boilerplate.go.txt</span><br><span class="line">├── main.go</span><br><span class="line">├── Makefile</span><br><span class="line">└── PROJECT</span><br><span class="line"></span><br><span class="line">15 directories, 44 files</span><br></pre></td></tr></table></figure><h2 id="Markers"><a href="#Markers" class="headerlink" title="Markers"></a>Markers</h2><p>Kubebuilder 提供了众多 Markers，支持对 CRD 的校验，生成等操作，具体可以参考<a href="https://book.kubebuilder.io/reference/markers.html">官方文档</a>。</p><h1 id="Code-Generator"><a href="#Code-Generator" class="headerlink" title="Code Generator"></a>Code Generator</h1><p>参考了 Kubernetes，Velero 等开源项目风格，将 apis 目录移至 pkg 层级下。</p><h2 id="文件准备"><a href="#文件准备" class="headerlink" title="文件准备"></a>文件准备</h2><h3 id="doc-go"><a href="#doc-go" class="headerlink" title="doc.go"></a>doc.go</h3><p>在 pkg&#x2F;apis&#x2F;android&#x2F;v1 目录下创建 doc.go 文件，参考内容如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// +k8s:deepcopy-gen=package</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Package v1 is the v1 version of the API.</span></span><br><span class="line"><span class="comment">// +groupName=android.huayun.io</span></span><br><span class="line"><span class="keyword">package</span> v1</span><br></pre></td></tr></table></figure><ul><li>groupName 的名称为 &lt;group&gt;.&lt;domain&gt;</li></ul><h3 id="register-go"><a href="#register-go" class="headerlink" title="register.go"></a>register.go</h3><p>在 pkg&#x2F;apis&#x2F;android&#x2F;v1 目录下创建 register.go 文件，参考内容如下</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;k8s.io/apimachinery/pkg/runtime/schema&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SchemeGroupVersion is group version used to register these objects.</span></span><br><span class="line"><span class="keyword">var</span> SchemeGroupVersion = GroupVersion</span><br><span class="line"></span><br><span class="line"><span class="comment">// Resource takes an unqualified resource and returns a Group qualified GroupResource</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Resource</span><span class="params">(resource <span class="type">string</span>)</span></span> schema.GroupResource &#123;</span><br><span class="line">    <span class="keyword">return</span> SchemeGroupVersion.WithResource(resource).GroupResource()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="lt-CRD-gt-types-go"><a href="#lt-CRD-gt-types-go" class="headerlink" title="&lt;CRD&gt;_types.go"></a>&lt;CRD&gt;_types.go</h3><p>以 pkg&#x2F;apis&#x2F;android&#x2F;v1&#x2F;animage_types.go 为例，新增以下 tag 信息</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Copyright 2022 AKE.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">limitations under the License.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">metav1 <span class="string">&quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> json tags are required.  Any new fields you add must have json tags for the fields to be serialized.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// AnImageSpec defines the desired state of AnImage</span></span><br><span class="line"><span class="keyword">type</span> AnImageSpec <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// INSERT ADDITIONAL SPEC FIELDS - desired state of cluster</span></span><br><span class="line"><span class="comment">// Important: Run &quot;make&quot; to regenerate code after modifying this file</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Foo is an example field of AnImage. Edit animage_types.go to remove/update</span></span><br><span class="line">Foo <span class="type">string</span> <span class="string">`json:&quot;foo,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// AnImageStatus defines the observed state of AnImage</span></span><br><span class="line"><span class="keyword">type</span> AnImageStatus <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// INSERT ADDITIONAL STATUS FIELD - define observed state of cluster</span></span><br><span class="line"><span class="comment">// Important: Run &quot;make&quot; to regenerate code after modifying this file</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// +genclient</span></span><br><span class="line"><span class="comment">// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object</span></span><br><span class="line"><span class="comment">// +kubebuilder:object:root=true</span></span><br><span class="line"><span class="comment">// +kubebuilder:subresource:status</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// AnImage is the Schema for the animages API</span></span><br><span class="line"><span class="keyword">type</span> AnImage <span class="keyword">struct</span> &#123;</span><br><span class="line">metav1.TypeMeta   <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">metav1.ObjectMeta <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line"></span><br><span class="line">Spec   AnImageSpec   <span class="string">`json:&quot;spec,omitempty&quot;`</span></span><br><span class="line">Status AnImageStatus <span class="string">`json:&quot;status,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object</span></span><br><span class="line"><span class="comment">// +kubebuilder:object:root=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// AnImageList contains a list of AnImage</span></span><br><span class="line"><span class="keyword">type</span> AnImageList <span class="keyword">struct</span> &#123;</span><br><span class="line">metav1.TypeMeta <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">metav1.ListMeta <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line">Items           []AnImage <span class="string">`json:&quot;items&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">SchemeBuilder.Register(&amp;AnImage&#123;&#125;, &amp;AnImageList&#123;&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>在 AnImage struct 上，新增 <code>+genclient</code></li><li>在 AnImage 和 AnImageList struct 上，新增 <code>+k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object</code></li></ul><h3 id="tools-go"><a href="#tools-go" class="headerlink" title="tools.go"></a>tools.go</h3><p>该文件主要用于追踪构建阶段所需的依赖包，而非运行阶段，因此，文件位置、名称和内容等信息根据具体情况而定。</p><p>在 hack 目录下创建 tools.go 文件，参考内容如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//go:build tools</span></span><br><span class="line"><span class="comment">// +build tools</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> tools</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> _ <span class="string">&quot;k8s.io/code-generator&quot;</span></span><br></pre></td></tr></table></figure><h3 id="update-codegen-sh"><a href="#update-codegen-sh" class="headerlink" title="update-codegen.sh"></a>update-codegen.sh</h3><p>该文件用于调用 Code Generator 的 generate-groups.sh 脚本，生成代码。参考内容如下，逻辑参考脚本注释</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#Copyright 2022 AKE.</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">you may not use this file except <span class="keyword">in</span> compliance with the License.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#    http://www.apache.org/licenses/LICENSE-2.0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#Unless required by applicable law or agreed to in writing, software</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">limitations under the License.</span></span><br><span class="line"></span><br><span class="line">set -o errexit</span><br><span class="line">set -o nounset</span><br><span class="line">set -o pipefail</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">this script expects to be run from the root of the android-operator repo.</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Corresponding to go mod init &lt;module&gt;.</span></span><br><span class="line">MODULE=huayun.io/ake/android-operator</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Corresponding to kubebuilder create api --group &lt;group&gt; --version &lt;version&gt;.</span></span><br><span class="line">GROUP_VERSION=android:v1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Generated output package.</span></span><br><span class="line">OUTPUT_PKG=pkg/generated</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">API package.</span></span><br><span class="line">APIS_PKG=pkg/apis</span><br><span class="line"></span><br><span class="line">SCRIPT_ROOT=$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)/..</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Sync k8s.io/code-generator to go.mod</span></span><br><span class="line">go mod tidy </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Grab code-generator version from go.mod.</span></span><br><span class="line">CODEGEN_VERSION=$(grep &#x27;k8s.io/code-generator&#x27; go.mod | awk &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">CODEGEN_PKG=$(go env GOPATH)/pkg/mod/k8s.io/code-generator@$&#123;CODEGEN_VERSION&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Prepare code-generator.</span></span><br><span class="line">if [[ ! -d $&#123;CODEGEN_PKG&#125; ]]; then</span><br><span class="line">    echo &quot;$&#123;CODEGEN_PKG&#125; is missing. Running &#x27;go mod download&#x27;.&quot;</span><br><span class="line">    go mod download</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;&gt;&gt; Using $&#123;CODEGEN_PKG&#125;&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">code-generator does work with go.mod but makes assumptions about</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the project living <span class="keyword">in</span> `<span class="variable">$GOPATH</span>/src`. To work around this and support</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">any location; create a temporary directory, use this as an output</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">base, and copy everything back once generated.</span></span><br><span class="line">TEMP_DIR=$(mktemp -d)</span><br><span class="line">cleanup() &#123;</span><br><span class="line">    echo &quot;&gt;&gt; Removing $&#123;TEMP_DIR&#125;&quot;</span><br><span class="line">    rm -rf &quot;$&#123;TEMP_DIR&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">trap &quot;cleanup&quot; EXIT SIGINT</span><br><span class="line"></span><br><span class="line">echo &quot;&gt;&gt; Temporary output directory $&#123;TEMP_DIR&#125;&quot;</span><br><span class="line"></span><br><span class="line">chmod +x &quot;$&#123;CODEGEN_PKG&#125;&quot;/generate-groups.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">generate the code with:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--output-base    because this script should also be able to run inside the vendor <span class="built_in">dir</span> of</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">                 k8s.io/kubernetes. The output-base is needed <span class="keyword">for</span> the generators to output into the vendor <span class="built_in">dir</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">                 instead of the <span class="variable">$GOPATH</span> directly. For normal projects this can be dropped.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$&#123;SCRIPT_ROOT&#125;</span>&quot;</span></span></span><br><span class="line">&quot;$&#123;CODEGEN_PKG&#125;&quot;/generate-groups.sh \</span><br><span class="line">  all \</span><br><span class="line"><span class="meta prompt_">  $</span><span class="language-bash">&#123;MODULE&#125;/<span class="variable">$&#123;OUTPUT_PKG&#125;</span> \</span></span><br><span class="line"><span class="language-bash">  <span class="variable">$&#123;MODULE&#125;</span>/<span class="variable">$&#123;APIS_PKG&#125;</span> \</span></span><br><span class="line"><span class="language-bash">  <span class="variable">$&#123;GROUP_VERSION&#125;</span> \</span></span><br><span class="line"><span class="language-bash">  --output-base <span class="string">&quot;<span class="variable">$&#123;TEMP_DIR&#125;</span>&quot;</span> \</span></span><br><span class="line"><span class="language-bash">  --go-header-file <span class="string">&quot;<span class="variable">$&#123;SCRIPT_ROOT&#125;</span>&quot;</span>/hack/boilerplate.go.txt</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Copy everything back.</span></span><br><span class="line">cp -a &quot;$&#123;TEMP_DIR&#125;/$&#123;MODULE&#125;/.&quot; &quot;$&#123;SCRIPT_ROOT&#125;/&quot;</span><br></pre></td></tr></table></figure><h3 id="Makefile"><a href="#Makefile" class="headerlink" title="Makefile"></a>Makefile</h3><p>Makefile 中新增 .PHONY，集成构建流程。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: update-codegen</span></span><br><span class="line"><span class="section">update-codegen: ## Generate code by code-generator</span></span><br><span class="line">bash ./hack/update-codegen.sh</span><br></pre></td></tr></table></figure><h2 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make update-codegen</span></span><br></pre></td></tr></table></figure><h2 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree pkg/generated/</span></span><br><span class="line"></span><br><span class="line">pkg/generated/</span><br><span class="line">├── clientset</span><br><span class="line">│   └── versioned</span><br><span class="line">│       ├── clientset.go</span><br><span class="line">│       ├── doc.go</span><br><span class="line">│       ├── fake</span><br><span class="line">│       │   ├── clientset_generated.go</span><br><span class="line">│       │   ├── doc.go</span><br><span class="line">│       │   └── register.go</span><br><span class="line">│       ├── scheme</span><br><span class="line">│       │   ├── doc.go</span><br><span class="line">│       │   └── register.go</span><br><span class="line">│       └── typed</span><br><span class="line">│           └── android</span><br><span class="line">│               └── v1</span><br><span class="line">│                   ├── android_client.go</span><br><span class="line">│                   ├── anfile.go</span><br><span class="line">│                   ├── animage.go</span><br><span class="line">│                   ├── doc.go</span><br><span class="line">│                   ├── fake</span><br><span class="line">│                   │   ├── doc.go</span><br><span class="line">│                   │   ├── fake_android_client.go</span><br><span class="line">│                   │   ├── fake_anfile.go</span><br><span class="line">│                   │   └── fake_animage.go</span><br><span class="line">│                   └── generated_expansion.go</span><br><span class="line">├── informers</span><br><span class="line">│   └── externalversions</span><br><span class="line">│       ├── android</span><br><span class="line">│       │   ├── interface.go</span><br><span class="line">│       │   └── v1</span><br><span class="line">│       │       ├── anfile.go</span><br><span class="line">│       │       ├── animage.go</span><br><span class="line">│       │       └── interface.go</span><br><span class="line">│       ├── factory.go</span><br><span class="line">│       ├── generic.go</span><br><span class="line">│       └── internalinterfaces</span><br><span class="line">│           └── factory_interfaces.go</span><br><span class="line">└── listers</span><br><span class="line">    └── android</span><br><span class="line">        └── v1</span><br><span class="line">            ├── anfile.go</span><br><span class="line">            ├── animage.go</span><br><span class="line">            └── expansion_generated.go</span><br><span class="line"></span><br><span class="line">16 directories, 26 files</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">使用 Kubebuilder 和 Code Generator 生成自定义的 K8s Operator 框架</summary>
    
    
    
    <category term="Scheduling &amp; Orchestration" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/"/>
    
    <category term="Kubernetes" scheme="http://shenxianghong.github.io/categories/Scheduling-Orchestration/Kubernetes/"/>
    
    
    <category term="Kubebuilder" scheme="http://shenxianghong.github.io/tags/Kubebuilder/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Plugin</title>
    <link href="http://shenxianghong.github.io/2022/03/20/2022-03-20%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Plugin/"/>
    <id>http://shenxianghong.github.io/2022/03/20/2022-03-20%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Plugin/</id>
    <published>2022-03-19T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.170Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="ObjectStore"><a href="#ObjectStore" class="headerlink" title="ObjectStore"></a>ObjectStore</h1><p><em><u>pkg&#x2F;plugin&#x2F;velero&#x2F;object_store.go</u></em></p><p><em>Velero 无该内置类型的 plugin，具体参考 <a href="https://github.com/vmware-tanzu/velero-plugin-for-aws"> velero-plugin-for-aws</a>、<a href="https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure">velero-plugin-for-microsoft-azure</a>、<a href="https://github.com/vmware-tanzu/velero-plugin-for-gcp"> velero-plugin-for-gcp</a>。</em></p><p>ObjectStore 包含以下接口</p><ul><li><p>Init</p><p>初始化 Object<br><em>如果接口返回 error，BackupStorageLocation Controller 则无法调用 IsValid 判断 Provider 的可用性</em></p></li><li><p>PutObject</p><p>上传 key（io.Reader）到 Provider 中</p></li><li><p>ObjectExists</p><p>判断 key 在 Provider 中是否存在</p></li><li><p>GetObject</p><p>获取 key 的内容（io.ReadCloser）<br><em>Velero 会在调用后负责 Close 该 io 操作，无需 plugin 操作</em></p></li><li><p>ListCommonPrefixes</p><p>获取满足给定公共前缀的所有 key</p></li><li><p>ListObjects</p><p>获取满足给定前缀的所有 key</p></li><li><p>DeleteObject</p><p>删除 Provider 中的指定 key<br><em>仅会删除 key 本身，如果对于文件存储类型的 Provider，需要在 plugin 中实现删除最后一个 key 时，同时删除目录的功能</em></p></li><li><p>CreateSignedURL</p><p>生成具有过期时间的 pre-signed url，用于获取 Provider 中的文件<br><em>对于文件存储类型等不具备提供对外服务的 Provider，该接口需要有其他服务支撑</em></p></li></ul><h1 id="VolumeSnapshotter"><a href="#VolumeSnapshotter" class="headerlink" title="VolumeSnapshotter"></a>VolumeSnapshotter</h1><p><em><u>pkg&#x2F;plugin&#x2F;velero&#x2F;volume_snapshotter.go</u></em></p><p><em>Velero 无该内置类型的 plugin，具体参考 <a href="https://github.com/vmware-tanzu/velero-plugin-for-aws"> velero-plugin-for-aws</a>、<a href="https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure">velero-plugin-for-microsoft-azure</a>、<a href="https://github.com/vmware-tanzu/velero-plugin-for-gcp"> velero-plugin-for-gcp</a>。</em></p><p>VolumeSnapshotter 包含以下接口</p><ul><li><p>Init</p><p>初始化 VolumeSnapshotshotter</p></li><li><p>CreateVolumeFromSnapshot</p><p>根据指定的 zone、IOPS 信息从快照恢复卷<br></p><p><em>Velero 创建卷的动作为同步处理，会一直等待，直至完成或者失败</em></p></li><li><p>GetVolumeID</p><p>根据指定的 PV 获取 VolumeID</p></li><li><p>SetVolumeID</p><p>对指定的 PV 设置 VolumeID</p></li><li><p>GetVolumeInfo</p><p>获取 Volume 信息</p></li><li><p>CreateSnapshot</p><p>对指定的卷创建快照<br><em>Velero 创建 PV 快照的动作为同步处理，会一直等待，直至完成或者失败</em></p></li><li><p>DeleteSnapshot</p><p>删除快照</p></li></ul><h1 id="DeleteItemAction"><a href="#DeleteItemAction" class="headerlink" title="DeleteItemAction"></a>DeleteItemAction</h1><p><em><u>pkg&#x2F;plugin&#x2F;velero&#x2F;delete_item_action.go</u></em></p><p><em>Velero 无该内置类型的 plugin。</em></p><p>DeleteItemAction 包含以下接口</p><ul><li><p>AppliesTo</p><p>返回应该对哪些资源执行额外操作（通过 Included&#x2F;Excluded Namespaces&#x2F;Resources 实现），结果会由 Execute 处理执行额外操作</p></li><li><p>Execute</p><p>根据自定义的逻辑判断是否要对函数入参 Item（即符合 AppliesTo 过滤后的资源对象）在删除 Backup 时，执行一些额外的操作</p></li></ul><h1 id="BackupItemAction"><a href="#BackupItemAction" class="headerlink" title="BackupItemAction"></a>BackupItemAction</h1><p><em><u>pkg&#x2F;plugin&#x2F;velero&#x2F;backup_item_action.go</u></em></p><p>BackupItemAction 包含以下接口</p><ul><li><p>AppliesTo</p><p>返回应该对哪些资源执行额外操作（通过 Included&#x2F;Excluded Namespaces&#x2F;Resources 实现），该过滤结果会和 Backup 本身的过滤取交集，结果会由 Execute 处理执行额外操作</p></li><li><p>Execute</p><p>根据自定义的逻辑判断是否要对函数入参 Item（即符合 AppliesTo 过滤后的资源对象）做额外操作，函数会返回两个核心内容</p><ul><li>更新后的 item，此后的流程会以此 item 为基准</li><li>需要额外操作的对象，会加入此后备份流程中执行备份</li></ul></li></ul><h2 id="velero-io-x2F-pv"><a href="#velero-io-x2F-pv" class="headerlink" title="velero.io&#x2F;pv"></a>velero.io&#x2F;pv</h2><p><em><u>pkg&#x2F;backup&#x2F;backup_pv_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: persistentvolumeclaims</p><p><strong>Execute</strong></p><ol><li>PVC item 未更新</li><li>获取 PVC 绑定的 PV 作为额外操作的对象返回</li></ol><h2 id="velero-io-x2F-pod"><a href="#velero-io-x2F-pod" class="headerlink" title="velero.io&#x2F;pod"></a>velero.io&#x2F;pod</h2><p><em><u>pkg&#x2F;backup&#x2F;pod_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: pods</p><p><strong>Execute</strong></p><ol><li>Pod item 未更新</li><li>获取 Pod 中使用的 PVC 作为额外操作的对象返回</li></ol><h2 id="velero-io-x2F-service-account"><a href="#velero-io-x2F-service-account" class="headerlink" title="velero.io&#x2F;service-account"></a>velero.io&#x2F;service-account</h2><p><em><u>pkg&#x2F;backup&#x2F;service_account_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: serviceaccounts</p><p><strong>Execute</strong></p><ol><li>Service Account item 未更新</li><li>获取 Service Account 关联的 ClusterRole 和 ClusterRoleBinding 作为额外操作的对象返回</li></ol><h2 id="velero-io-x2F-crd-remap-version"><a href="#velero-io-x2F-crd-remap-version" class="headerlink" title="velero.io&#x2F;crd-remap-version"></a>velero.io&#x2F;crd-remap-version</h2><p><em><u>pkg&#x2F;backup&#x2F;remap_crd_version_action</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: customresourcedefinition.apiextensions.k8s.io</p><p><strong>Execute</strong></p><ol><li>如果 CRD 的 apiVersion 为 apiextensions.k8s.io&#x2F;v1，并且如果是单一版本的 CRD，或者存在位解构的字段或者预留字段时，则将 v1 版本的 CRD item 转换为 v1beta1 版本，并返回<br><em>参考：<a href="https://kubernetes.io/zh/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions">https://kubernetes.io/zh/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions</a></em></li><li>无额外操作的对象</li></ol><h1 id="RestoreItemAction"><a href="#RestoreItemAction" class="headerlink" title="RestoreItemAction"></a>RestoreItemAction</h1><p><em><u>pkg&#x2F;plugin&#x2F;velero&#x2F;restore_item_action.go</u></em></p><p>RestoreItemAction 包含以下接口</p><ul><li><p>AppliesTo</p><p>返回应该对哪些资源执行额外操作（通过 Included&#x2F;Excluded Namespaces&#x2F;Resources 实现），该过滤结果会和 Restore 本身的过滤取交集，结果会由 Execute 处理执行额外操作</p></li><li><p>Execute</p><p>根据自定义的逻辑判断是否要对 Item（即符合 AppliesTo 过滤后的资源对象）做额外操作，函数会返回三个核心内容</p><ul><li>更新后的 item，此后的流程会以此 item 为基准</li><li>需要额外操作的对象，会加入此后恢复流程中执行恢复</li><li>是否跳过恢复的标识 skipRestore</li></ul></li></ul><h2 id="velero-io-x2F-job"><a href="#velero-io-x2F-job" class="headerlink" title="velero.io&#x2F;job"></a>velero.io&#x2F;job</h2><p><em><u>pkg&#x2F;restore&#x2F;job_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: jobs</p><p><strong>Execute</strong></p><ol><li>删除 Job item 中的 controller-uid 字段（job.Spec.Selector.MatchLabels 以及 job.Spec.Template.ObjectMeta.Labels），并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-pod-1"><a href="#velero-io-x2F-pod-1" class="headerlink" title="velero.io&#x2F;pod"></a>velero.io&#x2F;pod</h2><p><em><u>pkg&#x2F;restore&#x2F;pod_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: pods</p><p><strong>Execute</strong></p><ol><li>清空 Pod item 的 nodeName、priority 和无需保留卷、卷挂载信息，并返回<br><em>如果 Pod 卷或卷挂载以 pod.Spec.ServiceAccountName + “-token-“ 开头，则无需保留。</em></li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-restic"><a href="#velero-io-x2F-restic" class="headerlink" title="velero.io&#x2F;restic"></a>velero.io&#x2F;restic</h2><p><em><u>pkg&#x2F;restore&#x2F;restic_restore_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: pods</p><p><strong>Execute</strong></p><ol><li>获取到 Pod item 中的被 Restic 备份的卷信息，如果有的话，则会根据一系列的配置信息对 Pod item 注入一个 Init Container（restic-wait），并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-init-restore-hook"><a href="#velero-io-x2F-init-restore-hook" class="headerlink" title="velero.io&#x2F;init-restore-hook"></a>velero.io&#x2F;init-restore-hook</h2><p><em><u>pkg&#x2F;restore&#x2F;init_restorehook_pod_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: pods</p><p><strong>Execute</strong></p><ol><li>获取 Pod 中有关 init.hook.restore.velero.io&#x2F;xxx 的 annotation 信息，构建一个 Init Container，如果 Pod 没有相关的 annotation，则获取 Restore 中的 hook 信息，根据 selector 的匹配结果，构建一个 Init Container。以上构建的 Init Container 会追加在 Pod 中，顺序为：restic-wait（如果 Pod 已经存在），hook1，hook2…，追加作为更新后的 Pod item 返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-service"><a href="#velero-io-x2F-service" class="headerlink" title="velero.io&#x2F;service"></a>velero.io&#x2F;service</h2><p><em><u>pkg&#x2F;restore&#x2F;service_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: services</p><p><strong>Execute</strong></p><ol><li>如果 ClusterIP 不为 None（也就是说分配了一个 Service IP），则删除 ClusterIP，如果 Restore 没有指定 –preserve-nodeports 参数，则删除 Service 的 NodePort 信息，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-service-account-1"><a href="#velero-io-x2F-service-account-1" class="headerlink" title="velero.io&#x2F;service-account"></a>velero.io&#x2F;service-account</h2><p><em><u>pkg&#x2F;restore&#x2F;service_account_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: serviceaccounts</p><p><strong>Execute</strong></p><ol><li>删除 Service Account 中的运行状态时生成的 &lt;serviceAccountName&gt;-token，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-add-pvc-from-pod"><a href="#velero-io-x2F-add-pvc-from-pod" class="headerlink" title="velero.io&#x2F;add-pvc-from-pod"></a>velero.io&#x2F;add-pvc-from-pod</h2><p><em><u>pkg&#x2F;restore&#x2F;add_pvc_from_pod_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: pods</p><p><strong>Execute</strong></p><ol><li>Pod item 未更新</li><li>获取 Pod 中使用的 PVC 作为额外的操作对象返回</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-add-pv-from-pvc"><a href="#velero-io-x2F-add-pv-from-pvc" class="headerlink" title="velero.io&#x2F;add-pv-from-pvc"></a>velero.io&#x2F;add-pv-from-pvc</h2><p><em><u>pkg&#x2F;restore&#x2F;add_pv_from_pod_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: persistentvolumeclaims</p><p><strong>Execute</strong></p><ol><li>PVC item 未更新</li><li>获取 PVC 绑定的 PV 作为额外的操作对象返回</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-change-storage-class"><a href="#velero-io-x2F-change-storage-class" class="headerlink" title="velero.io&#x2F;change-storage-class"></a>velero.io&#x2F;change-storage-class</h2><p><em><u>pkg&#x2F;restore&#x2F;change_storageclass_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: persistentvolumeclaims, persistentvolumes</p><p><strong>Execute</strong></p><ol><li><p>获取集群中有关 StorageClass 映射关系的唯一的 ConfigMap 信息（即 ConfigMap label 中有 velero.io&#x2F;plugin-config&#x3D;”” 和 velero.io&#x2F;change-storage-class&#x3D;RestoreItemAction，如果不存在则不做映射关系），根据 PV 或 PVC 中的 StorageClassName 获得映射后的新 StorageClassName，更新 PV 或 PVC，并返回</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">change-storage-class</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">velero</span></span><br><span class="line">  <span class="attr">labels:</span> </span><br><span class="line">    <span class="attr">velero.io/plugin-config:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">velero.io/change-storage-class:</span> <span class="string">RestoreItemAction</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ussvd-sc:</span> <span class="string">local-sc</span></span><br></pre></td></tr></table></figure></li><li><p>无额外操作的对象</p></li><li><p>skipRestore 为 false</p></li></ol><h2 id="velero-io-x2F-role-bindings"><a href="#velero-io-x2F-role-bindings" class="headerlink" title="velero.io&#x2F;role-bindings"></a>velero.io&#x2F;role-bindings</h2><p><em><u>pkg&#x2F;restore&#x2F;rolebinding_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: rolebindings</p><p><strong>Execute</strong></p><ol><li>根据 Restore 中的 namespace 映射关系，修改 RoleBinding 的 namespace，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-cluster-role-bindings"><a href="#velero-io-x2F-cluster-role-bindings" class="headerlink" title="velero.io&#x2F;cluster-role-bindings"></a>velero.io&#x2F;cluster-role-bindings</h2><p><em><u>pkg&#x2F;restore&#x2F;clusterrolebinding_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: clusterrolebindings</p><p><strong>Execute</strong></p><ol><li>根据 Restore 中的 namespace 映射关系，修改 ClusterRoleBinding 的 namespace，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-crd-preserve-fields"><a href="#velero-io-x2F-crd-preserve-fields" class="headerlink" title="velero.io&#x2F;crd-preserve-fields"></a>velero.io&#x2F;crd-preserve-fields</h2><p><em><u>pkg&#x2F;restore&#x2F;crd_v1_preserve_unknown_fields_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: customresourcedefinition.apiextensions.k8s.io</p><p><strong>Execute</strong></p><ol><li>设置版本为 apiextensions.k8s.io&#x2F;v1 的 CRD 的 PreserveUnknownFields 信息，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-change-pvc-node-selector"><a href="#velero-io-x2F-change-pvc-node-selector" class="headerlink" title="velero.io&#x2F;change-pvc-node-selector"></a>velero.io&#x2F;change-pvc-node-selector</h2><p><em><u>pkg&#x2F;restore&#x2F;change_pvc_node_selector.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResources: persistentvolumeclaims</p><p><strong>Execute</strong></p><ol><li>获取集群中有关 PVC NodeSelector 映射关系的唯一 ConfigMap 信息，根据 PVC annotation 中的 volume.kubernetes.io&#x2F;selected-node 获得映射后的新 Node，如果存在映射关系，则认为新的 Node 存在；如果不存在映射关系，则判断旧 Node 是否存在，不存在则删除 volume.kubernetes.io&#x2F;selected-node 信息，存在则设置 PVC annotation nodeSelector 为旧 Node。无论怎样，均更新 PVC，并返回</li><li>无额外操作的对象</li><li>skipRestore 为 false</li></ol><h2 id="velero-io-x2F-apiservice"><a href="#velero-io-x2F-apiservice" class="headerlink" title="velero.io&#x2F;apiservice"></a>velero.io&#x2F;apiservice</h2><p><em><u>pkg&#x2F;restore&#x2F;apiservice_action.go</u></em></p><p><strong>AppliesTo</strong></p><p>IncludedResrouces: apiservices</p><p>LabelSelector: kube-aggregator.kubernetes.io&#x2F;automanaged</p><p><strong>Execute</strong></p><ol><li>apiservices item 未更新</li><li>无额外操作的对象</li><li>skipRestore 为 true，因为这些 apiservices 由 kube-aggergator 负责维护，无需恢复</li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 ObjectStore、VolumeSnapshotter 等插件相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Server</title>
    <link href="http://shenxianghong.github.io/2022/03/06/2022-03-06%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Server/"/>
    <id>http://shenxianghong.github.io/2022/03/06/2022-03-06%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Server/</id>
    <published>2022-03-05T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.169Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h1><p><em><u>pkg&#x2F;client&#x2F;factory.go</u></em><br><em><u>pkg&#x2F;client&#x2F;config.go</u></em><br><em><u>pkg&#x2F;cmd&#x2F;velero&#x2F;velero.go</u></em><br></p><p>Velero 的全局配置参数，比如 namespaces，features，cacert 和 colorized 等信息，是在初始化 velero 根 command 时，解析位于 host 的 &lt;HOME&gt;&#x2F;.config&#x2F;velero&#x2F;config.json 的配置文件获取配置对象，初始化 factory 对象，将其透传给下级子 command 实现，由于 velero 服务的启动也是 velero 的子命令（即 velero server），因此实现了全局配置透传功能。</p><h1 id="Generic-Controller"><a href="#Generic-Controller" class="headerlink" title="Generic Controller"></a>Generic Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;generic_controller.go</u></em><br><em><u>pkg&#x2F;controller&#x2F;interface.go</u></em><br><em><u>internal&#x2F;util&#x2F;managercontroller&#x2F;managercontroller.go</u></em></p><p>顾名思义，Generic Controller 定义所有 Controller 的通用行为，本身负责周期性调用 Controller 注册的方法处理 Key，维护 Controller  Key 的生命周期。</p><p>每一个 Controller 都继承了 Generic Controller，主要包括注册 syncHandler 和 resyncFunc，以及 queue 和 cacheSyncWaiters 等。</p><p>Generic Controller 主要包含以下核心属性：</p><p><strong>queue</strong></p><p>默认使用 K8s 提供的 NewNamedRateLimitingQueue，队列中就是需要处理的 Key，格式为 &lt;namespace&gt;&#x2F;&lt;name&gt; 或者 &lt;name&gt;（取决于对象是否是 namespaced scope）。</p><p>Generic Controller 提供了 enqueue 的方法，用于 Key 的入队（本质上就是 queue 的 Add 方法，只不过转换成了上述的格式）。</p><p><strong>syncHandler</strong></p><p>Generic Controller 会周期性的调用 Controller 注册的 syncHandler，处理 queue 中的 Key。</p><p><strong>resyncFunc</strong></p><p>Generic Controller 会根据 resyncPeriod 周期性的调用 Controller 注册的 resyncFunc，执行额外声明的逻辑。</p><p><strong>cacheSyncWaiters</strong></p><p>Generic Controller 在执行 syncHandler 和 resyncFunc 之前会等待注册在 cacheSyncWaiters 全部缓存完成（本质上，就是一组 func() bool 均返回 true 即可，只不过传入的均为 podInformer.HasSynced 函数）。</p><h2 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/generic_controller.go#L54">Run 源码</a></p><p>Generic Controller 的核心逻辑</p><ol><li>校验 syncHandler 和 resyncFunc 是否至少注册了一个</li><li>如果注册了 cacheSyncWaiters，则等待其缓存同步完成<br><em>PodVolumeBackup Controller 和 PodVolumeRestore Controller 均注册了 cacheSyncWaiters，用于同步 Pod、PVC 以及 PodVolumeBackup（PodVolumeRestore）</em> </li><li>启动指定 worker 数量的 Goroutine，每 1 秒钟处理一次以下逻辑<br><em>该逻辑本身是死循环，只有在 queue 关闭时返回 false，因此隔 1 秒钟还会重新执行</em><ol><li>从 queue 中获取 Key（Get）</li><li>调用 syncHandler 注册的 Handler，处理 Key<ul><li>如果处理成功，则在 queue 中移除（Forget）</li><li>如果处理失败，则限制速率重新加入 queue 中（AddRateLimited）</li></ul></li></ol></li><li>每隔 resyncPeriod 执行一次 resyncFunc 逻辑<br><em>resyncFunc 的处理不一定和 Key 相关，可以执行一些指标上报等操作，例如 Backup Controller 的 resyncFunc 实现</em></li></ol><h2 id="Runable"><a href="#Runable" class="headerlink" title="Runable"></a>Runable</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/internal/util/managercontroller/managercontroller.go#L31">Runable 源码</a></p><p>用于将调用 Run 函数启动 Controller 的方法封装成 manager.Runable 返回，供 manager.Add 以及 manager.Start 使用<br><em>manager 为 controller-runtime 的 manager</em></p><h1 id="Velero-Server"><a href="#Velero-Server" class="headerlink" title="Velero Server"></a>Velero Server</h1><p><em><u>pkg&#x2F;cmd&#x2F;server&#x2F;server.go</u></em></p><p>本质上是 velero cli 的 server 子命令，根据 install 以及更多的自定义参数，启动 Velero 服务。</p><h2 id="newServer"><a href="#newServer" class="headerlink" title="newServer"></a>newServer</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/3c49ec4fb4ff7f5aaa4ed56e8f7ff1a26f966d72/pkg/cmd/server/server.go#L246">newServer 源码</a></p><p>工厂函数</p><ol><li>设置 client 的 QPS 和 Burst，最终会作用在 Kube Client，Velero Client 和 Dynamic Client</li><li>初始化 Kube Client，Velero Client 和 Dynamic Client</li><li>初始化 PluginRegistry，发现注册在 &#x2F;plugins 目录下的所有插件，并调用 velero run-plugins 命令启动插件的 GRPC 服务<br><em>插件包括 item-action、objectStore 以及 volumeSnapshotter 等</em></li><li>如果 Velero 开启了 CSI 特性，则初始化 CSI Snapshot Client</li><li>构建 controller-runtime 的 manager 对象</li><li>初始化 CredentialFileStore，用于操作认证文件信息</li><li>根据以上内容，构建 server 对象</li></ol><h2 id="run"><a href="#run" class="headerlink" title="run"></a>run</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/3c49ec4fb4ff7f5aaa4ed56e8f7ff1a26f966d72/pkg/cmd/server/server.go#L352">run 源码</a></p><p>server 运行的主体逻辑</p><ol><li>如果配置了 profile 地址，则启动 pprof 服务</li><li>检查 Velero namespace 是否存在，如果不存在则报错</li><li>初始化 DiscoveryHelper，每 5 分钟刷新一次，获取可以备份的对象信息</li><li>检查 Velero 服务所需要的 CRD 是否存在，如果不存在则报错</li><li>检查 Restic 是否存在，如果不存在则输出 warning 信息，确保 restic 所需要的 secret 存在（即 velero-restic-credentials），初始化 RepositoryManager</li><li>调用 runControllers，启动所有的 Controller</li></ol><h2 id="runControllers"><a href="#runControllers" class="headerlink" title="runControllers"></a>runControllers</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/3c49ec4fb4ff7f5aaa4ed56e8f7ff1a26f966d72/pkg/cmd/server/server.go#L566">runControllers 源码</a></p><p>启动 controller 以及其他服务</p><ol><li>启动 promHttp 服务，对接 Prometheus</li><li>初始化 <a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/plugin/clientmgmt/manager.go#L30">pluginManager</a>，提供与 Velero Plugin 交互的原生接口</li><li>初始化 backupStoreGetter，提供操作 Backup 和 Restore 的上层接口<br><em>即 Provider 章节中的 StorageProvider</em></li><li>按需初始化 CSI Snapshot Lister 和 CSI SnapshotContent Lister</li><li>根据以上内容，初始化 Backup Controller、BackupSync Controller、Schedule Controller、GC Controller、BackupDeletion Controller、Restore Controller 以及 ResticRepo Controller，并将这些初步设定为默认开启的 Controller</li><li>此外，ServerStatusRequest Controller 和 DownloadRequest Controller 作为服务运行时的状态 Controller，也会作为默认开启<br><em>该类型的 Controller 与步骤 5 中的 Controller 处理逻辑相同，但是是分开处理和启动的</em></li><li>如果 Velero 服务为 restoreOnly 模式，则禁用 Backup Controller、Schedule Controller、GC Controller 以及 BackupDeletion Controller</li><li>将启用的 Controller 和禁用的 Controller 取差集后，即为最终 Velero 服务中启动的 Controller 信息</li><li>等待 Velero Client 和 CSI Snapshot Client 同步缓存（waitForCacheSync）</li><li>启动 BackupStorageLocation Controller（Reconciler 方式），按需启动 ServerStatusRequest Controller 和 DownloadRequest Controller</li><li>启动剩余的 Controller（不包含 Request 类型的 Controller），所有的 Controller 默认均为 1 worker</li></ol><h1 id="Restic-Server"><a href="#Restic-Server" class="headerlink" title="Restic Server"></a>Restic Server</h1><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restic&#x2F;server.go</u></em></p><p>本质上是 velero restic cli 的 server 子命令，根据自定义参数，启动 Restic 服务。</p><h2 id="newResticServer"><a href="#newResticServer" class="headerlink" title="newResticServer"></a>newResticServer</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/cmd/cli/restic/server.go#L119">newResticServer 源码</a></p><ol><li>初始化 KubeClient 和 Velero Client</li><li>初始化 PodInformer，仅获取调度在本节点上的 Pod</li><li>构建 controller-runtime 的 manager 对象</li><li>根据以上内容，构建 restic server 对象</li><li>判断挂载在 restic 服务中 &#x2F;hosts_pods 目录下所有的 Pod 信息和集群中的所有的 Pod 是否一一对应</li></ol><h2 id="run-1"><a href="#run-1" class="headerlink" title="run"></a>run</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/cmd/cli/restic/server.go#L183">run 源码</a></p><ol><li>启动 promHttp 服务，对接 Prometheus</li><li>初始化 CredentialFileStore，用于操作认证文件信息</li><li>根据以上内容，初始化 PodVolumeBackup Controller 和 PodVolumeRestore Controller</li><li>启动 PodVolumeBackup Controller 和 PodVolumeRestore Controller，默认均为 1 worker</li></ol><h1 id="Velero-Restic-Restore-Helper"><a href="#Velero-Restic-Restore-Helper" class="headerlink" title="Velero Restic Restore Helper"></a>Velero Restic Restore Helper</h1><p><em><u>cmd&#x2F;velero-restic-restore-helper&#x2F;main.go</u></em></p><p>本质是 Velero 项目的另一个 binary 执行文件（还有一个是 velero 本身），在恢复 Pod 卷数据时，会给该 Pod 注入一个 InitContainer，该 binary 就是 InitContainer 所用镜像（velero&#x2F;velero-restic-restore-helper:&lt;velero-version&gt;）中的启动服务。</p><h2 id="main"><a href="#main" class="headerlink" title="main"></a>main</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/cmd/velero-restic-restore-helper/main.go#L27">main 源码</a></p><p>每一个待恢复卷数据的 Pod 的 InitContainer 中运行的服务</p><ol><li>命令行接受一个参数，即 Restore 的 UID</li><li>启动死循环定时器，每一秒钟检查 InitContainer 的 &#x2F;restores 目录下每一个子目录的 .velero 目录下是否有所提供的 Restore UID 文件，如果每一个子目录都有该 UID 文件，则认为恢复完成，退出死循环，该 InitContainer 生命周期结束，否则，继续等待，无超时时间<br><em>&#x2F;restores 下每一个子目录代表一个待恢复的卷，命名为 Pod 使用的 PVC volumeMount 名称</em></li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 VeleroServer、ResticServer 等主体服务相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Provider</title>
    <link href="http://shenxianghong.github.io/2022/02/20/2022-02-20%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Provider/"/>
    <id>http://shenxianghong.github.io/2022/02/20/2022-02-20%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Provider/</id>
    <published>2022-02-19T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.169Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="Storage-Provider"><a href="#Storage-Provider" class="headerlink" title="Storage Provider"></a>Storage Provider</h1><p><em><u>pkg&#x2F;persistence&#x2F;object_store.go</u></em></p><p>StorageProvider 提供了一系列的封装了 ObjectStore Plugin 的接口，用于操作位于 BackupStorageLocation 上数据。</p><h2 id="IsValid"><a href="#IsValid" class="headerlink" title="IsValid"></a>IsValid</h2><p><strong>调用接口</strong></p><ul><li>ListCommonPrefixes(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;, &#x2F;)</li></ul><p><strong>主体逻辑</strong></p><p>针对获取到的公共前缀子目录，获取其子目录层级是否为 backups、restores、restic、metadata 和 plugins 之一，如果不是则返回 error，认为 BackupStorageLocation 不可用。</p><p><em>例如，BackupStorageLocation 上的目录层级为 &lt;bucket&gt;&#x2F;&lt;prefix&gt;&#x2F;backups&#x2F;xxx 和 &lt;bucket&gt;&#x2F;&lt;prefix&gt;&#x2F;invalid&#x2F;xxx，调用 ListCommonPrefixes，获取到的公共前缀子目录层级有 prefix&#x2F;backups 和 prefix&#x2F;invalid，进一步处理后，获取到的子目录层级为 backups 和 invalid，其中，invalid 不满足 5 个固定的名称之一，因此认为 BackupStorageLocation 不可用。</em></p><p><strong>应用场景</strong></p><ul><li>BackupStorageLocation Controller 会通过该接口周期性检查 BackupStorageLocation 是否可用</li></ul><h2 id="ListBackups"><a href="#ListBackups" class="headerlink" title="ListBackups"></a>ListBackups</h2><p><strong>调用接口</strong></p><ul><li>ListCommonPrefixes(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;, &#x2F;)</li></ul><p><strong>主体逻辑</strong></p><p>针对获取到的公共前缀子目录，其子目录层级为 Backup 的名称，聚合并返回。</p><p><em>例如，BackupStorageLocation 上的目录层级为 &lt;bucket&gt;&#x2F;&lt;prefix&gt;&#x2F;backups&#x2F;backupA 和 &lt;bucket&gt;&#x2F;&lt;prefix&gt;&#x2F;backups&#x2F;backupB，调用 ListCommonPrefixes，获取到的公共前缀子目录层级有 &lt;prefix&gt;&#x2F;backups&#x2F;BackupA 和 &lt;prefix&gt;&#x2F;backups&#x2F;BackupB，进一步处理后，获取到的子目录层级为 BackupA 和 BackupB，则返回包含两者的列表。</em></p><p><strong>应用场景</strong></p><ul><li>BackupSync Controller 在同步 Backup 时，用于获取 BackupStorageLocation 中的 Backup</li></ul><h2 id="PutBackup"><a href="#PutBackup" class="headerlink" title="PutBackup"></a>PutBackup</h2><p><strong>调用接口</strong></p><ul><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;.logs.gz, &lt;log&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;velero-backup.json, &lt;metadata&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;.tar.gz, &lt;content&gt;)</li><li>DeleteObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;velero-backup.json)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-podvolumebackups.json.gz, &lt;podvolumebackups&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-volumesnapshots.json.gz, &lt;volumesnapshots&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-resource-list.json.gz, &lt;resource-list&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshots.json.gz, &lt;csi-volumesnapshots&gt;)</li><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshotcontents.json.gz, &lt;csi-volumesnapshotcontents&gt;)</li></ul><p><strong>主体逻辑</strong></p><p>按照以下顺序上传文件</p><ol><li>Backup Logs<br><em>备份过程中，Velero 服务产生的日志</em></li><li>Backup Metadata<br><em>描述 Backup 本身的信息</em></li><li>Backup Content<br><em>被备份的资源内容</em></li><li>PodVolumeBackups<br><em>被备份的 Pod 卷信息，由 Restic 创建并维护</em></li><li>PodVolumeSnapshots<br><em>被备份的 Pod 卷快照信息，由 SnapshotProvider 创建并维护</em></li><li>Backup ResourcesList<br><em>被备份的资源清单</em></li><li>CSI VolumeSnapshot<br><em>被备份的 Pod 卷快照信息，由 CSI 创建并维护</em></li><li>CSI VolumeSnapshotContents<br><em>被备份的 Pod 卷快照内容信息，由 CSI 创建并维护</em></li></ol><p><em>第一步日志上传失败时，仅会打印错误日志，而不会中断上传流程，是因为该步骤不影响备份的主体逻辑。此后如果有步骤失败，会影响到 Backup 的状态，并会清空之前的操作，即调用 DeleteObject 删除已上传的数据。</em></p><p><strong>应用场景</strong></p><ul><li>Backup Controller 在备份完成时，备份的资源信息上传至 BackupStorageLocation 时</li></ul><h2 id="GetBackupMetadata"><a href="#GetBackupMetadata" class="headerlink" title="GetBackupMetadata"></a>GetBackupMetadata</h2><p><strong>调用接口</strong></p><ul><li>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;velero-backup.json)</li></ul><p><strong>主体逻辑</strong></p><p>获取到 velero-backup.json 文件，读取内容，解析成 Backup 对象格式。</p><p><strong>应用场景</strong></p><ul><li>BackupSync Controller 在同步 Backup 时，用于构建待同步的 Backup 对象</li></ul><h2 id="GetBackupVolumeSnapshots"><a href="#GetBackupVolumeSnapshots" class="headerlink" title="GetBackupVolumeSnapshots"></a>GetBackupVolumeSnapshots</h2><p><strong>调用接口</strong></p><ul><li>ObjectExists(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-volumesnapshots.json.gz)</li><li>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-volumesnapshots.json.gz)</li></ul><p><strong>主体逻辑</strong></p><p>判断 BackupVolumeSnapshots 是否存在，如果存在，则获取并解析返回。</p><p><strong>应用场景</strong></p><ul><li>Restore Controller 在恢复时，会获取 Backup 相关联的 VolumeSnapshot 并恢复</li><li>BackupDeletion Controller 在删除备份时，会一并删除 VolumeSnapshot 信息</li></ul><h2 id="GetBackupVolumeBackups"><a href="#GetBackupVolumeBackups" class="headerlink" title="GetBackupVolumeBackups"></a>GetBackupVolumeBackups</h2><p><strong>调用接口</strong></p><ul><li>ObjectExists(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-podvolumebackups.json.gz)</li><li>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-podvolumebackups.json.gz)</li></ul><p><strong>主体逻辑</strong></p><p>判断 PodVolumeBackup 是否存在，如果存在，则获取并解析返回。</p><p><strong>应用场景</strong></p><ul><li>BackupSync Controller 在处理需要同步的 Backup 时，也会判断是否有相关联的 PodVolumeBackup 需要被同步</li></ul><h2 id="GetBackupContents"><a href="#GetBackupContents" class="headerlink" title="GetBackupContents"></a>GetBackupContents</h2><p><strong>调用接口</strong></p><p>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;.tar.gz)</p><p><strong>主体逻辑</strong></p><p>调用接口，判断指定的备份内容。</p><p><strong>应用场景</strong></p><ul><li>Restore Controller 在恢复时，会将备份的内容下载到临时文件中，恢复创建资源</li><li>BackupDeletion Controller 在删除备份时，如果定义了 action，会将备份的内容下载到临时文件中，获取到 action 定义的动作并执行</li></ul><h2 id="GetCSIVolumeSnapshots"><a href="#GetCSIVolumeSnapshots" class="headerlink" title="GetCSIVolumeSnapshots"></a>GetCSIVolumeSnapshots</h2><p><strong>调用接口</strong></p><ul><li>ObjectExists(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshots.json.gz)</li><li>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshots.json.gz)</li></ul><p><strong>主体逻辑</strong></p><p>调用 ObjectExists 判断 VolumeSnapshots 是否存在，如果存在，则获取并解析返回</p><p><strong>应用场景</strong></p><ul><li>无</li></ul><h2 id="GetCSIVolumeSnapshotContents"><a href="#GetCSIVolumeSnapshotContents" class="headerlink" title="GetCSIVolumeSnapshotContents"></a>GetCSIVolumeSnapshotContents</h2><p><strong>调用接口</strong></p><ul><li>ObjectExists(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshotscontents.json.gz)</li><li>GetObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;&lt;backups&gt;&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-csi-volumesnapshotscontents.json.gz)</li></ul><p><strong>主体逻辑</strong></p><p>判断 VolumeSnapshotsContents 是否存在，如果存在，则获取并解析返回</p><p><strong>应用场景</strong></p><ul><li>BackupSync Controller 在获取到需要同步 Backup 时，如果 Velero 开启了 CSI 特性，用于获取 VolumeSnapshotContents 对象，后续也会同步该对象</li></ul><h2 id="BackupExists"><a href="#BackupExists" class="headerlink" title="BackupExists"></a>BackupExists</h2><p><strong>调用接口</strong></p><ul><li>ObjectExists(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;velero-backup.json)</li></ul><p><strong>主体逻辑</strong></p><p>调用接口，判断给定的备份是否存在。</p><p><strong>应用场景</strong></p><ul><li>Backup Controller 在备份时，会判断本次创建的备份在 BackupStorageLocation 中是否已经存在，如果存在则将备份状态设为 Failed</li></ul><h2 id="DeleteBackup"><a href="#DeleteBackup" class="headerlink" title="DeleteBackup"></a>DeleteBackup</h2><p><strong>调用接口</strong></p><ul><li>ListObjects(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;backups&#x2F;&lt;backup&gt;&#x2F;)</li><li>DeleteObject(&lt;bucket&gt;, &lt;key&gt;)</li></ul><p><strong>主体逻辑</strong></p><p>调用 ListObjects，获取指定备份名称目录下的所有文件，即 key，遍历所有文件，调用 DeleteObject 删除 key。<br><em>可以看到，Velero 在删除备份时仅会调用 DeleteBackup 删除所有的子文件，也就是所有的 key，但是不会删除这个备份目录，因此如果先要实现删除最后的空目录，需要在 StorageProvider 的 DeleteObject 接口实现。</em></p><p><strong>应用场景</strong></p><ul><li>BackupDeletion Controller 删除指定备份时，用于删除 BackupStorageLocation 中的 Backup 数据</li></ul><h2 id="PutRestoreLog"><a href="#PutRestoreLog" class="headerlink" title="PutRestoreLog"></a>PutRestoreLog</h2><p><strong>调用接口</strong></p><ul><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;restores&#x2F;&lt;restore&gt;&#x2F;restore-&lt;restore&gt;-logs.gz, &lt;log&gt;)</li></ul><p><strong>主体逻辑</strong></p><p>调用接口，上传恢复日志文件。</p><p><strong>应用场景</strong></p><ul><li>Restore Controller 在恢复完成时，用于上传恢复过程中 Velero 产生的日志</li></ul><h2 id="PutRestoreResults"><a href="#PutRestoreResults" class="headerlink" title="PutRestoreResults"></a>PutRestoreResults</h2><p><strong>调用接口</strong></p><ul><li>PutObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;restores&#x2F;&lt;restore&gt;&#x2F;restore-&lt;restore&gt;-logs.gz, &lt;result&gt;)</li></ul><p><strong>主体逻辑</strong></p><p>调用接口，上传恢复结果信息。</p><p><strong>应用场景</strong></p><ul><li>Restore Controller 在恢复完成时，用于将本次恢复过程中产生的 warning 和 error 信息上传</li></ul><h2 id="DeleteRestore"><a href="#DeleteRestore" class="headerlink" title="DeleteRestore"></a>DeleteRestore</h2><p><strong>调用接口</strong></p><ul><li>ListObject(&lt;bucket&gt;, &lt;prefix&gt;&#x2F;restores&#x2F;&lt;restore&gt;&#x2F;)</li><li>DeleteObject(&lt;bucket&gt;, &lt;key&gt;)</li></ul><p><strong>主体逻辑</strong></p><p>调用 ListObjects，获取指定恢复名称目录下的所有文件，即 key，遍历所有文件，调用 DeleteObject 删除 key。<br><em>可以看到，Velero 在删除恢复时仅会调用 DeleteBackup 删除所有的子文件，也就是所有的 key，但是不会删除这个恢复目录，因此如果先要实现删除最后的空目录，需要在 StorageProvider 的 DeleteObject 接口实现。</em></p><p><strong>应用场景</strong></p><ul><li>BackupDeletion Controller 在删除 Backup 时，会同步删除相关联的 Restore，并删除 BackupStorageLocation 中的 Restore 信息<br><em>BackupStorageLocation 中 Restore 的删除仅在该场景下，手动删除 Restore，不会触发 DeleteRestore 流程，也就是通过 velero restore delete xxx 是无法删除 BackupStorageLocation 中 Restore 文件的。</em></li></ul><h2 id="GetDownloadURL"><a href="#GetDownloadURL" class="headerlink" title="GetDownloadURL"></a>GetDownloadURL</h2><p><strong>调用接口</strong></p><ul><li>CreateSignedURL(&lt;bucket&gt;, &lt;target&gt;, 10min)<br><em>target 表示要根据 DownloadRequest 对象要获取的目标文件，具体参考 DownloadRequest 章节</em></li></ul><p><strong>主体逻辑</strong></p><p>根据 DownloadRequest 的对象类别，即 target，构建不同的目标文件路径，调用接口，获取 DownloadURL。</p><p><strong>应用场景</strong></p><ul><li>DownloadRequest Controller 在处理 DownloadRequest 对象时，会通过该接口构建 DownloadURL，并回写至 DownloadRequest 对象中</li></ul><h1 id="Snapshot-Provider"><a href="#Snapshot-Provider" class="headerlink" title="Snapshot Provider"></a>Snapshot Provider</h1><p><em><u>pkg&#x2F;backup&#x2F;item_backupper.go</u></em><br><em><u>pkg&#x2F;restore&#x2F;pv_restorer.go</u></em></p><p>Velero 并未像 Storage Provider 封装一些上层接口，而是将底层接口的调用简单封装了以下两个函数，用于备份和恢复时，对于 PV 类型的资源做的快照和恢复的操作。</p><h2 id="takePVSnapshot"><a href="#takePVSnapshot" class="headerlink" title="takePVSnapshot"></a>takePVSnapshot</h2><p><strong>调用接口</strong></p><ul><li>init(snapshotLocation.Spec.Config)</li><li>GetVolumeID(&lt;Unstructured PV&gt;)</li><li>GetVolumeInfo(&lt;volumeID&gt;, &lt;volumeZone&gt;)</li><li>CreateSnapshot(&lt;volumeID&gt;, &lt;volumeZone&gt;, &lt;tags&gt;)</li></ul><p><strong>主体逻辑</strong></p><ol><li>判断 Backup 的 SnapshotVolumes 是否开启，如果开启则表示需要对卷做快照，继续执行以下逻辑</li><li>如果 PV 已经被认领，则需要判断是否被 Restic 已经备份（没有被认领的 PV 肯定不会被 Restic 备份），如果已经备份，则不会再次创建卷快照</li><li>通过 PV 的 label 获取 PV 的 zone 信息（topology.kubernetes.io&#x2F;zone 或者 failure-domain.beta.kubernetes.io&#x2F;zone）</li><li>针对 backup 中每一个 Snapshot Location，初始化一个 volumeSnapshotter，调用 GetVolumeID 尝试获取 VolumeID<br><em>PV 卷肯定是由 Snapshot Provider 创建出来的，所以 GetVolumeID 肯定会有记录保存</em></li><li>根据 Backup 的 label 创建 Tag，并追加 velero.io&#x2F;backup&#x3D;&lt;backupName&gt; 和 velero.io&#x2F;pv&#x3D;&lt;pvName&gt;</li><li>调用 GetVolumeInfo 接口，获取到卷信息，包括卷类型和 IOPS</li><li>根据以上信息构建 volumeSnapshot 对象，调用 CreateSnapshot 接口，创建快照</li><li>更新 volumeSnapshot 状态等信息</li></ol><h2 id="executePVAction"><a href="#executePVAction" class="headerlink" title="executePVAction"></a>executePVAction</h2><p><strong>调用接口</strong></p><ul><li>init(snapshotLocation.Spec.Config)</li><li>CreateVolumeFromSnapshot(&lt;snapshotID&gt;, &lt;volumeType&gt;, &lt;volumeZone&gt;,  &lt;volumeIOPS&gt;)</li><li>SetVolumeID(&lt;pv&gt;, &lt;VolumeID&gt;)</li></ul><p><strong>主体逻辑</strong></p><ol><li>校验 PV 的合法性，判断名称是否存在</li><li>判断是否需要通过快照恢复卷，即 Backup 中是否指定了备份卷（backup.snapshotVolumes）以及 Restore 中是否指定了恢复卷（restore.restorePVs）</li><li>根据 PV 名称以及 Restore 相关信息获取 snapshot 对象</li><li>如果获取到 Snapshot 对象，则初始化 volumeSnapshotter</li><li>根据 snapshot 对象中的卷信息，如卷类型，zone，IOPS 等信息，调用 CreateVolumeFromSnapshot 创建卷，并获取 VolumeID 信息</li><li>调用 SetVolumeID，给 PV 设置 VolumeID，并返回 PV 的解构类型</li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 StorageProvider、SnapshotProvider 等维护站点资源相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Request</title>
    <link href="http://shenxianghong.github.io/2022/02/05/2022-02-05%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Request/"/>
    <id>http://shenxianghong.github.io/2022/02/05/2022-02-05%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Request/</id>
    <published>2022-02-04T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.168Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="DownloadRequest"><a href="#DownloadRequest" class="headerlink" title="DownloadRequest"></a>DownloadRequest</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/download_request_types.go">API</a></p><h2 id="DownloadTargetKind"><a href="#DownloadTargetKind" class="headerlink" title="DownloadTargetKind"></a>DownloadTargetKind</h2><p>代表着要从 BackupStorageLocation 中下载的文件，映射关系如下</p><table><thead><tr><th>DownloadTargetKind</th><th>BackupStorageLocation 中的文件</th></tr></thead><tbody><tr><td>BackupLog</td><td>backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-logs.gz</td></tr><tr><td>BackupContents</td><td>backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;.tar.gz</td></tr><tr><td>BackupVolumeSnapshots</td><td>backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-volumesnapshots.json.gz</td></tr><tr><td>BackupResourceList</td><td>backups&#x2F;&lt;backup&gt;&#x2F;&lt;backup&gt;-resource-list.json.gz</td></tr><tr><td>RestoreLog</td><td>restores&#x2F;&lt;restore&gt;&#x2F;&lt;restore&gt;-logs.gz</td></tr><tr><td>RestoreResults</td><td>restores&#x2F;&lt;restore&gt;&#x2F;restore-&lt;restore&gt;-results.gz</td></tr></tbody></table><h1 id="ServerStatusRequest"><a href="#ServerStatusRequest" class="headerlink" title="ServerStatusRequest"></a>ServerStatusRequest</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/server_status_request_types.go">API</a></p><p>ServerStatusRequest 不支持通过命令行手动创建，而是在获取 Velero 组件状态时，会自动生成该对象，由 ServerStatusRequest Controller 维护。</p><h1 id="DownloadRequest-Controller"><a href="#DownloadRequest-Controller" class="headerlink" title="DownloadRequest Controller"></a>DownloadRequest Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;download_request_controller.go</u></em><br><em><u>pkg&#x2F;cmd&#x2F;util&#x2F;downloadrequest&#x2F;downloadrequest.go</u></em></p><h2 id="Reconcile"><a href="#Reconcile" class="headerlink" title="Reconcile"></a>Reconcile</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/download_request_controller.go#L52">Reconcile 源码</a></p><ol><li>如果 DownloadRequest 状态不为空并且有过期时间的，代表该对象不是已经处理过，则需要进一步判断其是否达到过期时间<ul><li>如果已过期，则从集群中删除</li><li>如果未过期，并且状态为 Processed，则不做处理<br><em>虽然已经处理过了，但是并没有直接删除是因为有可能 log 文件流还在使用</em></li></ul></li><li>如果 DownloadRequest 状态是空或者 New 的，调用 StorageProvider 的 GetDownloadURL 接口获取 DownloadURL 信息并设置到 DownloadRequest 中，同时更新其状态为 Processed，重新设置过期时间为 10 分钟<br><em>如果调用 GetDownloadURL 时出现异常，则需要终止流程，并且重新入队，交给下次流程处理</em></li><li>最终，以上步骤中如果存在流程异常或者对象被合理删除，则不再重新入队，此后流程中，不再处理；否则，</li></ol><h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/cmd/util/downloadrequest/downloadrequest.go#L43">Stream 源码</a></p><p><em>上层应用方式，并非 DownloadRequest Controller 逻辑</em></p><ol><li>根据函数入参信息构建 DownloadRequest 对象，下发至集群中创建，后续由 DownloadRequest Controller 负责维护</li><li>每 25 毫秒检测一下，直至 DownloadRequest 的 DownloadURL 被设置<br><em>该动作就是 DownloadRequest Controller 核心工作内容</em></li><li>根据 DownloadURL 信息，构建 HTTP GET 请求，获取到 StorageProvider 中的文件数据，写入签名提供的 io.Writer 中</li></ol><p>应用的场景包括</p><ul><li>velero backup download</li><li>velero backup&#x2F;restore describe</li><li>velero backup&#x2F;restore logs</li></ul><h1 id="ServerStatusRequest-Controller"><a href="#ServerStatusRequest-Controller" class="headerlink" title="ServerStatusRequest Controller"></a>ServerStatusRequest Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;server_status_request_controller.go</u></em></p><h2 id="Reconcile-1"><a href="#Reconcile-1" class="headerlink" title="Reconcile"></a>Reconcile</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/server_status_request_controller.go#L63">Reconcile 源码</a></p><ol><li>如果 ServerStatusRequest 状态是空或者 New，则更新其状态为 Processed，设置处理时间戳以及 Velero 服务中安装的插件信息</li><li>如果 ServerStatusRequest 状态是 Processed，则判断其是否达到过期时间<ul><li>如果已过期，则从集群中删除</li><li>如果未过期，则设置下次入队时间为 5 分钟之后</li></ul></li><li>如果 ServerStatusRequest 状态不满足上述，则不再重新入队，此后流程中，不再处理</li></ol><h2 id="GetServerStatus"><a href="#GetServerStatus" class="headerlink" title="GetServerStatus"></a>GetServerStatus</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/cmd/cli/serverstatus/server_status.go#L41">GetServerStatus 源码</a></p><p><em>上层应用方式，非 ServerStatusRequest Controller 逻辑</em></p><ol><li>根据函数入参信息构建 ServerStatusRequest 对象，下发至集群中创建，后续由 ServerStatusRequest Controller 负责维护</li><li>每 250 毫秒检测一下，直至 ServerStatusRequest 的状态为 Processed，返回 ServerStatusRequest 对象信息<br><em>该动作就是 ServerStatusRequest Controller 核心工作内容</em></li></ol><p>应用的场景包括</p><ul><li>velero plugin get</li></ul>]]></content>
    
    
    <summary type="html">Velero 中与 DownloadRequest、ServerStatusRequest 等资源请求相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Restore</title>
    <link href="http://shenxianghong.github.io/2022/02/04/2022-02-04%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Restore/"/>
    <id>http://shenxianghong.github.io/2022/02/04/2022-02-04%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Restore/</id>
    <published>2022-02-03T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.168Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="Restore"><a href="#Restore" class="headerlink" title="Restore"></a>Restore</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/restore.go">API</a></p><h2 id="restore"><a href="#restore" class="headerlink" title="restore"></a>restore</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;restore</u></em></p><p>velero restore 包括 5 个子命令：create、delete、describe、get 和 logs。</p><h2 id="create"><a href="#create" class="headerlink" title="create"></a>create</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;create.go</u></em></p><p><strong>校验规则</strong></p><ul><li>–from-backup 和 –from-schedule 参数有且仅能有一个</li><li>在指定 –from-backup 或者 –from-schedule 参数时，其在集群中必须存在</li><li>在指定 –from-schedule 参数时，则由该 Schedule 创建出的 Backup 至少有一个</li></ul><p><strong>主体流程</strong></p><ol><li>如果指定了 –from-schedule 参数并且 –allow-partially-failed 参数为 true 时，获取集群中由该 Schedule 创建出的状态为 Completed 或者 PartiallyFailed 的最新 Backup，作为恢复的基准，并且将 –from-schedule 信息置空；否则，则直接透传 –from-schedule 信息用于后续构建 Restore 对象</li><li>根据命令行参数，构建 Restore 对象，下发至集群中创建，后续由 Restore Controller 负责维护</li><li>如果开启了 –wait，则启动 informer 监听 Restore 对象状态，阻塞直至状态不再是 New 或者 InProgress</li></ol><h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;delete.go</u></em></p><p><strong>校验规则</strong></p><ul><li>name、–all 和 –selector 参数有且仅能有一个</li><li>要删除的 Restore 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，获取集群中的 Restore 资源并删除</li></ol><h2 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;describe.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Restore 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 PodVolumeRestore 信息</li><li>将以上信息和 Restore 的元信息、规格、状态以及 Pod 卷数据恢复等汇总作为描述信息格式化输出<ul><li>如果 Restore 中有 Error 或者 Warning 的日志时，会构建 DownloadRequest 对象获取  RestoreResults 的信息，展示原因</li><li>在开启 –details 时，会输出恢复的 Pod 卷信息</li></ul></li></ol><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;get.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Restore 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 Restore 资源，根据 –output 指定的样式格式化输出</li></ol><h2 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restore&#x2F;logs.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Restore 在集群中必须存在</li><li>Restore 的状态必须为 Completed、PartiallyFailed 或者 Failed</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 DownloadRequest 对象，下发至集群中创建 RestoreLog，下发至集群中创建，后续由 DownloadRequest Controller 负责维护，获取 RestoreLog 的信息</li><li>阻塞直至 DownloadRequest 的 DownloadURL 被设置，将内容写入 stdout 中</li></ol><h1 id="PodVolumeRestore"><a href="#PodVolumeRestore" class="headerlink" title="PodVolumeRestore"></a>PodVolumeRestore</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/pod_volume_restore.go">API</a> </p><p>对象不支持手动创建，而是在恢复流程中，由 Restore Controller 调用 <strong>restoreItem</strong>，针对每一个 Pod 卷，创建一个该对象。</p><h1 id="Restore-Controller"><a href="#Restore-Controller" class="headerlink" title="Restore Controller"></a>Restore Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;restore_controller.go</u></em><br><em><u>pkg&#x2F;restore&#x2F;restore.go</u></em></p><h2 id="NewRestoreController"><a href="#NewRestoreController" class="headerlink" title="NewRestoreController"></a>NewRestoreController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restore_controller.go#L99">NewRestoreController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 Restore 资源的 Add 事件，将状态是空或者 New 的 Restore 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processQueueItem"><a href="#processQueueItem" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restore_controller.go#L178">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 Restore key，通过解析获取的 namespace 和 name 查询到集群中的 Restore 对象</li><li>仅处理状态为空或者 New 的 Restore 对象，调用 <strong>processRestore</strong>，执行恢复</li></ol><h2 id="processRestore"><a href="#processRestore" class="headerlink" title="processRestore"></a>processRestore</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restore_controller.go#L215">processRestore 源码</a></p><p>恢复的整体流程</p><ol><li><p>调用 <strong>validateAndComplete</strong> 做一些校验准备工作，并根据校验结果设置状态为 Restore 的状态为 FailedValidation 或者 InProgress</p></li><li><p>过滤掉校验失败的 Restore，调用 <strong>runValidatedRestore</strong>，执行恢复和上传恢复信息的流程</p></li><li><p>根据步骤 2 的恢复结果，设置 Restore 的状态</p><ul><li>如果有错误返回（函数返回 error），则认为恢复失败，将 Restore 状态设为 Failed</li><li>如果 Restore 的 Errors 存在错误信息，则为部分失败，将 Restore 状态设为 PartiallyFailed</li><li>否则认为 Restore 已完全恢复，将 Restore 状态设为 Completed</li></ul><p><em>runValidatedRestore 执行恢复过程中会设置 Restore 对象的 status.Errors 和 status.Warning 信息</em></p></li></ol><h2 id="validateAndComplete"><a href="#validateAndComplete" class="headerlink" title="validateAndComplete"></a>validateAndComplete</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restore_controller.go#L288">validateAndComplete 源码</a></p><p>校验 Restore 对象并返回 backupInfo 信息</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> backupInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">backup      *api.Backup</span><br><span class="line">location    *velerov1api.BackupStorageLocation</span><br><span class="line">backupStore persistence.BackupStore</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>在 Restore 对象的 ExcludedResources 中追加以下资源（以下资源会被备份，但是不会被恢复）<ul><li>nodes</li><li>events</li><li>events.events.k8s.io</li><li>backups.velero.io</li><li>restores.velero.io</li><li>resticrepositories.velero.io</li></ul></li><li>校验 Restore 对象的 IncludedResources 中是否包含上述资源</li><li>校验 included&#x2F;excluded resources&#x2F;namespaces 信息以及 –from-backup 和 –from-schedule 是否有且仅有一个</li><li>如果指定了 –from-schedule，则校验并获取 Schedule 下最新的一次 Backup，并设置在 Restore 中<br><em>如果没有设置，则 –from-backup 必然设置了，因此就不需要设置 Restore 的 Backup 信息了</em></li><li>根据 Restore 的 Backup 信息，查询并返回 BackupStorageLocation、Backup 和 StorageProvider 信息</li></ol><h2 id="runValidatedRestore"><a href="#runValidatedRestore" class="headerlink" title="runValidatedRestore"></a>runValidatedRestore</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restore_controller.go#L430">runValidatedRestore 源码</a></p><p>恢复的整体流程</p><ol><li><p>获取注册的 RestoreItemActions 插件<br><em>后续在调用 <strong>Restore</strong> 函数恢复时会使用到</em></p></li><li><p>调用 StorageProvider 的 GetBackupContents 接口，获取到 Backup 内容文件信息，写入临时文件中</p></li><li><p>根据 Restore 中的 Backup 名称信息，获取到集群中 PodVolumeBackup 信息</p></li><li><p>调用 StorageProvider 的 GetBackupVolumeSnapshots 接口，获取到 VolumeSnapshot 信息</p></li><li><p>用以上信息构建 Restore Request（原理类似 Backup 的 Request，不做赘述），其中 BackupReader 为步骤 2 中的临时文件句柄</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Request <span class="keyword">struct</span> &#123;</span><br><span class="line">*velerov1api.Restore</span><br><span class="line"></span><br><span class="line">Log              logrus.FieldLogger</span><br><span class="line">Backup           *velerov1api.Backup</span><br><span class="line">PodVolumeBackups []*velerov1api.PodVolumeBackup</span><br><span class="line">VolumeSnapshots  []*volume.Snapshot</span><br><span class="line">BackupReader     io.Reader</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 <strong>Restore</strong> 进行恢复，返回恢复的结果</p></li><li><p>重新获取 StorageProvider，避免长时间恢复中认证信息变动</p></li><li><p>关闭日志文件，本次恢复任务日志记录完毕，调用 StorageProvider 的 PutRestoreLog 接口，将恢复任务的日志信息上传至 BackupStorageLocation </p></li><li><p>统计 Warning 和 Error 级别日志数量，更新至 Restore 对象中，并构建 Result 对象（即代码块中的 m 对象），记录过程中产生的日志信息</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">restore.Status.Warnings = <span class="built_in">len</span>(restoreWarnings.Velero) + <span class="built_in">len</span>(restoreWarnings.Cluster)</span><br><span class="line"><span class="keyword">for</span> _, w := <span class="keyword">range</span> restoreWarnings.Namespaces &#123;</span><br><span class="line">restore.Status.Warnings += <span class="built_in">len</span>(w)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">restore.Status.Errors = <span class="built_in">len</span>(restoreErrors.Velero) + <span class="built_in">len</span>(restoreErrors.Cluster)</span><br><span class="line"><span class="keyword">for</span> _, e := <span class="keyword">range</span> restoreErrors.Namespaces &#123;</span><br><span class="line">restore.Status.Errors += <span class="built_in">len</span>(e)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">m := <span class="keyword">map</span>[<span class="type">string</span>]pkgrestore.Result&#123;</span><br><span class="line"><span class="string">&quot;warnings&quot;</span>: restoreWarnings,</span><br><span class="line"><span class="string">&quot;errors&quot;</span>:   restoreErrors,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>调用 StorageProvider 的 PutRestoreResults 接口，将 Result 信息上传至 BackupStorageLocation 中</p></li></ol><p>调用 StorageProvider 接口上传的具体文件对应关系如下：</p><table><thead><tr><th>名称</th><th>BackupStorageLocation 中的文件</th><th>数据源</th></tr></thead><tbody><tr><td>Log</td><td>restore-&lt;restore&gt;-logs.gz</td><td>步骤 8 中最终生成的 log 文件</td></tr><tr><td>Results</td><td>restore-&lt;restore&gt;-results.gz</td><td>步骤 9 中最终生成的 Result 对象</td></tr></tbody></table><h2 id="Restore-1"><a href="#Restore-1" class="headerlink" title="Restore"></a>Restore</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restore/restore.go#L159">Restore 源码</a></p><p>恢复动作本身的流程</p><ol><li>获取到 resource &amp; namespace 的 included &amp; excluded、resources hook 以及 resolvedActions（RestoreItemAction），构建 Restore Context，Context 是用于执行恢复所需要的上下文信息</li><li>将 request 中的 BackupReader 解压，并将内容解析成 Backup 的资源信息</li><li>如果 Velero 开启了 APIGroupVersions 特性，调用 <a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restore/prioritize_group_version.go#L46">chooseAPIVersionsToRestore</a> 对多 API Group Versions 的资源选择一个要恢复的版本</li><li>生成 update 队列，用于记录 Restore 状态信息，同时启动一个 Goroutine 监听队列，每秒钟获取一次 update 队列中的进度并更新至集群的 Restore 中</li><li>首先恢复 CRD 资源，调用 <strong>getOrderedResourceCollection</strong> 先获取要恢复的 CRD 资源集合，调用 <strong>processSelectedResource</strong> 开始恢复</li><li>接下来调用 <strong>getOrderedResourceCollection</strong> 获取剩余待恢复资源的有序集合，并调用 <strong>processSelectedResource</strong> 恢复<br><em>内置的恢复顺序为：<br>1. customresourcedefinitions<br />2. namespaces<br />3. storageclasses<br />4. volumesnapshotclass.snapshot.storage.k8s.io<br />5. volumesnapshotcontents.snapshot.storage.k8s.io<br />6. volumesnapshots.snapshot.storage.k8s.io<br />7. persistentvolumes<br />8. persistentvolumeclaims<br />9. secrets<br />10. configmaps<br />11. serviceaccounts<br />12. limitranges<br />13. pods<br />14. replicasets.apps<br />15. clusters.cluster.x-k8s.io<br />16. clusterresourcesets.addons.cluster.x-k8s.io</em></li><li>元数据恢复已经完成，更新集群中 Restore 的进度信息</li><li>等待 Restic 恢复所有的 Pod 卷数据<br><em>PodVolumeRestore 的创建位于步骤 6 中</em></li><li>等待 post restore exec hook 执行完毕</li></ol><h2 id="getOrderedResourceCollection"><a href="#getOrderedResourceCollection" class="headerlink" title="getOrderedResourceCollection"></a>getOrderedResourceCollection</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restore/restore.go#L1642">getOrderedResourceCollection 源码</a></p><p>构建要恢复的资源对象的有序集合</p><ol><li>构建需要恢复的资源列表，列表中元素为资源的名称，比如 customresourcedefinitions 等</li><li>针对每一个资源名称，构建 GroupResource，跳过已经处理的、被 included 和 excluded 排除在外的、类型为 namespace 的 GroupResource</li><li>针对该 GroupResource 的每一组资源实例（这组资源实例是以 namespace 做的划分），如果该资源实例的命名空间被排除，则忽略；否则，根据恢复时的命名空间映射关系，获取最终要创建恢复资源的命名空间</li><li>如果最终要恢复到的命名空间为空，代表该资源是集群级别的，并且在未指定包含全部命名空间或者指定了特定恢复的命名空间的情况，则忽略</li><li>针对每一组资源实例中的具体资源，根据 Backup 的 Content 目录读取该资源文件信息，反序列化成对象结构，最终针对该资源组实例，构建出一个可恢复、待恢复的资源集合</li></ol><h2 id="processSelectedResource"><a href="#processSelectedResource" class="headerlink" title="processSelectedResource"></a>processSelectedResource</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restore/restore.go#L582">processSelectedResource 源码</a></p><p>单个 item 资源的恢复流程</p><ol><li>针对每一个要恢复的 item 资源，在要恢复到的命名空间不存在的情况下，提前创建</li><li>根据 Backup 的 Content 目录读取该资源文件信息，反序列化成对象结构，调用 <strong>restoreItem</strong> 进行恢复</li><li>每恢复完一个对象，则更新一下 update 队列，上报恢复进度</li></ol><h2 id="restoreItem"><a href="#restoreItem" class="headerlink" title="restoreItem"></a>restoreItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restore/restore.go#L907">restoreItem 源码</a></p><p>单个 item 资源的恢复流程</p><ol><li>传入的 item 是解构状态的资源信息（runtime.Unstructured）</li><li>如果最终要恢复到的命名空间不为空，需要根据实际情况提前创建；如果为空，代表该资源是集群级别的，在不恢复集群级别资源时，会忽略掉该资源</li><li>以下资源视为“完成”，不会进行恢复<ul><li>相位为 Succeed 或者 Failed 的 Pod</li><li>已经有完成时间的 Job</li><li>已经恢复的资源</li><li>mirror Pod</li></ul></li><li>如果恢复的资源是 PV 类型，需要考虑以下场景<ul><li>如果要恢复的 PV 中有快照信息，代表着备份时 SnapshotProvider 执行过快照操作<br>先判断是否需要对其重命名，以下情况不需要重命名<ul><li>恢复时未指定命名空间映射关系</li><li>要恢复的 PV 未被认领</li><li>认领该 PV 的命名空间不需要被映射</li><li>当前集群中不存在重名 PV<br>如果恢复时，指定了命名空间映射关系，需要根据映射关系，将认领 PV 的命名空间（即 spec.ClaimRef.Namespace）进行更新，如果判断后不需要对 PV 重命名时，则说明该 PV 应该被恢复，反之需要判断该 PV 对象是否应该被恢复，具体规则如下</li><li>当前集群中不存在重名 PV，则应该被恢复</li><li>重名 PV 处于 Release 状态，等待直至超时</li><li>重名 PV 没有被认领，则不应该被恢复</li><li>重名 PV 被认领，但是没找到相关 PVC，则等待 PVC 创建直至超时</li><li>认领重名 PV 的 PVC 处于删除状态，等待直至超时</li><li>认领重名 PV 的 PVC 所在命名空间不存在或者处于删除状态，等待直至超时</li><li><em>默认超时时间为 10 分钟，未超时期间内会周期性判断，一旦超时则表示不应该被恢复</em><br>如果 PV 应该被恢复，则重置之前的绑定信息，调用 SnapshotProvider 的一系列接口恢复卷数据信息，参考 executePVAction，并根据需要重命名 PV</li></ul></li><li>如果要恢复的 PV 的卷数据是由 Restic 负责备份的（即 PodVolumeBackup annotation 信息中记录了 pv.Spec.ClaimRef.Name），则不会恢复，而是交给 StorageClass 重新动态供应</li><li>如果要恢复的 PV 的回收策略为 Delete，则不会恢复，而是交给 StorageClass 重新动态供应</li><li>如果并非以上任意场景，则不需要额外的特殊操作，重置绑定信息，进行后续流程直接恢复即可</li></ul></li><li>删除掉不关键的元信息，仅保留 name、namespace、labels 和 annotation，并删除对象 status 信息，执行 RestoreItemAction 的动作</li><li>如果恢复的资源是 PVC 类型，则重置之前的和 PV 的绑定信息以及 K8s 设置的 annotation，如果认领的 PV 重命名了，则同步更新 PVC 信息</li><li>根据命名空间映射关系，设置 item 的新命名空间，并设置 velero.io&#x2F;backup-name 和 velero.io&#x2F;restore-name 标签信息</li><li>在当前集群中创建 item 资源，如果 item 资源已经存在（但是却又不深度一致）并且是 ServiceAccount 类型，则会以集群当前的 ServiceAccount 资源为准合并 item 资源并更新，而对于其他类型的资源则认为恢复失败，原因是备份的版本和恢复的版本不一致；而如果已存在的 item 和待恢复的 item 深度一致，也就是两者版本一致，不会恢复，也不会视为错误</li><li>如果恢复的资源是 Pod 类型，会针对每一个被 Restic 备份的卷，创建一个 PodVolumeRestore 对象，后续由 PodVolumeRestore Controller 负责维护，同时，主进程会阻塞直到 PodVolumeRestore 有状态返回，表示卷数据恢复完成</li><li>如果恢复的资源是 Pod 类型，执行 post restore hook 操作</li><li>如果恢复的资源是 CRD 类型，则等待直至 CRD 资源变得可用才继续执行后续恢复流程</li></ol><h1 id="PodVolumeRestore-Controller"><a href="#PodVolumeRestore-Controller" class="headerlink" title="PodVolumeRestore Controller"></a>PodVolumeRestore Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;pod_volume_restore_controller.go</u></em><br><em><u>pkg&#x2F;restic&#x2F;exec_commands.go</u></em></p><h2 id="NewPodVolumeRestoreController"><a href="#NewPodVolumeRestoreController" class="headerlink" title="NewPodVolumeRestoreController"></a>NewPodVolumeRestoreController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_restore_controller.go#L72">NewPodVolumeRestoreController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler，并将 PodVolumeRestore、Pod 和 PVC 添加到 cacheSyncWaiters，等待同步完成</li><li>监听 PodVolumeRestore 资源的 Add 和 Update 事件，根据状态是 New 的 PodVolumeRestore 资源获取到相关联的 Pod，如果 Pod 运行在本节点，并且 Restic Init Container 处于 Running，则将 PodVolumeRestore 以 key（namespace&#x2F;name） 的形式加入 Generic Controller 的 queue 中<br><em>restic-wait 处于运行状态表示，该 Pod 正在等待 Restic 为其恢复卷数据</em></li><li>监听 Pod 资源的 Add 和 Update 事件，针对运行在本节点，并且 Restic Init Container 处于 Running，获取到相关联的 PodVolumeRestore 资源，将状态是 New 的 PodVolumeRestore 以 key（namespace&#x2F;name） 的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processQueueItem-1"><a href="#processQueueItem-1" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_restore_controller.go#L240">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 PodVolumeRestore key，通过解析获取的 namespace 和 name 查询到集群中的 PodVolumeRestore 对象</li><li>调用 <strong>processRestore</strong>，执行卷数据的备份</li></ol><h2 id="processRestore-1"><a href="#processRestore-1" class="headerlink" title="processRestore"></a>processRestore</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_restore_controller.go#L277">processRestore 源码</a></p><p>卷数据恢复的整体流程</p><ol><li>更新 PodVolumeRestore 状态为 InProgress</li><li>获取到 PodVolumeRestore 相关联的 Pod，进一步获取到 Pod 内部的挂载卷目录信息</li><li>调用 <strong>restorePodVolume</strong> 执行卷数据的恢复，如果调用结果有错误返回，则设置 PodVolumeRestore 状态为 Failed</li><li>更新 PodVolumeRestore 状态为 Completed</li></ol><h2 id="restorePodVolume"><a href="#restorePodVolume" class="headerlink" title="restorePodVolume"></a>restorePodVolume</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_restore_controller.go#L326">restorePodVolume 源码</a></p><p>借助 Restic 能力恢复卷数据的流程</p><ol><li>根据 Pod 内部的挂载卷信息和 Restic Pod 内部的 &#x2F;host_pods 目录，拼接出到 Pod 挂载数据卷目录<br><em>最终数据会从 Restic Repo 将卷数据恢复至这个目录，例如 &#x2F;host_pods&#x2F;new-pod-uid&#x2F;volumes&#x2F;volume-plugin-name&#x2F;volume-dir</em></li><li>生成用于连接 Restic Repo 所需要的临时密码文件，文件固定为 &#x2F;tmp&#x2F;credentials&#x2F;velero&#x2F;velero-restic-credentials-repository-password，内容为 static-passw0rd，用于 restic 原生命令中的 –password 参数<br><em>密码会以 Secret 的形式存储在集群中，名为 velero-restic-credentials，位于 velero 命名空间内</em></li><li>构建 restic restore 命令</li><li>如果 BackupStorageLocation 有 caCert 证书信息，会将其临时写入到磁盘中，供 Restic 认证使用，并设置在 restic restore 命令中</li><li>给 restic restore 命令设置 Restic 原生所需的环境变量信息</li><li>调用 <strong>RunRestore</strong>，执行 Restic 原生的卷数据恢复流程</li><li>为了保险起见，先移除卷目录下的 .velero 目录，然后重新创建，并写入 Restore 的 UID，Restic 的 Init Container 会一致等待直到读取到这个文件的生成</li></ol><h2 id="RunRestore"><a href="#RunRestore" class="headerlink" title="RunRestore"></a>RunRestore</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restic/exec_commands.go#L186">RunRestore 源码</a></p><p>调用 Restic 原生备份命令 restic restore</p><ol><li>通过 restic stats 命令获取到总快照的大小，并更新至 PodVolumeRestore 中</li><li>将入参的 Command 对象构建成可执行命令并执行</li><li>启动一个 Goroutine，每 10 秒钟获取一次已经恢复的数据目录总大小，并更新 PodVolumeRestore 总恢复进度（待恢复总文件大小和当前恢复文件大小）</li><li>恢复完成后，更新 PodVolumeRestore 进度至 100%<br><em>此处未判断恢复成功与否，只是将进度设为 100%，并返回 restic restore 的 stdout，stderr 和 err 信息，由上层调用方判断</em></li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 Restore 等恢复相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Backup</title>
    <link href="http://shenxianghong.github.io/2022/01/27/2022-01-27%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Backup/"/>
    <id>http://shenxianghong.github.io/2022/01/27/2022-01-27%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Backup/</id>
    <published>2022-01-26T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.167Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="Backup"><a href="#Backup" class="headerlink" title="Backup"></a>Backup</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/backup.go">API</a></p><h2 id="backup"><a href="#backup" class="headerlink" title="backup"></a>backup</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;backup.go</u></em></p><p>velero backup 包括 6 个子命令：create、delete、describe、download、get 和 logs。</p><h2 id="create"><a href="#create" class="headerlink" title="create"></a>create</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;create.go</u></em></p><p><strong>校验规则</strong></p><ul><li>必须指定 Backup 名称，除非指定了 –from-schedule 参数</li><li>在指定 –storage-location 参数时，其在集群中必须存在</li><li>在指定 –volume-snapshot-locations 参数时，其在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 Backup 对象，下发至集群中创建，后续由 Backup Controller 负责维护</li><li>如果开启了 –wait，则启动 informer 监听 Backup 对象状态，阻塞直至状态不再是 New 或者 InProgress</li></ol><p><em>如果 Backup 是基于定时任务（Schedule）创建的，则忽略其他所有的 filter 信息，以 Schedule 规格为准，除此之外，Backup 的名称也可以不指定，默认格式为 schedule-timestamp。</em></p><h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;delete.go</u></em></p><p><strong>校验规则</strong></p><ul><li>name、–all 和 –selector 参数有且仅能有一个</li><li>要删除的 Backup 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 DeleteBackupRequest 对象，下发至集群中创建，后续由 BackupDeletion Controller 负责维护</li></ol><h2 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;describe.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Backup 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 Backup 的删除事件</li><li>获取到卷备份的信息和 CSI 快照信息（如果 Velero 服务开启了 CSI 特性）</li><li>将以上信息和 Backup 的元信息、规格、状态等汇总作为描述信息格式化输出<br><em>在开启 –details 时，会构建 DownloadRequest 对象获取  BackupResourceList 的信息</em></li></ol><h2 id="download"><a href="#download" class="headerlink" title="download"></a>download</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;download.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Backup 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 DownloadRequest 对象，下发至集群中创建，后续由 DownloadRequest Controller 负责维护，获取 BackupContents 的信息 </li><li>阻塞直至 DownloadRequest 的 DownloadURL 被设置，将内容写入 –output 指定的位置</li></ol><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;get.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Backup 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 Backup 资源，根据 –output 指定的样式格式化输出</li></ol><h2 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup&#x2F;logs.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Backup 在集群中必须存在</li><li>Backup 的状态必须为 Completed、PartiallyFailed 或者 Failed</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 DownloadRequest 对象，下发至集群中创建，后续由 DownloadRequest Controller 负责维护，获取 BackupLog 的信息 </li><li>阻塞直至 DownloadRequest 的 DownloadURL 被设置，将内容写入 stdout 中</li></ol><h1 id="PodVolumeBackup"><a href="#PodVolumeBackup" class="headerlink" title="PodVolumeBackup"></a>PodVolumeBackup</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/pod_volume_backup.go">API</a></p><p>对象不支持手动创建，而是在备份流程中，由 Backup Controller 调用 <strong>backupPodVolumes</strong>，针对每一个 Pod 卷，创建一个该对象。</p><h1 id="Schedule"><a href="#Schedule" class="headerlink" title="Schedule"></a>Schedule</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/schedule.go">API</a></p><h2 id="schedule"><a href="#schedule" class="headerlink" title="schedule"></a>schedule</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;schedule&#x2F;schedule.go</u></em></p><p>velero schedule 包括 4 个子命令：create、delete、describe 和 get。</p><h2 id="create-1"><a href="#create-1" class="headerlink" title="create"></a>create</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;schedule&#x2F;create.go</u></em></p><p><strong>校验规则</strong></p><ul><li>–schedule 为必需参数</li><li>在指定 –storage-location 参数时，其在集群中必须存在</li><li>在指定 –volume-snapshot-locations 参数时，其在集群中必须存在</li></ul><p><em>创建定时备份任务时并不会校验 schedule 表达式的合法性，而是交给 Schedule Controller 作后续处理。</em></p><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 Schedule 对象，下发至集群中创建，后续由 Scheduler Controller 负责维护</li></ol><h2 id="delete-1"><a href="#delete-1" class="headerlink" title="delete"></a>delete</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;schedule&#x2F;delete.go</u></em></p><p><strong>校验规则</strong></p><ul><li>name、–all 和 –selector 参数有且仅能有一个</li><li>要删除的 Schedule 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，获取集群中的 Schedule 资源并删除</li></ol><h2 id="describe-1"><a href="#describe-1" class="headerlink" title="describe"></a>describe</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;schedule&#x2F;describe.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Schedule 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 Schedule 资源，格式化输出</li></ol><h2 id="get-1"><a href="#get-1" class="headerlink" title="get"></a>get</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;schedule&#x2F;get.go</u></em></p><p><strong>校验规则</strong></p><ul><li>要获取的 Schedule 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 Schedule 资源，根据 –output 指定的样式格式化输出</li></ol><h1 id="Backup-Controller"><a href="#Backup-Controller" class="headerlink" title="Backup Controller"></a>Backup Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;backup_controller.go</u></em><br><em><u>pkg&#x2F;backup&#x2F;backup.go</u></em></p><h2 id="NewBackupController"><a href="#NewBackupController" class="headerlink" title="NewBackupController"></a>NewBackupController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller.go#L89">NewBackupController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 Backup 资源的 Add 事件，将状态是空或者 New 的 Backup 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processBackup"><a href="#processBackup" class="headerlink" title="processBackup"></a>processBackup</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller.go#L207">processBackup 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 Backup key，通过解析获取的 namespace 和 name 查询到集群中的 Backup 对象</li><li>仅处理状态是空或者 New 的 Backup 对象</li><li>调用 <strong>prepareBackupRequest</strong> 做一些校验准备工作，并根据校验的结果设置 Backup 的状态为 FailedValidation 或者 InProgress</li><li>过滤掉校验失败的 Backup，调用 <strong>runBackup</strong>，执行备份和上传备份信息的流程，执行结果决定了备份是否顺利完成，如果有错误返回，则记录 Backup 状态为 Failed</li></ol><h2 id="prepareBackupRequest"><a href="#prepareBackupRequest" class="headerlink" title="prepareBackupRequest"></a>prepareBackupRequest</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller.go#L328">prepareBackupRequest 源码</a></p><p>在不破坏集群中原 Backup 对象（以下称为 original）的情况下，构建了一个 BackupRequest 对象（以下称为 request），这个对象包含了 original 的详细规格（即 original 的深拷贝），并且包含一些丰富处理流程的中间态信息，并且在整个备份流程中的操作都是基于 request，在备份完成后，会将 request 信息同步更新至集群中的 Backup 对象。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Request is a request for a backup, with all references to other objects</span></span><br><span class="line"><span class="comment">// materialized (e.g. backup/snapshot locations, includes/excludes, etc.)</span></span><br><span class="line"><span class="keyword">type</span> Request <span class="keyword">struct</span> &#123;</span><br><span class="line">*velerov1api.Backup</span><br><span class="line"></span><br><span class="line">StorageLocation           *velerov1api.BackupStorageLocation</span><br><span class="line">SnapshotLocations         []*velerov1api.VolumeSnapshotLocation</span><br><span class="line">NamespaceIncludesExcludes *collections.IncludesExcludes</span><br><span class="line">ResourceIncludesExcludes  *collections.IncludesExcludes</span><br><span class="line">ResourceHooks             []hook.ResourceHook</span><br><span class="line">ResolvedActions           []resolvedAction</span><br><span class="line"></span><br><span class="line">VolumeSnapshots  []*volume.Snapshot</span><br><span class="line">PodVolumeBackups []*velerov1api.PodVolumeBackup</span><br><span class="line">BackedUpItems    <span class="keyword">map</span>[itemKey]<span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对 request 赋值和校验的操作</p><ol><li>将 original 深拷贝至 request 中的 Backup 中，并设置 request  版本、过期时间、是否将卷数据备份至 Restic、StorageLocation 等信息</li><li>校验 BackupStorageLocation 的合法性，以及 access mode 是否为预期的 ReadWrite</li><li>检验 volume snapshot location 的合法性<br><em>backup.Spec.VolumeSnapshotLocation 为 []string 类型，支持多个 location，但是要求 location 和 VolumeSnapshotter 必须是一对一的关系（也就是说不允许多个 location 对应同一个 VolumeSnapshotter）。默认情况下，–snapshotvolume 为 true，所以只要存在一个合法的 default vsl，则最终的 backup.Spec.VolumeSnapshotLocation 均会包含这个 default vsl，详细逻辑参考 <a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller_test.go#L861">TestValidateAndGetSnapshotLocations</a></em></li><li>设置 request 的注解和 resources &amp; namespaces 的 included &amp; excluded 检验信息</li></ol><h2 id="runBackup"><a href="#runBackup" class="headerlink" title="runBackup"></a>runBackup</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller.go#L533">runBackup 源码</a></p><p>备份的整体流程</p><ol><li><p>基于临时文件句柄生成 gzip writer ，并指定 stdout 和 gzip writer 为 logger 输出，初始化用于统计日志级别数量的 counter<br><em>因此，日志不仅会输出在 Velero Pod 中，并且会生成 BackupLog，后续会上传至 BackupStorageLocation 中</em></p></li><li><p>生成一个用于存放 Backup 版本和内容的临时文件<br><em>后续在调用 <strong>Backup</strong> 时会传入该临时文件</em></p></li><li><p>获取注册的 BackupItemAction 插件<br><em>后续在调用 <strong>Backup</strong> 时会传入该 action 信息</em></p></li><li><p>通过 StorageProvider 的 BackupExists 接口判断远端存储中是否有同名备份</p><ul><li>如果存在，则设置 Backup 状态为 Failed，本次备份失败</li><li>如果不存在，则调用 <strong>Backup</strong> 进行准备与备份</li></ul></li><li><p>如果 Velero 开启了 CSI 特性，则获取集群中与该 Backup 相关的 VolumeSnapshots 和 VolumeSnapshotContents 信息<br><em>后续会上传至 BackupStorageLocation 中</em></p></li><li><p>设置 request 的卷快照总量与成功量、完成时间戳、Warnings 和 Errors 的个数以及备份的状态等等，关闭日志文件，本次备份任务日志记录完毕<br><em>备份的状态（Failed、PartiallyFailed 或者 Completed）是根据日志输出级别的统计决定的，fatalErrs 记录了调用 backupper.Backup 产生的错误日志信息，不仅如此，在后续上传备份文件的时候，如果发生异常，也会记录，所以 request 的状态是否为 Failed 是 fatalErrs 决定的，而状态是否为 Completed 和 PartiallyFailed 是根据日志中 Error 级别的输出数量决定的，<strong>该日志也包括调用 StorageProvider 中产生的日志级别信息</strong></em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">backup.Status.Warnings = logCounter.GetCount(logrus.WarnLevel)</span><br><span class="line">backup.Status.Errors = logCounter.GetCount(logrus.ErrorLevel)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Assign finalize phase as close to end as possible so that any errors</span></span><br><span class="line"><span class="comment">// logged to backupLog are captured. This is done before uploading the</span></span><br><span class="line"><span class="comment">// artifacts to object storage so that the JSON representation of the</span></span><br><span class="line"><span class="comment">// backup in object storage has the terminal phase set.</span></span><br><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="built_in">len</span>(fatalErrs) &gt; <span class="number">0</span>:</span><br><span class="line">backup.Status.Phase = velerov1api.BackupPhaseFailed</span><br><span class="line"><span class="keyword">case</span> logCounter.GetCount(logrus.ErrorLevel) &gt; <span class="number">0</span>:</span><br><span class="line">backup.Status.Phase = velerov1api.BackupPhasePartiallyFailed</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">backup.Status.Phase = velerov1api.BackupPhaseCompleted</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>重新获取 StorageProvider，避免长时间备份中认证信息变动， 调用 StorageProvider 的 PutBackup 接口将备份信息上传至 BackupStorageLocation 中，具体文件的对应关系如下：</p><table><thead><tr><th>名称</th><th>BackupStorageLocation 中的文件</th><th>数据源</th></tr></thead><tbody><tr><td>Metadata</td><td>velero-backup.json</td><td>backup.Backup 对象</td></tr><tr><td>Content</td><td>&lt;backup&gt;.tar.gz</td><td>步骤 2 中的临时文件内容</td></tr><tr><td>Log</td><td>&lt;backup&gt;-logs.gz</td><td>步骤 6 中最终生成的 log 文件</td></tr><tr><td>PodVolumeBackups</td><td>&lt;backup&gt;-podvolumebackups.json</td><td>backup.PodVolumeBackups</td></tr><tr><td>VolumeSnapshots</td><td>&lt;backup&gt;-volumesnapshots.json.gz</td><td>backup.VolumeSnapshots</td></tr><tr><td>BackupResourceList</td><td>&lt;backup&gt;-resource-list.json.gz</td><td>backup.BackedUpItems</td></tr><tr><td>CSIVolumeSnapshots</td><td>&lt;backup&gt;-csi-volumesnapshots.json.gz</td><td>步骤 5 中 volume snapshots</td></tr><tr><td>CSIVolumeSnapshotContents</td><td>&lt;backup&gt;-csi-volumesnapshotcontents.json.gz</td><td>步骤 5 中 volume snapshot contents</td></tr></tbody></table><p>这里需要区分 PodVolumeBackups 和 VolumeSnapshots</p><ul><li>PodVolumeBackups 是描述了备份的 Pod 中的卷数据信息，与之关联的是 Restic 相关概念，数据最终会写入 ResticRepository 中</li><li>VolumeSnapshots 是相比于 CSI 而言属于 Velero 原生的卷快照，用于描述一个 PV 快照的信息，本身作为 Backup 的一部分，数据最终会由对应的 SnapshotProvider 处理</li><li>即使两者最终的数据均不会存放在 BackupStorageLocation 中，但是仍然会在 BackupStorageLocation 中记录其基础信息</li></ul></li></ol><h2 id="Backup-1"><a href="#Backup-1" class="headerlink" title="Backup"></a>Backup</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/backup/backup.go#L205">Backup 源码</a></p><p>备份动作本身的流程</p><ol><li>基于传入的临时文件，生成 gzip writer，最终会以 <em>backup</em>.tar.gz 格式存放在 BackupStorageLocation 中作为 Content，该 tar.gz 包括两个主要内容：metadata 和 resources，前者用于存放版本，后者用于存放被备份资源的详细规格信息<br><em>区别于记录 Backup 本身的 Metadata，此处的 metdata 仅为一个目录层级；在后续 <strong>backupItem</strong> 流程中，会将资源信息写入 resources 文件中</em></li><li>在 metadata 目录下写入版本信息 version，固定值为 1.1.0</li><li>设置 request 的 resource &amp; namespace 的 included &amp; excluded、resources hook 以及 resolve action（BackupItemAction）<ul><li>namespace 和 resource 的处理方式并不一样，是因为 namespace 只要做匹配即可，存在与不存在很容易定性，但是 resource 有很多种表示方式，例如 pv 和 persistentvolumes，对于复杂的资源来讲，还有 ApiGroup 的概念，因此，需要 RESTmapping 的 ResourceFor 匹配出最合适且规范的一个 GVR，这也就是为什么使用时可以在合理范围任意指定资源名称均会匹配正确的原因</li><li>BackupItemAction 有两个接口，一个是 AppliesTo，一个是 Execute，前者用于返回 labelSelector，用于备份阶段的过滤筛选，后者用于执行 BackupItemAction 中定义的额外动作</li></ul></li><li>生成临时空文件，供后续 itemCollector 使用，itemCollector 根据 Backup 规格信息通过 K8s API 收集待备份的资源详细信息并写入空文件中<br><em>该空文件用于 <strong>getAllItems</strong> 时，作为每一个 item 的解构文件的根目录</em></li><li><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/backup/item_collector.go#L57">getAllItems</a> 通过 discovery 获取到所有的 API group（例如 batch&#x2F;v1beta1，networking.k8s.io&#x2F;v1beta1 等等），然后根据每个 group 获取到 resource（例如 cronjobs，networkpolicies 等等），根据 namespace 和 resource 的 include 和 exclude 以及标签选择器规则进行过滤资源，过滤后的结果就是待备份的对象（item）<br><em>item 的内容（unstructured.Unstructured 对象）已经写入了步骤 4 的临时目录里，同时，这个文件的路径会记录在 item 的 path 中，后续在 <strong>backupItem</strong> 时，会解析作为解构状态的 item 传入</em></li><li>更新 Backup 的待备份资源的总量信息</li><li>生成 update 队列，用于记录 Backup 状态信息，同时启动一个 Goroutine 监听队列，每秒钟获取一次 update 队列中的进度并更新至 Backup 中</li><li>遍历每一个待备份的 item，调用 <strong>backupItem</strong> 函数，进行备份，并将进度信息写入 update 队列中，完成进度上报</li><li>如果备份规格中指定了备份集群级别资源（IncludeClusterResources），则额外备份 CRD 资源<br><em>这里的 CRD 资源其实是有限制条件的，就是仅处理已经备份了与 CRD 相关的 CR 资源时，才会备份对应的 CRD</em></li><li>更新集群中 Backup 对象的备份进度信息至 100%</li></ol><h2 id="backupItem"><a href="#backupItem" class="headerlink" title="backupItem"></a>backupItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/backup/backup.go#L424">backupItem 源码</a></p><p>单个 item 资源的备份流程</p><ol><li>传入的 item 是解构状态的资源信息（runtime.Unstructured），解构数据来源于 item 的 path 字段，需要重新构建成 metav1.Object，提取信息</li><li>对于以下情况跳过备份，并且返回 false 标识，表示资源未参与备份<br><em>未参与备份的资源，即使在指定了备份集群级别资源时也不会备份相关的 CRD</em><ul><li>标签中有 velero.io&#x2F;exclude-from-backup 字段的资源</li><li>资源属于 Backup 规格中指定的 namespace 和 groupResource 的</li><li>非 namespace 的资源即是集群级别的，但是备份规格中的 IncludeClusterResources 为 false</li><li>资源处于删除状态</li></ul></li><li>对于已经备份的资源，自然也会跳过备份，但是返回 true 标识，表示资源已经备份</li><li>执行 pre hook 动作（只有类型是 Pod 的 资源才会真正的处理 pre hook），hook 作用的对象需要满足 BackupItemAction 中定义的 applyTo 接口的标签选择，hook command 的执行（即 execute 接口）是通过 K8s rest API exec 实现</li><li>针对类型是 Pod 的资源，在 spec.Volumes 中获取需要借助 Restic 备份的卷<br><em>由于 PV 和 PVC 是 1 对 1，PVC 和 Pod 是 1 对 n 的关系，所以在这里通过跟踪 PVC 的备份情况即可判断卷是否被备份过，备份过的卷，会在相关的 tracker 中以 PVC 为 key 作记录</em></li><li>调用 BackupItemAction 的 execute 接口，进行额外的操作，如更新资源等，此后的流程基于接口返回的对象继续操作，执行失败时，会执行 post hook 动作</li><li>针对类型是 PV 的资源，调用 takePVSnapshot，忽略已经被 Restic 备份的 PV，初始化 SnapshotProvider，通过一系列的接口，完成卷快照的操作，并将快照信息记录在 request 的 VolumeSnapshots 中<br><em>在 Velero 开启 CSI 特性时，需要额外加载一个 plugin（<a href="https://github.com/vmware-tanzu/velero-plugin-for-csi%EF%BC%89%EF%BC%8C%E8%AF%A5">https://github.com/vmware-tanzu/velero-plugin-for-csi），该</a> plugin 就是 SnapshotProvider 类型。因此在这步时，便会对 PV 做快照操作</em></li><li>针对类型是 Pod 的资源，调用 <strong>BackupPodVolumes</strong>，借助 Restic 能力实现对 Pod 卷数据的备份</li><li>执行 post hook 动作</li><li>在 resources 目录下写入备份的资源信息，资源会根据 kind、 namepace 等信息归类，文件内容为 item 的 runtime.Unstructured 形式，以 json 格式存储<br><em>文件是上层调用传入的 Content 文件</em></li><li>至此，针对单一的 item 备份流程结束，其中包含了存储在 kube-apiserver 中的结构化元信息和卷数据的备份</li></ol><h2 id="BackupPodVolumes"><a href="#BackupPodVolumes" class="headerlink" title="BackupPodVolumes"></a>BackupPodVolumes</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restic/backupper.go#L99">backupPodVolumes 源码</a></p><p>借助 Restic 能力备份卷数据的流程</p><ol><li>每一个 Pod 卷所属的 namespace 必须有且仅有一个对应的 ResticRepository 对象，如果不存在，则会创建一个，由 ResticRepository Controller 会负责维护状态，而 Backup Controller  会阻塞直至 ResticRepository 超时或者 ready<br><em>创建对象时会指定基于的 BackupStorageLocation，并将 BackupStorageLocation 转换成 RepoIdentifier 信息，也就是 Restic 原生命令中的 -r 参数</em></li><li>过滤掉 hostPath 类型的卷，对其余的合法卷会创建对应的 PodVolumeBackup 对象，其中 PodVolumeBackup 中会设置 velero.io&#x2F;backup-name 标签以及 PVC 的 UID 信息<br><em>此时，该对象的 spec.RepoIdentifier 已被设置，例如 s3:<a href="http://minio.velero.svc:9000/velero/restic/velero%E3%80%82%E6%AD%A4%E5%A4%96%EF%BC%8C%E7%94%B1%E4%BA%8E%E5%9C%A8">http://minio.velero.svc:9000/velero/restic/velero。此外，由于在</a> velero 1.6.3 中不会判断 Pod 的状态，因此依旧会对 pending 状态的 Pod 创建 PodVolumeBackup 对象，但是此 PodVolumeBackup 对象没有 nodeName 属性，导致 Restic 不作处理，从而阻塞 Velero 直至超时。除此之外，restic 状态异常也会导致类似问题，参考：<a href="https://github.com/vmware-tanzu/velero/issues/4874">https://github.com/vmware-tanzu/velero/issues/4874</a></em></li><li>PodVolumeBackup Controller 会负责卷的备份，而 Backup Controller 会阻塞直至卷备份返回完成或者失败</li></ol><h2 id="resync"><a href="#resync" class="headerlink" title="resync"></a>resync</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_controller.go#L166">resync 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 1 分钟</p><ol><li>获取集群中所有的 Backup 对象，更新 backup_total 指标，value 为集群中所有 Backup 总数</li><li>针对每一个状态已经完成且归属于某一个 Schedule 的 Backup，设置 backup_last_successful_timestamp 指标，key 为 Schedule 名称，value 为最近的一次备份时间戳</li></ol><h1 id="PodVolumeBackup-Controller"><a href="#PodVolumeBackup-Controller" class="headerlink" title="PodVolumeBackup Controller"></a>PodVolumeBackup Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;pod_volume_backup_controller.go</u></em><br><em><u>pkg&#x2F;restic&#x2F;exec_commands.go</u></em></p><h2 id="NewPodVolumeBackupController"><a href="#NewPodVolumeBackupController" class="headerlink" title="NewPodVolumeBackupController"></a>NewPodVolumeBackupController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_backup_controller.go#L72">NewPodVolumeBackupController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler，并将 PodVolumeBackup、Pod 和 PVC 添加到 cacheSyncWaiters，等待同步完成</li><li>监听 PodVolumeBackup 资源的 Add 和 Update 事件，将状态是空或者 New 并且位于当前节点的 PodVolumeBackup 资源以 key （namespace&#x2F;name） 的形式加入 Generic Controller 的 queue 中<br><em>PodVolumeBackup Controller 运行在 DaemonSet 形式的 Restic 服务中，挂载所在节点的 Pod 卷，因此 PodVolumeBackup 具有节点属性，PodVolumeBackup Controller 仅处理当前节点的 PodVolumeBackup 对象</em></li></ol><h2 id="processQueueItem"><a href="#processQueueItem" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_backup_controller.go#L140">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 PodVolumeBackup key，通过解析获取的 namespace 和 name 查询到集群中的 PodVolumeBackup 对象</li><li>仅处理状态为空或者 New 的 PodVolumeBackup 对象，调用 <strong>processBackup</strong>，执行卷数据的备份</li></ol><h2 id="ProcessBackup"><a href="#ProcessBackup" class="headerlink" title="ProcessBackup"></a>ProcessBackup</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_backup_controller.go#L188">ProcessBackup 源码</a></p><p>卷数据备份的整体流程</p><ol><li>更新 PodVolumeBackup 状态为 InProgress</li><li>校验 PodVolumeBackup 对象规格中声明的卷源 Pod 是否存在，获取到 Pod 卷在 host 上子目录信息<br><em>例如  &#x2F;host_pods&#x2F;e4ccf918-76d7-4972-a54a-39b39f15b53b&#x2F;volumes&#x2F;kubernetes.io~empty-dir&#x2F;plugins，&#x2F;host_pods 为 Restic Pod 中的目录，挂载了 host 的 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;， 详细逻辑参考 <a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/util/kube/utils_test.go#L159">TestGetVolumeDirectorySuccess</a></em></li><li>生成用于连接 Restic Repo 所需要的临时密码文件，文件固定为 &#x2F;tmp&#x2F;credentials&#x2F;velero&#x2F;velero-restic-credentials-repository-password，内容为 static-passw0rd，用于 restic 原生命令中的 –password 参数<br><em>密码会以 Secret 的形式存储在集群中，名为 velero-restic-credentials，位于 velero 命名空间内</em></li><li>构建 restic backup 命令</li><li>如果 BackupStorageLocation 有 caCert 证书信息，会将其临时写入到磁盘中，供 Restic 认证使用，并设置在 restic backup 命令中<br><em>因为本质上，Restic 的 repo 和 Velero 的 BackupStorageLocation 为同一个</em></li><li>给 restic backup 命令设置 Restic 原生所需的环境变量信息</li><li>在备份流程中生成 PodVolumeBackup 对象时，如果 Pod 卷源于 PVC，则会对 PodVolumeBackup 加一个 velero.io&#x2F;pvc-uid 的 label，值为 PVC 的 uid。因此，在这里会通过这个 label 判断卷是否源于 PVC，如果是，则会获取集群中所有带有此 label、状态已经完成并且 BackupStorageLocation 相同的 PodVolumeBackup 对象，如果存在则表示这个卷已经备份过，后续的备份会基于最近的一次备份点进行增量备份，反之则全量备份，这里的增量备份借助了 Restic 原生功能（–parent）<br><em>详细逻辑参考 <a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/pod_volume_backup_controller.go#L338">getParentSnapshot</a></em></li><li>调用 <strong>RunBackup</strong>，执行 Restic 原生的卷数据备份流程</li><li>更新 PodVolumeBackup 对象的状态、完成时间、快照 ID 和卷数据路径等信息</li></ol><h2 id="RunBackup"><a href="#RunBackup" class="headerlink" title="RunBackup"></a>RunBackup</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restic/exec_commands.go#L73">RunBackup 源码</a></p><p>调用 Restic 原生备份命令 restic backup</p><ol><li>将入参的 Command 对象构建成可执行命令并执行</li><li>启动一个 Goroutine，每 10 秒钟解析一次 restic backup 命令的标准输出，更新 PodVolumeBackup 的备份进度信息（待备份总文件大小和当前备份文件大小）</li><li>通过解析标准输出判断如果 Restic 备份成功，则更新 PodVolumeBackup 进度至 100%</li></ol><h1 id="Schedule-Controller"><a href="#Schedule-Controller" class="headerlink" title="Schedule Controller"></a>Schedule Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;schedule_controller.go</u></em></p><h2 id="NewScheduleController"><a href="#NewScheduleController" class="headerlink" title="NewScheduleController"></a>NewScheduleController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/schedule_controller.go#L60">NewScheduleController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 Schedule 资源的 Add 事件，将状态是空、New 或者 Enabled 的 Schedule 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processSchedule"><a href="#processSchedule" class="headerlink" title="processSchedule"></a>processSchedule</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/schedule_controller.go#L136">processSchedule 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 Schedule key，通过解析获取的 namespace 和 name 查询到集群中的 Schedule 对象</li><li>仅处理状态为空、New 或者 Enabled 的 Schedule 对象</li><li>检验 cron 表达式的合法性，根据校验结果更新 Schedule 的状态为 FailedValidation 或者 Enabled</li><li>判断是否到达定时任务的下次执行时间，如果达到则立即创建一个备份。另外，如果定时任务从未执行，也会立即创建一个备份任务</li></ol><h2 id="enqueueAllEnabledSchedules"><a href="#enqueueAllEnabledSchedules" class="headerlink" title="enqueueAllEnabledSchedules"></a>enqueueAllEnabledSchedules</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/schedule_controller.go#L115">enqueueAllEnabledSchedules 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 1 分钟</p><ol><li>获取集群中所有的 Schedule 对象</li><li>将状态是 Enabled 的 Schedule 对象加入到 Generic Controller 的 queue 中</li></ol><h1 id="BackupDeletion-Controller"><a href="#BackupDeletion-Controller" class="headerlink" title="BackupDeletion Controller"></a>BackupDeletion Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;backup_deletion_controller.go</u></em><br><em><u>internal&#x2F;delete&#x2F;delete_item_action_handler.go</u></em></p><p>删除 Backup 时，与 Backup 相关联的各种资源基本上都是通过 velero.io&#x2F;backup-name 标签获取到。因此，在备份的时候，创建的相关资源也都会打上该标签。</p><h2 id="NewBackupDeletionController"><a href="#NewBackupDeletionController" class="headerlink" title="NewBackupDeletionController"></a>NewBackupDeletionController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_deletion_controller.go#L86">NewBackupDeletionController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 DeleteBackupRequest 资源的 Add 事件，将 DeleteBackupRequest 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processQueueItem-1"><a href="#processQueueItem-1" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_deletion_controller.go#L146">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 DeleteBackupRequest key，通过解析获取的 namespace 和 name 查询到集群中的 DeleteBackupRequest 对象</li><li>仅处理状态不为 Processed 的 DeleteBackupRequest 对象，调用 <strong>processRequest</strong>，执行 Backup 的删除</li></ol><h2 id="processRequest"><a href="#processRequest" class="headerlink" title="processRequest"></a>processRequest</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_deletion_controller.go#L176">processRequest 源码</a></p><p>备份删除的整体流程</p><ol><li>如果 DeleteBackupRequest 对象所属的 Backup 信息不存在，则认为 DeleteBackupRequest 处理完成，即将其状态设为 Processed，并设置错误信息</li><li>删除集群中针对该 Backup 的其余 DeleteBackupRequest 对象，仅处理当前的</li><li>如果要删除的 Backup 处于 InProgress 状态或者不存在，则将 DeleteBackupRequest 状态设为 Processed，并设置错误信息</li><li>如果 Backup 所属的 BackupStorageLocation 不存在或者模式为 ReadOnly 时，则将 DeleteBackupRequest 状态设为 Processed，并设置错误信息</li><li>至此，校验工作已经完成，将 DeleteBackupRequest 状态设置为 InProgress，并设置 velero.io&#x2F;backup-name 和 velero.io&#x2F;backup-uid 标签</li><li>设置 Backup 的状态为 Deleting</li><li>获取注册的 DeleteItemAction 插件，如果获取到了，则下载 BackupStorageLocation 中的 Content 文件，构建运行 DeleteItemAction 所需要环境变量信息，调用 <strong>InvokeDeleteActions</strong> 处理 DeleteItemAction 中定义的逻辑</li><li>调用 StorageProvider 的 GetBackupVolumeSnapshots 方法获取 BackupVolumeSnapshotsKey（也就是 backup-volumesnapshots.json.gz） 的内容，调用 SnapshotProvider 的 DeleteSnapshot 接口删除 PV 快照信息</li><li>获取到与 Backup 相关联的 PodVolumeBackup 信息，进而获取到 Restic 的 snapshots，执行 restic forget 删除快照<br><em>创建备份的时候，会根据 Pod 卷创建 PodVolumeBackup 对象，并会设置 velero.io&#x2F;backup-name 标签</em></li><li>调用 StorageProvider 的 DeleteBackup 接口删除 BackupStorageLocation 中 Backup 所在的目录</li><li>如果 Velero 开启了 CSI 特性，那么也会删除与 Backup 相关联的 VolumeSnapshot 和 VolumeSnapshotContent 对象<br><em>删除之前会将 VolumeSnapshotContent 回收策略置为 Delete</em></li><li>调用 StorageProvider 的 DeleteRestore 方法，删除 BackupStorageLocation 上基于该 Backup 创建的 Restore 文件，删除基于该 Backup 创建的 Restore 对象</li><li>如果以上步骤均无错误返回，则删除集群中相关的 Backup 对象</li><li>更新 DeleteBackupRequest 状态设为 Processed，并设置错误信息</li><li>如果以上步骤均无报错返回，则删除与该 Backup 相关的所有 DeleteBackupRequest 对象</li></ol><h2 id="InvokeDeleteActions"><a href="#InvokeDeleteActions" class="headerlink" title="InvokeDeleteActions"></a>InvokeDeleteActions</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/internal/delete/delete_item_action_handler.go#L48">InvokeDeleteActions 源码</a></p><p>执行 DeleteItemAction 中的动作</p><ol><li>如果未定义 action 信息，则直接返回，继续处理删除流程</li><li>将传入的 BackupStorageLocation 中的 Content 文件解压至临时文件下，通过 discovery API 将文件内容转换成 GroupResource</li><li>遍历 GroupResource 中的所有资源，执行 DeleteItemAction 中声明的动作</li></ol><h2 id="deleteExpiredRequests"><a href="#deleteExpiredRequests" class="headerlink" title="deleteExpiredRequests"></a>deleteExpiredRequests</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_deletion_controller.go#L595">deleteExpiredRequests 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 1 小时</p><ol><li>获取集群中所有的 DeleteBackupRequest 对象，将状态已经处于 Processed，并且 age 超过 24 小时的 DeleteBackupRequest 对象删除<br><em>因为并非所有的 DeleteBackupRequest 对象在走完 syncHandler 流程后均会被删除</em></li></ol><h1 id="BackupSync-Controller"><a href="#BackupSync-Controller" class="headerlink" title="BackupSync Controller"></a>BackupSync Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;backup_sync_controller.go</u></em></p><h2 id="NewBackupSyncController"><a href="#NewBackupSyncController" class="headerlink" title="NewBackupSyncController"></a>NewBackupSyncController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_sync_controller.go#L60">NewBackupSyncController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 resyncFunc</li></ol><h2 id="run"><a href="#run" class="headerlink" title="run"></a>run</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_sync_controller.go#L124">run 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 30 秒</p><ol><li>获取集群中所有的 BackupStorageLocation 对象，构建一个默认的 BackupStorageLocation 位于第一位的列表</li><li>遍历步骤 1 中的 BackupStorageLocation 列表，如果同步周期等于 0 代表该 BackupStorageLocation 不作同步操作，直接跳过即可，否则判断其是否到达下次同步时间</li><li>调用 StorageProvider 的 ListBackups 方法获取所有的 Backup；同时获取集群中所有的 Backup</li><li>获取在 BackupStorageLocation 中但是不在集群中的 Backup，这些就是待同步的 Backup</li><li>针对每一个待同步的 Backup，调用 StorageProvider 的 GetBackupMetadata 方法，获取 Metadata 文件（即 velero-backup.json），解析内容得到 Backup 对象</li><li>设置 Backup 的 namespace、resourceVersion、storageLocation 和 label 等信息，并在集群中创建<br><em>既然已经存在于 BackupStorage Location，状态必然为完成状态（即不是空或者 New），因此不会被 Backup Controller 重复处理</em></li><li>调用 StorageProvider 的 GetPodVolumeBackups 方法获取与该 Backup 相关的 PodVolumeBackup</li><li>设置 PodVolumeBackup 的 namespace、resourceVersion、ownerReferences 和 label 等信息，并在集群中创建<br><em>同理，不会被 PodVolumeBackup Controller 重复处理</em></li><li>如果 Velero 开启了 CSI 特性，通过 StorageProvider 的 GetCSIVolumeSnapshotContents 方法获取与该 Backup 相关的 VolumeSnapshotContents</li><li>设置 VolumeSnapshotContent 的 resourceVersion 等信息，并在集群中创建</li><li>删除孤儿 Backup，也就是在集群中存在，状态为 Completed，但是在 BackupStorageLocation 中不存在的 Backup</li><li>更新集群中该 BackupStorageLocation 的上次同步时间<br><em>实际上步骤 4 获取 BackupStorageLocation 的 Backup 时可以作为同步操作</em></li></ol><h1 id="GC-Controller"><a href="#GC-Controller" class="headerlink" title="GC Controller"></a>GC Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;gc_controller.go</u></em></p><h2 id="NewGCController"><a href="#NewGCController" class="headerlink" title="NewGCController"></a>NewGCController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/gc_controller.go#L58">NewGCController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 Backup 资源的 Add 和 Update 事件，将 Backup 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processQueueItem-2"><a href="#processQueueItem-2" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/gc_controller.go#L104">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 Backup key，通过解析获取的 namespace 和 name 查询到集群中的 Backup 对象</li><li>仅处理已经过期的 Backup 对象</li><li>获取 Backup 所属的 BackupStorageLocation，判断其模式是否为 ReadWrite</li><li>获取集群中和该 Backup 相关的 DeleteBackupRequest 对象，如果其中存在状态为空、New 和 InProgress 的，则认为正在删除，本次不做处理；否则，构建一个 DeleteBackupRequest 对象，下发至集群中创建，后续由 BackupDeletion Controller 负责维护</li></ol><h2 id="enqueueAllBackups"><a href="#enqueueAllBackups" class="headerlink" title="enqueueAllBackups"></a>enqueueAllBackups</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/gc_controller.go#L90">enqueueAllBackups 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 1 小时</p><ol><li>获取集群中所有的 Backup 对象，全量加入到 Generic Controller 的 queue 中</li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 Backup、Schedule 等备份相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」源码走读 — Location</title>
    <link href="http://shenxianghong.github.io/2022/01/17/2022-01-17%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Location/"/>
    <id>http://shenxianghong.github.io/2022/01/17/2022-01-17%20Velero%20%E6%BA%90%E7%A0%81%E8%B5%B0%E8%AF%BB%20-%20Location/</id>
    <published>2022-01-16T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.166Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="BackupStorageLocation"><a href="#BackupStorageLocation" class="headerlink" title="BackupStorageLocation"></a>BackupStorageLocation</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/backupstoragelocation_types.go">API</a></p><h2 id="backup-location"><a href="#backup-location" class="headerlink" title="backup-location"></a>backup-location</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backuplocation&#x2F;backup-location.go</u></em></p><p>velero backup-location 包括 4 个子命令：create、delete、get 和 set。</p><h2 id="create"><a href="#create" class="headerlink" title="create"></a>create</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup-location&#x2F;create.go</u></em></p><p><strong>校验规则</strong></p><ul><li>–provider 和 –bucket 为必需参数</li><li>在指定 –backup-sync-period 参数时，其值必须要大于等于 0 </li><li>在指定 –credential 参数时，其值仅能包含一对 key-value</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，构建 BackupStorageLocation 对象，下发至集群中创建，后续由 BackupStorageLocation Controller 负责维护</li><li>如果新创建的 BackupStorageLocation 为默认的，则将集群中其余的 BackupStorageLocation 设为非默认</li></ol><h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup-location&#x2F;delete.go</u></em></p><p><strong>校验规则</strong></p><ul><li>name、–all 和 –selector 参数有且仅能有一个</li><li>要删除的 BackupStorageLocation 在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行参数，获取集群中的 BackupStorageLocation 资源并删除</li></ol><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup-location&#x2F;get.go</u></em></p><p><strong>校验规则</strong></p><ul><li>如果显式指定要获取的 BackupStorageLocation，则其在集群中必须存在</li></ul><p><strong>流程逻辑</strong></p><ol><li>获取到 BackupStorageLocation 资源，根据 –output 指定的样式格式化输出</li></ol><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;backup-location&#x2F;set.go</u></em></p><p><strong>校验规则</strong></p><ul><li>在指定 –credential 参数时，其值仅能包含一对 key-value</li></ul><p><strong>主体流程</strong></p><ol><li>根据命令行提供的参数信息，将其更新至集群中的 BackupStorageLocation 对象中</li><li>其中，如果参数信息是将其设置为默认（–default），则会将集群中其余的 BackupStorageLocation 设为非默认</li></ol><h1 id="ResticRepository"><a href="#ResticRepository" class="headerlink" title="ResticRepository"></a>ResticRepository</h1><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/restic_repository.go">API</a></p><p>ResticRepository 不支持通过命令行手动创建，而是在备份流程中，由 Backup Controller 调用 <strong>ensureRepo</strong>，针对每一个卷命名空间，创建一个该对象。<br><em>注意是 Pod 所在的命名空间（即卷命名空间），而非 Velero 或者 Restic 所在的命名空间</em></p><h2 id="repo"><a href="#repo" class="headerlink" title="repo"></a>repo</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restic&#x2F;repo&#x2F;repo.go</u></em></p><h3 id="get-1"><a href="#get-1" class="headerlink" title="get"></a>get</h3><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restic&#x2F;repo&#x2F;get.go</u></em></p><p><strong>校验规则</strong></p><ul><li>如果显式指定要获取的 ResticRepository，则其在集群中必须存在</li></ul><p><strong>主体流程</strong></p><ol><li>获取到 ResticRepository 资源，根据 –output 指定的样式格式化输出</li></ol><h2 id="server"><a href="#server" class="headerlink" title="server"></a>server</h2><p><em><u>pkg&#x2F;cmd&#x2F;cli&#x2F;restic&#x2F;server.go</u></em></p><p>server 本身是 velero restic 的 hidden 类型的命令，是 Restic 服务的启动命令。</p><ol><li>由于 Pod 会将所在所在节点的 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods 挂在到容器内 &#x2F;host_pods 目录下，因此，会校验当前节点的所有 Pod 卷是否均已挂载到容器内</li><li>启动 Restic 服务，内部会启动 1 个 PodVolumeBackupController 和 1 个 PodVolumeRestoreController，用于处理卷备份与恢复的流程</li></ol><h1 id="BackupStorageLocation-Controller"><a href="#BackupStorageLocation-Controller" class="headerlink" title="BackupStorageLocation Controller"></a>BackupStorageLocation Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;backup_storage_location_controller.go</u></em></p><h2 id="Reconcile"><a href="#Reconcile" class="headerlink" title="Reconcile"></a>Reconcile</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/backup_storage_location_controller.go#L55">Reconcile 源码</a></p><ol><li>针对集群中的每一个 BackupStorageLocation，如果不存在默认的时，会根据 Velero 服务启动命令中的信息设置一个默认 <br><em>在 Velero 之前版本中，Velero 服务启动时可以设置默认的 BackupStorageLocation，在 2.0 之后废弃，改用 velero backup-location set –default 的方式，而在 Controller 中仍然保留了这段逻辑，用于向后兼容</em></li><li>计算 BackupStorageLocation 是否已经准备好进行验证（即是否到达上次验证时间 + 验证频率），规则大致为<ul><li>频率等于 0 时，不作验证</li><li>频率小于 0 时，为不合法场景，将频率重置为默认的 1 分钟</li><li>如果未做过验证（即第一次尝试验证时），无视其设置的验证频率，直接返回 true，表示立即开始验证流程</li></ul></li><li>构建请求 StorageProvider 中所需要 BackupStorageLocation  对象，其中如果 BackupStorageLocation 中设置了 Credential 信息，则会获取位于 Velero 命名空间下的 Secret，将 Secret 内容以 &lt;Secret Name&gt; - &lt;Secret Key&gt; 的形式持久化到磁盘中，并将 BackupStorageLocation 的 credentialsFile 字段指向该文件<br><br><em>通常位于 &#x2F;tmp&#x2F;credentials&#x2F;velero 目录中</em></li><li>通过 StorageProvider 的 IsValid 接口判断 BackupStorageLocation 是否可用</li><li>更新集群中 BackupStorageLocation 状态和上次验证时间</li><li>最终无论结果如何，都会重新入队</li></ol><h1 id="ResticRepository-Controller"><a href="#ResticRepository-Controller" class="headerlink" title="ResticRepository Controller"></a>ResticRepository Controller</h1><p><em><u>pkg&#x2F;controller&#x2F;restic_repository_controller.go</u></em></p><h2 id="NewResticRepositoryController"><a href="#NewResticRepositoryController" class="headerlink" title="NewResticRepositoryController"></a>NewResticRepositoryController</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restic_repository_controller.go#L57">NewResticRepositoryController 源码</a></p><p>工厂函数</p><ol><li>注册 Generic Controller 中的 syncHandler 和 resyncFunc</li><li>监听 ResticRepository 资源的 Add 事件，将 ResticRepository 以 key（namespace&#x2F;name）的形式加入 Generic Controller 的 queue 中</li></ol><h2 id="processQueueItem"><a href="#processQueueItem" class="headerlink" title="processQueueItem"></a>processQueueItem</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restic_repository_controller.go#L111">processQueueItem 源码</a></p><p>注册在 Generic Controller 中 syncHandler 的实现</p><ol><li>函数入参就是 Generic Controller 的 queue 中待处理的 ResticRepository key，通过解析获取的 namespace 和 name 查询到集群中的 ResticRepository 对象</li><li>如果 ResticRepository 对象状态为空或者是 New，则调用 <strong>initializeRepo</strong> 初始化一个 Restic 仓库</li><li>否则会进一步判断 ResticRepository 对象状态<ul><li>如果状态为 Ready，则执行 restic prune 命令，判断是否可以建立连接，并更新 ResticRepository 上次维护时间信息</li><li>如果状态为 NotReady，则调用 <strong>ensureRepo</strong> 尝试检查或初始化一个仓库，并根据返回结果更新 ResticRepository 的状态为 Ready 或者 NotReady<br><em>restic prune 的执行失败并不会影响到主流程，只是会在 ResticRepository 对象中记录错误信息</em></li></ul></li></ol><h2 id="initializeRepo"><a href="#initializeRepo" class="headerlink" title="initializeRepo"></a>initializeRepo</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restic_repository_controller.go#L157">initializeRepo 源码</a></p><p>尝试初始化 Restic 仓库的主体流程（真正初始化的动作位于 <strong>ensureRepo</strong>）</p><ol><li>ResticRepository 对象中有 BackupStorageLocation 的信息，根据这个信息获取集群中的 BackupStorageLocation 对象，如果获取失败，则更新 ResticRepository 对象的状态为 NotReady</li><li>调用 <strong>GetRepoIdentifier</strong> 获取 Restic 仓库信息（即 –repo 所需的信息），并更新至 ResticRepository 对象中，如果获取失败，则将 ResticRepository 对象的状态设置为 NotReady</li><li>调用 <strong>ensureRepo</strong> 尝试检查或初始化一个仓库，并根据返回结果更新 ResticRepository 的状态和上次维护时间信息</li></ol><h2 id="ensureRepo"><a href="#ensureRepo" class="headerlink" title="ensureRepo"></a>ensureRepo</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restic_repository_controller.go#L205">ensureRepo 源码</a></p><p>检查 Restic 仓库是否存在，如果不存在则尝试初始化一个</p><ol><li>通过执行 restic snapshots 的结果，来确保 Restic 仓库存在并且权限可达</li><li>如果命令执行返回错误信息中包含 “Is there a repository at the following location?”  字符串，表示 Restic 仓库不存在，会通过 restic init 命令初始化一个新仓库</li></ol><h2 id="GetRepoIdentifier"><a href="#GetRepoIdentifier" class="headerlink" title="GetRepoIdentifier"></a>GetRepoIdentifier</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/restic/config.go#L101">GetRepoIdentifier 源码</a></p><p>构建 Restic 命令行需要的 –repo 参数内容</p><ol><li>根据 BackupStorageLocation 的 Provider 信息获取到对应后端类型（velero.io&#x2F;provider），Velero Restic 支持的类型有 velero.io&#x2F;aws、velero.io&#x2F;azure 和 velero.io&#x2F;gcp，拼接后作为 RepoPrefix</li><li>RepoPrefix 拼接上 ResticRepository 中的 VolumeNamespace 信息作为 RepoIdentifier，也就是 Restic 原生命令中的 –repo 参数</li></ol><h2 id="enqueueAllRepositories"><a href="#enqueueAllRepositories" class="headerlink" title="enqueueAllRepositories"></a>enqueueAllRepositories</h2><p><a href="https://github.com/vmware-tanzu/velero/blob/5fe3a50bfddc2becb4c0bd5e2d3d4053a23e95d2/pkg/controller/restic_repository_controller.go#L97">enqueueAllRepositories 源码</a></p><p>注册在 Generic Controller 中 resyncFunc 的实现，周期为 5 分钟</p><ol><li>获取集群中所有的 ResticRepository 对象，全量加入到 Generic Controller 的 queue 中<br><em>之所以是全量，是因为网络连接的不确定性，需要重新判断所有的 ResticRepository 可达状态</em></li></ol>]]></content>
    
    
    <summary type="html">Velero 中与 Location、Repository 等存储站点相关的流程梳理</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Rust 」数据类型</title>
    <link href="http://shenxianghong.github.io/2022/01/16/2022-01-16%20Rust%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>http://shenxianghong.github.io/2022/01/16/2022-01-16%20Rust%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</id>
    <published>2022-01-15T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.161Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/rust/logo.png"></div><hr><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Rust 是静态编译语言，在编译时必须知道所有变量的类型</p><ul><li>基于使用的值，编译器通常能够推断出它的具体类型</li><li>但如果可能的类型比较多，例如把 String 转为整数的 parse 方法，就必须添加类型的标注，否则编译会报错</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">guess</span>: <span class="type">u32</span> = <span class="string">&quot;42&quot;</span>.<span class="title function_ invoke__">parse</span>().<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Not a number&quot;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, guess);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于针对数字 42 在 Rust 中有很多数据类型可以将其包含在内，如 <code>i32</code> 和 <code>u32</code> 等等，所以要给变量具体指明类型，如果未指明，则会编译报错：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">error[E0282]: type annotations needed</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">src/main.rs:2:9</span></span><br><span class="line">  |</span><br><span class="line">2 |     let guess = &quot;42&quot;.parse().expect(&quot;Not a number&quot;);</span><br><span class="line">  |         ^^^^^ consider giving `guess` a type</span><br></pre></td></tr></table></figure><h1 id="标量类型"><a href="#标量类型" class="headerlink" title="标量类型"></a>标量类型</h1><p>一个标量类型代表一个单个的值。</p><p>Rust 有四个主要的标量类型：</p><ul><li>整数类型</li><li>浮点类型</li><li>布尔类型</li><li>字符类型</li></ul><h2 id="整数类型"><a href="#整数类型" class="headerlink" title="整数类型"></a>整数类型</h2><p>整数类型没有小数部分，无符号整数类型以 <code>u</code>（usize）开头，有符号整数类型以 <code>i</code> （integer）开头，例如 u32 就是一个无符号的整数类型，占据 32 位的空间。</p><h3 id="整数类型表"><a href="#整数类型表" class="headerlink" title="整数类型表"></a>整数类型表</h3><ul><li>每种都分 i 和 u，以及固定的位数</li><li>有符号的范围是 <code>-(2^n^ - 1) 到 2^n-1^ - 1</code></li><li>无符号范围：<code>0 到 2^n^ -1</code></li></ul><table><thead><tr><th>Length</th><th>Signed</th><th>Unsigned</th></tr></thead><tbody><tr><td>8-bit</td><td>i8</td><td>u8</td></tr><tr><td>16-bit</td><td>i16</td><td>u16</td></tr><tr><td>32-bit</td><td>i32</td><td>u32</td></tr><tr><td>64-bit</td><td>i64</td><td>u64</td></tr><tr><td>128-bit</td><td>i128</td><td>u128</td></tr><tr><td>arch</td><td>isize</td><td>usize</td></tr></tbody></table><p><code>isize</code> 和 <code>usize</code> 类型的位数由程序运行的计算机的架构所决定，如果是 64 位计算机，那就是 64 位的。使用场景比如，对某个集合进行索引操作。</p><h3 id="整数字面值"><a href="#整数字面值" class="headerlink" title="整数字面值"></a>整数字面值</h3><table><thead><tr><th>Number literals</th><th>Example</th></tr></thead><tbody><tr><td>Decimal</td><td>98_222</td></tr><tr><td>Hex</td><td>0xff</td></tr><tr><td>Octal</td><td>0o77</td></tr><tr><td>Binary</td><td>0b1111_0000</td></tr><tr><td>Byte (u8 only)</td><td>b’A’</td></tr></tbody></table><ul><li><p>除了 <code>byte</code> 类型外，所有的数字字面值都允许使用类型后缀，例如 57u8</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="comment">// 此时，foo 的类型为 u8，值为 57</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">foo</span> = <span class="number">57u8</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, foo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>整数的默认类型就是 <code>i32</code></p></li></ul><h3 id="整数溢出"><a href="#整数溢出" class="headerlink" title="整数溢出"></a>整数溢出</h3><p>例如，u8 的范围是 0 - 255，如果把一个 u8 类型变量的值设为 256，那么：</p><ul><li><strong>调试模式下编译</strong>： Rust 会检查整数溢出，如果发生溢出，程序在运行时就会 panic</li><li><strong>发布模式下编译</strong>： Rust 不会检查可能导致 panic 的整数溢出，如果发生溢出，Rust 会执行<strong>环绕操作</strong>，也就是 256 变为 1，257 变为 2，以此类推</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">foo</span>: <span class="type">u8</span> = <span class="number">255</span>;</span><br><span class="line">    foo = foo + <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, foo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>cargo run</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">thread &#x27;main&#x27; panicked at &#x27;attempt to add with overflow&#x27;, src/main.rs:3:11</span><br><span class="line">note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace</span><br></pre></td></tr></table></figure><p><em>cargo build –release</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./target/release/hello-world</span></span><br><span class="line">1</span><br></pre></td></tr></table></figure><h2 id="浮点类型"><a href="#浮点类型" class="headerlink" title="浮点类型"></a>浮点类型</h2><p>Rust 的浮点类型使用了 IEEE-754 标准来表述，有两种基础的浮点类型，也就是含有小数部分的类型：</p><ul><li>f32，单精度</li><li>f64，双精度，Rust 中默认的浮点类型</li></ul><h2 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h2><p>Rust 的布尔类型（true &amp; false）占用 1 字节大小，符号为 bool。</p><h2 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h2><p>Rust 中 <code>char</code> 类型用来描述语言中最基础的单个字符，字符类型的字面值使用单引号，占用 4 字节的大小，是 Unicode 的标量值，可以表示比 ASCII 多得多的字符内容，如拼音，中日韩文，零长度空白字符，emoji 表情等。</p><p>范围是 <code>U+0000 到 U+D7FF</code> 和 <code>U+E000</code> 到 <code>U+10FFFF</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = <span class="string">&#x27;z&#x27;</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">y</span>: <span class="type">char</span> = <span class="string">&#x27;字&#x27;</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">z</span> = &#x27;😄&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="复合类型"><a href="#复合类型" class="headerlink" title="复合类型"></a>复合类型</h1><p>复合类型可以将多个值放到一个类型里。</p><p>Rust 有两个主要的复合类型：</p><ul><li>元组</li><li>数组</li></ul><h2 id="元组（Tuple）"><a href="#元组（Tuple）" class="headerlink" title="元组（Tuple）"></a>元组（Tuple）</h2><p>元组可以将多个类型的多个值放到一个类型里，并且长度固定，一旦声明不可改变。</p><p>元组的类型为：<code>(类型1,类型2,...)</code></p><p>访问元组中的元素值可以使用<strong>模式匹配（destructure）和点标记法</strong>。</p><p><strong>模式匹配</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">tup</span>: (<span class="type">i32</span>, <span class="type">bool</span>, <span class="type">char</span>) = (<span class="number">500</span>, <span class="literal">false</span>, <span class="string">&#x27;A&#x27;</span>);</span><br><span class="line">    <span class="comment">// x, y, z 的类型与值分别对应 tup 中的三个元素，即 let x: 132 = 500</span></span><br><span class="line">    <span class="keyword">let</span> (x, y, z) = tup;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;&quot;</span>, x, y, z);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>点标记法</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">tup</span>: (<span class="type">i32</span>, <span class="type">bool</span>, <span class="type">char</span>) = (<span class="number">500</span>, <span class="literal">false</span>, <span class="string">&#x27;A&#x27;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;&quot;</span>, tup.<span class="number">0</span>, tup.<span class="number">1</span>, tup.<span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>点标记法的“索引“不可以是变量。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">tup</span>: (<span class="type">i32</span>, <span class="type">bool</span>, <span class="type">char</span>) = (<span class="number">500</span>, <span class="literal">false</span>, <span class="string">&#x27;A&#x27;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">i</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, tup.i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">error[E0609]: no field `i` on type `(i32, bool, char)`</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">src/main.rs:4:24</span></span><br><span class="line">  |</span><br><span class="line">4 |     println!(&quot;&#123;&#125;&quot;, tup.i)</span><br><span class="line">  |                        ^</span><br></pre></td></tr></table></figure><p>和 Python 等其他语言一样，当元组中只有一个元素，类型和值均需要加逗号，当没有逗号时，编译器会认为其是一个标量类型，括号会被视为多余。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">tup</span>: (<span class="type">i32</span>,) = (<span class="number">1</span>,);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, tup.<span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>数组可以将多个值放到一个类型中，但是数组中每个元素的类型必须相同，并且长度固定，一旦声明不可改变。</p><p>数组的类型为：<code>[类型;长度]</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">a</span>: [<span class="type">i32</span>;<span class="number">5</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了上述的声明方式外，如果数组中的每个元素值都相同，那么可以快速声明为：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="comment">// 相当于 let a = [3, 3, 3, 3, 3]</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">a</span> = [<span class="number">3</span>;<span class="number">5</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似于 Golang，访问数组中的元素值可以使用<strong>索引法</strong>。</p><p><strong>索引越界</strong></p><p>如果访问的索引超出了数组的范围，处理方式和 Golang 类似，也就是：</p><ul><li>编译时会通过，但是不是绝对的，Rust 编译器无法直接判断出是否越界等较复杂的情况</li><li>运行时会报错，区别于 C 和 C++ 等，虽然数组在内存中为连续的地址，但是越界的内存空间不属于该数组，所以无法访问</li></ul>]]></content>
    
    
    <summary type="html">Rust 中的标量类型与复合类型</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Rust" scheme="http://shenxianghong.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>「 Rust 」变量与可变性</title>
    <link href="http://shenxianghong.github.io/2022/01/15/2022-01-15%20Rust%20%E5%8F%98%E9%87%8F%E4%B8%8E%E5%8F%AF%E5%8F%98%E6%80%A7/"/>
    <id>http://shenxianghong.github.io/2022/01/15/2022-01-15%20Rust%20%E5%8F%98%E9%87%8F%E4%B8%8E%E5%8F%AF%E5%8F%98%E6%80%A7/</id>
    <published>2022-01-14T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.160Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/rust/logo.png"></div><hr><h1 id="可变性"><a href="#可变性" class="headerlink" title="可变性"></a>可变性</h1><ul><li>声明变量使用 <code>let</code> 关键字</li><li>默认情况下，变量是不可变的（Immutable）</li><li>声明变量时，在变量前面加上 <code>mut</code>，就可以使变量可变</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">foo</span> = <span class="number">1</span>;</span><br><span class="line">    foo = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;bar is &#123;&#125;&quot;</span>, foo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="变量与常量"><a href="#变量与常量" class="headerlink" title="变量与常量"></a>变量与常量</h1><p>常量（constant）在绑定值以后也是不可变的，但是它与不可变的变量有很多区别：</p><ul><li>不可以使用 mut，常量永远都是不可变的</li><li>声明常量使用 <code>const</code> 关键字，它的类型必须被标注</li><li>常量可以在任何作用域内进行声明，包括全局作用域</li><li>常量只可以绑定到常量表达式，无法绑定到函数的调用结果或只能在运行时才能计算出的值</li></ul><p>在程序运行期间，常量在其声明的作用域内一直有效</p><p>命名规范：Rust 里常量使用全大写字母，每个单词之间用下划线分开，例如：MAX_POINTS</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rust 里可以通过下划线，增强数字的可读性</span></span><br><span class="line"><span class="keyword">const</span> MAX_POINTS: <span class="type">u32</span> = <span class="number">100_1000</span>;</span><br></pre></td></tr></table></figure><h1 id="Shadow（隐藏）"><a href="#Shadow（隐藏）" class="headerlink" title="Shadow（隐藏）"></a>Shadow（隐藏）</h1><p>Rust 中允许使用同名的变量来覆盖之前的变量，区别于 Golang，不仅可以用于覆盖值，可以类型也可以不一样。一般用于在不额外声明变量的场景下，进行类型转换。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = <span class="number">5</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = x + <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;x is &#123;&#125;&quot;</span>, x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>使用 mut 关键字</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">x</span> = <span class="number">5</span>;</span><br><span class="line">    x = x + <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;x is &#123;&#125;&quot;</span>, x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>shadow 和把变量标记为 mut 是不一样的</p><ul><li>如果不使用 let 关键字，那么重新给非 mut 的变量赋值会导致编译时错误</li><li>使用 let 声明的同名新变量，也是不可变的</li><li>使用 let 声明的同名新变量，它的类型可以与之前不同</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">name</span> = <span class="string">&quot;Arthur Morgan&quot;</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">name</span> = name.<span class="title function_ invoke__">len</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">13</span><br></pre></td></tr></table></figure><p><em>使用 mut 关键字</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">name</span> = <span class="string">&quot;Arthur Morgan&quot;</span>;</span><br><span class="line">    name = name.<span class="title function_ invoke__">len</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">error[E0308]: mismatched types</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">src/main.rs:3:12</span></span><br><span class="line">  |</span><br><span class="line">3 |     name = name.len();</span><br><span class="line">  |            ^^^^^^^^^^ expected `&amp;str`, found `usize`</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Rust 的变量、常量与 shadow</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Rust" scheme="http://shenxianghong.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」操作卷数据（CSI）</title>
    <link href="http://shenxianghong.github.io/2022/01/10/2022-01-10%20Velero%20%E6%93%8D%E4%BD%9C%E5%8D%B7%E6%95%B0%E6%8D%AE%EF%BC%88CSI%EF%BC%89/"/>
    <id>http://shenxianghong.github.io/2022/01/10/2022-01-10%20Velero%20%E6%93%8D%E4%BD%9C%E5%8D%B7%E6%95%B0%E6%8D%AE%EF%BC%88CSI%EF%BC%89/</id>
    <published>2022-01-09T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.153Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><p>可以将 CSI 快照支持集成到 Velero 中，使 Velero 能够使用 Kubernetes CSI 快照 API 备份和恢复 CSI 支持的卷。通过 CSI 快照 API，Velero 可以支持任何具有 CSI 快照的卷，而无需特定的 Velero 插件。</p><p><em>在 Velero v1.6 中，此特性为 beta 版本，目前 1.9+ 为稳定版本</em></p><h1 id="前置依赖"><a href="#前置依赖" class="headerlink" title="前置依赖"></a>前置依赖</h1><ul><li>Kubernetes 版本至少为 1.17</li><li>集群中的 CSI 具备快照能力，兼容 v1beta1 版本 API</li><li>跨集群 CSI 卷快照恢复时，CSI Driver 快照类名需要保持一致</li></ul><h1 id="部署-Velero，开启-CSI-特性"><a href="#部署-Velero，开启-CSI-特性" class="headerlink" title="部署 Velero，开启 CSI 特性"></a>部署 Velero，开启 CSI 特性</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero install \</span></span><br><span class="line"><span class="language-bash">     --provider aws \</span></span><br><span class="line"><span class="language-bash">     --features EnableCSI \</span></span><br><span class="line"><span class="language-bash">     --plugins velero/velero-plugin-for-aws:v1.0.0,velero/velero-plugin-for-csi:v0.1.0 \</span></span><br><span class="line"><span class="language-bash">     --bucket velero \</span></span><br><span class="line"><span class="language-bash">     --secret-file ./credentials-velero \</span></span><br><span class="line"><span class="language-bash">     --use-volume-snapshots=<span class="literal">false</span> \</span></span><br><span class="line"><span class="language-bash">     --backup-location-config region=minio,s3ForcePathStyle=<span class="string">&quot;true&quot;</span>,s3Url=http://minio.velero.svc:9000</span></span><br></pre></td></tr></table></figure><p><strong>参数说明</strong></p><ul><li><code>--features</code> 开启 feature 特性</li></ul><h1 id="流程验证"><a href="#流程验证" class="headerlink" title="流程验证"></a>流程验证</h1><p><strong>StorageClass</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">openebs-lvmsc</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">volgroup:</span> <span class="string">&quot;lvm_im&quot;</span></span><br><span class="line">  <span class="attr">fstype:</span> <span class="string">&quot;ext4&quot;</span></span><br><span class="line">  <span class="attr">maxVolumeSize:</span> <span class="string">&quot;5&quot;</span> </span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">local.csi.openebs.io</span>  </span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">WaitForFirstConsumer</span></span><br></pre></td></tr></table></figure><p><strong>PersistentVolumeClaim</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">local-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">openebs-lvmsc</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">30Mi</span></span><br></pre></td></tr></table></figure><p><strong>Pod</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-local-im</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">  <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">perfrunner</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.27</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;sh&quot;</span>]</span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;-c&quot;</span>, <span class="string">&quot;while true ;do sleep 50; done&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/datadir</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">fio-vol</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fio-vol</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">local-pvc</span></span><br></pre></td></tr></table></figure><p><strong>操作验证</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入测试数据</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it pod-local-im <span class="built_in">ls</span> /datadir</span></span><br><span class="line">data        lost+found</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建备份任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup create default --include-namespaces default</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看快照信息，发现此时 Velero 已经调用 CSI 创建了 volumesnapshot，并生成了 volumesnapshotcontent，并且查看 volumesnapshot 的状态 readyToUse 为 True</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get volumesnapshot</span></span><br><span class="line">NAMESPACE   NAME                     READYTOUSE   SOURCEPVC   SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS         SNAPSHOTCONTENT                                    CREATIONTIME   AGE</span><br><span class="line">default     velero-local-pvc-bdbw8   true         local-pvc                           30Mi          csi-local-snapclass   snapcontent-93903201-f07a-405c-92d9-2c0b6bafd6a1   117s           118s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get volumesnapshotcontent</span></span><br><span class="line">NAME                                               READYTOUSE   RESTORESIZE   DELETIONPOLICY   DRIVER                 VOLUMESNAPSHOTCLASS   VOLUMESNAPSHOT           VOLUMESNAPSHOTNAMESPACE   AGE</span><br><span class="line">snapcontent-93903201-f07a-405c-92d9-2c0b6bafd6a1   true         31457280      Delete           local.csi.openebs.io   csi-local-snapclass   velero-local-pvc-bdbw8   default                   2m38s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模拟故障</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete -f pod.yaml &amp;&amp; kubectl delete -f pvc.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建恢复任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore create --from-backup default</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get volumesnapshotcontent</span> </span><br><span class="line">NAME                                               READYTOUSE   RESTORESIZE   DELETIONPOLICY   DRIVER                 VOLUMESNAPSHOTCLASS   VOLUMESNAPSHOT           VOLUMESNAPSHOTNAMESPACE   AGE</span><br><span class="line">snapcontent-93903201-f07a-405c-92d9-2c0b6bafd6a1   true         31457280      Delete           local.csi.openebs.io   csi-local-snapclass   velero-local-pvc-bdbw8   default                   3m31s</span><br><span class="line">velero-velero-local-pvc-bdbw8-z9t2f                true         0             Delete           local.csi.openebs.io                         velero-local-pvc-bdbw8   default                   2m3s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到，Velero 调用 CSI Driver 基于之前的 volumesnapshot 恢复出来了一个 PVC</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pvc</span></span><br><span class="line">NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE</span><br><span class="line">local-pvc   Bound    pvc-f034e865-340a-40cf-9381-3b95b1bd2f1f   30Mi       RWO            openebs-lvmsc   4m16s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pvc -o yaml</span></span><br><span class="line">&lt;skip&gt;</span><br><span class="line">spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    dataSource:</span><br><span class="line">      apiGroup: snapshot.storage.k8s.io</span><br><span class="line">      kind: VolumeSnapshot</span><br><span class="line">      name: velero-local-pvc-bdbw8</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 30Mi</span><br><span class="line">    storageClassName: openebs-lvmsc</span><br><span class="line">    volumeMode: Filesystem</span><br><span class="line">    volumeName: pvc-f034e865-340a-40cf-9381-3b95b1bd2f1f</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据已经从快照恢复</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it pod-local-im <span class="built_in">ls</span> /datadir</span></span><br><span class="line">data        lost+found</span><br></pre></td></tr></table></figure><h1 id="流程走读"><a href="#流程走读" class="headerlink" title="流程走读"></a>流程走读</h1><p>Velero 的 CSI 支持不依赖 Velero VolumeSnapshotter 插件。相反，Velero 采用一组 BackupItemAction 插件用于在操作 PersistentVolumeClaims 之前进行一些额外的动作。</p><p>备份时，当 BackupItemAction 发现有一个 PersistentVolumeClaims 指向由 CSI Driver 创建的 PersistentVolume 时，它将获取具有相同 Driver 名称的 VolumeSnapshotClass 来创建以 PersistentVolumeClaim 为源的 CSI VolumeSnapshot 对象，VolumeSnapshot 和 PersistentVolumeClaim 位于同一命名空间中。</p><p>接着，CSI external-snapshotter watch 到 VolumeSnapshot 之后创建一个 VolumeSnapshotContent 对象，它将指向存储系统中实际的、基于磁盘的快照。 external-snapshotter 会调用 CSI Driver 的 snapshot 方法，Driver 会调用存储系统的 API 生成快照。一旦生成 ID 并且存储系统将快照标记为可用于恢复，VolumeSnapshotContent 对象将使用 status.snapshotHandle 进行更新，并且设置status.readyToUse 字段为 true。</p><p>Velero 将在备份 tarball 中包含生成的 VolumeSnapshot 和 VolumeSnapshotContent 对象，并将 JSON 文件中的所有 VolumeSnapshots 和 VolumeSnapshotContents 对象上传到对象存储系统。当 Velero 将备份同步到新集群时，VolumeSnapshotContent 对象也将同步到集群中，以便 Velero 可以适当地管理备份过期。</p><p>VolumeSnapshotClass 的 DeletionPolicy 设置为 Retain 时，Velero 备份的生命周期内保留存储系统中的卷快照，并防止在发生灾难时删除存储系统中的卷快照，其中命名空间与VolumeSnapshot 对象可能会丢失。</p><p>当 Velero 备份到期时，VolumeSnapshot 对象将被删除，VolumeSnapshotContent 对象的 DeletionPolicy 将更新 Delete，以释放存储系统上的空间。</p>]]></content>
    
    
    <summary type="html">借助 CSI 实现对 Kubernetes 集群中容器卷数据的备份与恢复</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Rust 」快速开始 — Cargo</title>
    <link href="http://shenxianghong.github.io/2022/01/09/2022-01-09%20Rust%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B%20-%20Cargo/"/>
    <id>http://shenxianghong.github.io/2022/01/09/2022-01-09%20Rust%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B%20-%20Cargo/</id>
    <published>2022-01-08T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.128Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/rust/logo.png"></div><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Cargo 是 Rust 的构建系统和包管理工具，可以帮助构建代码、下载依赖库、构建依赖库等。</p><p>安装 Rust 的时候会默认安装 Cargo，可以通过 <code>cargo --version</code> 判断是否安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo --version</span></span><br><span class="line">cargo 1.57.0 (b2e52d7ca 2021-10-21)</span><br></pre></td></tr></table></figure><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>使用 <code>cargo new &lt;path&gt;</code> 创建一个工程项目，工程项目名为 <code>&lt;path&gt;</code>。同时，也会创建一个 <code>&lt;path&gt;</code> 的目录，在不显示声明 vcs 的情况下，默认会同时创建 git 仓库，可以通过 <code>cargo new &lt;path&gt; --vcs xxx</code> 指定其他 vcs，或者通过 <code>--vcs none</code> 不创建 vcs。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo new hello-world</span></span><br><span class="line">     Created binary (application) `hello-world` package</span><br><span class="line">     </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree -a hello-world</span></span><br><span class="line">hello-world</span><br><span class="line">├── .git</span><br><span class="line">├── .gitignore</span><br><span class="line">├── Cargo.toml</span><br><span class="line">└── src</span><br><span class="line">    └── main.rs</span><br></pre></td></tr></table></figure><ul><li>src 目录用于存放源代码</li><li>Cargo.toml  是项目的配置文件，类似于 Golang 的 go.mod 文件</li><li>.gitignore 中包含忽略 &#x2F;target 的信息</li></ul><h3 id="Cargo-toml"><a href="#Cargo-toml" class="headerlink" title="Cargo.toml"></a>Cargo.toml</h3><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[package]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;hello-world&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">edition</span> = <span class="string">&quot;2021&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html</span></span><br><span class="line"></span><br><span class="line"><span class="section">[dependencies]</span></span><br></pre></td></tr></table></figure><ul><li>package 用于描述项目信息的<ul><li>name — 项目名</li><li>version — 项目版本</li><li>authors — 开发者昵称和邮箱信息，<em>如果系统中存在</em></li><li>edtion — 使用的 Rust 版本</li></ul></li><li>dependecies 用于描述项目的依赖项，在 Rust 中代码的包（库）称为 <code>crate</code></li></ul><h3 id="转换为-Cargo"><a href="#转换为-Cargo" class="headerlink" title="转换为 Cargo"></a>转换为 Cargo</h3><p>如果创建项目时没有使用 Cargo，也可以把项目转化为使用 Cargo，具体做法为：把源代码移到 src 目录下，创建 Cargo.toml 并填写相应的配置。</p><h1 id="构建项目"><a href="#构建项目" class="headerlink" title="构建项目"></a>构建项目</h1><p>满足 Cargo 规范的项目，可以使用 <code>cargo build</code> 来构建项目。</p><h2 id="cargo-build"><a href="#cargo-build" class="headerlink" title="cargo build"></a>cargo build</h2><h3 id="dev"><a href="#dev" class="headerlink" title="dev"></a>dev</h3><p><strong>unoptimized + debuginfo</strong></p><p>在项目的根目录下，执行 <code>cargo build</code> 会将可执行文件编译在 <code>target/debug/hello-world</code> 目录下，第一次构建时，会在顶层目录生成 cargo.lock 文件，负责追踪项目依赖的精确版本，类似于 Golang 的 go.sum 文件。</p><p><em>cargo.lock</em></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This file is automatically @generated by Cargo.</span></span><br><span class="line"><span class="comment"># It is not intended for manual editing.</span></span><br><span class="line"><span class="attr">version</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[package]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;hello-world&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo build</span></span><br><span class="line">   Compiling hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">    Finished dev [unoptimized + debuginfo] target(s) in 2.21s</span><br></pre></td></tr></table></figure><h3 id="release"><a href="#release" class="headerlink" title="release"></a>release</h3><p><strong>optimized</strong></p><p>默认情况，<code>cargo build</code> 适用于开发阶段的常规编译，在最终发布构建时，可以通过 <code>cargo build --release</code> 发布，这样在编译的时候会进行优化，代码运行的更快，但是编译的时间也更长，同时，会在 <code>target/release</code> 而不是 <code>target/debug</code> 生成可执行文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo build --release</span></span><br><span class="line">   Compiling hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">    Finished release [optimized] target(s) in 0.38s</span><br></pre></td></tr></table></figure><h2 id="cargo-run"><a href="#cargo-run" class="headerlink" title="cargo run"></a>cargo run</h2><p><code>cargo run</code> 本质上就是编译代码 + 执行结果，如果之前编译成功过，且源码没有改变，那么就会直接运行二进制文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">   Compiling hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">    Finished dev [unoptimized + debuginfo] target(s) in 0.66s</span><br><span class="line">     Running `target/debug/hello-world`</span><br><span class="line">Hello, world!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">    Finished dev [unoptimized + debuginfo] target(s) in 0.00s</span><br><span class="line">     Running `target/debug/hello-world`</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure><h2 id="cargo-check"><a href="#cargo-check" class="headerlink" title="cargo check"></a>cargo check</h2><p><code>cargo check</code> 用于检查代码，确保能通过编译，但是不会实质的进行编译，<code>cargo check</code> 运行速度比 <code>cargo build</code> 快得多，可以用于开发阶段反复检查，提高效率。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo check</span></span><br><span class="line">    Checking hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">    Finished dev [unoptimized + debuginfo] target(s) in 0.06s</span><br></pre></td></tr></table></figure><p>当检查有错误时，会报错提示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo check</span></span><br><span class="line">    Checking hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">error: expected one of `-&gt;`, `;`, `where`, or `&#123;`, found `err`</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">src/main.rs:1:11</span></span><br><span class="line">  |</span><br><span class="line">1 | fn main() err &#123;</span><br><span class="line">  |           ^^^ expected one of `-&gt;`, `;`, `where`, or `&#123;`</span><br><span class="line"></span><br><span class="line">error: could not compile `hello-world` due to previous error</span><br></pre></td></tr></table></figure><h1 id="国内源加速"><a href="#国内源加速" class="headerlink" title="国内源加速"></a>国内源加速</h1><p>默认情况下，cargo 获取包依赖等通过 crate.io，由于网络问题，可以将其替换成国内的 cargo 源。</p><p><em>~&#x2F;.cargo&#x2F;config</em></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[source.crates-io]</span></span><br><span class="line"><span class="attr">registry</span> = <span class="string">&quot;https://github.com/rust-lang/crates.io-index&quot;</span></span><br><span class="line"><span class="attr">replace-with</span> = <span class="string">&#x27;sjtu&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清华大学</span></span><br><span class="line"><span class="section">[source.tuna]</span></span><br><span class="line"><span class="attr">registry</span> = <span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 中国科学技术大学</span></span><br><span class="line"><span class="section">[source.ustc]</span></span><br><span class="line"><span class="attr">registry</span> = <span class="string">&quot;git://mirrors.ustc.edu.cn/crates.io-index&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上海交通大学</span></span><br><span class="line"><span class="section">[source.sjtu]</span></span><br><span class="line"><span class="attr">registry</span> = <span class="string">&quot;https://mirrors.sjtug.sjtu.edu.cn/git/crates.io-index&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rustcc 社区</span></span><br><span class="line"><span class="section">[source.rustcc]</span></span><br><span class="line"><span class="attr">registry</span> = <span class="string">&quot;git://crates.rustcc.cn/crates.io-index&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Rust 包管理工具 Cargo 的介绍与使用</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Rust" scheme="http://shenxianghong.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>「 Rust 」概念初识</title>
    <link href="http://shenxianghong.github.io/2022/01/08/2022-01-08%20Rust%20%E6%A6%82%E5%BF%B5%E5%88%9D%E8%AF%86/"/>
    <id>http://shenxianghong.github.io/2022/01/08/2022-01-08%20Rust%20%E6%A6%82%E5%BF%B5%E5%88%9D%E8%AF%86/</id>
    <published>2022-01-07T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.127Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/rust/logo.png"></div><hr><h1 id="单次猜测"><a href="#单次猜测" class="headerlink" title="单次猜测"></a>单次猜测</h1><p><em>获取用户的命令行输入</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;guess a number&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    io::<span class="title function_ invoke__">stdin</span>().<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;error reading line&quot;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;your number is &#123;&#125;&quot;</span>, guess);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="库的引用"><a href="#库的引用" class="headerlink" title="库的引用"></a>库的引用</h2><p>默认情况下 Rust 会将 <code>prelude</code> 模块（预导入模块）的内容导入到每个程序的作用域中，如果要使用的库不位于 <code>prelude</code> 模块中，则需要通过 <code>use</code> 关键字显示的导入。在此示例中，获取用户命令行输入的库为 io 库，而 io 库位于 Rust 标准库 std 中，导入方法为 <code>use std::io;</code> </p><h2 id="变量的不可变"><a href="#变量的不可变" class="headerlink" title="变量的不可变"></a>变量的不可变</h2><p>默认情况下，Rust 的变量均为不可变的（immutable）。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">foo</span> = <span class="number">1</span>;</span><br><span class="line">    foo = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;foo is &#123;&#125;&quot;</span>, foo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">error[E0384]: cannot assign twice to immutable variable `foo`</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">src/main.rs:3:5</span></span><br><span class="line">  |</span><br><span class="line">2 |     let foo = 1;</span><br><span class="line">  |         ---</span><br><span class="line">  |         |</span><br><span class="line">  |         first assignment to `foo`</span><br><span class="line">  |         help: consider making this binding mutable: `mut foo`</span><br><span class="line">3 |     foo = 2;</span><br><span class="line">  |     ^^^^^^^ cannot assign twice to immutable variable</span><br></pre></td></tr></table></figure><p>如果要声明一个可变的变量，那么需要在变量前加上 <code>mut</code> 关键字</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">foo</span> = <span class="number">1</span>;</span><br><span class="line">    foo = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;bar is &#123;&#125;&quot;</span>, foo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">bar is 2</span><br></pre></td></tr></table></figure><p>需要注意的是，引用默认也是不可变的，而 <code>read_line()</code> 方法会根据用户的输入修改传入的变量，因此，也要对入参声明可变。</p><h2 id="关联函数"><a href="#关联函数" class="headerlink" title="关联函数"></a>关联函数</h2><p><code>String::new()</code> 会返回字符串的一个新的实例，内部是 utf-8 编码的，中间的两个冒号表示 <code>new()</code> 是 <code>String</code> 这个类型的关联函数，关联函数表示针对这个类型本身来实现的，不是针对这个类型的某个特定示例来实现的，也就是 <code>new()</code> 不会作用于 guess 实例，类似于 Golang 中的结构体方法。</p><p>同理，<code>io::stdin()</code> 会返回一个 Stdin 类型的句柄。</p><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>Rust 中有很多种 Result 类型，即有通用泛型的 Result，也有针对特定类型的 Result，例如 <code>io::Result</code> ，Result 实际上就是一个枚举类型，包括两个值，一个是 <code>Ok</code> 一个是 <code>Err</code> ，<code>expect()</code> 方法用作错误判断，如果返回的值为 Err，那么会中断程序并将入参输出。</p><h2 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h2><p>区别于 Golang，<code>println!()</code> 中如果想输出变量，那么必须要有占位符，即 <code>&#123;&#125;</code>。</p><h1 id="神秘数字"><a href="#神秘数字" class="headerlink" title="神秘数字"></a>神秘数字</h1><p><em>引入第三方 rand 包，实现随机数的生成</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">secret_number</span> = rand::<span class="title function_ invoke__">thread_rng</span>().<span class="title function_ invoke__">gen_range</span>(<span class="number">1</span>, <span class="number">101</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;secret_number is &#123;&#125;&quot;</span>, secret_number);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;guess a number&quot;</span>)</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    io::<span class="title function_ invoke__">stdin</span>().<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;error reading line&quot;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;your number is &#123;&#125;&quot;</span>, guess);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="第三方依赖包"><a href="#第三方依赖包" class="headerlink" title="第三方依赖包"></a>第三方依赖包</h2><p>在 <code>Cargo.toml</code> 的 <code>dependencies</code> 新增 <code>package = version</code> 信息为项目新增第三方依赖包。</p><p><code>^</code> 表示任何一个与指定版本 api 兼容的库均可以，并且该标识为默认。</p><p><em>Cargo.toml</em></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[package]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;hello-world&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">edition</span> = <span class="string">&quot;2021&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html</span></span><br><span class="line"></span><br><span class="line"><span class="section">[dependencies]</span></span><br><span class="line"><span class="attr">rand</span> = <span class="string">&quot;^0.3.14&quot;</span></span><br></pre></td></tr></table></figure><p>首次构建时，cargo 会更新源的 index，根据 <code>Cargo.toml</code> 的内容下载依赖，将下载的依赖信息写入 <code>Cargo.lock</code> 中，并完成源码和依赖的构建，当后续源码或者发生变化，则仅会重新构建变化部分。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo build</span></span><br><span class="line">  Updating crates.io index</span><br><span class="line">  Downloaded rand v0.3.23</span><br><span class="line">  Downloaded rand v0.4.6</span><br><span class="line">  Downloaded 2 crates (87.7 KB) in 0.77s</span><br><span class="line">   Compiling libc v0.2.112</span><br><span class="line">   Compiling rand v0.4.6</span><br><span class="line">   Compiling rand v0.3.23</span><br><span class="line">   Compiling hello-world v0.1.0 (/Users/shenxianghong/Documents/Project/Rustaceans/hello-world)</span><br><span class="line">    Finished dev [unoptimized + debuginfo] target(s) in 5.06s</span><br></pre></td></tr></table></figure><p><em>Cargo.lock</em></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;skip&gt;</span><br><span class="line"><span class="section">[[package]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;libc&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.2.112&quot;</span></span><br><span class="line"><span class="attr">source</span> = <span class="string">&quot;registry+https://github.com/rust-lang/crates.io-index&quot;</span></span><br><span class="line"><span class="attr">checksum</span> = <span class="string">&quot;1b03d17f364a3a042d5e5d46b053bbbf82c92c9430c592dd4c064dc6ee997125&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[package]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;rand&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.3.23&quot;</span></span><br><span class="line"><span class="attr">source</span> = <span class="string">&quot;registry+https://github.com/rust-lang/crates.io-index&quot;</span></span><br><span class="line"><span class="attr">checksum</span> = <span class="string">&quot;64ac302d8f83c0c1974bf758f6b041c6c8ada916fbb44a609158ca8b064cc76c&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = [</span><br><span class="line"> <span class="string">&quot;libc&quot;</span>,</span><br><span class="line"> <span class="string">&quot;rand 0.4.6&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>当对依赖跨大版本版本更新时，需要手动修改 <code> Cargo.toml</code> ，除了可以通过重新构建的方式，还可以通过 <code>cargo update</code> 重新维护依赖关系。</p><p><em>rand 包升级至 0.7</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo update</span></span><br><span class="line">    Updating crates.io index</span><br><span class="line">    Removing cfg-if v1.0.0</span><br><span class="line">      Adding fuchsia-cprng v0.1.1</span><br><span class="line">    Removing getrandom v0.1.16</span><br><span class="line">    Removing ppv-lite86 v0.2.16</span><br><span class="line">    Removing rand v0.7.3</span><br><span class="line">      Adding rand v0.3.23</span><br><span class="line">      Adding rand v0.4.6</span><br><span class="line">    Removing rand_chacha v0.2.2</span><br><span class="line">    Removing rand_core v0.5.1</span><br><span class="line">      Adding rand_core v0.3.1</span><br><span class="line">      Adding rand_core v0.4.2</span><br><span class="line">    Removing rand_hc v0.2.0</span><br><span class="line">      Adding rdrand v0.4.0</span><br><span class="line">    Removing wasi v0.9.0+wasi-snapshot-preview1</span><br><span class="line">      Adding winapi v0.3.9</span><br><span class="line">      Adding winapi-i686-pc-windows-gnu v0.4.0</span><br><span class="line">      Adding winapi-x86_64-pc-windows-gnu v0.4.0</span><br><span class="line">shenxianghong@Corgi hello-world % cargo update</span><br><span class="line">    Updating crates.io index</span><br><span class="line">      Adding cfg-if v1.0.0</span><br><span class="line">    Removing fuchsia-cprng v0.1.1</span><br><span class="line">      Adding getrandom v0.1.16</span><br><span class="line">      Adding ppv-lite86 v0.2.16</span><br><span class="line">    Removing rand v0.3.23</span><br><span class="line">    Removing rand v0.4.6</span><br><span class="line">      Adding rand v0.7.3</span><br><span class="line">      Adding rand_chacha v0.2.2</span><br><span class="line">    Removing rand_core v0.3.1</span><br><span class="line">    Removing rand_core v0.4.2</span><br><span class="line">      Adding rand_core v0.5.1</span><br><span class="line">      Adding rand_hc v0.2.0</span><br><span class="line">    Removing rdrand v0.4.0</span><br><span class="line">      Adding wasi v0.9.0+wasi-snapshot-preview1</span><br><span class="line">    Removing winapi v0.3.9</span><br><span class="line">    Removing winapi-i686-pc-windows-gnu v0.4.0</span><br><span class="line">    Removing winapi-x86_64-pc-windows-gnu v0.4.0</span><br></pre></td></tr></table></figure><p>除此之外，<code>cargo update</code> 还可以用于依赖包的小版本升级：当执行升级时，Cargo 会忽略 Cargo.lock，根据 Cargo.toml 的包版本信息，升级到最新的小版本，而不会突破大版本，升级之后 Cargo.lock 会更新，而 Cargo.toml 保持不变，也就是基于语义化的版本升级。</p><h2 id="Trait"><a href="#Trait" class="headerlink" title="Trait"></a>Trait</h2><p>Trait 可以理解成 Golang 中的接口，定义了许多方法。<code>rand::Rng</code> 就是一个 Trait，定义了一组随机数生成器所需要的方法。<code>rand::thread_rng()</code> 这个函数返回是一个 <code>ThreadRng</code> 类型，本质上是一个运行在本地线程空间中，通过操作系统获取随机数种子的随机数生成器，而 <code>gen_range()</code> 就是 Trait 的方法之一。</p><p><em>不导入 trait，但是使用 trait 方法，会引起报错</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo run</span></span><br><span class="line">error[E0599]: no method named `gen_range` found for struct `ThreadRng` in the current scope</span><br><span class="line"><span class="meta prompt_">   --&gt; </span><span class="language-bash">src/main.rs:6:44</span></span><br><span class="line">    |</span><br><span class="line">6   |     let secret_number = rand::thread_rng().gen_range(1, 101);</span><br><span class="line">    |                                            ^^^^^^^^^ method not found in `ThreadRng`</span><br><span class="line">    |</span><br><span class="line">   ::: /Users/shenxianghong/.cargo/registry/src/github.com-1ecc6299db9ec823/rand-0.4.6/src/lib.rs:524:8</span><br><span class="line">    |</span><br><span class="line">524 |     fn gen_range&lt;T: PartialOrd + SampleRange&gt;(&amp;mut self, low: T, high: T) -&gt; T where Self: Sized &#123;</span><br><span class="line">    |        --------- the method is available for `ThreadRng` here</span><br><span class="line">    |</span><br><span class="line">    = help: items from traits can only be used if the trait is in scope</span><br><span class="line">help: the following trait is implemented but not in scope; perhaps add a `use` for it:</span><br><span class="line">    |</span><br><span class="line">1   | use rand::Rng;</span><br><span class="line">    |</span><br></pre></td></tr></table></figure><h1 id="比较猜测数字与神秘数字"><a href="#比较猜测数字与神秘数字" class="headerlink" title="比较猜测数字与神秘数字"></a>比较猜测数字与神秘数字</h1><p><em>猜测数字为 string 类型，神秘数字为 int 类型，转换后进行大小比较</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"><span class="keyword">use</span> std::cmp::Ordering;</span><br><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">secret_number</span> = rand::<span class="title function_ invoke__">thread_rng</span>().<span class="title function_ invoke__">gen_range</span>(<span class="number">1</span>, <span class="number">101</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;secret_number is &#123;&#125;&quot;</span>, secret_number);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;guess a number&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    io::<span class="title function_ invoke__">stdin</span>().<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;error reading line&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">guess</span>: <span class="type">u32</span> = guess.<span class="title function_ invoke__">trim</span>().<span class="title function_ invoke__">parse</span>().<span class="title function_ invoke__">expect</span>(<span class="string">&quot;error parsing guess number&quot;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;your number is &#123;&#125;&quot;</span>, guess);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">match</span> guess.<span class="title function_ invoke__">cmp</span>(&amp;secret_number) &#123;</span><br><span class="line">        Ordering::Less =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too small&quot;</span>),</span><br><span class="line">        Ordering::Greater =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too big&quot;</span>),</span><br><span class="line">        Ordering::Equal =&gt; <span class="built_in">println!</span>(<span class="string">&quot;You win&quot;</span>),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><p><code>std::cmp::Ordering</code> 是一个枚举类型，包含三个值，分别是 <code>Ordering::Less</code>、<code>Ordering::Greater</code> 和 <code>Ordering::Equal </code> ，枚举类型的使用也需要使用双冒号格式。</p><h2 id="match"><a href="#match" class="headerlink" title="match"></a>match</h2><p><code>cmp</code> 方法返回的是 Ordering 类型，根据不同的分支（arm）判断匹配模式，从而执行不同的逻辑，即 <code>=&gt;</code> 之后的逻辑，类似于 Golang 中的 switch case 用法。</p><h2 id="Shadow"><a href="#Shadow" class="headerlink" title="Shadow"></a>Shadow</h2><p>Rust 中允许使用同名的变量来覆盖之前的变量，区别于 Golang，不仅可以用于覆盖值，可以类型也可以不一样。一般用于在不额外声明变量的场景下，进行类型转换。</p><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><p>Rust 是强类型语言，并且具备类型推断的能力，<code>gen_range(1, 101)</code> 会返回 1 到 100 之间的随机整数，Rust 中涵盖此范围的类型很多，比如 i32、u32、i64 等等，如果未做进一步的声明，Rust 默认其为 i32。</p><p>可以注意到，变量 guess 被转换成了 u32 类型，而接下来还对变量 guess 和 secret_number 进行了 match 比较，因此 Rust 也会将变量 secret_number 设置为 u32 类型编译，因此，如果没有 match 比较，则 Rust 会将其默认为 i32。</p><h1 id="多次猜测"><a href="#多次猜测" class="headerlink" title="多次猜测"></a>多次猜测</h1><p><em>增加死循环，直至猜对退出；增加错误处理，完善健壮性</em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"><span class="keyword">use</span> std::cmp::Ordering;</span><br><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">secret_number</span> = rand::<span class="title function_ invoke__">thread_rng</span>().<span class="title function_ invoke__">gen_range</span>(<span class="number">1</span>, <span class="number">101</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">loop</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;guess a number&quot;</span>);</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">        io::<span class="title function_ invoke__">stdin</span>().<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;error reading line&quot;</span>);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">guess</span>: <span class="type">u32</span> = <span class="keyword">match</span> guess.<span class="title function_ invoke__">trim</span>().<span class="title function_ invoke__">parse</span>() &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(num) =&gt; num,</span><br><span class="line">            <span class="title function_ invoke__">Err</span>(_) =&gt; <span class="keyword">continue</span></span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;your number is &#123;&#125;&quot;</span>, guess);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">match</span> guess.<span class="title function_ invoke__">cmp</span>(&amp;secret_number) &#123;</span><br><span class="line">            Ordering::Less =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too small&quot;</span>),</span><br><span class="line">            Ordering::Greater =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Too big&quot;</span>),</span><br><span class="line">            Ordering::Equal =&gt; &#123;</span><br><span class="line">                <span class="built_in">println!</span>(<span class="string">&quot;You win&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="死循环"><a href="#死循环" class="headerlink" title="死循环"></a>死循环</h2><p>Rust 中的死循环使用 <code>loop</code> 关键字，退出使用 <code>break</code> 关键字，继续使用 <code>continue</code> 关键字。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>Rust 中常用的错误处理方式是基于 match 模式，例如 parse() 方法返回 Result 类型，该类型包括两个枚举值。其中 <code>Ok(num)</code>  表示猜测数字解析成功，num 为解析之后的数字，通过 &#x3D;&gt; 赋值给 guess。同理，<code>Err(_)</code> 表示解析失败，<code>_</code> 为错误信息，下划线表示忽略。</p>]]></content>
    
    
    <summary type="html">通过一个简单的猜数游戏，了解 Rust 程序的一些基础概念</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Rust" scheme="http://shenxianghong.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」操作卷数据（Restic）</title>
    <link href="http://shenxianghong.github.io/2022/01/06/2022-01-06%20Velero%20%E6%93%8D%E4%BD%9C%E5%8D%B7%E6%95%B0%E6%8D%AE%EF%BC%88Restic%EF%BC%89/"/>
    <id>http://shenxianghong.github.io/2022/01/06/2022-01-06%20Velero%20%E6%93%8D%E4%BD%9C%E5%8D%B7%E6%95%B0%E6%8D%AE%EF%BC%88Restic%EF%BC%89/</id>
    <published>2022-01-05T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.116Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="与-Restic-集成安装"><a href="#与-Restic-集成安装" class="headerlink" title="与 Restic 集成安装"></a>与 Restic 集成安装</h1><h2 id="命令行安装"><a href="#命令行安装" class="headerlink" title="命令行安装"></a>命令行安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">velero install \</span><br><span class="line">    --provider aws \</span><br><span class="line">    --bucket velero \</span><br><span class="line">    --plugins velero/velero-plugin-for-aws:v1.0.0 \</span><br><span class="line">    --secret-file /root/credential \</span><br><span class="line">    --use-restic \</span><br><span class="line">    --default-volumes-to-restic \</span><br><span class="line">    --use-volume-snapshots=false</span><br></pre></td></tr></table></figure><p><strong>参数说明</strong></p><ul><li><code>use-restic</code> 表示是否启用 Restic 组件操作 Pod 中的卷数据</li><li><code>default-volumes-to-restic</code> 表示是否默认备份 Pod 中所有的卷</li></ul><h2 id="部署文件"><a href="#部署文件" class="headerlink" title="部署文件"></a>部署文件</h2><p>相比于之前的部署结果：</p><ul><li>在指定 <code>--use-restic</code> 之后，额外部署了 DaemonSet 类型的 Restic 服务</li><li>在指定 <code>--default-volumes-to-restic</code> 之后，Velero 的启动参数中会新增 feature 特性</li></ul><p><strong>default-volumes-to-restic</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">server</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--features=</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--default-volumes-to-restic=true</span></span><br></pre></td></tr></table></figure><p><strong>use-restic</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">component:</span> <span class="string">velero</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">restic</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">velero</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">restic</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">component:</span> <span class="string">velero</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">restic</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">restic</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">server</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--features=</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/velero</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NODE_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VELERO_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VELERO_SCRATCH_DIR</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">/scratch</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GOOGLE_APPLICATION_CREDENTIALS</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">/credentials/cloud</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">AWS_SHARED_CREDENTIALS_FILE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">/credentials/cloud</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">AZURE_CREDENTIALS_FILE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">/credentials/cloud</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ALIBABA_CLOUD_CREDENTIALS_FILE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">/credentials/cloud</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">velero:dev</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">restic</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/host_pods</span></span><br><span class="line">          <span class="attr">mountPropagation:</span> <span class="string">HostToContainer</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">host-pods</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/scratch</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">scratch</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/credentials</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">cloud-credentials</span></span><br><span class="line">      <span class="attr">securityContext:</span></span><br><span class="line">        <span class="attr">runAsUser:</span> <span class="number">0</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">velero</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/lib/kubelet/pods</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">host-pods</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">        <span class="attr">name:</span> <span class="string">scratch</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cloud-credentials</span></span><br><span class="line">        <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">secretName:</span> <span class="string">cloud-credentials</span></span><br><span class="line">  <span class="attr">updateStrategy:</span> &#123;&#125;</span><br></pre></td></tr></table></figure><h2 id="部署结果"><a href="#部署结果" class="headerlink" title="部署结果"></a>部署结果</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -n velero</span></span><br><span class="line">NAME                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">minio-54b5867494-6plnl    1/1     Running     0          12m</span><br><span class="line">minio-setup-54vx8         0/1     Completed   0          12m</span><br><span class="line">restic-vqdmn              1/1     Running     0          14m</span><br><span class="line">velero-598755d478-7l8gd   1/1     Running     0          14m</span><br></pre></td></tr></table></figure><h1 id="流程验证"><a href="#流程验证" class="headerlink" title="流程验证"></a>流程验证</h1><p>以 local PV 作为 Pod 卷数据为例</p><p><strong>PV</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">100Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp/example</span></span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">sxh-1</span></span><br></pre></td></tr></table></figure><p><strong>PVC</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">50Mi</span></span><br></pre></td></tr></table></figure><p><strong>Pod</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;/bin/sh&quot;</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;-c&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;sleep 1000000&quot;</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">local-pvc</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">&quot;/mnt&quot;</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">local-pvc</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">example-pvc</span></span><br></pre></td></tr></table></figure><p><strong>操作验证</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入测试数据</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it example-pod <span class="built_in">ls</span> /mnt</span></span><br><span class="line">hello-here</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建备份任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup create default</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模拟故障</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /tmp/example/* &amp;&amp; kubectl delete pod test-pod &amp;&amp; kubectl delete pvc test-claim &amp;&amp; kubectl delete pv test-pv</span> </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新部署 pv，后续在 troubleshooting 会说明原因</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f pv.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建恢复任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore create default --from-backup default</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看测试数据</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it example-pod <span class="built_in">ls</span> /mnt</span></span><br><span class="line">hello-here</span><br></pre></td></tr></table></figure><h1 id="流程走读"><a href="#流程走读" class="headerlink" title="流程走读"></a>流程走读</h1><p>Velero 在对 Pod 卷数据做备份时，可以与开源项目 Restic 集成，集成使用时，Restic 本身的优势也会得到支持，如<strong>加密传输</strong>， <strong>压缩备份</strong>， <strong>增量备份</strong>， <strong>断点续传</strong>等。</p><h2 id="CRD"><a href="#CRD" class="headerlink" title="CRD"></a>CRD</h2><p>有关卷备份与恢复的 CRD 包含：<code>podvolumebackups.velero.io</code>、<code>podvolumerestores.velero.io</code> 和 <code>resticrepositories.velero.io</code>。</p><h3 id="ResticRepository"><a href="#ResticRepository" class="headerlink" title="ResticRepository"></a>ResticRepository</h3><p>Restic 中 <code>repository</code> 的概念，表示备份用于存储的位置。</p><p>原生 Restic 中通过 <code>restic init --repo &lt;repo&gt;</code> 的方式初始化不同的 backend。</p><p><strong>local</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restic init --repo /srv/restic-repo</span></span><br><span class="line">enter password for new repository:</span><br><span class="line">enter password again:</span><br><span class="line">created restic repository 085b3c76b9 at /srv/restic-repo</span><br><span class="line">Please note that knowledge of your password is required to access the repository.</span><br><span class="line">Losing your password means that your data is irrecoverably lost.</span><br></pre></td></tr></table></figure><p><strong>sftp</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restic -r sftp:user@host:/srv/restic-repo init</span></span><br><span class="line">enter password for new repository:</span><br><span class="line">enter password again:</span><br><span class="line">created restic repository f1c6108821 at sftp:user@host:/srv/restic-repo</span><br><span class="line">Please note that knowledge of your password is required to access the repository.</span><br><span class="line">Losing your password means that your data is irrecoverably lost.</span><br></pre></td></tr></table></figure><p><strong>Amazon S3</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> AWS_ACCESS_KEY_ID=&lt;MY_ACCESS_KEY&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> AWS_SECRET_ACCESS_KEY=&lt;MY_SECRET_ACCESS_KEY&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restic -r s3:s3.amazonaws.com/bucket_name init</span></span><br><span class="line">enter password for new repository:</span><br><span class="line">enter password again:</span><br><span class="line">created restic repository eefee03bbd at s3:s3.amazonaws.com/bucket_name</span><br><span class="line">Please note that knowledge of your password is required to access the repository.</span><br><span class="line">Losing your password means that your data is irrecoverably lost.</span><br></pre></td></tr></table></figure><p><strong>Minio Server</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> AWS_ACCESS_KEY_ID=&lt;YOUR-MINIO-ACCESS-KEY-ID&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> AWS_SECRET_ACCESS_KEY= &lt;YOUR-MINIO-SECRET-ACCESS-KEY&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./restic -r s3:http://localhost:9000/restic init</span></span><br><span class="line">enter password for new repository:</span><br><span class="line">enter password again:</span><br><span class="line">created restic repository 6ad29560f5 at s3:http://localhost:9000/restic1</span><br><span class="line">Please note that knowledge of your password is required to access</span><br><span class="line">the repository. Losing your password means that your data is irrecoverably lost.</span><br></pre></td></tr></table></figure><p>在 Velero 中封装了初始化 Restic Repository 的动作（具体包含 <code>restic init</code>、<code>restic check</code> 和 <code>restic prune</code>），但是仅支持 <code>velero.io/aws</code>（包含 aws 或者非 aws，但是兼容 s3 的存储，如 minio）、<code>velero.io/aure</code> 和 <code>velero.io/gcp</code>。</p><p><em>pkg&#x2F;restic&#x2F;config.go</em></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// getRepoPrefix returns the prefix of the value of the --repo flag for</span></span><br><span class="line"><span class="comment">// restic commands, i.e. everything except the &quot;/&lt;repo-name&gt;&quot;.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getRepoPrefix</span><span class="params">(location *velerov1api.BackupStorageLocation)</span></span> (<span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line"><span class="keyword">var</span> bucket, prefix <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> location.Spec.ObjectStorage != <span class="literal">nil</span> &#123;</span><br><span class="line">layout := persistence.NewObjectStoreLayout(location.Spec.ObjectStorage.Prefix)</span><br><span class="line"></span><br><span class="line">bucket = location.Spec.ObjectStorage.Bucket</span><br><span class="line">prefix = layout.GetResticDir()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">backendType := getBackendType(location.Spec.Provider)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> repoPrefix := location.Spec.Config[<span class="string">&quot;resticRepoPrefix&quot;</span>]; repoPrefix != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line"><span class="keyword">return</span> repoPrefix, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> backendType &#123;</span><br><span class="line"><span class="keyword">case</span> AWSBackend:</span><br><span class="line"><span class="keyword">var</span> url <span class="type">string</span></span><br><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="comment">// non-AWS, S3-compatible object store</span></span><br><span class="line"><span class="keyword">case</span> location.Spec.Config[<span class="string">&quot;s3Url&quot;</span>] != <span class="string">&quot;&quot;</span>:</span><br><span class="line">url = location.Spec.Config[<span class="string">&quot;s3Url&quot;</span>]</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">region, err := getAWSBucketRegion(bucket)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">url = <span class="string">&quot;s3.amazonaws.com&quot;</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = fmt.Sprintf(<span class="string">&quot;s3-%s.amazonaws.com&quot;</span>, region)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;s3:%s/%s&quot;</span>, strings.TrimSuffix(url, <span class="string">&quot;/&quot;</span>), path.Join(bucket, prefix)), <span class="literal">nil</span></span><br><span class="line"><span class="keyword">case</span> AzureBackend:</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;azure:%s:/%s&quot;</span>, bucket, prefix), <span class="literal">nil</span></span><br><span class="line"><span class="keyword">case</span> GCPBackend:</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;gs:%s:/%s&quot;</span>, bucket, prefix), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;&quot;</span>, errors.New(<span class="string">&quot;restic repository prefix (resticRepoPrefix) not specified in backup storage location&#x27;s config&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对每一个待备份卷数据的 Pod 所在的 namespace，velero 会创建一个和 namespace 对应的 ResticRepository，如果对应 namespace 的 ResticRepository 存在，则不会重复创建，命名方式为 <code>&lt;namespace&gt;-&lt;backupstoragelocation&gt;-&lt;id&gt;</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restic repo get</span></span><br><span class="line">NAME                    STATUS   LAST MAINTENANCE</span><br><span class="line">default-default-n5mz4   Ready    2022-01-06 16:05:14 +0800 CST</span><br><span class="line">velero-default-8q767    Ready    2022-01-06 15:46:31 +0800 CST</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get resticrepositories -n velero</span></span><br><span class="line">NAME                    AGE</span><br><span class="line">default-default-n5mz4   2m</span><br><span class="line">velero-default-8q767    2m28s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get resticrepositories -n velero default-default-n5mz4 -o yaml</span></span><br><span class="line">&lt;skip&gt;</span><br><span class="line">spec:</span><br><span class="line">  backupStorageLocation: default</span><br><span class="line">  maintenanceFrequency: 168h0m0s</span><br><span class="line">  resticIdentifier: s3:http://minio.velero.svc:9000/velero/restic/default</span><br><span class="line">  volumeNamespace: default</span><br></pre></td></tr></table></figure><p>在 BackupStorageLocation 中的存储方式如下：</p><p><strong>velero.io&#x2F;aws</strong></p><div align=center><img width="600" style="border: 0px" src="/gallery/velero/resticrepositories-in-minio.png"></div><h3 id="PodVolumeBackup"><a href="#PodVolumeBackup" class="headerlink" title="PodVolumeBackup"></a>PodVolumeBackup</h3><p>代表 Pod 卷备份任务，每有一个待备份的 Pod 卷，Velero 会创建一个和 backup 对应的 PodVolumeBackup，由于该 CR 是和 backup 对应且 backup 名称唯一，所以针对相同的 Pod 卷的多次备份，会创建多个 PodVolumeBackup，命名方式为 <code>&lt;backup&gt;-&lt;id&gt;</code>，各节点上的 restic daemonset  controller 会根据 PodVolumeBackup指定 <code>restic backup</code> 命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get podvolumebackups -n velero</span></span><br><span class="line">NAME            AGE</span><br><span class="line">default-l2dd6   105s</span><br><span class="line">velero-j2xj5    2m5s</span><br><span class="line">velero-llv9m    2m5s</span><br><span class="line">velero-nxlkq    2m13s</span><br><span class="line">velero-x6m72    2m7s</span><br><span class="line">velero-xqdhk    2m7s</span><br><span class="line">velero-z7rhq    2m12s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe podvolumebackups -n velero default-l2dd6</span></span><br><span class="line">&lt;skip&gt;</span><br><span class="line">Spec:</span><br><span class="line">  Backup Storage Location:  default</span><br><span class="line">  Node:                     sxh-1</span><br><span class="line">  Pod:</span><br><span class="line">    Kind:           Pod</span><br><span class="line">    Name:           example-pod</span><br><span class="line">    Namespace:      default</span><br><span class="line">    UID:            bb17e801-b595-4e96-8ced-e27e8686be23</span><br><span class="line">  Repo Identifier:  s3:http://minio.velero.svc:9000/velero/restic/default</span><br><span class="line">  Tags:</span><br><span class="line">    Backup:        default</span><br><span class="line">    Backup - UID:  2fa40af0-2dcc-43dc-9636-79e5f1c95045</span><br><span class="line">    Ns:            default</span><br><span class="line">    Pod:           example-pod</span><br><span class="line">    Pod - UID:     bb17e801-b595-4e96-8ced-e27e8686be23</span><br><span class="line">    Pvc - UID:     f89b5daf-cf5e-49f1-9ba8-26e62f55baf2</span><br><span class="line">    Volume:        local-pvc</span><br><span class="line">  Volume:          local-pvc</span><br></pre></td></tr></table></figure><h3 id="PodVolumeRestore"><a href="#PodVolumeRestore" class="headerlink" title="PodVolumeRestore"></a>PodVolumeRestore</h3><p>代表 Pod volume 的恢复任务，每有一个待恢复的 Pod 卷，Velero 会创建一个和 restore 对应的 PodVolumeRestore，由于该 CR 是和 restore 对应且 restore 名称唯一，所以针对相同的 Pod 卷建多个 PodVolumeRestore，命名方式为 <code>&lt;restore&gt;-&lt;id&gt;</code>，各节点上的 restic daemonset  controller 会根据 PodVolumeRestore执行 <code>restic restore</code> 命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get podvolumerestores -n velero</span></span><br><span class="line">NAME                        AGE</span><br><span class="line">alls-20220106165015-p54kz   6m17s</span><br><span class="line">alls-20220106165349-rl4sh   2m42s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe podvolumerestores alls-20220106165349-rl4sh -n velero</span></span><br><span class="line">Spec:</span><br><span class="line">  Backup Storage Location:  default</span><br><span class="line">  Pod:</span><br><span class="line">    Kind:           Pod</span><br><span class="line">    Name:           example-pod</span><br><span class="line">    Namespace:      default</span><br><span class="line">    UID:            d72f5c66-2f93-4e4b-b2f6-0e5ce0aa2042</span><br><span class="line">  Repo Identifier:  s3:http://minio.velero.svc:9000/velero/restic/default</span><br><span class="line">  Snapshot ID:      abdd9af5</span><br><span class="line">  Volume:           local-pvc</span><br></pre></td></tr></table></figure><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p>Velero 在开启 Restic 对 Pod volume 备份时，根据以下两种方式获取待备份卷的信息：</p><p><strong>Velero args</strong></p><p>在开启 <code>default-volumes-to-restic</code> 时，默认所有备份均使用 restic 备份所有的 Pod 卷。该参数即可以在 <code>velero install</code> 中全局生效，也可以在 <code>velero backup create</code> 时针对单次备份生效。</p><p><em>pkg&#x2F;cmd&#x2F;cli&#x2F;install&#x2F;install.go</em></p><p><strong>Pod annotation</strong></p><p>在未开启 <code>default-volumes-to-restic</code> 时，Velero 会根据 Pod annotation 的中声明信息，获取待备份的 Pod 卷，例如 <code>backup.velero.io/backup-volumes=nginx-logs</code>，也可以指定排除备份的卷，例如 <code>backup.velero.io/backup-volumes-excludes=nginx-logs</code>。</p><p><strong>注意</strong></p><ol><li><p>如果两种方式均开启时，仅 <code>backup-volumes-excludes</code> 生效</p></li><li><p>并非所有的 in-tree volume 均会备份。例如，以下卷类型不会参与备份</p><ul><li><strong>hostpath</strong>，由于 hostpath 不会挂载到 <code>/var/lib/kubelet/pods</code> 中，因此无法被 Restic 获取</li><li><strong>secret</strong>，会作为 K8s metadata 单独备份</li><li><strong>configMap</strong>，会作为 K8s metadata 单独备份</li><li><strong>projected</strong>，为运行时状态数据，不会备份</li><li>**”default-token”**，默认的 service account token，不需要备份</li></ul></li></ol><p>如上所述，Velero 为 Pod 中要备份的每个卷创建一个  PodVolumeBackup，并等待其状态返回 completed 或者 failed。</p><p>与此同时，每个节点的 restic controller 会有一个 <code>/var/lib/kubelet/pods</code> 的 hostPath 卷挂载用来访问 Pod 的卷数据，通过访问该 hostPath 卷，获取到待备份的 Pod 卷数据后，执行 <code>restic backup</code>，并根据实际情况将 odVolumeBackup 状态设置为 completed 或者 failed。</p><p>在每一个 PodVolumeBackup 完成时，Velero 会将信息添加到 <code>&lt;backup-name&gt;-podvolumebackups.json.gz</code> 文件中，备份完成时，汇总候上传到后端存储中，该文件中包含本次备份所有的 PodVolumeBackup  信息。</p><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p>当对 Pod 卷数据进行恢复时，Velero 会根据 restore 的 <code>--from-backup</code> 的备份获取到 PodVolumeBackup。</p><p>对于获取到 PodVolumeBackup，Velero 会确保待恢复 Pod 的 namespace有与之对应的  ResticRepository，如果不存在，则创建一个，并执行 <code>restic init</code> 和 <code>restic check</code>。</p><p>Velero 向每一个待恢复卷数据的 Pod 注入一个 init 容器，这个程序会一直等待，直到在每一个恢复的卷中找到一个位于 .velero 下的文件，该文件的名称是恢复任务的 UID，即 Pod 完成所有卷数据的恢复。</p><p>Velero 创建出来的这个待恢复的 Pod，Kubernetes 调度器将这个 Pod 调度到一个可工作的节点，确保该 Pod 处于运行状态。如果 Pod 由于某种原因（即集群资源不足）启动失败，则不会进行 Restic 恢复。</p><p>Velero 为 Pod 中要恢复的每个卷创建一个 PodVolumeRestore，并等待其状态返回 completed 或者 failed。</p><p>与此同时，每个节点的 restic controller 会有一个 <code>/var/lib/kubelet/pods</code> 的 hostPath 卷挂载用来访问 Pod 的卷数据，等待 Pod 运行 init 容器，通过访问该 hostPath 卷，获取到待备份的 Pod 卷数据后，执行 <code>restic restore</code>，成功之后，将文件写入 Pod 卷中的 .velero 子目录中，名称是恢复任务的 UID，并根据实际情况将 PodVolumeRestore 状态设置为 completed 或者 failed。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l /mnt/.velero</span></span><br><span class="line">total 0</span><br><span class="line">-rw-r--r--    1 root     root             0 Jan 17 06:28 b1f704be-7f60-475e-833f-4471544a2f87</span><br></pre></td></tr></table></figure><p>当 init 容器在 .velero 下获取到所有的待恢复的卷信息后，便会成功退出，Pod 继续运行其他 init 容器&#x2F;主进程。</p><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><h3 id="静态供应的-PV-的备份与恢复"><a href="#静态供应的-PV-的备份与恢复" class="headerlink" title="静态供应的 PV 的备份与恢复"></a>静态供应的 PV 的备份与恢复</h3><p>默认情况下，Velero 会备份静态 PV，如 local pv、nfs pv 等，但是在恢复的时候，如果待恢复的对象中包含使用该 PV 的 Pod 时，Velero 并不会恢复 PV，而是默认由 StorageClass 动态供应创建 PV。此时， PVC 会处于 pending 状态（由于不存在 PV），Pod 也会处于 pending 状态（由于 PVC pending），restore 任务会等待直至超时。</p><p>目前来看 Velero 社区并没有将此视为 bug，建议在使用层面进行处理，方案的核心思路是如果恢复的 Pod 使用静态的 PV 时，需要确保恢复流程执行之前，存在一个可以满足 PVC 的 PV，例如以下两种方案：</p><p><strong>手动创建 PV</strong></p><p>也就是流程验证中的操作，通过手动创建 PV，来与 Velero 恢复的 PVC 进行绑定，完成后续恢复流程。</p><p><strong>单独备份 PV</strong></p><p>通过 <code>--include-resources pv</code> 单独备份静态 PV，在恢复之前，单独恢复静态 PV，具体流程为：</p><ol><li>备份静态 PV</li><li>创建备份任务</li><li>恢复静态 PV</li><li>恢复备份任务</li></ol><blockquote><p><a href="https://github.com/vmware-tanzu/velero/issues/2520">https://github.com/vmware-tanzu/velero/issues/2520</a></p></blockquote>]]></content>
    
    
    <summary type="html">借助 Restic 实现对 Kubernetes 集群中容器卷数据的备份与恢复</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Rust 」快速开始</title>
    <link href="http://shenxianghong.github.io/2022/01/02/2022-01-02%20Rust%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2022/01/02/2022-01-02%20Rust%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2022-01-01T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.103Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="150" style="border: 0px" src="/gallery/rust/logo.png"></div><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Rust 是由 Mozilla 主导开发的通用、编译型编程语言。设计准则为“安全、并发、实用”，支持函数式、并发式、过程式以及面向对象的编程风格。<br>Rust 语言原本是 Mozilla 员工 Graydon Hoare 的私人计划，而 Mozilla 于 2009 年开始赞助这个计划，并且在 2010 年首次公开。也在同一年，其编译器源代码开始由原本的 OCaml 语言转移到用 Rust 语言，进行 bootstrapping 工作，称做 “rustc”，并于 2011 年实际完成。这个可自我编译的编译器在架构上采用了 LLVM 做为它的后端。<br>第一个有版本号的 Rust 编译器于 2012 年 1 月发布。Rust 1.0 是第一个稳定版本，于 2015 年 5 月 15 日发布。<br>Rust 是在完全开放的情况下进行开发，并且相当欢迎社区的反馈。在 1.0 稳定版之前，语言设计也因为透过撰写 Servo 网页浏览器排版引擎和 rustc 编译器本身，而有进一步的改善。虽然它由 Mozilla 资助，但它其实是一个共有项目，有很大部分的代码是来自于社区的贡献者。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="Rust-官网"><a href="#Rust-官网" class="headerlink" title="Rust 官网"></a>Rust 官网</h2><p><a href="https://www.rust-lang.org/">https://www.rust-lang.org</a></p><h2 id="Rustup-安装"><a href="#Rustup-安装" class="headerlink" title="Rustup 安装"></a>Rustup 安装</h2><p>Rustup 是一个针对 Rust 语言的工具链管理器（toolchain manager），其目标是让交叉编译 Rust 代码更加简单。Rustup 是一个命令行应用，能够下载并在不同版本的 Rust 工具链中进行切换 —— 如编译器 <code>rustc</code>和标准库，该应用所支持的平台数量不少。事实上，<code>rustc</code> 本身就支持大约 56 个平台，而 <code>rustup</code> 实际上能够为其中 14 个平台管理编译器，为 30 个平台管理标准库。</p><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><h4 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h4><p>Rust 发布在三个不同的 channel 上：stable，beta 和 nightly，其实就是三种不同的版本</p><ul><li><strong>stable</strong> — Rust 的稳定版本，每 6 周发布一次。</li><li><strong>beta</strong> — Rust 的公开测试版本，将是下一个 stable 版本</li><li><strong>nightly</strong> — 每天更新，包含一些实验性的新特性</li></ul><h4 id="toolchain"><a href="#toolchain" class="headerlink" title="toolchain"></a>toolchain</h4><p>工具链的标准命名格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;channel&gt;[-&lt;date&gt;][-&lt;host&gt;]</span><br><span class="line"></span><br><span class="line">&lt;channel&gt;       = stable|beta|nightly|&lt;version&gt;</span><br><span class="line">&lt;date&gt;          = YYYY-MM-DD</span><br><span class="line">&lt;host&gt;          = &lt;target-triple&gt;</span><br></pre></td></tr></table></figure><p>工具链默认被安装在 <code>RUSTUP_HOME</code> （Unix系统：<code>~/.rustup</code> ，Windows系统：<code>%USERPROFILE%/.rustup</code>）目录下。</p><h4 id="components"><a href="#components" class="headerlink" title="components"></a>components</h4><p>工具链由若干组件构成，通过 <code>rustup component list</code> 命令可以查看所有可用和已经安装的组件。</p><p>Rustup 默认安装的组件有：</p><ul><li><strong>rustc</strong> — Rust 编译器</li><li><strong>rust-std</strong> — Rust 标准库</li><li><strong>cargo</strong> — 包管理和构建工具</li><li><strong>rust-docs</strong> — Rust 文档</li><li><strong>rustfmt</strong> — 用来格式化 Rust 源代码</li><li><strong>clippy</strong> — Rust 的代码检查工具</li></ul><h4 id="profile"><a href="#profile" class="headerlink" title="profile"></a>profile</h4><p>不同的 profile 包含不同的组件，安装 rustup 时有三种 profile 可选：</p><ul><li><strong>minimal</strong> — 包含 rustc、rust-std、cargo </li><li><strong>default</strong> — 包含 rustc、rust-std、cargo、rust-docs、rustfmt、clippy </li><li><strong>complete</strong> — 包含所有组件</li></ul><p>可以使用 <code>rustup set profile</code> 命令修改 <code>profile</code>，比如：<code>rustup set profile minimal</code>。</p><h3 id="macOS-amp-linux"><a href="#macOS-amp-linux" class="headerlink" title="macOS &amp; linux"></a>macOS &amp; linux</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl --proto <span class="string">&#x27;=https&#x27;</span> --tlsv1.2 -sSf https://sh.rustup.rs | sh</span></span><br><span class="line">info: downloading installer</span><br><span class="line"></span><br><span class="line">Welcome to Rust!</span><br><span class="line"></span><br><span class="line">This will download and install the official compiler for the Rust</span><br><span class="line">programming language, and its package manager, Cargo.</span><br><span class="line"></span><br><span class="line">Rustup metadata and toolchains will be installed into the Rustup</span><br><span class="line">home directory, located at:</span><br><span class="line"></span><br><span class="line">  /Users/shenxianghong/.rustup</span><br><span class="line"></span><br><span class="line">This can be modified with the RUSTUP_HOME environment variable.</span><br><span class="line"></span><br><span class="line">The Cargo home directory located at:</span><br><span class="line"></span><br><span class="line">  /Users/shenxianghong/.cargo</span><br><span class="line"></span><br><span class="line">This can be modified with the CARGO_HOME environment variable.</span><br><span class="line"></span><br><span class="line">The cargo, rustc, rustup and other commands will be added to</span><br><span class="line">Cargo&#x27;s bin directory, located at:</span><br><span class="line"></span><br><span class="line">  /Users/shenxianghong/.cargo/bin</span><br><span class="line"></span><br><span class="line">This path will then be added to your PATH environment variable by</span><br><span class="line">modifying the profile files located at:</span><br><span class="line"></span><br><span class="line">  /Users/shenxianghong/.profile</span><br><span class="line">  /Users/shenxianghong/.zshenv</span><br><span class="line"></span><br><span class="line">You can uninstall at any time with rustup self uninstall and</span><br><span class="line">these changes will be reverted.</span><br><span class="line"></span><br><span class="line">Current installation options:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   default host triple: aarch64-apple-darwin</span><br><span class="line">     default toolchain: stable (default)</span><br><span class="line">               profile: default</span><br><span class="line">  modify PATH variable: yes</span><br><span class="line"></span><br><span class="line">1) Proceed with installation (default)</span><br><span class="line">2) Customize installation</span><br><span class="line">3) Cancel installation</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">1</span></span><br><span class="line"></span><br><span class="line">info: profile set to &#x27;default&#x27;</span><br><span class="line">info: default host triple is aarch64-apple-darwin</span><br><span class="line">info: syncing channel updates for &#x27;stable-aarch64-apple-darwin&#x27;</span><br><span class="line">686.2 KiB / 686.2 KiB (100 %) 527.5 KiB/s in  1s ETA:  0s</span><br><span class="line">info: latest update on 2021-12-02, rust version 1.57.0 (f1edd0429 2021-11-29)</span><br><span class="line">info: downloading component &#x27;cargo&#x27;</span><br><span class="line">  3.7 MiB /   3.7 MiB (100 %)   1.2 MiB/s in  1s ETA:  0s</span><br><span class="line">info: downloading component &#x27;clippy&#x27;</span><br><span class="line">info: downloading component &#x27;rust-std&#x27;</span><br><span class="line"> 23.1 MiB /  23.1 MiB (100 %)   4.0 MiB/s in  6s ETA:  0s</span><br><span class="line">info: downloading component &#x27;rustc&#x27;</span><br><span class="line"> 59.4 MiB /  59.4 MiB (100 %)   4.5 MiB/s in 15s ETA:  0s</span><br><span class="line">info: downloading component &#x27;rustfmt&#x27;</span><br><span class="line">info: installing component &#x27;cargo&#x27;</span><br><span class="line">info: installing component &#x27;clippy&#x27;</span><br><span class="line">info: installing component &#x27;rust-std&#x27;</span><br><span class="line"> 23.1 MiB /  23.1 MiB (100 %)  19.4 MiB/s in  1s ETA:  0s</span><br><span class="line">info: installing component &#x27;rustc&#x27;</span><br><span class="line"> 59.4 MiB /  59.4 MiB (100 %)  21.9 MiB/s in  2s ETA:  0s</span><br><span class="line">info: installing component &#x27;rustfmt&#x27;</span><br><span class="line">info: default toolchain set to &#x27;stable-aarch64-apple-darwin&#x27;</span><br><span class="line"></span><br><span class="line">  stable-aarch64-apple-darwin installed - rustc 1.57.0 (f1edd0429 2021-11-29)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Rust is installed now. Great!</span><br><span class="line"></span><br><span class="line">To get started you may need to restart your current shell.</span><br><span class="line">This would reload your PATH environment variable to include</span><br><span class="line">Cargo&#x27;s bin directory ($HOME/.cargo/bin).</span><br><span class="line"></span><br><span class="line">To configure your current shell, run:</span><br><span class="line">source $HOME/.cargo/env</span><br></pre></td></tr></table></figure><h2 id="更新-Rust"><a href="#更新-Rust" class="headerlink" title="更新 Rust"></a>更新 Rust</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup update</span></span><br><span class="line">info: syncing channel updates for &#x27;stable-aarch64-apple-darwin&#x27;</span><br><span class="line">info: latest update on 2021-12-02, rust version 1.57.0 (f1edd0429 2021-11-29)</span><br><span class="line">info: downloading component &#x27;rust-src&#x27;</span><br><span class="line">info: downloading component &#x27;cargo&#x27;</span><br><span class="line">info: downloading component &#x27;clippy&#x27;</span><br><span class="line">info: downloading component &#x27;rust-std&#x27;</span><br><span class="line"> 23.1 MiB /  23.1 MiB (100 %)  11.6 MiB/s in  2s ETA:  0s</span><br><span class="line">info: downloading component &#x27;rustc&#x27;</span><br><span class="line"> 59.4 MiB /  59.4 MiB (100 %)  12.6 MiB/s in  4s ETA:  0s</span><br><span class="line">info: downloading component &#x27;rustfmt&#x27;</span><br><span class="line">info: removing previous version of component &#x27;rust-src&#x27;</span><br><span class="line">info: removing previous version of component &#x27;cargo&#x27;</span><br><span class="line">info: removing previous version of component &#x27;clippy&#x27;</span><br><span class="line">info: removing previous version of component &#x27;rust-std&#x27;</span><br><span class="line">info: removing previous version of component &#x27;rustc&#x27;</span><br><span class="line">info: removing previous version of component &#x27;rustfmt&#x27;</span><br><span class="line">info: installing component &#x27;rust-src&#x27;</span><br><span class="line">info: installing component &#x27;cargo&#x27;</span><br><span class="line">info: installing component &#x27;clippy&#x27;</span><br><span class="line">info: installing component &#x27;rust-std&#x27;</span><br><span class="line"> 23.1 MiB /  23.1 MiB (100 %)  18.8 MiB/s in  1s ETA:  0s</span><br><span class="line">info: installing component &#x27;rustc&#x27;</span><br><span class="line"> 59.4 MiB /  59.4 MiB (100 %)  21.3 MiB/s in  2s ETA:  0s</span><br><span class="line">info: installing component &#x27;rustfmt&#x27;</span><br><span class="line">info: checking for self-updates</span><br><span class="line"></span><br><span class="line">  stable-aarch64-apple-darwin updated - rustc 1.57.0 (f1edd0429 2021-11-29) (from rustc 1.53.0 (53cb7b09b 2021-06-17))</span><br><span class="line"></span><br><span class="line">info: cleaning up downloads &amp; tmp directories</span><br></pre></td></tr></table></figure><h2 id="卸载-Rust"><a href="#卸载-Rust" class="headerlink" title="卸载 Rust"></a>卸载 Rust</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup self uninstall</span></span><br><span class="line">Thanks for hacking in Rust!</span><br><span class="line"></span><br><span class="line">This will uninstall all Rust toolchains and data, and remove</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HOME/.cargo/bin from your PATH environment variable.</span></span><br><span class="line"></span><br><span class="line">Continue? (y/N) y</span><br><span class="line"></span><br><span class="line">info: removing rustup home</span><br><span class="line">info: removing cargo home</span><br><span class="line">info: removing rustup binaries</span><br><span class="line">info: rustup is uninstalled</span><br></pre></td></tr></table></figure><h2 id="安装校验"><a href="#安装校验" class="headerlink" title="安装校验"></a>安装校验</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustc --version</span></span><br><span class="line">rustc 1.57.0 (f1edd0429 2021-11-29)</span><br></pre></td></tr></table></figure><h2 id="离线文档"><a href="#离线文档" class="headerlink" title="离线文档"></a>离线文档</h2><p><em>即 rust-docs 工具。</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup doc</span></span><br></pre></td></tr></table></figure><p><strong>rustup doc 在 apple m1 架构下，文件不存在，无法打开，报错为</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">error: couldn&#x27;t open browser: command &#x27;open&#x27; did not execute successfully; exit status: 1</span><br><span class="line">command stderr:</span><br><span class="line">The file /Users/shenxianghong/.rustup/toolchains/stable-aarch64-apple-darwin/share/doc/rust/html/index.html does not exist.</span><br></pre></td></tr></table></figure><p><strong>Workaround</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup toolchain install stable-x86_64-apple-darwin</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup doc --toolchain=stable-x86_64-apple-darwin</span></span><br></pre></td></tr></table></figure><blockquote><p> <a href="https://github.com/rust-lang/rustup/issues/2692">https://github.com/rust-lang/rustup/issues/2692</a></p></blockquote><h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><h2 id="文件标准"><a href="#文件标准" class="headerlink" title="文件标准"></a>文件标准</h2><ul><li>程序文件后缀名：rs</li><li>文件命名规范： hello_world.rs（snake case）</li></ul><h2 id="编译与运行"><a href="#编译与运行" class="headerlink" title="编译与运行"></a>编译与运行</h2><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p><strong>rustc 适合简单的 Rust 程序编译</strong>，即 <code>rustc &lt;file&gt;</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustc main.rs</span></span><br></pre></td></tr></table></figure><p>编译成功后，会生成一个二进制文件，在 Windows 上还会生成一个 .pdb 文件，里面包含调试信息。</p><p>类似于 Golang，当待编译的 Rust 程序文件中没有入口函数时，会编译报错</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustc rust.rs</span></span><br><span class="line">error[E0601]: `main` function not found in crate `rust`</span><br><span class="line"><span class="meta prompt_"> --&gt; </span><span class="language-bash">rust.rs:1:1</span></span><br><span class="line">  |</span><br><span class="line">1 | / fn test() &#123;</span><br><span class="line">2 | |     println!(&quot;test&quot;)</span><br><span class="line">3 | | &#125;</span><br><span class="line">  | |_^ consider adding a `main` function to `rust.rs`</span><br><span class="line"></span><br><span class="line">error: aborting due to previous error</span><br><span class="line"></span><br><span class="line">For more information about this error, try `rustc --explain E0601`.</span><br></pre></td></tr></table></figure><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>类似于 Golang，Rust 是 ahead-of-time 编译的语言，可执行文件的运行不依赖于 Rust 环境。</p><p><strong>Windows</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">.\main.exe</span></span><br></pre></td></tr></table></figure><p><strong>Linux &amp; MacOS</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./main</span></span><br></pre></td></tr></table></figure><h2 id="简单剖析"><a href="#简单剖析" class="headerlink" title="简单剖析"></a>简单剖析</h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Hello World&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>定义函数使用 <code>fn</code> 关键字，<code>main</code> 函数的作用为每个 Rust 可执行程序最先运行的代码</li><li>Rust 的缩进是 4 个空格，而不是 tab</li><li>println! 是一个 Rust macro（宏），如果是函数的话，就没有 <code>!</code></li><li>代码行以 <code>;</code> 结尾，表示表达式结束，关于表达式和语句的后续会提到</li></ul>]]></content>
    
    
    <summary type="html">Rust 简介、安装与 Hello World</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Rust" scheme="http://shenxianghong.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>「 Golang 」Web Server 代码结构</title>
    <link href="http://shenxianghong.github.io/2021/12/01/2021-12-01%20Golang%20Web%20Server%20%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/"/>
    <id>http://shenxianghong.github.io/2021/12/01/2021-12-01%20Golang%20Web%20Server%20%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/</id>
    <published>2021-11-30T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.036Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="100" style="border: 0px" src="/gallery/golang/logo.svg"></div><hr><h1 id="Open-Source"><a href="#Open-Source" class="headerlink" title="Open Source"></a>Open Source</h1><p><a href="https://github.com/slok/kubewebhook%EF%BC%88Go">https://github.com/slok/kubewebhook（Go</a> framework to create Kubernetes mutating and validating webhooks.）。是一个用于创建 Kubernetes mutating 和 validating webhook 的 Golang 框架，其中提供了用于生产环境的<a href="https://github.com/slok/k8s-webhook-example">示例模板</a>。</p><h1 id="Sample"><a href="#Sample" class="headerlink" title="Sample"></a>Sample</h1><p><a href="https://github.com/shenxianghong/shenxianghong.github.io/tree/main/elegant-code/web-structure">https://github.com/shenxianghong/shenxianghong.github.io/tree/main/elegant-code/web-structure</a></p><h1 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h1><h2 id="handlers"><a href="#handlers" class="headerlink" title="handlers"></a>handlers</h2><p>handlers 中聚焦实际的业务处理逻辑</p><h3 id="welcome-go"><a href="#welcome-go" class="headerlink" title="welcome.go"></a>welcome.go</h3><p>请求到来时，组装返回的消息内容</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> handlers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Welcome 抽象了一系列的业务逻辑</span></span><br><span class="line"><span class="comment">// 例如 Hello 用于组装返回的消息内容</span></span><br><span class="line"><span class="keyword">type</span> Welcome <span class="keyword">interface</span> &#123;</span><br><span class="line">Hello() <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口实现</span></span><br><span class="line"><span class="keyword">type</span> WelcomeHandler <span class="keyword">struct</span> &#123;</span><br><span class="line">User <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 业务逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h WelcomeHandler)</span></span> Hello() <span class="type">string</span> &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;hello %s, welcome.&quot;</span>, h.User)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 工厂函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewWelcomeHandler</span><span class="params">()</span></span> Welcome &#123;</span><br><span class="line"><span class="keyword">var</span> handler WelcomeHandler</span><br><span class="line">handler.User = <span class="string">&quot;Arthur&quot;</span></span><br><span class="line"><span class="keyword">return</span> handler</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="goodbye-go"><a href="#goodbye-go" class="headerlink" title="goodbye.go"></a>goodbye.go</h3><p>原理类似 welcome.go</p><h2 id="web"><a href="#web" class="headerlink" title="web"></a>web</h2><p>web 框架的基础结构</p><h3 id="handlers-go"><a href="#handlers-go" class="headerlink" title="handlers.go"></a>handlers.go</h3><p>调用业务逻辑，构建 http.Handler 类型，作为请求的 handler 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> web</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;net/http&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 逻辑路由的工厂函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h handler)</span></span> welcomeHandler() http.Handler &#123;</span><br><span class="line"><span class="keyword">return</span> http.HandlerFunc(<span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">w.Write([]<span class="type">byte</span>(h.welcome.Hello()))</span><br><span class="line">w.WriteHeader(http.StatusOK)</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h handler)</span></span> goodbyeHandler() http.Handler  &#123;</span><br><span class="line"><span class="keyword">return</span> http.HandlerFunc(<span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">w.Write([]<span class="type">byte</span>(h.goodbye.Goodbye()))</span><br><span class="line">w.WriteHeader(http.StatusOK)</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="router-go"><a href="#router-go" class="headerlink" title="router.go"></a>router.go</h3><p>用于注册业务逻辑部分的路由，也就是子路由</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> web</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;net/http&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h handler)</span></span> router(router *http.ServeMux) &#123;</span><br><span class="line">    <span class="comment">// 逻辑路由的工厂函数返回 http.Handler 类型,用于注册子路由</span></span><br><span class="line">router.Handle(<span class="string">&quot;/welcome&quot;</span>, h.welcomeHandler())</span><br><span class="line">router.Handle(<span class="string">&quot;/goodbye&quot;</span>, h.goodbyeHandler())</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="web-go"><a href="#web-go" class="headerlink" title="web.go"></a>web.go</h3><p>web 框架的上层对象，包括配置和根路由 handler 的生成等</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> web</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;elegant-coding/handlers&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;errors&quot;</span></span><br><span class="line"><span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置信息</span></span><br><span class="line"><span class="comment">// 上层会传入业务逻辑的工厂函数来初始化这个结构体，同样的，也可以传入比如全局的 logger 等信息</span></span><br><span class="line"><span class="comment">// 初始化下面的 handler 时会根据这个配置信息</span></span><br><span class="line"><span class="keyword">type</span> Config <span class="keyword">struct</span> &#123;</span><br><span class="line">WelcomeHandler handlers.Welcome</span><br><span class="line">GoodbyeHandler handlers.Goodbye</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于做一些校验设置默认信息等</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Config)</span></span> defaults() <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.WelcomeHandler == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;welcome handler is missing&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> c.GoodbyeHandler == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;goodbye handler is missing&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 封装了 http.Handler，同时也包含了一系列的业务逻辑的接口实现</span></span><br><span class="line"><span class="keyword">type</span> handler <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// 业务逻辑的 interface</span></span><br><span class="line">welcome handlers.Welcome</span><br><span class="line">goodbye handlers.Goodbye</span><br><span class="line"><span class="comment">// 原生 http handler 功能</span></span><br><span class="line">handler http.Handler</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用原生的 http.Handler.ServeHTTP，启动服务</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h handler)</span></span> ServeHTTP(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">h.handler.ServeHTTP(w, r)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化上面的 handler</span></span><br><span class="line"><span class="comment">// 返回的是一个 http.Handler 类型，是为了在主函数的时候作为根路由的 handler</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(config Config)</span></span> http.Handler &#123;</span><br><span class="line"><span class="keyword">if</span> err := config.defaults(); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">&quot;handler configuration is not valid&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mux := http.NewServeMux()</span><br><span class="line">h := handler&#123;</span><br><span class="line">welcome: config.WelcomeHandler,</span><br><span class="line">goodbye: config.GoodbyeHandler,</span><br><span class="line">handler: mux,</span><br><span class="line">&#125;</span><br><span class="line">h.router(mux)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> h</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="main-go"><a href="#main-go" class="headerlink" title="main.go"></a>main.go</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;net/http&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;elegant-coding/handlers&quot;</span></span><br><span class="line"><span class="string">&quot;elegant-coding/web&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// 根路由的 handler 函数</span></span><br><span class="line">handler := web.New(web.Config&#123;</span><br><span class="line">        <span class="comment">// 通过工厂函数生成 handler</span></span><br><span class="line">WelcomeHandler: handlers.NewWelcomeHandler(),</span><br><span class="line">GoodbyeHandler: handlers.NewGoodbyeHandler(),</span><br><span class="line">&#125;)</span><br><span class="line">mux := http.NewServeMux()</span><br><span class="line">mux.Handle(<span class="string">&quot;/&quot;</span>, handler)</span><br><span class="line">server := http.Server&#123;</span><br><span class="line">Addr:    <span class="string">&quot;:8081&quot;</span>,</span><br><span class="line">Handler: mux,</span><br><span class="line">&#125;</span><br><span class="line">err := server.ListenAndServe()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err.Error())</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">记一次在 Kubewebhook 项目中学到的 web 代码结构</summary>
    
    
    
    <category term="Programming" scheme="http://shenxianghong.github.io/categories/Programming/"/>
    
    
    <category term="Golang" scheme="http://shenxianghong.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」操作元数据</title>
    <link href="http://shenxianghong.github.io/2021/06/28/2021-06-28%20Velero%20%E6%93%8D%E4%BD%9C%E5%85%83%E6%95%B0%E6%8D%AE/"/>
    <id>http://shenxianghong.github.io/2021/06/28/2021-06-28%20Velero%20%E6%93%8D%E4%BD%9C%E5%85%83%E6%95%B0%E6%8D%AE/</id>
    <published>2021-06-27T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.036Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="部署-MinIO-服务"><a href="#部署-MinIO-服务" class="headerlink" title="部署 MinIO 服务"></a>部署 MinIO 服务</h1><p><em>以 Velero 提供的 <a href="https://github.com/vmware-tanzu/velero/blob/v1.6.3/examples/minio/00-minio-deployment.yaml">MinIO 服务</a> 进行 DEMO 验证，为了便于操作将 ClusterIP 改为 NodePort</em></p><h2 id="部署结果"><a href="#部署结果" class="headerlink" title="部署结果"></a>部署结果</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get all -n velero -l component=minio</span></span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/minio-54b5867494-28dvt   1/1     Running   0          80s</span><br><span class="line"></span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/minio   NodePort   10.96.107.103   &lt;none&gt;        9000:30188/TCP   80s</span><br><span class="line"></span><br><span class="line">NAME                    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/minio   1/1     1            1           80s</span><br><span class="line"></span><br><span class="line">NAME                               DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/minio-54b5867494   1         1         1       80s</span><br><span class="line"></span><br><span class="line">NAME                    COMPLETIONS   DURATION   AGE</span><br><span class="line">job.batch/minio-setup   1/1           6s         80s</span><br></pre></td></tr></table></figure><p>账号密码通过 MinIO 服务中 MINIO_ACCESS_KEY 和 MINIO_SECRET_KEY 环境变量设置，登陆后效果如下：</p><div align=center><img width="500" style="border: 0px" src="/gallery/velero/minio.png"></div><p><em>其中，minio-setup 的 Job 已经创建出了一个名为 velero 的 Bucket</em></p><h2 id="准备认证文件"><a href="#准备认证文件" class="headerlink" title="准备认证文件"></a>准备认证文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; credentials-velero &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">[default]</span><br><span class="line">aws_access_key_id = minio</span><br><span class="line">aws_secret_access_key = minio123</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h1 id="部署-Velero-服务"><a href="#部署-Velero-服务" class="headerlink" title="部署 Velero 服务"></a>部署 Velero 服务</h1><h2 id="命令行安装"><a href="#命令行安装" class="headerlink" title="命令行安装"></a>命令行安装</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">velero</span> <span class="string">install</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--provider</span> <span class="string">aws</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--plugins</span> <span class="string">velero/velero-plugin-for-aws:v1.0.0</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--bucket</span> <span class="string">velero</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--secret-file</span> <span class="string">./credentials-velero</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--use-volume-snapshots=false</span> <span class="string">\</span></span><br><span class="line">     <span class="string">--backup-location-config</span> <span class="string">region=minio,s3ForcePathStyle=&quot;true&quot;,s3Url=http://minio.velero.svc:9000</span></span><br></pre></td></tr></table></figure><p><strong>参数说明</strong></p><ul><li><code>provider</code> 指定 plugin 的 provider，默认格式为 x&#x2F;y，如果省略 x 部分，则默认为 velero.io，需要与 plugin 注册的保持一致</li><li><code>plugins</code> 指定 plugin 使用的镜像</li><li><code>bucket</code> 为对象存储中的存储桶概念</li><li><code>secret-file</code> 用于与后端存储服务认证的信息，如果存储服务不需要凭证，则将 secret-file 替换成 no-secret</li><li><code>use-volume-snapshots</code> 是否自动创建一个 SnapshotLocation，如果不打算通过创建卷快照，则设置为 false，默认为 true</li><li><code>backup-location-config</code> 为默认的 BackupStorageLocation 信息，可以在部署 Velero 后增量配置</li></ul><h2 id="部署结果-1"><a href="#部署结果-1" class="headerlink" title="部署结果"></a>部署结果</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get all -n velero -l component=velero</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/velero-64b8fddd66-fqdvt   1/1     Running   0          32s</span><br><span class="line"></span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/velero   1/1     1            1           32s</span><br><span class="line"></span><br><span class="line">NAME                                DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/velero-64b8fddd66   1         1         1       32s</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get crd -l component=velero</span></span><br><span class="line">NAME                                CREATED AT</span><br><span class="line">backups.velero.io                   2022-11-07T08:54:56Z</span><br><span class="line">backupstoragelocations.velero.io    2022-11-07T08:54:56Z</span><br><span class="line">deletebackuprequests.velero.io      2022-11-07T08:54:56Z</span><br><span class="line">downloadrequests.velero.io          2022-11-07T08:54:56Z</span><br><span class="line">podvolumebackups.velero.io          2022-11-07T08:54:56Z</span><br><span class="line">podvolumerestores.velero.io         2022-11-07T08:54:56Z</span><br><span class="line">resticrepositories.velero.io        2022-11-07T08:54:56Z</span><br><span class="line">restores.velero.io                  2022-11-07T08:54:56Z</span><br><span class="line">schedules.velero.io                 2022-11-07T08:54:56Z</span><br><span class="line">serverstatusrequests.velero.io      2022-11-07T08:54:56Z</span><br><span class="line">volumesnapshotlocations.velero.io   2022-11-07T08:54:56Z</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup-location get</span></span><br><span class="line">NAME      PROVIDER   BUCKET/PREFIX   PHASE       LAST VALIDATED                  ACCESS MODE   DEFAULT</span><br><span class="line">default   aws        velero          Available   2022-11-07 16:55:06 +0800 CST   ReadWrite     true</span><br></pre></td></tr></table></figure><h1 id="流程验证"><a href="#流程验证" class="headerlink" title="流程验证"></a>流程验证</h1><p><em>以 Velero 提供的基础 <a href="https://github.com/vmware-tanzu/velero/blob/v1.6.3/examples/nginx-app/base.yaml">nginx 服务</a>进行 DEMO 验证</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get all -n nginx-example</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-deployment-5bcc46cc5-fmnf4   1/1     Running   0          106s</span><br><span class="line">pod/nginx-deployment-5bcc46cc5-njlhk   1/1     Running   0          106s</span><br><span class="line"></span><br><span class="line">NAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">service/my-nginx   LoadBalancer   10.96.158.105   &lt;pending&gt;     80:30449/TCP   106s</span><br><span class="line"></span><br><span class="line">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment   2/2     2            2           106s</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginx-deployment-5bcc46cc5   2         2         2       106s</span><br></pre></td></tr></table></figure><p><strong>操作验证</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建备份任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup create default</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup get</span></span><br><span class="line">NAME      STATUS      ERRORS   WARNINGS   CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR</span><br><span class="line">default   Completed   0        0          2022-11-07 17:03:46 +0800 CST   29d       default            &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模拟故障</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete ns nginx-example</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建恢复任务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore create default --from-backup default</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore get</span></span><br><span class="line">NAME                     BACKUP    STATUS      STARTED                         COMPLETED                       ERRORS   WARNINGS   CREATED                         SELECTOR</span><br><span class="line">default-20221107170719   default   Completed   2022-11-07 17:07:19 +0800 CST   2022-11-07 17:08:19 +0800 CST   0        119        2022-11-07 17:07:19 +0800 CST   &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复结果查看</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get all -n nginx-example</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-deployment-5bcc46cc5-fmnf4   1/1     Running   0          90s</span><br><span class="line">pod/nginx-deployment-5bcc46cc5-njlhk   1/1     Running   0          90s</span><br><span class="line"></span><br><span class="line">NAME               TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">service/my-nginx   LoadBalancer   10.96.27.235   &lt;pending&gt;     80:31162/TCP   59s</span><br><span class="line"></span><br><span class="line">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment   2/2     2            2           73s</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginx-deployment-5bcc46cc5   2         2         2       89s</span><br></pre></td></tr></table></figure><p>可以初步看到以下几个特点：</p><ul><li>Deployment 和 Pod 在恢复之后，UUID 并未变化</li><li>Service 和 Pod 的 IP 与端口在恢复之后，被重新分配</li></ul><p><strong>MinIO 中相关的数据</strong></p><div align=center><img width="500" style="border: 0px" src="/gallery/velero/minio-data.png"></div><h1 id="备份与恢复数据结构"><a href="#备份与恢复数据结构" class="headerlink" title="备份与恢复数据结构"></a>备份与恢复数据结构</h1><h2 id="Backup-数据结构"><a href="#Backup-数据结构" class="headerlink" title="Backup 数据结构"></a>Backup 数据结构</h2><div align=center><img width="400" style="border: 0px" src="/gallery/velero/backup.png"></div><table><thead><tr><th>name</th><th>content</th></tr></thead><tbody><tr><td>velero-backup.json</td><td>Backup 对象的 Json 格式</td></tr><tr><td>default-volumesnapshots.json.gz</td><td>Velero 中 VolumeSnapshots 对象的 Json 格式</td></tr><tr><td>default-podvolumebackups.json.gz</td><td>PodvolumeBackups 对象的 Json 格式</td></tr><tr><td>default-csi-volumesnapshots.json.gz</td><td>CSI 中 VolumeSnapshots 对象的 Json 格式</td></tr><tr><td>default-csi-volumesnapshotcontents.json.gz</td><td>CSI 中 VolumeSnapshotsContent 对象的 Json 格式</td></tr><tr><td>default-logs.gz</td><td>备份任务日志</td></tr><tr><td>default.tar.gz</td><td>备份的全部数据，包括两子内容：metadata 和 resources，metadata 文件夹中包含一个 verison 文件，内容为 1.1.0；resources 文件夹中包含各类资源全名的子文件夹，例如 alertmanagers.monitoring.coreos.com，里面包含以 namespaces 或 cluster 区分的资源对象的 Json 格式</td></tr><tr><td>default-resource-list.json.gz</td><td>备份的资源清单，格式为 {“资源全名”: [各资源信息，格式为 ns&#x2F;name]}</td></tr></tbody></table><h2 id="Restore-数据结构"><a href="#Restore-数据结构" class="headerlink" title="Restore 数据结构"></a>Restore 数据结构</h2><div align=center><img width="400" style="border: 0px" src="/gallery/velero/restore.png"></div><table><thead><tr><th>name</th><th>content</th></tr></thead><tbody><tr><td>restore-default-20221107170719-results.gz</td><td>恢复的详情信息，格式为 {“errors”:{},”warnings”:{“cluster”: [“各资源恢复异常原因”], “各 namespace”: [“各资源恢复异常原因”]}}</td></tr><tr><td>restore-default-20221107170719-logs.gz</td><td>恢复任务日志</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">通过 Velero 实现对 Kubernetes 集群元数据的备份与恢复</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Velero 」快速开始</title>
    <link href="http://shenxianghong.github.io/2021/06/07/2021-06-07%20Velero%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2021/06/07/2021-06-07%20Velero%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2021-06-06T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.024Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="170" style="border: 0px" src="/gallery/velero/logo.svg"></div><hr><blockquote><p>based on <strong>v1.6.3</strong></p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Velero 可以提供备份和还原 Kubernetes 集群资源和持久卷的能力，可以在公有云或本地搭建的私有云环境安装 Velero，可以提供以下能力：</p><ul><li>备份集群数据，并在集群故障的情况下进行还原</li><li>将集群资源迁移到其他集群</li><li>将生产集群复制到开发和测试集群</li></ul><p>Velero 包含一个在集群上运行的服务器端和在本地运行的命令行客户端。</p><p><a href="https://velero.io/">Velero 官方文档</a></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero install</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–backup-location-config</td><td>描述 BackupStorageLocation 的配置信息</td></tr><tr><td>–bucket</td><td>BackupStorageLocation 中 bucket 信息，参考对象存储中的概念<br><em>和 no-default-backup-location 必须存在其一</em></td></tr><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–crds-only</td><td>仅生成 CRD 资源类别，默认为 false<br><em>主要用于已经安装 Velero 的集群升级 CRD</em></td></tr><tr><td>–crds-version</td><td>默认为 v1，指定 CRD 的 resource version</td></tr><tr><td>–default-restic-prune-frequency</td><td>对 Restic repo 执行 restic prune 的默认周期，默认为 1 周</td></tr><tr><td>–default-volumes-to-restic</td><td>全局参数，表示是否由 Restic 备份所有的 Pod 卷，默认为 false</td></tr><tr><td>–dry-run</td><td>生成资源，但是不会实际创建<br><em>通常会和 -o 参数一起使用，指定默认输出格式</em></td></tr><tr><td>–image</td><td>Velero 和 Restic Pod 的镜像，默认和 Velero binary 版本一致</td></tr><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–no-default-backup-location</td><td>表示是否创建默认的 BackupStorageLocation，默认为 false<br><em>和 provider &amp; bucket 必须存在其一</em></td></tr><tr><td>–no-secret</td><td>不为 BackupStorageLocation 生成认证 Secret<br><em>和 –secret-file 必须存在其一</em></td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–plugins</td><td>Velero plugin 的镜像</td></tr><tr><td>–pod-annotations</td><td>Velero 和 Restic Pod 中追加的注释信息</td></tr><tr><td>–prefix</td><td>BackupStorageLocation 中 prefix 信息，参考对象存储中的概念</td></tr><tr><td>–provider</td><td>指定 StorageProvider，例如 aws, gcp 等<br /><em>和 no-default-backup-location 必须存在其一</em></td></tr><tr><td>–restic-pod-cpu-limit&#x2F;–restic-pod-cpu-request&#x2F;<br />–restic-pod-mem-limit&#x2F;–restic-pod-mem-request</td><td>Restic Pod 的资源限制信息</td></tr><tr><td>–restore-only</td><td>是否以 Restore-Only 形式运行服务，即 Backup、Schedule 和 GC controller 都会被禁用，仅启动 Restore Controller<br><em>参数已经废弃，取而代之的是将 BackupStorageLocation 设为 ReadOnly</em></td></tr><tr><td>–sa-annotations</td><td>Velero 的 ServiceAccount 中追加的注释信息</td></tr><tr><td>–secret-file</td><td>BackupStorageLocation 所需要的认证文件<br><em>Velero 会将该文件以 Secret 形式创建，并挂载在 Velero 的 &#x2F;cloud&#x2F;credentials；和 –no-secret 必须存在其一</em></td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr><tr><td>–snapshot-location-config</td><td>描述 VolumeSnapshotLocation 的配置信息</td></tr><tr><td>–use-restic</td><td>是否同时创建 Restic 服务</td></tr><tr><td>–use-volume-snapshots</td><td>是否自动创建一个 SnapshotLocation，默认为 true</td></tr><tr><td>–velero-pod-cpu-limit&#x2F;–velero-pod-cpu-request&#x2F;<br />–velero-pod-mem-limit&#x2F;–velero-pod-mem-request</td><td>Velero Pod 的资源限制信息</td></tr><tr><td>–wait</td><td>阻塞直至 Velero deployment 是 Ready<br><em>手动退出等待可以 ctrl-c，并不会影响到安装流程</em></td></tr></tbody></table><h2 id="uninstall"><a href="#uninstall" class="headerlink" title="uninstall"></a>uninstall</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero uninstall</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–force</td><td>是否强制卸载，忽略确认信息，默认为 false</td></tr><tr><td>–wait</td><td>阻塞直至 Velero 被完全卸载<br/><em>手动退出等待可以 ctrl-c，并不会影响到卸载流程</em></td></tr></tbody></table><h2 id="Customize"><a href="#Customize" class="headerlink" title="Customize"></a>Customize</h2><h3 id="Velero-Server"><a href="#Velero-Server" class="headerlink" title="Velero Server"></a>Velero Server</h3><p>以下参数均为 Velero 服务启动时的额外参数</p><p><em>部分参数可以通过 install 指定，而其余参数只能通过定制化 Velero Deployment 的启动参数</em></p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–log-level</td><td>日志级别，可选的有 debug、info、warn、error、fatal、panic 和 trace，默认为 Info<br><em>在安装 velero 服务时的全局参数 -v 代表时 velero 调用其他第三方库时透传下去的日志级别，而非 velero 本身的日志级别，第三方库采用的日志库通常为 klog 或者 glog 等，通过 -v 指定日志级别，高于该级别的日志不会输出，如 -v &#x3D; 5。 Velero 采用的日志库为 logrus，有 debug 、 info 、 warn 、 error 、 fatal 、 panic 和 trace，通过该参数指定，低于该级别的日志不会输出。</em></td></tr><tr><td>–log-format</td><td>日志格式，可选的有 text 和 json，默认为 text</td></tr><tr><td>–plugin-dir</td><td>Velero Plugins 的存放位置，默认为 &#x2F;plugins</td></tr><tr><td>–metrics-address</td><td>暴露至 Prometheus 的端口，默认为 8085</td></tr><tr><td>–backup-sync-period</td><td>备份同步的时间间隔，默认为 1 分钟，设置为 0 时表示禁用同步</td></tr><tr><td>–restic-timeout</td><td>Pod 卷备份与恢复的执行超时时间，默认为 240 分钟</td></tr><tr><td>–restore-only</td><td>是否以 Restore-Only 形式运行服务，即 Backup、Schedule 和 GC controller 都会被禁用，仅启动 Restore Controller <br/><em>参数已经废弃，取而代之的是将 BackupStorageLocation 设为 ReadOnly</em></td></tr><tr><td>–disable-controllers</td><td>禁止启动的 Controller，可选的有 Backup、BackupDeletion、BackupSync、DownloadRequest、GarbageCollection、ResticRepo、Restore、Schedule 和 ServerStatusRequest，默认不禁止</td></tr><tr><td>–restore-resource-priorities</td><td>期望的资源恢复顺序，任何不在列表中的资源都将在优先资源之后按字母顺序恢复，默认恢复顺序为<br />1. customresourcedefinitions<br />2. namespaces<br />3. storageclasses<br />4. volumesnapshotclass.snapshot.storage.k8s.io<br />5. volumesnapshotcontents.snapshot.storage.k8s.io<br />6. volumesnapshots.snapshot.storage.k8s.io<br />7. persistentvolumes<br />8. persistentvolumeclaims<br />9. secrets<br />10. configmaps<br />11. serviceaccounts<br />12. limitranges<br />13. pods<br />14. replicasets.apps<br />15. clusters.cluster.x-k8s.io<br />16. clusterresourcesets.addons.cluster.x-k8s.io</td></tr><tr><td>–default-backup-storage-location</td><td>默认的 BackupStorageLocation 名称，默认为 default<br /><em>参数已经废弃，取而代之的是将 BackupStorageLocation 的 –default 设置为 true</em></td></tr><tr><td>–store-validation-frequency</td><td>BackupStorageLocation 的检验时间间隔，默认为 1 分钟，设置为 0 时表示禁用校验</td></tr><tr><td>–default-volume-snapshot-locations</td><td>SnapshotProvider 的信息，例如 provider1:location-01,provider2:location-02</td></tr><tr><td>–client-qps</td><td>访问 Kubernetes API 的最大 QPS，默认为 20，如果为 0，则置为 5<br /><em>详情查看 client-go</em></td></tr><tr><td>–client-burst</td><td>访问 Kubernetes API 的最大突发请求量，默认为 30，如果为 0，则置为 10<br /><em>详情查看 client-go</em></td></tr><tr><td>–profiler-address</td><td>pprof 信息的地址，默认为 localhost:6060</td></tr><tr><td>–terminating-resource-timeout</td><td>恢复期间等待 PV 和 namespace 创建完成的超时时间，默认为 10 分钟</td></tr><tr><td>–default-backup-ttl</td><td>backup 的过期时间，默认为 30 天</td></tr><tr><td>–default-restic-prune-frequency</td><td>对 Restic repo 执行 restic prune 的周期，默认为 1 周</td></tr><tr><td>–default-volumes-to-restic</td><td>是否由 Restic 备份所有的 Pod 卷，默认为 false</td></tr></tbody></table><h3 id="Restic-Server"><a href="#Restic-Server" class="headerlink" title="Restic Server"></a>Restic Server</h3><p>以下参数均为 Restic 服务启动时的额外参数</p><p><em>由于 Restic 不存在安装命令，因此只能通过定制化 Restic DaemonSet 的启动参数</em></p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–log-level</td><td>日志级别，可选的有 debug、info、warn、error、fatal、panic 和 trace，默认为 Info<br><em>在安装 velero 服务时的全局参数 -v 代表时 velero 调用其他第三方库时透传下去的日志级别，而非 velero 本身的日志级别，第三方库采用的日志库通常为 klog 或者 glog 等，通过 -v 指定日志级别，高于该级别的日志不会输出，如 -v &#x3D; 5。 Velero 采用的日志库为 logrus，有 debug 、 info 、 warn 、 error 、 fatal 、 panic 和 trace，通过该参数指定，低于该级别的日志不会输出。</em></td></tr><tr><td>–log-format</td><td>日志格式，可选的有 text 和 json，默认为 text</td></tr></tbody></table><h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><h2 id="StorageProvider"><a href="#StorageProvider" class="headerlink" title="StorageProvider"></a>StorageProvider</h2><p>StorageProvider 用于存放备份过程中产生的元数据信息、由 Restic 备份的卷数据信息、备份和恢复的任务日志等，对应的资源对象为 BackupStorageLocation。</p><h3 id="create"><a href="#create" class="headerlink" title="create"></a>create</h3><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/main/pkg/apis/velero/v1/backupstoragelocation_types.go">BackupStorageLocation API</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup-location create</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–access-mode</td><td>访问权限，默认为 ReadWrite，可选值有 ReadWrite 和 ReadOnly</td></tr><tr><td>–backup-sync-period</td><td>备份同步的时间间隔，默认为 1 分钟，设置为 0 时表示禁用同步</td></tr><tr><td>–bucket</td><td>BackupStorageLocation 中 bucket 信息，参考对象存储中的概念</td></tr><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–config</td><td>描述 BackupStorageLocation 配置信息</td></tr><tr><td>–credential</td><td>连接 BackupStorageLocation 所需要的认证信息<br><em>格式为 key-value，key 为 K8s secret 的名称，value 为 secret 中的 key，仅支持一对</em></td></tr><tr><td>–default</td><td>是否为默认的 BackupStorageLocation</td></tr><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–labels</td><td>设置创建出来的 BackupStorageLocation 对象的标签信息</td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–prefix</td><td>BackupStorageLocation 中 prefix 信息，参考对象存储中的概念</td></tr><tr><td>–provider</td><td>指定 StorageProvider，例如 aws, gcp 等</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr><tr><td>–validation-frequency</td><td>BackupStorageLocation 的检验时间间隔，默认为 1 分钟，设置为 0 时表示禁用校验</td></tr></tbody></table><h3 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup-location delete</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–all</td><td>删除所有 BackupStorageLocation 对象</td></tr><tr><td>–confirm</td><td>确认删除交互</td></tr><tr><td>–selector</td><td>删除满足标签选择的所有 BackupStorageLocation 对象</td></tr></tbody></table><p><em>name，–all 和 –selector 仅能指定一个</em></p><h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup-location get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–default</td><td>仅展示默认的 BackupStorageLocation</td></tr><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–selector</td><td>可以通过标签选择器展示符合要求的 BackupStorageLocation 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup-location <span class="built_in">set</span></span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–credential</td><td>连接 BackupStorageLocation 所需要的认证信息<br><em>格式为 key-value，key 为 K8s secret 的名称，value 为 secret 中的 key，仅支持一对</em></td></tr><tr><td>–default</td><td>设置为默认的 BackupStorageLocation<br><em>默认的仅能有一个，其余的会被设置为 false</em></td></tr></tbody></table><h2 id="SnapshotProvider"><a href="#SnapshotProvider" class="headerlink" title="SnapshotProvider"></a>SnapshotProvider</h2><p>SnapshotProvider 用于存放备份过程中的卷快照数据，数据源自于 SnapshotProvider Plugin。</p><h3 id="create-1"><a href="#create-1" class="headerlink" title="create"></a>create</h3><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/main/pkg/apis/velero/v1/volume_snapshot_location.go">VolumeSnapshotLocation API</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero snapshot-location create</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–config</td><td>描述 VolumeSnapshotLocation 的配置信息</td></tr><tr><td>–label-columns</td><td>在 table 样式下，用于自定义表格栏信息</td></tr><tr><td>–labels</td><td>设置创建出来的 VolumeSnapshotLocation 对象的标签信息</td></tr><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–provider</td><td>指定 SnapshotProvider，例如 aws, gcp 等</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h3 id="get-1"><a href="#get-1" class="headerlink" title="get"></a>get</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero snapshot-location get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏信息展示</td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–selector</td><td>可以通过标签选择器获取符合要求的 VolumeSnapshotLocation 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h2 id="ResticRepository"><a href="#ResticRepository" class="headerlink" title="ResticRepository"></a>ResticRepository</h2><p>目前 Velero 仅支持 Restic AWS、AZURE 和 GCP 作为卷数据存储，数据的采集和传输均由 Velero Restic 操作，目标会上传至卷数据存储，对应的资源对象为 ResticRepository。</p><h3 id="repo"><a href="#repo" class="headerlink" title="repo"></a>repo</h3><h4 id="get-2"><a href="#get-2" class="headerlink" title="get"></a>get</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restic repo get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏信息展示</td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–selector</td><td>可以通过标签选择器获取符合要求的 ResticRepository 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero plugin add</span></span><br></pre></td></tr></table></figure><p><em>name 就是镜像地址</em></p><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–image-pull-policy</td><td>plugin 镜像的拉取策略，可选的有 Always，IfNotPresent 和 Never，默认为 IfNotPresent</td></tr></tbody></table><h2 id="get-3"><a href="#get-3" class="headerlink" title="get"></a>get</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero plugin get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–timeout</td><td>命令输出的超时时间，默认为 5 秒钟</td></tr></tbody></table><h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero plugin remove</span></span><br></pre></td></tr></table></figure><h1 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h1><h2 id="即时备份"><a href="#即时备份" class="headerlink" title="即时备份"></a>即时备份</h2><p>即时备份（on-demand）也就是单次的备份任务，对应的资源对象为 Backup。</p><h3 id="create-2"><a href="#create-2" class="headerlink" title="create"></a>create</h3><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/backup.go">Backup API</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;name&gt;</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–default-volumes-to-restic</td><td>默认为 true，即由 restic 备份所有的 Pod 卷<br /><em>如果不指定，则以全局的为主</em></td></tr><tr><td>–include-namespaces &#x2F; –exclude-namespaces</td><td>显式包含&#x2F;排除的命名空间，支持逗号分割</td></tr><tr><td>–include-resources &#x2F; –exclude-resources</td><td>显式包含&#x2F;排除的资源，支持逗号分割</td></tr><tr><td>–from-schedule</td><td>基于某一个定时备份创建一次即时备份<br /><em>指定此参数时，其他的 filter flag 均会失效，并以 Schedule 的模板为准；不指定备份名称时会以 schedule-timestamp 作为备份任务名称</em></td></tr><tr><td>–include-cluster-resources</td><td>是否备份集群级别的资源，默认为 true<br /><em>即使开启了此特性，如果并未备份全量 namespaces 的资源，仍然不会备份集群级别资源</em></td></tr><tr><td>–label-columns</td><td>在 table 样式下，用于自定义表格栏信息</td></tr><tr><td>–labels</td><td>设置创建出来的 Backup 对象的标签信息</td></tr><tr><td>–ordered-resources</td><td>指定备份的顺序<br /><em>集群级别的资源格式为 <code>resource name</code>，非集群级别的资源格式为 <code>namespace/resource name</code>，例如 pods&#x3D;ns1&#x2F;pod1,ns1&#x2F;pod2;persistentvolumeclaims&#x3D;ns1&#x2F;pvc4,ns1&#x2F;pvc8</em></td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–selector</td><td>可以通过标签选择器备份符合要求的资源</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr><tr><td>–snapshot-volumes</td><td>默认为 true，即备份时，默认会对 PV 资源调用 SnapshotProvider 打快照</td></tr><tr><td>–storage-location</td><td>指定 BackupStorageLocation，仅支持单个</td></tr><tr><td>–ttl</td><td>过期时间，默认 720 小时</td></tr><tr><td>–volume-snapshot-locations</td><td>指定 VolumeSnapshotLocation，支持多个</td></tr><tr><td>–wait</td><td>阻塞直至备份状态不再是 New 或者 InProgress<br /><em>手动退出等待可以 ctrl-c，并不会影响到备份任务</em></td></tr></tbody></table><h3 id="delete-1"><a href="#delete-1" class="headerlink" title="delete"></a>delete</h3><p>velero backup 的删除涉及到存储在远端数据的同步删除，因此并非单纯删除 Backup 对象，而是借助于 DeleteBackupRequest 对象。</p><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/delete_backup_request.go">DeleteBackupRequest API</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup delete</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–all</td><td>删除所有资源</td></tr><tr><td>–confirm</td><td>确认删除交互</td></tr><tr><td>–selector</td><td>删除满足标签选择的所有资源</td></tr></tbody></table><p><em>name，–all 和 –selector 仅能指定一个</em></p><h3 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup describe</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–details</td><td>更详细的信息输出</td></tr><tr><td>–insecure-skip-tls-verify</td><td>是否跳过 TLS 验证，默认为 false</td></tr><tr><td>–selector</td><td>可以通过标签选择器获取符合要求的 Backup 对象</td></tr></tbody></table><h3 id="download"><a href="#download" class="headerlink" title="download"></a>download</h3><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/download_request_types.go">DownloadRequest CR</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup download</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–force</td><td>下载文件存在则覆盖</td></tr><tr><td>–insecure-skip-tls-verify</td><td>是否跳过 TLS 验证，默认为 false</td></tr><tr><td>–output</td><td>文件保存的路径，默认为当前目录，名称为 &lt;backup&gt;-data.tar.gz</td></tr><tr><td>–timeout</td><td>等待下载的超时时间，默认为 1m</td></tr></tbody></table><h3 id="get-4"><a href="#get-4" class="headerlink" title="get"></a>get</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–selector</td><td>可以通过标签选择器展示符合要求的 Backup 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h3 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero backup logs</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–insecure-skip-tls-verify</td><td>是否跳过 TLS 验证，默认为 false</td></tr><tr><td>–timeout</td><td>等待获取日志的超时时间，默认为 1 分钟</td></tr></tbody></table><h2 id="定时备份"><a href="#定时备份" class="headerlink" title="定时备份"></a>定时备份</h2><p>定时备份（schedule）是符合特定时间规律，由 Velero 控制面负责触发的备份任务，对应的资源对象为 Schedule。</p><h3 id="create-3"><a href="#create-3" class="headerlink" title="create"></a>create</h3><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/schedule.go">Schedule CR</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero schedule create</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–default-volumes-to-restic</td><td>是否由 Restic 备份所有的 Pod 卷，默认为 true<br /><em>优先级小于 velero install 中的对应参数</em></td></tr><tr><td>–include-cluster-resources</td><td>是否备份集群级别的资源，默认为 true<br /><em>即使开启了此特性，如果并未备份全量 namespaces 的资源，仍然不会备份集群级别资源</em></td></tr><tr><td>–include-namespaces &#x2F; –exclude-namespaces</td><td>显式包含&#x2F;排除的命名空间，支持逗号分割</td></tr><tr><td>–include-resources &#x2F; –exclude-resources</td><td>显式包含&#x2F;排除的资源，支持逗号分割</td></tr><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–labels</td><td>设置创建出来的 Backup 对象的标签信息</td></tr><tr><td>–ordered-resources</td><td>指定备份的顺序<br /><em>集群级别的资源格式为 resource name，非集群级别的资源格式为 namespace&#x2F;resource name，例如 pods&#x3D;ns1&#x2F;pod1,ns1&#x2F;pod2;persistentvolumeclaims&#x3D;ns1&#x2F;pvc4,ns1&#x2F;pvc8</em></td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–schedule</td><td>定时规则的表达式<br/>不仅支持 cron 表达式，还支持易读的形式，例如 “0 *&#x2F;6 * * *” 和 @every 6h</td></tr><tr><td>–selector</td><td>可以通过标签选择器备份符合要求的资源</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr><tr><td>–snapshot-volumes</td><td>备份时，是否会对 PV 资源调用 SnapshotProvider 打快照，默认为 true，</td></tr><tr><td>–storage-location</td><td>指定 BackupStorageLocation，仅支持单个</td></tr><tr><td>–ttl</td><td>过期时间，默认 720 小时</td></tr><tr><td>–use-owner-references-in-backup</td><td>由 Schedule 创建出来的 Backup 是否带有 OwnerReferences 信息，默认为 false，</td></tr><tr><td>–volume-snapshot-locations</td><td>卷快照的存储后端，支持多个</td></tr></tbody></table><h3 id="delete-2"><a href="#delete-2" class="headerlink" title="delete"></a>delete</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero schedule delete</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–all</td><td>删除所有 Schedule 对象</td></tr><tr><td>–confirm</td><td>确认删除交互</td></tr><tr><td>–selector</td><td>删除满足标签选择器的所有 Schedule 对象</td></tr></tbody></table><h3 id="describe-1"><a href="#describe-1" class="headerlink" title="describe"></a>describe</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero schedule describe</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–selector</td><td>可以通过标签选择器获取符合要求的 Schedule 对象</td></tr></tbody></table><h3 id="get-5"><a href="#get-5" class="headerlink" title="get"></a>get</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero schedule get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–selector</td><td>可以通过标签选择器展示符合要求的 Schedule 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h1 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h1><h2 id="create-4"><a href="#create-4" class="headerlink" title="create"></a>create</h2><p><a href="https://raw.githubusercontent.com/vmware-tanzu/velero/release-1.6/pkg/apis/velero/v1/restore.go">Restore API</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore create</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–allow-partially-failed</td><td>在开启 –from-schedule 时，是否允许从部分失败的 Backup 中恢复</td></tr><tr><td>–include-namespaces &#x2F; –exclude-namespaces</td><td>显式包含&#x2F;排除的命名空间，支持逗号分割</td></tr><tr><td>–include-resources &#x2F; –exclude-resources</td><td>显式包含&#x2F;排除的资源，支持逗号分割</td></tr><tr><td>–from-backup</td><td>指定从哪一个 Backup 中恢复</td></tr><tr><td>–from-schedule</td><td>指定从哪一个 Schedule 中恢复<br><em>从 Schedule 最新创建的 Backup 恢复</em></td></tr><tr><td>–include-cluster-resources</td><td>默认为 true，即恢复集群级别的资源<br><em>即使开启了此特性，如果并未恢复全量 namespaces 的资源，仍然不会恢复集群级别资源</em></td></tr><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–labels</td><td>设置创建出来的 Restore 对象的标签信息</td></tr><tr><td>–namespace-mappings</td><td>恢复时，命名空间的映射关系<br><em>例如，src1:dst1,src2:dst2</em></td></tr><tr><td>–output</td><td>dry run，指定生成配置文件的格式，可选的有 table，json 和 yaml</td></tr><tr><td>–preserve-nodeports</td><td>恢复时，是否保留 Service 资源的 NodePort 信息，默认为 true，</td></tr><tr><td>–restore-volumes</td><td>恢复时，是否从快照中恢复卷数据，默认为 true</td></tr><tr><td>–selector</td><td>可以通过标签选择器恢复符合要求的资源</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr><tr><td>–wait</td><td>阻塞直至恢复状态不再是 New 或者 InProgress<br><em>手动退出等待可以 ctrl-c，并不会影响到恢复任务</em></td></tr></tbody></table><h2 id="delete-3"><a href="#delete-3" class="headerlink" title="delete"></a>delete</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore delete</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–all</td><td>删除所有 Restore 对象</td></tr><tr><td>–confirm</td><td>确认删除交互</td></tr><tr><td>–selector</td><td>删除满足标签选择器的所有 Restore 对象</td></tr></tbody></table><h2 id="describe-2"><a href="#describe-2" class="headerlink" title="describe"></a>describe</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore describe</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–details</td><td>更详细的信息输出</td></tr><tr><td>–insecure-skip-tls-verify</td><td>是否跳过 TLS 验证，默认为 false</td></tr><tr><td>–selector</td><td>可以通过标签选择器获取符合要求的 Restore 对象</td></tr></tbody></table><h2 id="get-6"><a href="#get-6" class="headerlink" title="get"></a>get</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore get</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–label-columns</td><td>在 table 样式下，自定义表格栏展示</td></tr><tr><td>–output</td><td>格式化输出的样式，可选的有 table，json 和 yaml，默认为 table</td></tr><tr><td>–selector</td><td>可以通过标签选择器展示符合要求的 Restore 对象</td></tr><tr><td>–show-labels</td><td>在 table 样式下，最后一栏展示标签信息</td></tr></tbody></table><h2 id="logs-1"><a href="#logs-1" class="headerlink" title="logs"></a>logs</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">velero restore logs</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–cacert</td><td>连接 BackupStorageLocation 时所需要的 TLS 证书</td></tr><tr><td>–insecure-skip-tls-verify</td><td>是否跳过 TLS 验证，默认为 false</td></tr><tr><td>–timeout</td><td>等待获取日志的超时时间，默认为 1 分钟</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">通过 Velero 命令行工具快速上手使用</summary>
    
    
    
    <category term="Disaster Recovery" scheme="http://shenxianghong.github.io/categories/Disaster-Recovery/"/>
    
    
    <category term="Velero" scheme="http://shenxianghong.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」源码编译</title>
    <link href="http://shenxianghong.github.io/2021/04/22/2021-04-22%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    <id>http://shenxianghong.github.io/2021/04/22/2021-04-22%20Kata%20Containers%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/</id>
    <published>2021-04-21T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.017Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>2.4.3</strong></p></blockquote><h1 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h1><p>这里采用 ubuntu:18.04 容器化编译，各依赖版本参考<a href="https://github.com/kata-containers/kata-containers/blob/2.4.3/versions.yaml">版本说明</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --privileged -dit -v /sys/fs/cgroup:/sys/fs/cgroup:ro -v /dev:/dev --name kata-build ubuntu:18.04</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">exec</span> -it kata-build bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可选的 TARGET_ARCH 有 amd64 和 arm64</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> TARGET_ARCH=amd64</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> GOPATH=/root/go</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> GOPROXY=https://proxy.golang.com.cn,direct</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> https_proxy=http://10.52.17.42:7890</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p <span class="variable">$GOPATH</span>/bin</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/docker</span></span><br></pre></td></tr></table></figure><h2 id="Dependence"><a href="#Dependence" class="headerlink" title="Dependence"></a>Dependence</h2><ul><li><p>软件包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get update &amp;&amp; apt-get -y install git wget make curl gcc xz-utils sudo flex bison bc python3 ninja-build pkg-config libglib2.0-dev librbd-dev libseccomp-dev libpixman-1-dev apt-utils libcap-ng-dev cpio libpmem-dev libelf-dev</span></span><br></pre></td></tr></table></figure></li><li><p>Golang 1.16.10 - 1.17.3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://go.dev/dl/go1.16.10.linux-<span class="variable">$TARGET_ARCH</span>.tar.gz &amp;&amp; tar -C /usr/local -zxvf go1.16.10.linux-<span class="variable">$TARGET_ARCH</span>.tar.gz &amp;&amp; <span class="built_in">cp</span> /usr/local/go/bin/go /usr/bin/go</span></span><br></pre></td></tr></table></figure></li><li><p>Rust （1.58.1，仅在手动编译 kata-agent 组件时需要）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl https://sh.rustup.rs -sSf | sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> <span class="variable">$HOME</span>/.cargo/env</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup override <span class="built_in">set</span> 1.58.1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ARCH=$(<span class="built_in">uname</span> -m)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ARCH</span>&quot;</span> = <span class="string">&quot;ppc64le&quot;</span> -o <span class="string">&quot;<span class="variable">$ARCH</span>&quot;</span> = <span class="string">&quot;s390x&quot;</span> ]; <span class="keyword">then</span> <span class="built_in">export</span> LIBC=gnu; <span class="keyword">else</span> <span class="built_in">export</span> LIBC=musl; <span class="keyword">fi</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">[ <span class="variable">$&#123;ARCH&#125;</span> == <span class="string">&quot;ppc64le&quot;</span> ] &amp;&amp; <span class="built_in">export</span> ARCH=powerpc64le</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rustup target add <span class="variable">$&#123;ARCH&#125;</span>-unknown-linux-<span class="variable">$&#123;LIBC&#125;</span></span></span><br></pre></td></tr></table></figure></li><li><p>yq 3.4.1</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_<span class="variable">$TARGET_ARCH</span> &amp;&amp; <span class="built_in">chmod</span> +x yq_linux_<span class="variable">$TARGET_ARCH</span> &amp;&amp; <span class="built_in">mv</span> yq_linux_<span class="variable">$TARGET_ARCH</span> <span class="variable">$GOPATH</span>/bin/yq &amp;&amp; <span class="built_in">cp</span> <span class="variable">$GOPATH</span>/bin/yq /usr/bin/</span></span><br></pre></td></tr></table></figure></li><li><p>docker</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -sSL https://get.docker.com/ | sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;storage-driver&quot;: &quot;vfs&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">service docker start</span></span></span><br></pre></td></tr></table></figure></li></ul><h2 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h2><ul><li><p>kata-containers 2.4.3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">GO111MODULE=off go get -d -u github.com/kata-containers/kata-containers</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout 2.4.3</span></span><br></pre></td></tr></table></figure></li><li><p>tests 2.4.3（仅在编译 UEFI ROM 时需要）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">GO111MODULE=off go get -d github.com/kata-containers/tests</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/tests</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout 2.4.3</span></span><br></pre></td></tr></table></figure></li><li><p>qemu（x86 下为 v6.2.0，arm64 下为 v6.1.0，仅在编译 QEMU 时需要）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">GO111MODULE=off go get -d github.com/qemu/qemu</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$&#123;GOPATH&#125;</span>/src/github.com/qemu/qemu</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout v6.2.0</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="Kata-Containers"><a href="#Kata-Containers" class="headerlink" title="Kata Containers"></a>Kata Containers</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/src/runtime</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make &amp;&amp; sudo -E PATH=<span class="variable">$PATH</span> make install</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;local&#x2F;bin&#x2F;containerd-shim-kata-v2</li><li>&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kata-collect-data.sh</li><li>&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kata-monitor</li><li>&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kata-runtime</li><li>&#x2F;usr&#x2F;share&#x2F;defaults&#x2F;kata-containers&#x2F;configuration.toml</li></ul><h1 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据社区 release 中所推荐对应架构所使用的 image 发行版，分别设置 rootfs 和 initrd 镜像，这里以 x86 架构为例</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./rootfs-builder/rootfs.sh -l</span></span><br><span class="line">alpine</span><br><span class="line">centos</span><br><span class="line">clearlinux</span><br><span class="line">debian</span><br><span class="line">ubuntu</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x86 下推荐 clearlinux，arm64 下推荐 ubuntu</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> rootfsdistro=clearlinux</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x86 和 arm64 下均推荐 alpine</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> initrddistro=alpine</span></span><br></pre></td></tr></table></figure><p><strong>编译 Kata agent（可选）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/src/agent &amp;&amp; make</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认情况下，Kata agent 是使用 seccomp 功能构建的。如果要构建没有 seccomp 功能的 Kata agent，则需要使用 SECCOMP=no 运行 make</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make -C <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/src/agent SECCOMP=no</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果在配置文件中启用了 seccomp 但构建了没有 seccomp 功能的 Kata Agent，则 runtime 会保守地退出并显示一条错误消息</span></span><br></pre></td></tr></table></figure><h2 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h2><p><strong>创建镜像文件系统</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ROOTFS_DIR=<span class="variable">$&#123;GOPATH&#125;</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/rootfs-builder/rootfs</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">rm</span> -rf <span class="variable">$&#123;ROOTFS_DIR&#125;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/rootfs-builder</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">script -fec <span class="string">&#x27;sudo -E GOPATH=$GOPATH USE_DOCKER=true ./rootfs.sh $&#123;rootfsdistro&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p><strong>添加 Kata agent</strong></p><p><em>仅在 Kata agent 定制化后添加</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0550 -t <span class="variable">$&#123;ROOTFS_DIR&#125;</span>/usr/bin ../../../src/agent/target/x86_64-unknown-linux-musl/release/kata-agent</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0440 ../../../src/agent/kata-agent.service <span class="variable">$&#123;ROOTFS_DIR&#125;</span>/usr/lib/systemd/system/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0440 ../../../src/agent/kata-containers.target <span class="variable">$&#123;ROOTFS_DIR&#125;</span>/usr/lib/systemd/system/</span></span><br></pre></td></tr></table></figure><p><strong>构建镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/image-builder</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">script -fec <span class="string">&#x27;sudo -E USE_DOCKER=true ./image_builder.sh $&#123;ROOTFS_DIR&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p><strong>安装镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">commit=$(git <span class="built_in">log</span> --format=%h -1 HEAD)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">date</span>=$(<span class="built_in">date</span> +%Y-%m-%d-%T.%N%z)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">image=<span class="string">&quot;kata-containers-<span class="variable">$&#123;date&#125;</span>-<span class="variable">$&#123;commit&#125;</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0640 -D kata-containers.img <span class="string">&quot;/usr/share/kata-containers/<span class="variable">$&#123;image&#125;</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">(<span class="built_in">cd</span> /usr/share/kata-containers &amp;&amp; sudo <span class="built_in">ln</span> -sf <span class="string">&quot;<span class="variable">$image</span>&quot;</span> kata-containers.img)</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-containers-&lt;date&gt;</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-containers.img</li></ul><h2 id="initrd"><a href="#initrd" class="headerlink" title="initrd"></a>initrd</h2><p><strong>创建镜像文件系统</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ROOTFS_DIR=<span class="string">&quot;<span class="variable">$&#123;GOPATH&#125;</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/rootfs-builder/rootfs&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">rm</span> -rf <span class="variable">$&#123;ROOTFS_DIR&#125;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/rootfs-builder</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">script -fec <span class="string">&#x27;sudo -E GOPATH=$GOPATH AGENT_INIT=yes USE_DOCKER=true ./rootfs.sh $&#123;initrddistro&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p><strong>添加 Kata agent</strong></p><p><em>仅在 Kata agent 定制化后添加</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0550 -T ../../../src/agent/target/<span class="variable">$&#123;ARCH&#125;</span>-unknown-linux-<span class="variable">$&#123;LIBC&#125;</span>/release/kata-agent <span class="variable">$&#123;ROOTFS_DIR&#125;</span>/sbin/init</span></span><br></pre></td></tr></table></figure><p><strong>构建镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/osbuilder/initrd-builder</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">script -fec <span class="string">&#x27;sudo -E AGENT_INIT=yes USE_DOCKER=true ./initrd_builder.sh $&#123;ROOTFS_DIR&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p><strong>安装镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">commit=$(git <span class="built_in">log</span> --format=%h -1 HEAD)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">date</span>=$(<span class="built_in">date</span> +%Y-%m-%d-%T.%N%z)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">image=<span class="string">&quot;kata-containers-initrd-<span class="variable">$&#123;date&#125;</span>-<span class="variable">$&#123;commit&#125;</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -o root -g root -m 0640 -D kata-containers-initrd.img <span class="string">&quot;/usr/share/kata-containers/<span class="variable">$&#123;image&#125;</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">(<span class="built_in">cd</span> /usr/share/kata-containers &amp;&amp; sudo <span class="built_in">ln</span> -sf <span class="string">&quot;<span class="variable">$image</span>&quot;</span> kata-containers-initrd.img)</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-containers-initrd-&lt;date&gt;</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-containers-initrd.img</li></ul><h1 id="Hypervisor"><a href="#Hypervisor" class="headerlink" title="Hypervisor"></a>Hypervisor</h1><h2 id="QEMU"><a href="#QEMU" class="headerlink" title="QEMU"></a>QEMU</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">qemu_directory=<span class="variable">$&#123;GOPATH&#125;</span>/src/github.com/qemu/qemu</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">packaging_dir=<span class="string">&quot;<span class="variable">$&#123;GOPATH&#125;</span>/src/github.com/kata-containers/kata-containers/tools/packaging&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$qemu_directory</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据架构的 QEMU，应用对应版本的 patch</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$packaging_dir</span>/scripts/apply_patches.sh <span class="variable">$packaging_dir</span>/qemu/patches/6.2.x/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">本地 commit 去除 dirty</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global user.email kata@kata.com</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global user.name kata</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -am <span class="string">&quot;update&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$packaging_dir</span>/scripts/configure-hypervisor.sh kata-qemu &gt; kata.cfg</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">eval</span> ./configure <span class="string">&quot;<span class="subst">$(cat kata.cfg)</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make -j $(<span class="built_in">nproc</span>)</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo -E make install</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;bin&#x2F;qemu-system-&lt;arch&gt;</li><li>&#x2F;usr&#x2F;libexec&#x2F;kata-qemu&#x2F;virtiofsd</li><li>&#x2F;usr&#x2F;share&#x2F;kata-qemu&#x2F;qemu&#x2F;*</li></ul><h1 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/kata-containers/tools/packaging/kernel</span></span><br></pre></td></tr></table></figure><p><strong>x86 操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x86 环境下删除 arm-experimental 中的 patch 文件，避免误 patch</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf patches/5.15.x/arm-experimental/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh setup</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh build</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh install</span></span><br></pre></td></tr></table></figure><p><strong>arm64 操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重复 patch 导致流程异常，注释即可</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&quot;377s/^/#/&quot;</span> build-kernel.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh -a aarch64 -E -d setup</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh -a aarch64 -E -d build</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./build-kernel.sh -a aarch64 -E -d install</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;config-5.15.26</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;vmlinux.container</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;vmlinux-5.15.26-90</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;vmlinuz.container</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;vmlinuz-5.15.26-90</li></ul><h1 id="UEFI-ROM"><a href="#UEFI-ROM" class="headerlink" title="UEFI ROM"></a>UEFI ROM</h1><p><em>UEFI ROM 仅在 arm64 环境下需要，用于设备热插拔</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kata-containers/tests</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">.ci/aarch64/install_rom_aarch64.sh</span></span><br></pre></td></tr></table></figure><p><strong>编译结果</strong></p><ul><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-flash0.img</li><li>&#x2F;usr&#x2F;share&#x2F;kata-containers&#x2F;kata-flash1.img</li></ul>]]></content>
    
    
    <summary type="html">基于源码在 x86 和 arm64 架构下容器化编译 Kata Containers 的参考流程</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」快速开始</title>
    <link href="http://shenxianghong.github.io/2021/04/15/2021-04-15%20Kata%20Containers%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/"/>
    <id>http://shenxianghong.github.io/2021/04/15/2021-04-15%20Kata%20Containers%20%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</id>
    <published>2021-04-14T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:07.016Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>3.0.0</strong></p></blockquote><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>Kata Containers 社区提供了 x86 架构制品，arm64 架构制品需要手动编译。这里以 x86 架构的社区制品安装为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/kata-containers/kata-containers/releases/download/3.0.0/kata-static-3.0.0-x86_64.tar.xz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xvf kata-static-3.0.0-x86_64.tar.xz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree opt/kata/</span></span><br><span class="line">opt/kata/</span><br><span class="line">├── bin # 可执行的二进制文件与脚本</span><br><span class="line">│   ├── cloud-hypervisor</span><br><span class="line">│   ├── containerd-shim-kata-v2</span><br><span class="line">│   ├── firecracker</span><br><span class="line">│   ├── jailer</span><br><span class="line">│   ├── kata-collect-data.sh</span><br><span class="line">│   ├── kata-monitor</span><br><span class="line">│   ├── kata-runtime</span><br><span class="line">│   └── qemu-system-x86_64</span><br><span class="line">├── libexec # 可执行的二进制文件</span><br><span class="line">│   └── virtiofsd</span><br><span class="line">├── runtime-rs # Rust 实现下的 shimv2</span><br><span class="line">│   └── bin</span><br><span class="line">│       └── containerd-shim-kata-v2</span><br><span class="line">└── share</span><br><span class="line">    ├── bash-completion # 命令行补全脚本</span><br><span class="line">    │   └── completions</span><br><span class="line">    │       └── kata-runtime</span><br><span class="line">    ├── defaults # 不同 hypervisor 实现下的静态配置文件</span><br><span class="line">    │   └── kata-containers</span><br><span class="line">    │       ├── configuration-acrn.toml</span><br><span class="line">    │       ├── configuration-clh.toml</span><br><span class="line">    │       ├── configuration-dragonball.toml</span><br><span class="line">    │       ├── configuration-fc.toml</span><br><span class="line">    │       ├── configuration-qemu.toml</span><br><span class="line">    │       └── configuration.toml -&gt; configuration-qemu.toml</span><br><span class="line">    ├── kata-containers # 内核与 guest 镜像</span><br><span class="line">    │   ├── config-5.19.2</span><br><span class="line">    │   ├── kata-alpine-3.15.initrd</span><br><span class="line">    │   ├── kata-clearlinux-latest.image</span><br><span class="line">    │   ├── kata-containers.img -&gt; kata-clearlinux-latest.image</span><br><span class="line">    │   ├── kata-containers-initrd.img -&gt; kata-alpine-3.15.initrd</span><br><span class="line">    │   ├── vmlinux-5.19.2-96</span><br><span class="line">    │   ├── vmlinux.container -&gt; vmlinux-5.19.2-96</span><br><span class="line">    │   ├── vmlinuz-5.19.2-96</span><br><span class="line">    │   └── vmlinuz.container -&gt; vmlinuz-5.19.2-96</span><br><span class="line">    └── kata-qemu # QEMU 依赖</span><br><span class="line">        └── qemu</span><br><span class="line">            ├── bios-256k.bin</span><br><span class="line">            ├── bios.bin</span><br><span class="line">            ├── bios-microvm.bin</span><br><span class="line">            ├── edk2-aarch64-code.fd</span><br><span class="line">            ├── edk2-arm-code.fd</span><br><span class="line">            ├── edk2-arm-vars.fd</span><br><span class="line">            ├── edk2-i386-code.fd</span><br><span class="line">            ├── edk2-i386-secure-code.fd</span><br><span class="line">            ├── edk2-i386-vars.fd</span><br><span class="line">            ├── edk2-licenses.txt</span><br><span class="line">            ├── edk2-x86_64-code.fd</span><br><span class="line">            ├── edk2-x86_64-secure-code.fd</span><br><span class="line">            ├── efi-virtio.rom</span><br><span class="line">            ├── firmware</span><br><span class="line">            │   ├── 50-edk2-i386-secure.json</span><br><span class="line">            │   ├── 50-edk2-x86_64-secure.json</span><br><span class="line">            │   ├── 60-edk2-aarch64.json</span><br><span class="line">            │   ├── 60-edk2-arm.json</span><br><span class="line">            │   ├── 60-edk2-i386.json</span><br><span class="line">            │   └── 60-edk2-x86_64.json</span><br><span class="line">            ├── hppa-firmware.img</span><br><span class="line">            ├── kvmvapic.bin</span><br><span class="line">            ├── linuxboot.bin</span><br><span class="line">            ├── linuxboot_dma.bin</span><br><span class="line">            ├── multiboot_dma.bin</span><br><span class="line">            ├── pvh.bin</span><br><span class="line">            ├── qboot.rom</span><br><span class="line">            ├── qemu-nsis.bmp</span><br><span class="line">            ├── s390-ccw.img</span><br><span class="line">            └── s390-netboot.img</span><br></pre></td></tr></table></figure><h1 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h1><p>Kata Containers 中配置的优先级为：动态配置项 &gt; 静态配置项 &gt; 默认值</p><ul><li>动态配置项是通过 OCI spec 中的 annotations 传递，主流的 Container Engine 均实现支持将容器 annotations 透传至 Kata 运行时</li><li>各个动态与静态配置项支持与否视 hypervisor 具体实现的能力有所区别</li></ul><h2 id="hypervisor"><a href="#hypervisor" class="headerlink" title="hypervisor"></a>hypervisor</h2><p>动态配置项的前缀为 io.katacontainers.hypervisor.&lt;静态配置项&gt;</p><h3 id="QEMU"><a href="#QEMU" class="headerlink" title="QEMU"></a>QEMU</h3><table><thead><tr><th>静态配置项</th><th>动态配置</th><th>含义</th></tr></thead><tbody><tr><td>path</td><td>Y</td><td>hypervisor 可执行文件的路径</td></tr><tr><td>kernel</td><td>Y</td><td>VM 内核路径</td></tr><tr><td>image</td><td>Y</td><td>VM rootfs 镜像路径，与 initrd 有且仅有一个</td></tr><tr><td>initrd</td><td>Y</td><td>VM rootfs 镜像路径，与 image 有且仅有一个</td></tr><tr><td>machine_type</td><td>Y</td><td>QEMU 机器类型，例如 amd64 架构下为 q35、arm64 架构下为 virt</td></tr><tr><td>confidential_guest</td><td>N</td><td>是否启用机密容器特性。机密容器需要 host 支持 tdxProtection（<a href="https://software.intel.com/content/www/us/en/develop/articles/intel-trust-domain-extensions.html">Intel Trust Domain Extensions</a>）、sevProtection（<a href="https://developer.amd.com/sev/">AMD Secure Encrypted Virtualization</a>）、pefProtection（<a href="https://www.kernel.org/doc/html/latest/powerpc/ultravisor.html">IBM POWER 9 Protected Execution Facility</a>）以及 seProtection（<a href="https://www.kernel.org/doc/html/latest/virt/kvm/s390-pv.html">IBM Secure Execution (IBM Z &amp; LinuxONE)</a>）。不支持 CPU 和内存的热插拔以及 NVDIMM 设备，不支持 arm64 架构</td></tr><tr><td>rootless</td><td>Y</td><td>是否以非 root 权限的随机用户启动 QEMU VMM，默认为 false</td></tr><tr><td>enable_annotations</td><td>N</td><td>允许 hypervisor 动态配置的配置项</td></tr><tr><td>valid_hypervisor_paths</td><td>N</td><td>以 glob(3) 规则校验 path 参数是否为合法的路径集合</td></tr><tr><td>kernel_params</td><td>Y</td><td>VM kernel 的额外附加参数，默认为空</td></tr><tr><td>firmware</td><td>Y</td><td>固件路径，默认为空</td></tr><tr><td>firmware_volume</td><td>Y</td><td>固件卷路径，默认为空</td></tr><tr><td>machine_accelerators</td><td>Y</td><td>机器加速器参数，默认为空</td></tr><tr><td>seccompsandbox</td><td>N</td><td>seccomp 参数。QEMU seccomp sandbox 是 QEMU VM 中的一种安全特性，通过限制 QEMU 进程的系统调用，以提高 VM 的安全性。它使用了 Linux 内核提供的 seccomp 机制，将 QEMU 进程限制在一组安全的系统调用中，从而降低 VM 遭受攻击的风险。推荐设置 &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;bpf_jit_enable 文件内容为 1，以降低该特性带来的性能下降</td></tr><tr><td>cpu_features</td><td>Y</td><td>CPU 特性参数，默认为空</td></tr><tr><td>default_vcpus</td><td>Y</td><td>VM 默认的 CPU 数量，默认为 1，最大为 host CPU 数量</td></tr><tr><td>default_maxvcpus</td><td>Y</td><td>VM 最大的 CPU 数量，默认为 host CPU 数量，具体能否使用到 host CPU 数量，还需要视 hypervisor 限制而定。过大的 CPU 数量会影响到 VM 的性能以及内存占比</td></tr><tr><td>default_bridges</td><td>N</td><td>VM 默认的 PCI 桥数量，默认为 1，最大为 5。目前，仅支持 PCI bridge，每个 PCI bridge 最多支持 30 个设备的热插拔，每个 VM 最多支持 5 个 PCI bridge（这可能是 QEMU 或内核中的一个 bug）</td></tr><tr><td>default_memory</td><td>Y</td><td>VM 默认的内存总量，默认为 1，最大为 host 内存总量</td></tr><tr><td>memory_slots</td><td>Y</td><td>VM 默认的内存插槽数量，默认为 10，即内存热添加次数上限为 10</td></tr><tr><td>default_maxmemory</td><td>Y</td><td>VM 最大的内存总量，默认为  host 内存总量</td></tr><tr><td>memory_offset</td><td>Y</td><td>VM 内存偏移量，用于描述 NVDIMM 设备的内存空间，当 block_device_driver 为 nvdimm 时，需要设置此参数，最终会追加到 default_maxmemory 中</td></tr><tr><td>enable_virtio_mem</td><td>Y</td><td>是否启用 virtio-mem 设备，默认为 false。virtio-mem 设备可以提高 VM 的内存性能。它通过在 host 和 VM 之间共享内存，使 VM 可以直接访问 host 内存，而无需通过复制或传输数据。这种直接访问可显著降低内存访问延迟和 CPU 使用率，并提高 VM 的性能和吞吐量。推荐设置 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;overcommit_memory 文件内容为 1</td></tr><tr><td>disable_block_device_use</td><td>Y</td><td>禁止块设备用于容器的 rootfs。例如 devicemapper 之类的存储驱动程序中，容器的 rootfs 由块设备支持，出于性能原因，块设备默认直接传递给 hypervisor。 禁用传递时，会用 virtio-fs 传递 rootfs</td></tr><tr><td>shared_fs</td><td>Y</td><td>host 和 VM 之间共享文件系统类型，默认为 virtio-fs，此外支持 virtio-9p 和 virtio-fs-nydus</td></tr><tr><td>virtio_fs_daemon</td><td>Y</td><td>vhost-user-fs 可执行文件的路径</td></tr><tr><td>valid_virtio_fs_daemon_paths</td><td>N</td><td>以 glob(3) 规则校验 virtio_fs_daemon 参数是否为合法的路径集合</td></tr><tr><td>virtio_fs_cache_size</td><td>Y</td><td>DAX 缓存大小，默认为 0 MiB。virtio_fs 支持 DAX（Direct Access）模式，这意味着 VM 可以直接访问 host 的文件系统缓存，从而提高了读取和写入数据的速度</td></tr><tr><td>virtio_fs_extra_args</td><td>Y</td><td>vhost-user-fs 的额外附加参数</td></tr><tr><td>virtio_fs_cache</td><td>Y</td><td>virtio-fs 文件系统在 VM 和 host 之间共享文件时的缓存模式，默认是 auto，此外支持 none 和 always。none 表示 VM 中不缓存文件系统的元数据、数据和路径名查找，所有这些信息都需要从 host 中获取。在这种模式下，任何对文件的修改都会立即被推送到 host；alway 则截然相反，表示 VM 中的文件系统元数据、数据和路径名查找都会被缓存，并且永不过期；而 auto 表示 VM 中的元数据和路径名查找缓存会在一定时间后过期（默认为 1 秒），而数据则会在文件打开时缓存（即 close-to-open 一致性）。在这种模式下，VM 会根据需要从 host 中获取文件信息，而不是每次都从 host 获取</td></tr><tr><td>block_device_driver</td><td>Y</td><td>hypervisor 用于管理容器 rootfs 的块存储驱动程序，默认为 virtio-scsi，此外支持 virtio-blk 和 nvdimm。virtio-scsi 是一种基于SCSI 协议的存储虚拟化技术；virtio-blk 则是一种用于块设备的存储虚拟化技术，在使用 virtio-scsi 和 virtio-blk 时，host 上的块设备可以被 VM 视为本地的块设备，从而可以在 VM 中进行读写操作；nvdimm 是一种用于非易失性内存（NVM）的存储技术。它允许将内存作为块设备使用，并提供了与传统块设备相似的可靠性和数据完整性保护</td></tr><tr><td>block_device_aio</td><td>Y</td><td>QEMU 使用的块设备异步 I&#x2F;O 机制，默认为 io_uring，此外支持 threads 和 native。threads 表示 QEMU 使用基于 pthread 的磁盘 I&#x2F;O 机制，这种机制是在用户空间实现的，可以在多个线程之间共享 CPU 时间，但是性能比较一般；native 表示 QEMU 使用本地的 Linux I&#x2F;O 机制。这种机制是在内核空间实现的，可以获得更好的性能，但是需要特权；io_uring 表示 QEMU 使用 Linux io_uring API 来实现异步 I&#x2F;O，这种机制提供了 Linux 中最快的 I&#x2F;O 操作，可以在 QEMU 5.0 及以上版本中使用，但需要 Linux 内核版本大于 5.1，io_uring 机制可以减少 CPU 的上下文切换次数，提高 I&#x2F;O 操作的效率</td></tr><tr><td>block_device_cache_set</td><td>Y</td><td>是否将缓存相关选项设置给块设备，默认为 false。该参数影响到 block_device_cache_direct 和 block_device_cache_noflush 是否生效</td></tr><tr><td>block_device_cache_direct</td><td>Y</td><td>是否启用 O_DIRECT 选项，默认为 false。O_DIRECT 是一种 Linux 系统提供的选项，可以绕过 host 页缓存，直接访问块设备，从而提高存储 I&#x2F;O 的性能。受 block_device_cache_set 参数设置影响</td></tr><tr><td>block_device_cache_noflush</td><td>Y</td><td>是否忽略块设备的缓存刷盘请求，默认为 false。受 block_device_cache_set 参数设置影响</td></tr><tr><td>enable_iothreads</td><td>Y</td><td>是否启用独立的 I&#x2F;O 线程，默认为 false。启用时，块设备的 I&#x2F;O 操作将在一个单独的 I&#x2F;O 线程中处理，而非 QEMU 的主线程中进行处理，可以减少了主线程的阻塞时间，提高 VM 的 I&#x2F;O 性能</td></tr><tr><td>enable_mem_prealloc</td><td>Y</td><td>是否启用 VM 内存预分配，默认为 false。启用 VM 内存的预分配可以使内存分配更加稳定和可预测，从而提高 VM 的性能。但是，预分配内存也会占用更多的系统资源，降低容器密度</td></tr><tr><td>enable_hugepages</td><td>Y</td><td>是否启用 VM 大页内存，默认为 false。Huge Pages 的特点是将内存分配成固定大小的页（通常为 2MB 或 1GB），从而降低了页表的大小和操作系统内核的开销，使用 Huge Pages 分配 VM 内存可以提升性能。在启用大页内存时，内存预分配（enable_mem_prealloc）会被强制设置启用</td></tr><tr><td>enable_vhost_user_store</td><td>Y</td><td>是否启用 vhost-user 存储设备，默认为 false。启用 vhost-user 存储设备可以将 host 上的块设备虚拟化为一种可以在 VM 中使用的设备，通过 vhost-user 协议在 host 和 VM 之间传输数据，从而提高 VM 的存储性能。在启用 vhost-user 存储设备时，Linux 中的一些保留块类型（Major Range 240-254）将被选择用于表示 vhost-user 设备</td></tr><tr><td>vhost_user_store_path</td><td>Y</td><td>vhost-user 设备的目录，默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;vhost-user。在该目录下，”block” 子目录用于存储块设备，”block&#x2F;sockets” 子目录用于存储 vhost-user sockets，”block&#x2F;devices” 子目录用于存储模拟的块设备节点</td></tr><tr><td>enable_iommu</td><td>Y</td><td>是否启用 vIOMMU 设备，默认为 false。vIOMMU 用于将 VM 的 I&#x2F;O 操作隔离在一个独立的内存地址空间中，以提高 VM 的安全性和性能。此外，vIOMMU 还可以提供更好的 I&#x2F;O 性能，因为它可以减少 VM 和 host 之间的数据传输次数</td></tr><tr><td>enable_iommu_platform</td><td>Y</td><td>是否启用 IOMMU_PLATFORM 设备，默认为 false。IOMMU_PLATFORM 用于设备 DMA（Direct Memory Access）操作隔离在一个独立的内存地址空间中，以提高系统的安全性和性能。此外，IOMMU_PLATFORM 还可以提供更好的 DMA 性能，因为它可以减少系统和设备之间的数据传输次数。</td></tr><tr><td>valid_vhost_user_store_paths</td><td>N</td><td>以 glob(3) 规则校验 vhost_user_store_path 参数是否为合法的路径集合</td></tr><tr><td>file_mem_backend</td><td>Y</td><td>基于文件的内存支持的路径，默认为空。基于文件的 VM 内存支持是一种将 VM 内存保存在文件中的技术，而不是保存在 host 的物理内存中。此外，使用基于文件的 VM 内存还可以减少 VM 和 host 之间的数据传输，从而提高 VM 的性能。在使用 virtio-fs 时，该选项会自动启用，并使用 “&#x2F;dev&#x2F;shm” 作为后端文件</td></tr><tr><td>valid_file_mem_backends</td><td>N</td><td>以 glob(3) 规则校验 file_mem_backend 参数是否为合法的路径集合</td></tr><tr><td>pflashes</td><td>N</td><td>向 VM 中添加的镜像文件路径，默认为空。镜像文件通常用于模拟系统中的 BIOS 或 UEFI  固件等。例如，arm64 架构下的内存热插拔则需要提供一对 pflash</td></tr><tr><td>enable_debug</td><td>N</td><td>是否启用 hypervisor 和内核的 debug 参数，默认为 false</td></tr><tr><td>disable_nesting_checks</td><td>N</td><td>是否禁止嵌套虚拟化环境检查，默认为 false。禁用嵌套检查可以从运行时的行为与在裸机上相同</td></tr><tr><td>msize_9p</td><td>Y</td><td>virtio-9p 共享文件系统中描述 9p 数据包有效载荷的字节数量，默认为 8192</td></tr><tr><td>disable_image_nvdimm</td><td>Y</td><td>是否禁止使用 NVDIMM 设备挂载 VM 镜像，默认为 false。在未禁用且支持 NVDIMM 设备时，VM 镜像会借助 NVDIMM 设备热添加，否则，使用 virtio-block 设备</td></tr><tr><td>hotplug_vfio_on_root_bus</td><td>Y</td><td>是否允许 VFIO 设备在 root 总线上热插拔，默认为 true。VFIO 是一种用于虚拟化环境中的设备直通技术，它允许将物理设备直接分配给 VM，从而提高 VM 的性能和可靠性。然而，在桥接设备上进行 VFIO 设备的热插拔存在一些限制，特别是对于具有大型 PCI 条的设备。因此，通过将该选项设置为 true，可以在 root 总线上启用 VFIO 设备的热插拔，从而解决这些限制问题</td></tr><tr><td>pcie_root_port</td><td>Y</td><td>pcie_root_port 设备数量，默认为 0。在热插拔 PCIe 设备之前需要添加 pcie_root_port 设备，主要针对使用一些大型 PCI 条设备（如 Nvidia GPU）的情况。仅在启用 hotplug_vfio_on_root_bus 且 machine_type 为 q35 时生效</td></tr><tr><td>disable_vhost_net</td><td>Y</td><td>是否禁用 vhost-net 作为 virtio-net 的后端，默认为 false。使用 vhost-net 时意味着在提高网络 I&#x2F;O 性能的同时，会牺牲一定的安全性（因为 vhost-net 运行在 ring0 模式下，具有最高的权限和特权）</td></tr><tr><td>entropy_source</td><td>Y</td><td>熵源路径，默认为 &#x2F;dev&#x2F;urandom，用于生成随机数的来源。&#x2F;dev&#x2F;random 是一个阻塞的熵源，如果 host 的熵池用尽，VM 的启动时间会增加，可能会导致启动超时。相比之下，&#x2F;dev&#x2F;urandom 是一个非阻塞的熵源，可以适用于大多数场景</td></tr><tr><td>valid_entropy_sources</td><td>N</td><td>以 glob(3) 规则校验 entropy_source 参数是否为合法的路径集合</td></tr><tr><td>guest_hook_path</td><td>Y</td><td>VM 中 hook 脚本路径，默认为空。hook 必须按照其 hook 类型存储在 guest_hook_path 的子目录中，例如 “guest_hook_path&#x2F;{prestart,poststart,poststop}”。Kata agent 将扫描这些目录查找可执行文件，按字母顺序将其添加到容器的生命周期中，并在 VM 运行时命名空间中执行</td></tr><tr><td>rx_rate_limiter_max_rate</td><td>Y</td><td>网络 I&#x2F;O inbound 带宽限制，默认为 0，即不作限制。在 QEMU 中，借助 HTB(Hierarchy Token Bucket) 限制管理</td></tr><tr><td>tx_rate_limiter_max_rate</td><td>Y</td><td>网络 I&#x2F;O outbound 带宽限制，默认为 0，即不作限制。在 QEMU 中，借助 HTB(Hierarchy Token Bucket) 限制管理</td></tr><tr><td>guest_memory_dump_path</td><td>N</td><td>VM 内存转储文件路径，默认为空。在出现 GUEST_PANICKED 事件时，VM 的内存将被转储到 host 文件系统下的指定目录中（如果该目录不存在，会自动创建）。被转储的文件（也称为 vmcore 文件）可以使用 crash 或 gdb 等工具进行处理。注意，转储 VM 内存可能需要很长时间，具体取决于 VM 内存的大小，并且会占用大量磁盘空间</td></tr><tr><td>guest_memory_dump_paging</td><td>N</td><td>是否启用 VM 内存分页，默认为 false。在 VM 内存转储时，将使用分页机制来处理虚拟地址和物理地址之间的映射关系。如果禁用该选项，则将使用物理地址而不是虚拟地址来进行转储。比如，如果希望使用 gdb 工具而不是 crash 工具，或者需要在 ELF vmcore 中使用VM 的虚拟地址，那么则需要启用内存分页功能</td></tr><tr><td>enable_guest_swap</td><td>Y</td><td>是否启用 VM 中的交换空间，默认为 false。启用时，会将一个 raw 格式的设备添加到 VM 中作为 SWAP 设备。如果 annotations[“io.katacontainers.container.resource.swappiness”] 大于 0，则根据 annotations[“io.katacontainers.container.resource.swap_in_bytes”] 计算 SWAP 设备大小：默认为 swap_in_bytes - memory_limit_in_bytes；如果 swap_in_bytes 未设置，则为 memory_limit_in_bytes，如果均未设置，则为 default_memory</td></tr><tr><td>use_legacy_serial</td><td>Y</td><td>是否使用传统的串行接口作为 VM 控制台设备，默认为 false</td></tr><tr><td>disable_selinux</td><td>N</td><td>是否禁用在 hypervisor 上应用 SELinux，默认为 false</td></tr></tbody></table><h2 id="factory"><a href="#factory" class="headerlink" title="factory"></a>factory</h2><p>不支持动态配置项</p><table><thead><tr><th>静态配置项</th><th>含义</th></tr></thead><tbody><tr><td>enable_template</td><td>是否启用 VM 模板，默认为 false。 启用后，从模板克隆创建新的 VM。 它们将通过只读映射共享相同的内核、initramfs 和 Kata agent 内存。 如果在同一 host 上运行许多 Kata 容器，VM 模板有助于加快容器的创建并节省大量内存。仅支持镜像类型为 initrd</td></tr><tr><td>template_path</td><td>VM 模板保存的路径，默认为 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;template</td></tr><tr><td>vm_cache_number</td><td>VMCache 的数量，默认为 0，表示禁用 VMCache。VMCache 是一种在使用之前将 VM 创建为缓存的功能，有助于加快容器的创建。 该功能由服务器和通过 Unix socket 进行通信的客户端组成，服务器将创建一些 VM 并缓存起来。如果启用了 VMCache 功能，kata-runtime 在创建新的 sandbox 时会向 VMCache 服务器请求 VM</td></tr><tr><td>vm_cache_endpoint</td><td>VMCache 服务器的 socket 地址，默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock</td></tr></tbody></table><h2 id="runtime"><a href="#runtime" class="headerlink" title="runtime"></a>runtime</h2><p>动态配置项的前缀为 io.katacontainers.config.runtime.&lt;静态配置项&gt;</p><table><thead><tr><th>静态配置项</th><th>动态配置</th><th>含义</th></tr></thead><tbody><tr><td>enable_debug</td><td>N</td><td>是否启用 containerd-shim-kata-v2 的 debug 参数，默认为 false</td></tr><tr><td>internetworking_model</td><td>Y</td><td>VM 与容器网络的连通方式，默认为 tcfilter，此外支持 tcfilter、macvtap 和 none。无论哪种方式，tap 设备都是创建的，区别在于 tap 设备和容器网络是如何打通的</td></tr><tr><td>disable_guest_seccomp</td><td>Y</td><td>是否在 VM 中启用 seccomp 特性，默认为 false。启用时，seccomp 配置文件会由 Kata agent 传递到 VM 中并应用，用于提供额外的安全层</td></tr><tr><td>enable_tracing</td><td>N</td><td>是否启用 opentracing 的 traces 和 spans，默认为 false</td></tr><tr><td>jaeger_endpoint</td><td>N</td><td>Jaeger 服务地址，默认为 <code>http://localhost:14268/api/traces</code></td></tr><tr><td>jaeger_user</td><td>N</td><td>Jaeger 服务账号，默认为空</td></tr><tr><td>jaeger_password</td><td>N</td><td>Jaeger 服务密码，默认为空</td></tr><tr><td>disable_new_netns</td><td>Y</td><td>是否禁止为 shim 和 hypervisor 进程创建网络命名空间，默认为 false。适用于 internetworking_model 为 none，此时 tap 设备将位于 host 网络命名空间中，并可以直接连接到 bridge（如 OVS）</td></tr><tr><td>sandbox_cgroup_only</td><td>Y</td><td>是否仅启用 sandboxCgroup，默认为 false。启用时，cgroups 仅有一个 sandboxCgroup，用于限制所有的 Kata 进程；禁用时，cgroups 分为 sandboxCgroup 和 overheadCgroup，除 vCPU 线程外的其他 Kata 进程和线程都将在 overheadCgroup 下运行</td></tr><tr><td>static_sandbox_resource_mgmt</td><td>N</td><td>是否启用静态资源管理，默认为 false。启用时，Kata Containers 将在 VM 启动之前尝试确定适当的资源大小，而非动态更新 VM 中的内存和 CPU 数量，用作不支持 CPU 和内存热插拔的硬件架构或 hypervisor 解决方案</td></tr><tr><td>sandbox_bind_mounts</td><td>N</td><td>VM 中待挂载 host 的文件路径，默认为空。启用时，host 的该路径文件会被以只读的形式挂载到 VM 的 &#x2F;run&#x2F;kata-containers&#x2F;shared&#x2F;containers&#x2F;sandbox-mounts 路径中，不会暴露给容器工作负载，仅为潜在的 VM 服务提供</td></tr><tr><td>vfio_mode</td><td>Y</td><td>VFIO 的模式，默认为 guest-kernel，可选的有 vfio 和 guest-kernel。vfio 与 runC 的行为相近，在容器中，VFIO 设备将显示为 VFIO 字符设备，位于 &#x2F;dev&#x2F;vfio 下，确切的名称可能与 host 不同（需要匹配 VM 的 IOMMU 组号，而不是 host 的）；guest-kernel 是 Kata 特有的行为，VFIO 设备由 VM 内核中的驱动程序管理，意味着它将显示为一个或多个设备节点或网络接口，具体取决于设备的特性。这种模式要求容器内的工作负载具有显式支持 VM 内设备的代码或逻辑</td></tr><tr><td>disable_guest_empty_dir</td><td>N</td><td>是否禁用在 VM 文件系统创建 emptyDir 挂载点，默认为 false。禁用时，Kata Containers 将不会在 VM 文件系统上创建 Kubernetes emptyDir 挂载点，而是在 host 上创建 emptyDir 挂载点，并通过 virtio-fs 共享，虽然更慢一些，但允许从 host 共享文件到 VM 中</td></tr><tr><td>experimental</td><td>Y</td><td>体验特性，默认为空。<em>暂未有支持的体验特性</em></td></tr><tr><td>enable_pprof</td><td>Y</td><td>是否启用 pprof，默认为 false。启用后，可以通过 kata-monitor 运行 pprof 工具来分析 shim 进程</td></tr></tbody></table><h2 id="annotation-参数扩展"><a href="#annotation-参数扩展" class="headerlink" title="annotation 参数扩展"></a>annotation 参数扩展</h2><p>Kata Containers 可以通过 annotation 的方式定制化每一个 Kata 容器的底层运行时参数：</p><ul><li>上层容器运行时将 annotation 透传至底层运行时（例如 Containerd 1.4.x 以上的版本支持 annotation 透传；CRI-O 默认透传所有 annotation，无需额外配置。<em>具体参考 Container Manager 集成</em>）</li><li>Kata Containers 配置中开启识别特定的 annotation（[hypervisor].enable_annotations）</li></ul><p>此外，Kata Containers 支持 OCI 和容器级别的配置，例如：</p><p><strong>OCI 配置</strong></p><table><thead><tr><th>配置项</th><th>含义</th></tr></thead><tbody><tr><td>io.katacontainers.config_path</td><td>Kata Containers 配置文件路径</td></tr><tr><td>io.katacontainers.pkg.oci.bundle_path</td><td>OCI bundle 路径</td></tr><tr><td>io.katacontainers.pkg.oci.container_type</td><td>OCI 容器类型，可选的有 pod_container 和 pod_sandbox</td></tr></tbody></table><p><strong>容器配置</strong></p><table><thead><tr><th>配置项</th><th>含义</th></tr></thead><tbody><tr><td>io.katacontainers.container.resource.swappiness</td><td>即 Resources.Memory.Swappiness，用于配置容器内存管理器在何时将内存页面写入 SWAP 空间的一个相对度量。该参数的值介于 0 和 100 之间，表示内存页面的使用频率</td></tr><tr><td>io.katacontainers.container.resource.swap_in_bytes</td><td>即 Resources.Memory.Swap，用于配置容器可以使用的 SWAP 空间的大小</td></tr></tbody></table><p>例如，通过 annotation 启动一个忽略底层默认大小，具有 5 CPUs 的 VM：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kata</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">io.katacontainers.config.hypervisor.default_vcpus:</span> <span class="string">&quot;5&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">runtimeClassName:</span> <span class="string">kata</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kata</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;tail -f /dev/null&quot;</span>]</span><br></pre></td></tr></table></figure><h1 id="与-Container-Manager-集成"><a href="#与-Container-Manager-集成" class="headerlink" title="与 Container Manager 集成"></a>与 Container Manager 集成</h1><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p><em>TODO：Docker 23.0.0 版本，新增了运行时 shim 的支持，也就支持了 Kata Containers</em></p><h2 id="Containerd"><a href="#Containerd" class="headerlink" title="Containerd"></a>Containerd</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成 Containerd 默认的配置文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p /etc/containerd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">containerd config default | sudo <span class="built_in">tee</span> /etc/containerd/config.toml</span></span><br></pre></td></tr></table></figure><p>可以看到，Containerd 的默认底层运行时为 runC，新增以下内容支持 Kata Containers：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span></span><br><span class="line">   <span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.kata]</span></span><br><span class="line">       <span class="attr">runtime_type</span> = <span class="string">&quot;io.containerd.kata.v2&quot;</span></span><br><span class="line">       <span class="attr">privileged_without_host_devices</span> = <span class="literal">true</span></span><br><span class="line">       <span class="attr">pod_annotations</span> = [<span class="string">&quot;io.katacontainers.*&quot;</span>]</span><br><span class="line">       <span class="attr">container_annotations</span> = [<span class="string">&quot;io.katacontainers.*&quot;</span>]</span><br><span class="line">       <span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.kata.options]</span></span><br><span class="line">          <span class="attr">ConfigPath</span> = <span class="string">&quot;/opt/kata/share/defaults/kata-containers/configuration.toml&quot;</span></span><br></pre></td></tr></table></figure><h2 id="CRI-O"><a href="#CRI-O" class="headerlink" title="CRI-O"></a>CRI-O</h2><p><em>TODO</em></p><p>至此，可以单独通过 Container Manager 各自的命令行运行 Kata Containers，以 Containerd 为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ctr image pull docker.io/library/ubuntu:latest</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ctr run --runtime io.containerd.run.kata.v2 -t --<span class="built_in">rm</span> docker.io/library/ubuntu:latest hello sh -c <span class="string">&quot;free -h&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ctr run --runtime io.containerd.run.kata.v2 -t --memory-limit 536870912 --<span class="built_in">rm</span> docker.io/library/ubuntu:latest hello sh -c <span class="string">&quot;free -h&quot;</span></span></span><br></pre></td></tr></table></figure><h1 id="与-Kubernetes-集成"><a href="#与-Kubernetes-集成" class="headerlink" title="与 Kubernetes 集成"></a>与 Kubernetes 集成</h1><p>Kubernetes 中对于运行时的集成是通过 <a href="https://kubernetes.io/docs/concepts/containers/runtime-class/">RuntimeClass</a> 资源对象，例如</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">RuntimeClass</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">node.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kata-containers</span></span><br><span class="line"><span class="attr">handler:</span> <span class="string">kata</span></span><br><span class="line"><span class="attr">overhead:</span></span><br><span class="line">  <span class="attr">podFixed:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;140Mi&quot;</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span></span><br><span class="line"><span class="attr">scheduling:</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">runtime:</span> <span class="string">kata</span></span><br></pre></td></tr></table></figure><h2 id="handler"><a href="#handler" class="headerlink" title="handler"></a>handler</h2><p>需要和 CRI 中注册的 handler（HANDLER_NAME） 保持一致。</p><p><strong>Containerd</strong></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.$&#123;HANDLER_NAME&#125;]</span></span><br></pre></td></tr></table></figure><p><strong>CRI-O</strong></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[crio.runtime.runtimes.$&#123;HANDLER_NAME&#125;]</span></span><br></pre></td></tr></table></figure><h2 id="scheduling"><a href="#scheduling" class="headerlink" title="scheduling"></a>scheduling</h2><p>通过为 RuntimeClass 指定 scheduling 字段， 可以通过设置约束，确保运行该 RuntimeClass 的 Pod 被调度到支持该 RuntimeClass 的节点上。 如果未设置 scheduling，则假定所有节点均支持此 RuntimeClass 。</p><p>为了确保 Pod 会被调度到支持指定运行时的节点上，每个节点需要设置一个通用的 label 用于被 runtimeclass.scheduling.nodeSelector 挑选。在 admission 阶段，RuntimeClass 的 nodeSelector 将会与 Pod 的 nodeSelector 合并，取二者的交集。如果有冲突，Pod 将会被拒绝。</p><p>如果节点需要阻止某些需要特定 RuntimeClass 的 Pod，可以在 tolerations 中指定。 与 nodeSelector 一样，tolerations 也在 admission 阶段与 Pod 的 tolerations 合并，取二者的并集。</p><h2 id="overhead"><a href="#overhead" class="headerlink" title="overhead"></a>overhead</h2><p>在节点上运行 Pod 时，Pod 本身占用大量系统资源。这些资源是运行 Pod 内容器所需资源的附加资源。Overhead 是一个特性，用于计算 Pod 基础设施在容器请求和限制之上消耗的资源。</p><p>在 Kubernetes 中，Pod 的开销是根据与 Pod 的 RuntimeClass 相关联的开销在准入控制时设置的。</p><p>如果启用了 Pod Overhead，在调度 Pod 时，除了考虑容器资源请求的总和外，还要考虑 Pod 开销。 类似地，Kubelet 将在确定 Pod cgroups 的大小和执行 Pod 驱逐排序时也会考虑 Pod 开销。</p><h1 id="VM-factory"><a href="#VM-factory" class="headerlink" title="VM factory"></a>VM factory</h1><h2 id="VMCache"><a href="#VMCache" class="headerlink" title="VMCache"></a>VMCache</h2><p>VMCache 是一项新功能，可在使用前将 VM 创建为缓存。它有助于加快新容器的创建。</p><p>该功能由借助 Unix socket 通信的一个 gRPC Server 和一些 Client 组成。</p><p>VMCache server 将事先创建并缓存一些 VM，它将 VM 转换为 gRPC 格式并在收到 client 请求时返回；grpccache factory 是 VMCache 客户端，它将请求到的 gRPC 格式的 VM 并将其转换回 VM。如果启用了 VMCache 功能，Kata 运行时在创建新的 sandbox 时会向 grpccache 请求获取 VM。</p><p><strong>与 VM tmplating 的区别</strong></p><p>VM tmplating 和 VMCache 都有助于加快新容器的创建。</p><p>当启用 VM tmplating 时，通过从预先创建的模板 VM 克隆来创建新的 VM，它们将以只读模式共享相同的 initramfs、内核和 agent 内存。因此，如果在同一主机上运行许多 Kata 容器，它会节省大量内存。</p><p>而 VMCache 不容易受到共享内存 CVE 的影响，因为每个 VM 不共享内存。</p><p><strong>如何启用 VM Cache</strong></p><p>配置文件中修改以下配置项：</p><ul><li>[factory].vm_cache_number 指定 VM 缓存的个数</li><li>[factory].vm_cache_endpoint 指定 socket 地址（自动创建），默认为 &#x2F;var&#x2F;run&#x2F;kata-containers&#x2F;cache.sock</li></ul><p>通过以下命令创建一个 VM 模板供以后使用，通过 CTRL+C 退出：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory init</span></span><br></pre></td></tr></table></figure><p>区别于 VM templating，VMCache 创建的 VM 是处于运行状态，而非保存在 [factory].template_path 目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory status</span></span><br><span class="line">VM cache server pid = 38308</span><br><span class="line">VM pid = 38334 Cpu = 1 Memory = 2048MiB</span><br><span class="line">VM pid = 38331 Cpu = 1 Memory = 2048MiB</span><br><span class="line">VM pid = 38332 Cpu = 1 Memory = 2048MiB</span><br><span class="line">vm factory not enabled</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -la /run/vc/vm</span></span><br><span class="line">a78a9744-5984-4e54-bda9-9b6280bf9a3f</span><br><span class="line">41648333-a4a3-48ee-b80b-f7c19e3081b1</span><br><span class="line">57d2dd69-0e73-4779-b23f-68ee8e4f66de</span><br><span class="line">template</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory destroy</span></span><br><span class="line">vm factory destroyed</span><br></pre></td></tr></table></figure><p><strong>已知限制</strong></p><ul><li>无法与 VM templating 共存</li><li>仅支持 QEMU 作为 hypervisor</li><li>[hypervisor].shared_fs 为 virtio-9p（社区有支持 virtio-fs 的提案 <a href="https://github.com/kata-containers/kata-containers/pull/4522%EF%BC%8C%E4%BD%86%E6%88%AA%E8%87%B3">https://github.com/kata-containers/kata-containers/pull/4522，但截至</a> Kata 3.0.0 暂未合入）</li></ul><p><em>经验证，截至 Kata 3.0.0，VMCache 并不能开箱即用，在 VMCache 流程中部分变量缺少赋值，导致代码报错</em></p><h2 id="VM-templating"><a href="#VM-templating" class="headerlink" title="VM templating"></a>VM templating</h2><p>VM templating 是 Kata Containers 的一项功能，可以借助克隆技术创建新的 VM。启用后，新的 VM 将通过从预先创建的模板进行克隆来创建，它们将以只读模式共享相同的 initramfs、内核和 agent 内存。类似于内核的 fork 进程操作，这里 fork 的是 VM。</p><p><strong>与 VMCache 的区别</strong></p><p>VMCache 和 VM templating 都有助于加快新容器的创建。</p><p>启用 VMCache 后，VMCache 服务器会创建新的 VM。所以它不容易受到共享内存 CVE 的攻击，因为每个 VM 都不共享内存。</p><p>如果在同一主机上运行许多 Kata 容器，VM templating 可以节省大量内存。</p><p><strong>优势</strong></p><p>如果在同一主机上运行许多 Kata 容器，VM templating 有助于加快新容器的创建并节省大量内存。如果正在运行高密度工作负载，或者非常关心容器启动速度，VM templating 可能非常有用。</p><p>在一个<a href="https://github.com/kata-containers/runtime/pull/303#issuecomment-395846767">示例</a>中，创建了 100 个 Kata 容器，每个容器都拥有 128MB 的 VM 内存，并且在启用 VM templating 特性时最终总共节省了 9GB 的内存，这大约是 VM 内存总量的 72%。</p><p>在另一个<a href="https://gist.github.com/bergwolf/06974a3c5981494a40e2c408681c085d">示例</a>中，创建了 10 个 Kata 容器，并计算了每个容器的平均启动速度。结果表明，VM templating 将 Kata 容器的创建速度提高了 38.68%。</p><p><strong>不足</strong></p><p>VM templating 的一个缺点是它无法避免跨 VM 侧通道攻击，例如最初针对 Linux KSM 功能的 CVE-2015-2877。得出的结论是，“相互不信任的租户之间用于内存保护的共享直到写入的方法本质上是可检测的信息泄露，并且可以归类为潜在的被误解的行为而不是漏洞。”如果对此敏感，不要使用 VM templating 或 KSM。</p><p><strong>如何启用 VM templating</strong></p><p>配置文件中修改以下配置项：</p><ul><li>hypervisor 为 qemu，且版本为 v4.1.0 以上</li><li>[factory].enable_template 设为 true</li><li>VM 镜像为 initrd 类型，即为 [hypervisor].initrd</li><li>[hypervisor].shared_fs 为 virtio-9p</li></ul><p>通过以下命令创建一个 VM 模板：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory init</span></span><br><span class="line">vm factory initialized</span><br></pre></td></tr></table></figure><p>创建的模板默认保存在 &#x2F;run&#x2F;vc&#x2F;vm&#x2F;template，可以通过 [factory].template_path 指定：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> /run/vc/vm/template</span></span><br><span class="line">memory  state</span><br></pre></td></tr></table></figure><p>模板通过以下命令销毁：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory destroy</span></span><br><span class="line">vm factory destroyed</span><br></pre></td></tr></table></figure><p>如果不想手动调用 kata-runtime factory init，在启用 VM templating 后，默认创建的第一个 Kata 容器将自动创建一个 VM 模板。</p><h1 id="kata-runtime"><a href="#kata-runtime" class="headerlink" title="kata-runtime"></a>kata-runtime</h1><p>kata-runtime 是一个命令行工具，支持以下功能：</p><h2 id="check-kata-check"><a href="#check-kata-check" class="headerlink" title="check (kata-check)"></a>check (kata-check)</h2><p>检测当前环境是否可以运行 Kata Containers 以及版本是否正确。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime check --verbose</span></span><br><span class="line">INFO[0000] IOMMUPlatform is disabled by default.        </span><br><span class="line">WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=29825 source=runtime</span><br><span class="line">INFO[0000] CPU property found                            arch=amd64 description=&quot;Intel Architecture CPU&quot; name=GenuineIntel pid=29825 source=runtime type=attribute</span><br><span class="line">INFO[0000] CPU property found                            arch=amd64 description=&quot;Virtualization support&quot; name=vmx pid=29825 source=runtime type=flag</span><br><span class="line">INFO[0000] CPU property found                            arch=amd64 description=&quot;64Bit CPU&quot; name=lm pid=29825 source=runtime type=flag</span><br><span class="line">INFO[0000] CPU property found                            arch=amd64 description=SSE4.1 name=sse4_1 pid=29825 source=runtime type=flag</span><br><span class="line">INFO[0000] kernel property found                         arch=amd64 description=&quot;Intel KVM&quot; name=kvm_intel pid=29825 source=runtime type=module</span><br><span class="line">INFO[0000] kernel property found                         arch=amd64 description=&quot;Kernel-based Virtual Machine&quot; name=kvm pid=29825 source=runtime type=module</span><br><span class="line">INFO[0000] kernel property found                         arch=amd64 description=&quot;Host kernel accelerator for virtio&quot; name=vhost pid=29825 source=runtime type=module</span><br><span class="line">INFO[0000] kernel property found                         arch=amd64 description=&quot;Host kernel accelerator for virtio network&quot; name=vhost_net pid=29825 source=runtime type=module</span><br><span class="line">INFO[0000] kernel property found                         arch=amd64 description=&quot;Host Support for Linux VM Sockets&quot; name=vhost_vsock pid=29825 source=runtime type=module</span><br><span class="line">System is capable of running Kata Containers</span><br><span class="line">INFO[0000] device available                              arch=amd64 check-type=full device=/dev/kvm name=kata-runtime pid=29825 source=runtime</span><br><span class="line">INFO[0000] feature available                             arch=amd64 check-type=full feature=create-vm name=kata-runtime pid=29825 source=runtime</span><br><span class="line">System can currently create Kata Containers</span><br></pre></td></tr></table></figure><p>可选的 flags 包括：</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–check-version-only</td><td>仅对比前使用版本和最新可用版本（需要网络支持，且非 root 用户）</td></tr><tr><td>–include-all-releases</td><td>包含过滤预发布的版本</td></tr><tr><td>–no-network-checks, -n</td><td>不借助网络执行检测，该参数等价于设置 KATA_CHECK_NO_NETWORK 环境变量</td></tr><tr><td>–only-list-releases</td><td>仅列出较新的可用版本（需要网络支持，且非 root 用户）</td></tr><tr><td>–strict, -s</td><td>进行严格检查</td></tr><tr><td>–verbose, -v</td><td>展示详细的检查项</td></tr></tbody></table><h2 id="env-kata-env"><a href="#env-kata-env" class="headerlink" title="env (kata-env)"></a>env (kata-env)</h2><p>Kata Containers 配置展示，默认输出格式为 TOML。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">env</span></span> </span><br><span class="line">[Kernel]</span><br><span class="line">  Path = &quot;/opt/kata/share/kata-containers/vmlinux-5.19.2-96&quot;</span><br><span class="line">  Parameters = &quot;systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.log=debug agent.debug_console agent.debug_console_vport=1026&quot;</span><br><span class="line"></span><br><span class="line">[Meta]</span><br><span class="line">  Version = &quot;1.0.26&quot;</span><br><span class="line"></span><br><span class="line">[Image]</span><br><span class="line">  Path = &quot;/opt/kata/share/kata-containers/kata-clearlinux-latest.image&quot;</span><br><span class="line"></span><br><span class="line">[Initrd]</span><br><span class="line">  Path = &quot;&quot;</span><br><span class="line"></span><br><span class="line">[Hypervisor]</span><br><span class="line">  MachineType = &quot;q35&quot;</span><br><span class="line">  Version = &quot;QEMU emulator version 6.2.0 (kata-static)\nCopyright (c) 2003-2021 Fabrice Bellard and the QEMU Project developers&quot;</span><br><span class="line">  Path = &quot;/opt/kata/bin/qemu-system-x86_64&quot;</span><br><span class="line">  BlockDeviceDriver = &quot;virtio-scsi&quot;</span><br><span class="line">  EntropySource = &quot;/dev/urandom&quot;</span><br><span class="line">  SharedFS = &quot;virtio-fs&quot;</span><br><span class="line">  VirtioFSDaemon = &quot;/opt/kata/libexec/virtiofsd&quot;</span><br><span class="line">  SocketPath = &quot;&quot;</span><br><span class="line">  Msize9p = 8192</span><br><span class="line">  MemorySlots = 10</span><br><span class="line">  PCIeRootPort = 2</span><br><span class="line">  HotplugVFIOOnRootBus = true</span><br><span class="line">  Debug = true</span><br><span class="line"></span><br><span class="line">[Runtime]</span><br><span class="line">  Path = &quot;/usr/local/bin/kata-runtime&quot;</span><br><span class="line">  Debug = true</span><br><span class="line">  Trace = false</span><br><span class="line">  DisableGuestSeccomp = true</span><br><span class="line">  DisableNewNetNs = false</span><br><span class="line">  SandboxCgroupOnly = false</span><br><span class="line">  [Runtime.Config]</span><br><span class="line">    Path = &quot;/etc/kata-containers/configuration.toml&quot;</span><br><span class="line">  [Runtime.Version]</span><br><span class="line">    OCI = &quot;1.0.2-dev&quot;</span><br><span class="line">    [Runtime.Version.Version]</span><br><span class="line">      Semver = &quot;3.0.0&quot;</span><br><span class="line">      Commit = &quot;e2a8815ba46360acb8bf89a2894b0d437dc8548a-dirty&quot;</span><br><span class="line">      Major = 3</span><br><span class="line">      Minor = 0</span><br><span class="line">      Patch = 0</span><br><span class="line"></span><br><span class="line">[Host]</span><br><span class="line">  Kernel = &quot;4.18.0-305.43.25.ar.el7.x86_64&quot;</span><br><span class="line">  Architecture = &quot;amd64&quot;</span><br><span class="line">  VMContainerCapable = true</span><br><span class="line">  SupportVSocks = true</span><br><span class="line">  [Host.Distro]</span><br><span class="line">    Name = &quot;CentOS Linux&quot;</span><br><span class="line">    Version = &quot;7&quot;</span><br><span class="line">  [Host.CPU]</span><br><span class="line">    Vendor = &quot;GenuineIntel&quot;</span><br><span class="line">    Model = &quot;QEMU Virtual CPU version (cpu64-rhel6)&quot;</span><br><span class="line">    CPUs = 8</span><br><span class="line">  [Host.Memory]</span><br><span class="line">    Total = 12057632</span><br><span class="line">    Free = 3352124</span><br><span class="line">    Available = 8508112</span><br><span class="line"></span><br><span class="line">[Agent]</span><br><span class="line">  Debug = true</span><br><span class="line">  Trace = false</span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–json</td><td>以 JSON 格式展示</td></tr></tbody></table><h2 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h2><p>借助 debug console，进入 VM 控制台，需要 [agent].debug_console_enabled 设置为 true。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 Pod 而言是其 SandboxID</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime <span class="built_in">exec</span> 27ab74433f11c0b64e404a841d5e2f8296a723ebfa4e598b4d9d32871173b82c</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–kata-debug-port</td><td>debug console 监听的端口，默认为 1026 或者 0</td></tr></tbody></table><h2 id="metrics"><a href="#metrics" class="headerlink" title="metrics"></a>metrics</h2><p>收集与用于运行 sandbox 的基础设施相关的指标，例如 runtime、agent、hypervisor 等。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 Pod 而言是其 SandboxID</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime metrics 27ab74433f11c0b64e404a841d5e2f8296a723ebfa4e598b4d9d32871173b82c</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP kata_hypervisor_fds Open FDs <span class="keyword">for</span> hypervisor.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE kata_hypervisor_fds gauge</span></span><br><span class="line">kata_hypervisor_fds 122</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP kata_hypervisor_io_stat Process IO statistics.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE kata_hypervisor_io_stat gauge</span></span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;cancelledwritebytes&quot;&#125; 0</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;rchar&quot;&#125; 5.915546e+06</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;readbytes&quot;&#125; 1.1665408e+07</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;syscr&quot;&#125; 95522</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;syscw&quot;&#125; 202276</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;wchar&quot;&#125; 3.715404e+06</span><br><span class="line">kata_hypervisor_io_stat&#123;item=&quot;writebytes&quot;&#125; 2.097152e+06</span><br></pre></td></tr></table></figure><h2 id="direct-volume"><a href="#direct-volume" class="headerlink" title="direct-volume"></a>direct-volume</h2><p>管理 Kata Containers 的直通卷。*具体使用方式参考 <strong>Kata Containers Block Volume 直通</strong>说明。*</p><p><strong>add</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume add --volume-path /var/lib/kubelet/pods/8c3d29ad-84b8-45f0-9fcc-8e16778cb3cb/volumes/kubernetes.io~csi/pvc-a950ed68-622c-4ec4-81fa-506f16de2196/mount --mount-info \&#123;\&quot;volume-type\&quot;:\&quot;block\&quot;,\&quot;device\&quot;:\&quot;/dev/sdm\&quot;,\&quot;fstype\&quot;:\&quot;xfs\&quot;\&#125;</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr><tr><td>–mount-info</td><td>管理卷挂载的详情信息</td></tr></tbody></table><p><strong>remove</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume delete --volume-path /var/lib/kubelet/pods/8c3d29ad-84b8-45f0-9fcc-8e16778cb3cb/volumes/kubernetes.io~csi/pvc-a950ed68-622c-4ec4-81fa-506f16de2196/mount</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr></tbody></table><p><strong>stats</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume stats --volume-path /var/lib/kubelet/pods/8c3d29ad-84b8-45f0-9fcc-8e16778cb3cb/volumes/kubernetes.io~csi/pvc-a950ed68-622c-4ec4-81fa-506f16de2196/mount</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr></tbody></table><p><strong>resize</strong></p><p><em>截至 Kata Containers 3.0.0，社区仍未实现 VM 中 Kata agent 的逻辑</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime direct-volume resize --volume-path /var/lib/kubelet/pods/8c3d29ad-84b8-45f0-9fcc-8e16778cb3cb/volumes/kubernetes.io~csi/pvc-a950ed68-622c-4ec4-81fa-506f16de2196/mount --size 1756519562</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–volume-path</td><td>待操作的目标卷路径</td></tr><tr><td>–size</td><td>调整后的预期卷大小（单位为：Byte）</td></tr></tbody></table><h2 id="factory-1"><a href="#factory-1" class="headerlink" title="factory"></a>factory</h2><p>管理 Kata Containers 的 VM factory。<em>具体使用方式参考 <strong>VM factory</strong> 说明。</em></p><p><strong>init</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory init</span></span><br><span class="line">vm factory initialized</span><br></pre></td></tr></table></figure><p><strong>status</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory status</span></span><br><span class="line">vm factory is on</span><br></pre></td></tr></table></figure><p><strong>destroy</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime factory destroy</span></span><br><span class="line">vm factory destroyed</span><br></pre></td></tr></table></figure><h2 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h2><p>管理 VM 中的 iptables 信息。</p><p><strong>get</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime iptables get --sandbox-id xxx --v6</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–sandbox-id</td><td>待操作的 Sandbox ID</td></tr><tr><td>–v6</td><td>获取 IPV6 的 iptables</td></tr></tbody></table><p><strong>set</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-runtime iptables <span class="built_in">set</span> --sandbox-id xxx --v6 ./iptables</span></span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–sandbox-id</td><td>待操作的 Sandbox ID</td></tr><tr><td>–v6</td><td>设置 IPV6 的 iptables</td></tr></tbody></table><h1 id="kata-monitor"><a href="#kata-monitor" class="headerlink" title="kata-monitor"></a>kata-monitor</h1><p>Kata monitor 是一个守护进程，能够收集和暴露在同一 host 上运行的所有 Kata 容器工作负载相关的指标。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kata-monitor</span></span><br><span class="line">INFO[0000] announce                                      app=kata-monitor arch=amd64 git-commit=fcad969e5200607df3b0b31983cc64488e156e99 go-version=go1.16.10 listen-address=&quot;127.0.0.1:8090&quot; log-level=info os=linux runtime-endpoint=/run/containerd/containerd.sock version=0.3.0</span><br></pre></td></tr></table></figure><p>可选的 flags 包括</p><table><thead><tr><th>名称</th><th>含义</th></tr></thead><tbody><tr><td>–listen-address</td><td>监听 HTTP 请求的地址，默认为 127.0.0.1:8090</td></tr><tr><td>–log-level</td><td>服务日志级别，可选有 trace&#x2F;debug&#x2F;info&#x2F;warn&#x2F;error&#x2F;fatal&#x2F;panic，默认为 info</td></tr><tr><td>–runtime-endpoint</td><td>CRI 容器运行时服务的 socket 地址，默认为 &#x2F;run&#x2F;containerd&#x2F;containerd.sock</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Kata Containers 在 Kubernetes 集群场景中的配置与基础使用示例</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
  <entry>
    <title>「 Kata Containers 」架构与组件概述</title>
    <link href="http://shenxianghong.github.io/2021/04/06/2021-04-06%20Kata%20Containers%20%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0/"/>
    <id>http://shenxianghong.github.io/2021/04/06/2021-04-06%20Kata%20Containers%20%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0/</id>
    <published>2021-04-05T16:00:00.000Z</published>
    <updated>2023-06-19T01:18:06.996Z</updated>
    
    <content type="html"><![CDATA[<div align=center><img width="200" style="border: 0px" src="/gallery/kata-containers/logo.svg"></div><hr><blockquote><p>based on <strong>2.1.1</strong></p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Kata Containers 是一个开源项目，它采用轻量化虚拟机作为容器的隔离来构建一个安全容器运行时，而其虚拟化技术作为容器的二层保护为负载提供了更好的隔离性，这使得 Kata Containers 兼具传统容器的形态和虚拟机的安全性。 早在 2015 年，来自英特尔开源技术中心的工程师就开始探索采用 英特尔® 虚拟技术（英特尔® Virtualization Technology，英特尔® VT）来提高容器的安全隔离性，并以此发起了英特尔® Clear Containers 开源项目，与此同时，来自 Hyper.sh（一家中国的高科技初创公司）的工程师也发起了 runV10 开源项目，这两个项目采用的技术和目的都非常相似，都是为了将容器置于一个安全“沙箱“，以便进一步促进该技术发展和成熟。随后在 2017 年，英特尔和 Hyper.sh 团队将这两个开源项目在社区合并成了一个新的项目 Kata Containers。 传统虚拟机（VMs）可提供硬件隔离，而容器可快速响应，且占用空间相对较小，Kata Containers 将这两者的优势完美结合了起来。 每个容器或 Pod 都在自己单独的虚拟机中启动， 并不再能够访问主机内核，杜绝了恶意代码侵入其它相临容器的可能。由于 Kata Containers 同时具备硬件隔离，也使得互不信任的租户，甚至于生产应用或前生产应用都能够在同一集群内安全运行，从而使得在裸机上运行容器即服务（Containers as a Service, CaaS）成为可能。</p><h1 id="Assets"><a href="#Assets" class="headerlink" title="Assets"></a>Assets</h1><p>Kata Containers 创建一个 VM，在其中运行一个或多个容器。需要通过启动 hypervisor 创建虚拟机来实现这一点。hypervisor 需要两个 assets 来完成这项任务：一个 Linux 内核和一个用于引导 VM 的小型根文件系统镜像。</p><h2 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a>kernel</h2><p>guest 内核传递到 hypervisor 用于引导虚拟机。 Kata Containers 中提供了一个对虚机启动时间和内存占用做了高度优化的默认内核，仅提供了容器工作负载所需的必要服务。该内核是基于最新的上游 Linux 内核做的定制化。</p><h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><p>hypervisor 使用一个镜像文件，该文件提供了一个最小的根文件系统，供 guest 内核用来启动 VM 和托管 Kata 容器。 Kata Containers 支持基于 initrd 和 rootfs 的最小 guest 镜像（但是，并非所有的 hypervisor 均支持）。默认包同时提供 image 和 initrd，两者都是使用 osbuilder 工具创建的。</p><h3 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h3><p>默认打包的 rootfs 映像，也称 mini O&#x2F;S，是一个高度优化的容器引导系统。</p><p>使用此镜像启动 Kata 容器的背后流程为：</p><ol><li>运行时将启动 hypervisor</li><li>hypervisor 将使用 guest 内核启动 rootfs 镜像</li><li>内核将在 VM 根环境中以 PID 1（systemd）启动 init 守护进程</li><li>在 rootfs 上下文中运行的 systemd 将在 VM 的根上下文中启动 kata-agent</li><li>kata-agent 将创建一个新的容器环境，将其根文件系统设置为用户请求的文件系统（例如 Ubuntu、busybox 等）</li><li>kata-agent 将在新容器内执行容器启动命令</li></ol><p>下表总结了默认的 rootfs，显示了创建的环境、在这些环境中运行的服务（适用于所有平台）以及每个服务使用的根文件系统：</p><table><thead><tr><th>Process</th><th>Environment</th><th>systemd service?</th><th>rootfs</th><th>User accessible</th><th>Notes</th></tr></thead><tbody><tr><td>systemd</td><td>VM root</td><td>n&#x2F;a</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/guest-assets.md#guest-image">VM guest image</a></td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console">debug console</a></td><td>The init daemon, running as PID 1</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/README.md#agent">Agent</a></td><td>VM root</td><td>yes</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/guest-assets.md#guest-image">VM guest image</a></td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console">debug console</a></td><td>Runs as a systemd service</td></tr><tr><td><code>chronyd</code></td><td>VM root</td><td>yes</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/guest-assets.md#guest-image">VM guest image</a></td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console">debug console</a></td><td>Used to synchronise the time with the host</td></tr><tr><td>container workload (<code>sh(1)</code> in <a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/example-command.md">the example</a>)</td><td>VM container</td><td>no</td><td>User specified (Ubuntu in <a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/example-command.md">the example</a>)</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/README.md#exec-command">exec command</a></td><td>Managed by the agent</td></tr></tbody></table><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/rootfs.png"></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 11:53 ?        00:00:00 /sbin/init</span><br><span class="line">root         2     0  0 11:53 ?        00:00:00 [kthreadd]</span><br><span class="line">&lt;skip...&gt;</span><br><span class="line">root        61     1  0 11:53 ?        00:00:00 /usr/bin/kata-agent</span><br><span class="line">root        71    61  0 11:53 ?        00:00:00 /pause</span><br><span class="line">root        73    61  0 11:53 ?        00:00:00 tail -f /dev/null</span><br><span class="line">root        75    61  0 11:55 pts/0    00:00:00 [bash]</span><br><span class="line">root        77    75  0 11:55 pts/0    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./usr/bin/kata-agent</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;announce&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:56:42.558066805+08:00&quot;,&quot;source&quot;:&quot;agent&quot;,&quot;pid&quot;:&quot;88325&quot;,&quot;subsystem&quot;:&quot;root&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;version&quot;:&quot;0.1.0&quot;,&quot;api-version&quot;:&quot;0.0.1&quot;,&quot;agent-version&quot;:&quot;2.1.0&quot;,&quot;config&quot;:&quot;AgentConfig &#123; debug_console: false, dev_mode: false, log_level: Info, hotplug_timeout: 3s, debug_console_vport: 0, log_vport: 0, container_pipe_size: 0, server_addr: \&quot;vsock://-1:1024\&quot;, unified_cgroup_hierarchy: false &#125;&quot;,&quot;agent-type&quot;:&quot;rust&quot;,&quot;agent-commit&quot;:&quot;2.1.0-645e950b8e0e238886adbff695a793126afb584f&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;starting uevents handler&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:56:42.558356885+08:00&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;source&quot;:&quot;agent&quot;,&quot;subsystem&quot;:&quot;uevent&quot;,&quot;pid&quot;:&quot;88325&quot;,&quot;version&quot;:&quot;0.1.0&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;ttRPC server started&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:56:42.558522099+08:00&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;source&quot;:&quot;agent&quot;,&quot;version&quot;:&quot;0.1.0&quot;,&quot;subsystem&quot;:&quot;rpc&quot;,&quot;pid&quot;:&quot;88325&quot;,&quot;address&quot;:&quot;vsock://-1:1024&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="initrd"><a href="#initrd" class="headerlink" title="initrd"></a>initrd</h3><p>initrd 镜像是一个压缩的 cpio(1) 归档文件，它是从加载到内存中的 rootfs 创建的，并用作 Linux 启动过程的一部分。在启动过程中，内核将其解压到一个特殊的 tmpfs 挂载实例中，该实例成为初始根文件系统。</p><p>使用此镜像启动 Kata 容器的背后流程为：</p><ol><li>运行时将启动 hypervisor</li><li>hypervisor 将使用 guest 内核启动 initrd 镜像</li><li>内核将在 VM 根环境中以 PID 1（kata-agent）启动 init 守护进程</li><li>kata-agent 将创建一个新的容器环境，将其根文件系统设置为用户请求的文件系统（例如 Ubuntu、busybox 等）</li><li>kata-agent 将在新容器内执行容器启动命令</li></ol><p>下表总结了默认的 initrd，显示了创建的环境、在这些环境中运行的服务（适用于所有平台）以及每个服务使用的根文件系统：</p><table><thead><tr><th>Process</th><th>Environment</th><th>rootfs</th><th>User accessible</th><th>Notes</th></tr></thead><tbody><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/README.md#agent">Agent</a></td><td>VM root</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/guest-assets.md#guest-image">VM guest image</a></td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console">debug console</a></td><td>Runs as the init daemon (PID 1)</td></tr><tr><td>container workload</td><td>VM container</td><td>User specified (Ubuntu in this example)</td><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/README.md#exec-command">exec command</a></td><td>Managed by the agent</td></tr></tbody></table><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/initrd.png"></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 06:23 hvc0     00:00:02 /init</span><br><span class="line">root         2     0  0 06:23 ?        00:00:00 [kthreadd]</span><br><span class="line">&lt;skip...&gt;</span><br><span class="line">root        41     1  0 06:23 hvc0     00:00:00 /pause</span><br><span class="line">root        43     1  0 06:23 hvc0     00:00:00 tail -f /dev/null</span><br><span class="line">root        45     1  0 06:24 pts/0    00:00:00 [bash]</span><br><span class="line">root        58    45  0 06:27 pts/0    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./sbin/init</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;announce&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:58:37.454291069+08:00&quot;,&quot;source&quot;:&quot;agent&quot;,&quot;pid&quot;:&quot;66236&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;subsystem&quot;:&quot;root&quot;,&quot;version&quot;:&quot;0.1.0&quot;,&quot;api-version&quot;:&quot;0.0.1&quot;,&quot;agent-type&quot;:&quot;rust&quot;,&quot;agent-commit&quot;:&quot;2.1.0-645e950b8e0e238886adbff695a793126afb584f&quot;,&quot;agent-version&quot;:&quot;2.1.0&quot;,&quot;config&quot;:&quot;AgentConfig &#123; debug_console: false, dev_mode: false, log_level: Info, hotplug_timeout: 3s, debug_console_vport: 0, log_vport: 0, container_pipe_size: 0, server_addr: \&quot;vsock://-1:1024\&quot;, unified_cgroup_hierarchy: false &#125;&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;starting uevents handler&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:58:37.455243334+08:00&quot;,&quot;version&quot;:&quot;0.1.0&quot;,&quot;subsystem&quot;:&quot;uevent&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;pid&quot;:&quot;66236&quot;,&quot;source&quot;:&quot;agent&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;ttRPC server started&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;ts&quot;:&quot;2021-07-14T14:58:37.455325746+08:00&quot;,&quot;version&quot;:&quot;0.1.0&quot;,&quot;pid&quot;:&quot;66236&quot;,&quot;subsystem&quot;:&quot;rpc&quot;,&quot;source&quot;:&quot;agent&quot;,&quot;name&quot;:&quot;kata-agent&quot;,&quot;address&quot;:&quot;vsock://-1:1024&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><table><thead><tr><th>Image type</th><th>Default distro</th><th>Init daemon</th><th>Reason</th><th>Notes</th></tr></thead><tbody><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/background.md#root-filesystem-image">image</a></td><td><a href="https://clearlinux.org/">Clear Linux</a> (for x86_64 systems)</td><td>systemd</td><td>Minimal and highly optimized</td><td>systemd offers flexibility</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/guest-assets.md#initrd-image">initrd</a></td><td><a href="https://alpinelinux.org/">Alpine Linux</a></td><td>Kata <a href="https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/README.md#agent">agent</a> (as no systemd support)</td><td>Security hardened and tiny C library</td><td></td></tr></tbody></table><h2 id="osbuilder"><a href="#osbuilder" class="headerlink" title="osbuilder"></a>osbuilder</h2><p>osbuilder 本身是 Kata Containers 项目中的一个模块，主要负责构建 guest OS 的引导镜像。</p><p>Kata Containers 支持两种引导镜像：rootfs 和 initrd。无论哪种方式，默认都会将 kata-agent 编译到镜像中，在对 kata-agent 有定制化需求的场景下，可以手动编译后添加到镜像中。</p><h1 id="Virtualization"><a href="#Virtualization" class="headerlink" title="Virtualization"></a>Virtualization</h1><p>Kata 容器是在传统 namespace 隔离之上创建的以硬件虚拟化为基础的第二层隔离。 Kata 启动一个轻量级虚拟机，并使用 guest 中特供的内核来承载容器工作负载。</p><h2 id="接口映射"><a href="#接口映射" class="headerlink" title="接口映射"></a>接口映射</h2><p>Kata 容器的典型部署场景是借助 CRI 实现在 Kubernetes 中进行。在每个节点上，Kubelet 将与 CRI 实现者（如 Containerd 或 CRI-O 等）交互，CRI 实现者将与 Kata Containers（基于 OCI 规范的底层运行时）交互。</p><div align=center><img width="700" style="border: 0px" src="/gallery/kata-containers/virtual-map.png"></div><h2 id="hypervisor（VMM）"><a href="#hypervisor（VMM）" class="headerlink" title="hypervisor（VMM）"></a>hypervisor（VMM）</h2><p>Kata Containers 本身支持多种 hypervisor 工具，如 QEMU、cloud-hypervisor、firecracker、ACRN 和 Dragonball（Kata 3.0 引入）。</p><table><thead><tr><th>Hypervisor</th><th>Written in</th><th>Architectures</th><th>Type</th><th>Configuration file</th></tr></thead><tbody><tr><td><a href="https://projectacrn.org/">ACRN</a></td><td>C</td><td>x86_64</td><td>Type 1 (bare metal)</td><td>configuration-acrn.toml</td></tr><tr><td><a href="https://github.com/cloud-hypervisor/cloud-hypervisor">Cloud Hypervisor</a></td><td>rust</td><td>aarch64, x86_64</td><td>Type 2 (<a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine">KVM</a>)</td><td>configuration-clh.toml</td></tr><tr><td><a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a></td><td>rust</td><td>aarch64, x86_64</td><td>Type 2 (<a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine">KVM</a>)</td><td>configuration-fc.toml</td></tr><tr><td><a href="http://www.qemu-project.org/">QEMU</a></td><td>C</td><td>all</td><td>Type 2 (<a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine">KVM</a>)</td><td>configuration-qemu.toml</td></tr><tr><td><a href="https://github.com/openanolis/dragonball-sandbox">Dragonball</a></td><td>rust</td><td>aarch64, x86_64</td><td>Type 2 (<a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine">KVM</a>)</td><td>configuration-dragonball.toml</td></tr></tbody></table><p><strong>异同点参考</strong></p><table><thead><tr><th>Hypervisor</th><th>Summary</th><th>Features</th><th>Limitations</th><th>Container Creation speed</th><th>Memory density</th><th>Use cases</th><th>Comment</th></tr></thead><tbody><tr><td><a href="https://projectacrn.org/">ACRN</a></td><td>Safety critical and real-time workloads</td><td></td><td></td><td>excellent</td><td>excellent</td><td>Embedded and IOT systems</td><td>For advanced users</td></tr><tr><td><a href="https://github.com/cloud-hypervisor/cloud-hypervisor">Cloud Hypervisor</a></td><td>Low latency, small memory footprint, small attack surface</td><td>Minimal</td><td></td><td>excellent</td><td>excellent</td><td>High performance modern cloud workloads</td><td></td></tr><tr><td><a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a></td><td>Very slimline</td><td>Extremely minimal</td><td>Doesn’t support all device types</td><td>excellent</td><td>excellent</td><td>Serverless &#x2F; FaaS</td><td></td></tr><tr><td><a href="http://www.qemu-project.org/">QEMU</a></td><td>Lots of features</td><td>Lots</td><td></td><td>good</td><td>good</td><td>Good option for most users</td><td></td></tr><tr><td><a href="https://github.com/openanolis/dragonball-sandbox">Dragonball</a></td><td>Built-in VMM, low CPU and memory overhead</td><td>Minimal</td><td></td><td>excellent</td><td>excellent</td><td>Optimized for most container workloads</td><td>out-of-the-box Kata Containers experience</td></tr></tbody></table><h3 id="QEMU-x2F-KVM"><a href="#QEMU-x2F-KVM" class="headerlink" title="QEMU&#x2F;KVM"></a>QEMU&#x2F;KVM</h3><p>Kata Containers with QEMU 与 Kubernetes 完全兼容（此外，Kata 社区对 QEMU 作了<a href="https://github.com/kata-containers/kata-containers/tree/main/tools/packaging/qemu/patches">定制化的 patch 补丁</a>）</p><p>取决于不同的 host 架构，Kata Containers 支持各种机器类型（machine），例如 x86 系统上的 q35、ARM 系统上的 virt 和 IBM Power 系统上的 pseries。</p><p>使用到的设备和特性有：</p><ul><li>virtio VSOCK or virtio serial</li><li>virtio block or virtio SCSI</li><li><a href="https://www.redhat.com/en/virtio-networking-series">virtio net</a></li><li>virtio fs or virtio 9p (recommend: virtio fs)</li><li>VFIO</li><li>hotplug</li><li>machine accelerators</li></ul><p>Kata 容器中使用加速器（accelerators）和热插拔来管理资源限制、缩短启动时间并减少内存占用。</p><p><strong>加速器</strong></p><p>加速器是特定于体系结构的，可用于提高性能并启用机器类型的特定功能。 Kata 容器中支持以下机器加速器：</p><ul><li><p>NVDIMM</p><p>此机器加速器特定于 x86，并且仅支持 q35 机器类型。 nvdimm 用于将根文件系统作为持久内存设备提供给 VM</p></li></ul><p><strong>设备热插拔</strong></p><p>Kata Containers VM 为了更快的启动时间和减少内存占用，往往是以最少的资源启动。在容器启动过程中，设备会热插拔到 VM 中。例如，当指定了额外 CPU 时，便是通过热添加的方式追加资源。 </p><p>Kata Containers 支持热添加以下设备：</p><ul><li>Virtio block</li><li>Virtio SCSI</li><li>VFIO</li><li>CPU</li></ul><h3 id="Firecracker-x2F-KVM"><a href="#Firecracker-x2F-KVM" class="headerlink" title="Firecracker&#x2F;KVM"></a>Firecracker&#x2F;KVM</h3><p>Firecracker 是基于 <a href="https://github.com/rust-vmm">rust-VMM</a> 的衍生项目，支持的设备类型有限，但能提供更轻的体量和攻击面，专注于 FaaS 场景。因此，带有 Firecracker VMM 的 Kata 容器支持 CRI API 的一个子集。 Firecracker 不支持文件系统共享，仅支持基于块存储驱动程序。 Firecracker 不支持设备热插拔，也不支持 VFIO。因此，带有 Firecracker VMM 的 Kata Containers 不支持在启动后更新容器资源，也不支持设备透传。</p><p>支持的设备类型：</p><ul><li>virtio VSOCK</li><li>virtio block</li><li>virtio net</li></ul><h3 id="Cloud-Hypervisor-x2F-KVM"><a href="#Cloud-Hypervisor-x2F-KVM" class="headerlink" title="Cloud Hypervisor&#x2F;KVM"></a>Cloud Hypervisor&#x2F;KVM</h3><p>Cloud Hypervisor 同样是基于 <a href="https://github.com/rust-vmm">rust-VMM</a> 的衍生项目，旨在为运行现代云工作负载提供更小的占用空间和更小的攻击面。具有 Cloud Hypervisor 的 Kata Containers 提供与 Kubernetes 的几乎完全兼容性，与 QEMU 能力相当。从 Kata Containers 1.12 和 2.0.0 版本开始，Cloud Hypervisor 配置支持 CPU 和内存大小调整、设备热插拔（磁盘和 VFIO）、通过 virtio-fs 共享文件系统、基于块的卷、从 VM 镜像启动由 pmem 设备支持，并为每个 VMM 线程（例如所有 virtio 设备工作线程）提供细粒度的 seccomp 过滤器。</p><p>支持的设备类型与特性：</p><ul><li>virtio VSOCK or virtio serial</li><li>virtio block</li><li>virtio net</li><li>virtio fs</li><li>virtio pmem</li><li>VFIO</li><li>hotplug</li><li>seccomp filters</li><li><a href="https://github.com/cloud-hypervisor/cloud-hypervisor/blob/main/vmm/src/api/openapi/cloud-hypervisor.yaml">HTTP OpenAPI</a></li></ul><p><strong>总结</strong></p><table><thead><tr><th>Solution</th><th>release introduced</th><th>brief summary</th></tr></thead><tbody><tr><td>Cloud Hypervisor</td><td>1.10</td><td>upstream Cloud Hypervisor with rich feature support, e.g. hotplug, VFIO and FS sharing</td></tr><tr><td>Firecracker</td><td>1.5</td><td>upstream Firecracker, rust-VMM based, no VFIO, no FS sharing, no memory&#x2F;CPU hotplug</td></tr><tr><td>QEMU</td><td>1.0</td><td>upstream QEMU, with support for hotplug and filesystem sharing</td></tr></tbody></table><h1 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h1><p>Kata Containers 与现有标准运行时兼容。从存储的角度来看，这意味着容器工作负载可能使用的存储量没有限制。由于 cgroups 无法设置存储分配限制，如果希望限制容器使用的存储量，请考虑使用现有设施，例如 quota(1) 限制或 device mapper 限制。</p><h2 id="virtio-SCSI"><a href="#virtio-SCSI" class="headerlink" title="virtio SCSI"></a>virtio SCSI</h2><p>virtio-scsi 用于将工作负载镜像（例如 busybox:latest）共享到 VM 内的容器环境中。现阶段，Kata Containers 支持 virtio SCSI 和 virtio BLK，后者由于较多限制已不做推荐。</p><h2 id="virtio-FS"><a href="#virtio-FS" class="headerlink" title="virtio FS"></a>virtio FS</h2><p>virtio-fs（VIRTIO）覆盖文件系统挂载点来共享工作负载镜像。kata-agent 使用此挂载点作为容器进程的根文件系统。</p><p>对于 virtio-fs，运行时为每个创建的 VM 启动一个 virtiofsd 守护进程（在主机上下文中运行）。</p><p>Kata Containers 使用轻量级虚拟机和硬件虚拟化技术来提供更强隔离，以构建安全的容器运行时。但也正是因为使用了虚拟机，容器的根文件系统无法像 runC 那样直接使用主机上构建好的目录，而需要有一种方法把 host 上的目录共享给 guest。</p><p>在此之前，有两种方法能够透传 host 目录或者数据给 guest，一种是基于 file 的方案，一个是基于 block 的方案。而这两种方案各有利弊，这里分别以 9pfs 和 devicemapper 为例来说明：</p><table><thead><tr><th></th><th>9pfs</th><th>devicemapper</th></tr></thead><tbody><tr><td>优势</td><td>使用 host 的 overlayfs，充分利用 host page cache</td><td>性能较好，POSIX 语义兼容性较好</td></tr><tr><td>痛点</td><td>基于网络协议，未对虚拟化场景做优化，性能较差；POSIX 语义兼容性不好</td><td>无法利用 host page cache，需要维护 lvm volume</td></tr></tbody></table><p>针对以上两个方案的痛点和优势，virtio-fs 在某种程度上做了很好的互补，在 Kata Containers 中，支持两种文件共享方式：virtio-fs 和 virtio-9p，在 Kata Containers 2.x 之后，virtio-fs 作为默认且推荐的方案选择。</p><p>virtio-fs 本身采用类似于 CS 的架构，选择 FUSE 作为文件系统，而非网络文件系统协议。server 端是位于 host 上的 virtiofsd，用于向 guest 提供 fuse 服务；client 端是把 guest kernel 抽象成一个 fuse client，用于挂载 host 上导出的目录。两者之间通过 vhost_user 建立连接。</p><p>最大的特点是利用了 VM 和 VMM 同时部署在一个 host 上的，数据的共享访问都是通过共享内存的方式，避免了 VM 和 VMM 之间的网络通讯，共享内存访问比基于网络文件系统协议访问要更轻量级也有更好的本地文件系统语义和一致性。在面对多 guest 要 mmap 同一个文件的时候，virtio-fs 会将该文件 mmap 到 QEMU 的进程空间里，其余的 guest 通过 DAX 直接访问。</p><div align=center><img width="400" style="border: 0px" src="/gallery/kata-containers/virtiofs.png"></div><div align=center><img width="700" style="border: 0px" src="/gallery/kata-containers/virtiofs-detail.png"></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">qemu 进程参数节选</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef | grep qemu</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">/usr/bin/qemu-system-x86_64</span><br><span class="line">-name sandbox-f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9</span><br><span class="line">-uuid 50041ac8-a9ed-4a60-9db1-44a55b2343d8</span><br><span class="line">-machine pc,accel=kvm,kernel_irqchip</span><br><span class="line">-cpu host,pmu=off</span><br><span class="line"> </span><br><span class="line">-device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-117410659,guest-cid=117410659 -chardev socket,id=char-25f51af992a053e1,path=/run/vc/vm/f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-25f51af992a053e1,tag=kataShared</span><br><span class="line"> </span><br><span class="line">-kernel /usr/share/kata-containers/vmlinux-5.10.25-85</span><br><span class="line">-initrd /usr/share/kata-containers/kata-containers-initrd-2021-07-14-11:02:27.932339999+0800-645e950</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">宿主机共享目录</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ll /run/kata-containers/shared/sandboxes/f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9/shared</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">total 16</span><br><span class="line">drwxr-xr-x 3 root root  60 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e</span><br><span class="line">            drwxr-xr-x 1 root root 40 Jul 19 14:57 rootfs</span><br><span class="line">-rw-rw-rw- 1 root root   0 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-1b95530f54b2fab0-termination-log</span><br><span class="line">drwxrwxrwt 3 root root 140 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-395f94e69275ce07-serviceaccount</span><br><span class="line">            lrwxrwxrwx 1 root root 13 Jul 19 14:57 ca.crt -&gt; ..data/ca.crt</span><br><span class="line">            lrwxrwxrwx 1 root root 16 Jul 19 14:57 namespace -&gt; ..data/namespace</span><br><span class="line">            lrwxrwxrwx 1 root root 12 Jul 19 14:57 token -&gt; ..data/token</span><br><span class="line">-rw-r--r-- 1 root root 212 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-45f076005d889842-hosts</span><br><span class="line">-rw-r--r-- 1 root root 103 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-70624933bdd41bd7-resolv.conf</span><br><span class="line">-rw-r--r-- 1 root root  15 Jul 19 14:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-c4568deafa816abf-hostname</span><br><span class="line">drwxr-xr-x 3 root root  60 Jul 19 14:57 f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9</span><br><span class="line">            drwxr-xr-x 1 root root 40 Jul 19 14:57 rootfs</span><br><span class="line">-rw-r--r-- 1 root root 103 Jul 19 14:57 f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9-172f4c5d001a82b4-resolv.conf</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">虚拟机 mount 点</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount | grep kataShared</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">kataShared on /run/kata-containers/shared/containers type virtiofs (rw,relatime)</span><br><span class="line">kataShared on /run/kata-containers/f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9/rootfs type virtiofs (rw,relatime)</span><br><span class="line">kataShared on /run/kata-containers/6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e/rootfs type virtiofs (rw,relatime)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">虚拟机共享目录</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l /run/kata-containers/shared/containers</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span></span><br><span class="line">total 16</span><br><span class="line">drwxr-xr-x 3 root root  60 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e</span><br><span class="line">-rw-rw-rw- 1 root root   0 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-1b95530f54b2fab0-termination-log</span><br><span class="line">drwxrwxrwt 3 root root 140 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-395f94e69275ce07-serviceaccount</span><br><span class="line">-rw-r--r-- 1 root root 212 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-45f076005d889842-hosts</span><br><span class="line">-rw-r--r-- 1 root root 103 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-70624933bdd41bd7-resolv.conf</span><br><span class="line">-rw-r--r-- 1 root root  15 Jul 19 06:57 6cc73ba11330cfbdb54bf40c77613d5f832aad01413d566ff8dabbf4e29d748e-c4568deafa816abf-hostname</span><br><span class="line">drwxr-xr-x 3 root root  60 Jul 19 06:57 f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9</span><br><span class="line">-rw-r--r-- 1 root root 103 Jul 19 06:57 f13846d4f1d58e82b2d3f461c3f2296c57992d415e32d7b41f689cf1126ee8d9-172f4c5d001a82b4-resolv.conf</span><br></pre></td></tr></table></figure><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/storage-compare.png"></div><h2 id="Devicemapper"><a href="#Devicemapper" class="headerlink" title="Devicemapper"></a>Devicemapper</h2><p>devicemapper snapshotter 是一个特例。snapshotter 使用专用的块设备而不是格式化的文件系统，并且在块级别而不是文件级别运行。用于容器根文件系统直接使用底层块设备而不是覆盖文件系统。块设备映射到覆盖层的顶部读写层。与使用 virtio-fs 共享容器文件系统相比，这种方法提供了更好的 I&#x2F;O 性能。</p><p>Kata Containers 具有热插拔添加和热插拔移除块设备的能力。这使得在 VM 启动后启动的容器可以使用块设备。</p><p>用户可以通过在容器内调用 mount(8) 来检查容器是否使用 devicemapper 块设备作为其 rootfs。如果使用 devicemapper 块设备，根文件系统（&#x2F;）将从 &#x2F;dev&#x2F;vda 挂载。用户可以通过运行时配置禁止直接挂载底层块设备。</p><h1 id="VSOCKs"><a href="#VSOCKs" class="headerlink" title="VSOCKs"></a>VSOCKs</h1><p>虚拟机中的进程可以通过以下两种方式与主机中的进程进行通信：</p><ul><li>使用串口，虚拟机中的进程可以在串口设备读&#x2F;写数据，主机中的进程可以从在 Unix socket 读&#x2F;写数据。但是，串行链接一次限制对一个进程的读&#x2F;写访问</li><li>更新、更简单的方法是 VSOCK，它可以接受来自多个客户端的连接</li></ul><p>在 Kata Containers 2.x 中实现默认采用 VSOCK 的方式（依赖 4.8 以上版本内核和 vhost_vsock 内核模块）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">.----------------------.</span><br><span class="line">| .------------------. |</span><br><span class="line">| | .-----.  .-----. | |</span><br><span class="line">| | |cont1|  |cont2| | |</span><br><span class="line">| | `-----&#x27;  `-----&#x27; | |</span><br><span class="line">| |       |   |      | |</span><br><span class="line">| |    .---------.   | |</span><br><span class="line">| |    |  agent  |   | |</span><br><span class="line">| |    `---------&#x27;   | |</span><br><span class="line">| |       |   |      | |</span><br><span class="line">| | POD .-------.    | |</span><br><span class="line">| `-----| vsock |----&#x27; |</span><br><span class="line">|       `-------&#x27;      |</span><br><span class="line">|         |   |        |</span><br><span class="line">|  .------.   .------. |</span><br><span class="line">|  | shim |   | shim | |</span><br><span class="line">|  `------&#x27;   `------&#x27; |</span><br><span class="line">| Host                 |</span><br><span class="line">`----------------------&#x27;</span><br></pre></td></tr></table></figure><p><strong>优势</strong></p><ul><li><p>高密度 Pod</p><p>在 shimv1 使用 kata-proxy 建立 VM 和主机之间的连接，每一个 Pod 的内存大小大概是 4.5 MB 左右，在高密度 Pod 的集群中，内存的消耗过大。</p></li><li><p>可靠性</p><p>kata-proxy 负责虚拟机和主机进程之间的连接，如果 kata-proxy 异常，所有连接都会中断，尽管容器仍在运行。由于通过 VSOCK 的通信是直接的，与容器失去通信的唯一场景是 VM 本身或 containerd-shim-kata-v2 异常停止，但是在这种情况下，容器也会被自动删除。</p></li></ul><h1 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h1><p>Kata Containers 受限于 hypervisor 的功能，没有直接采用 Docker 默认的 Bridge 网络方案，而是采用的 macvtap 或者 tcfilter（使用 tc rules 将 veth 的 ingress 和 egress 队列分别对接 tap 的 egress 和 ingress 队列实现 veth 和 tap 的直连）方案。Kata Containers 本身是支持 CNI 管理网络的，网络方面相比容器，虽有额外开销但兼容性不差。</p><p>Docker 默认采用的容器网络方案是基于 network namespace + bridge + veth pairs 的，即在 host 上创建一个 network namespace，在 docker0 网桥上连接 veth pairs 的一端，再去 network namespace 中连上另一端，打通容器和 host 之间的网络。<br>这种方案得益于 namespace 技术，而许多 hypervisor 比如 QEMU 不能处理 veth interfaces。所以 Kata Containers 为 VM 创建了 TAP interfaces 来打通 VM 和 host 之间的网络。传统的 Container Engine 比如 Docker，会为容器创建 network namespace 和 veth pair，然后 Kata 会将 veth pair 的一端连上 TAP，即 macvtap 方案。</p><div align=center><img width="700" style="border: 0px" src="/gallery/kata-containers/networking.png"></div><p>Kata Containers 网络由 network namespaces、tap 和 tc 打通，创建 sandbox 之前首先创建网络命名空间，里面有 veth-pair 和 tap 两种网络接口，eth0 属于 veth-pair 类型接口，一端接入 CNI 创建的网络命名空间，一端接入宿主机；tap0_kata 属于 tap 类型接口，一端接入 cni 创建的网络命名空间，一端接入 QEMU 创建的 hypervisor，并且在 CNI 创建的网络命名空间使用 tc 策略打通 eth0 网络接口和 tap0_kata 网络接口，相当于把 eth0 和 tap0_kata 两个网络接口连成一条线。</p><p>sandbox 环境中只有 eth0 网络接口，这个接口是 QEMU 和 tap 模拟出的接口，mac、ip、掩码都和宿主机中 CNI 创建的网络命名空间中 eth0 的配置一样。</p><p>容器运行在 sandbox 环境中，容器采用共享宿主机网络命名空间方式创建容器，所以在容器中看到的网络配置和 sandbox 一样。</p><p><strong>网络流量走向：</strong><br>流量进入宿主机后首先由物理网络通过网桥或者路由接入到网络命名空间，网络命名空间中在使用 tc 策略牵引流量到 tap 网络接口，然后再通过 tap 网络接口把流量送入虚拟化环境中，最后虚拟化环境中的容器共享宿主机网络命名空间后就可以在容器中拿到网络流量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: eth0@if29: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether fe:68:1c:e3:47:da brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.244.166.150/32 brd 10.244.166.150 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::fc68:1cff:fee3:47da/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: tap0_kata: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1430 qdisc mq state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether 76:c7:1b:ab:30:64 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::74c7:1bff:feab:3064/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s qdisc show dev eth0</span><br><span class="line">qdisc noqueue 0: root refcnt 2</span><br><span class="line"> Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)</span><br><span class="line"> backlog 0b 0p requeues 0</span><br><span class="line">qdisc ingress ffff: parent ffff:fff1 ----------------</span><br><span class="line"> Sent 480 bytes 5 pkt (dropped 0, overlimits 0 requeues 0)</span><br><span class="line"> backlog 0b 0p requeues 0</span><br><span class="line"> </span><br><span class="line">[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s filter show dev eth0 ingress</span><br><span class="line">filter protocol all pref 49152 u32</span><br><span class="line">filter protocol all pref 49152 u32 fh 800: ht divisor 1</span><br><span class="line">filter protocol all pref 49152 u32 fh 800::800 order 2048 key ht 800 bkt 0 terminal flowid ??? not_in_hw  (rule hit 5 success 5)</span><br><span class="line">  match 00000000/00000000 at 0 (success 5 )</span><br><span class="line">        action order 1: mirred (Egress Redirect to device tap0_kata) stolen</span><br><span class="line">        index 1 ref 1 bind 1 installed 439 sec used 437 sec</span><br><span class="line">        Action statistics:</span><br><span class="line">        Sent 480 bytes 5 pkt (dropped 0, overlimits 0 requeues 0)</span><br><span class="line">        backlog 0b 0p requeues 0</span><br><span class="line"> </span><br><span class="line">[root@node1 kata]# ip netns exec cni-d27eff58-b9c9-a258-3a1e-a34528d9796f tc -s filter show dev tap0_kata ingress</span><br><span class="line">filter protocol all pref 49152 u32</span><br><span class="line">filter protocol all pref 49152 u32 fh 800: ht divisor 1</span><br><span class="line">filter protocol all pref 49152 u32 fh 800::800 order 2048 key ht 800 bkt 0 terminal flowid ??? not_in_hw  (rule hit 12 success 12)</span><br><span class="line">  match 00000000/00000000 at 0 (success 12 )</span><br><span class="line">        action order 1: mirred (Egress Redirect to device eth0) stolen</span><br><span class="line">        index 2 ref 1 bind 1 installed 451 sec used 165 sec</span><br><span class="line">        Action statistics:</span><br><span class="line">        Sent 768 bytes 12 pkt (dropped 0, overlimits 0 requeues 0)</span><br><span class="line">        backlog 0b 0p requeues 0</span><br></pre></td></tr></table></figure><div align=center><img width="600" style="border: 0px" src="/gallery/kata-containers/networking2.png"></div><h1 id="Kata-Containers"><a href="#Kata-Containers" class="headerlink" title="Kata Containers"></a>Kata Containers</h1><h2 id="kata-runtime-v1"><a href="#kata-runtime-v1" class="headerlink" title="kata-runtime (v1)"></a>kata-runtime (v1)</h2><p>kata-runtime 实现 OCI 运行时标准，负责处理 OCI 标准命令，并启动 kata-shim 实例。</p><h2 id="kata-agent-v1-amp-v2"><a href="#kata-agent-v1-amp-v2" class="headerlink" title="kata-agent (v1 &amp; v2)"></a>kata-agent (v1 &amp; v2)</h2><p>kata-agent 是运行在 Kata 创建的 VM 中的管理程序，使用 libcontainer 管理容器和容器中的进程服务。具体来说，kata-agent 借助 QEMU、VIRTIO serial 或 VSOCK interface 的形式在 host 上暴露一个 socket 文件，并在 VM 内运行一个 gRPC server 和 Kata 其他组件交互，runtime（kata-runtime &amp; containerd-shim-kata-v2）会通过 gRPC 来与 kata-agent 通信，来管理 VM 中的容器。</p><h2 id="kata-proxy-v1"><a href="#kata-proxy-v1" class="headerlink" title="kata-proxy (v1)"></a>kata-proxy (v1)</h2><p>可选进程，在支持 VSOCK 的环境可以不需要。kata-proxy 给多个 kata-shim 和 kata-runtime 提供对 kata-agent 访问入口，负责路由 I&#x2F;O 流和信号。kata-proxy 连接到 kata-agent 的 socket 上。一般情况下，kata-runtime 会通过 kata-proxy 来与 VM 内的 kata-agent 通信，管理 VM 内容器进程。</p><h2 id="kata-shim-v1"><a href="#kata-shim-v1" class="headerlink" title="kata-shim (v1)"></a>kata-shim (v1)</h2><p>kata-shim 的出现主要是考虑了 VM 内有多个容器的情况。在此之前，每个容器进程的回收由外层的一个 Reaper 负责。而 Kata Containers 方案中，容器运行在一个 VM 内，runtime 是无法监控、控制和回收这些 VM 内的容器，最多就是看到 QEMU 等进程，所以就设计了 kata-shim，用来监控容器进程，处理容器的所有 I&#x2F;O 流，以及转发所有的要发送出去的信号。kata-runtime 会为每个容器创建一个对应的 kata-shim，每个 Pod sandbox（infra）也会有一个 kata-shim。</p><h2 id="containerd-shim-kata-v2-v1-amp-v2"><a href="#containerd-shim-kata-v2-v1-amp-v2" class="headerlink" title="containerd-shim-kata-v2 (v1 &amp; v2)"></a>containerd-shim-kata-v2 (v1 &amp; v2)</h2><p>在 Kata Containers v1.5 版本之后，整合了原本的 kata-runtime、kata-shim、kata-proxy 以及 reaper 的功能。</p><p>在原方案（v1）中，每个 Pod 需要 2N + 1 个 shim（N 代表容器，每个容器需要一个 containerd-shim 和 kata-shim，而每一个 Pod sandbox 也需要一个 kata-shim）。而 containerd-shim-kata-v2 实现了 <a href="https://github.com/containerd/containerd/tree/master/runtime/v2">Containerd Runtime V2 (Shim API， 用于 runtime 和 Containerd 集成)</a>，K8s 只需要为每个 Pod、包括其内部的多个容器创建一个 shimv2 就够了。除此之外，无论 kata-agent 的 gRPC server 是否使用 VSOCK 暴露到 host 上，都不再需要单独的 kata-proxy。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/shimv2.svg"></div><ul><li>蓝色区域代表的是 Kubernetes CRI 的组件；红色区域代表的是 Kata Containers 的组件；黄色区域代表的是 Kata Containers 的 VM</li><li>shimV1 中 CRI 的流程只会通过 kata-proxy （非 Vsock 环境）和 VM 通信管理容器进程等</li><li>runc cmdline 就是实现了 OCI 标准的命令行工具</li><li>在 Kata 1.5 之后版本中 kata-runtime 得以保留，但是仅用作命令行工具判断 Kata Containers 的运行环境等，真正的 runtime 为 containerd-shim-kata-v2</li></ul><p><strong>Kata Containers 1.x</strong></p><table><thead><tr><th>Component</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://github.com/kata-containers/agent">agent</a></td><td>core</td><td>Management process running inside the virtual machine &#x2F; POD that sets up the container environment.</td></tr><tr><td><a href="https://github.com/kata-containers/documentation">documentation</a></td><td>documentation</td><td>Documentation common to all components (such as design and install documentation).</td></tr><tr><td><a href="https://github.com/kata-containers/ksm-throttler">KSM throttler</a></td><td>optional core</td><td>Daemon that monitors containers and deduplicates memory to maximize container density on the host.</td></tr><tr><td><a href="https://github.com/kata-containers/osbuilder">osbuilder</a></td><td>infrastructure</td><td>Tool to create “mini O&#x2F;S” rootfs and initrd images for the hypervisor.</td></tr><tr><td><a href="https://github.com/kata-containers/packaging">packaging</a></td><td>infrastructure</td><td>Scripts and metadata for producing packaged binaries (components, hypervisors, kernel and rootfs).</td></tr><tr><td><a href="https://github.com/kata-containers/proxy">proxy</a></td><td>core</td><td>Multiplexes communications between the shims, agent and runtime.</td></tr><tr><td><a href="https://github.com/kata-containers/runtime">runtime</a></td><td>core</td><td>Main component run by a container manager and providing a containerd shimv2 runtime implementation.</td></tr><tr><td><a href="https://github.com/kata-containers/shim">shim</a></td><td>core</td><td>Handles standard I&#x2F;O and signals on behalf of the container process.</td></tr></tbody></table><p><strong>Kata Containers 2.x</strong></p><table><thead><tr><th>Component</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/tools/agent-ctl">agent-ctl</a></td><td>utility</td><td>Tool that provides low-level access for testing the agent.</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/src/agent">agent</a></td><td>core</td><td>Management process running inside the virtual machine &#x2F; POD that sets up the container environment.</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/docs">documentation</a></td><td>documentation</td><td>Documentation common to all components (such as design and install documentation).</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/tools/osbuilder">osbuilder</a></td><td>infrastructure</td><td>Tool to create “mini O&#x2F;S” rootfs and initrd images for the hypervisor.</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/tools/packaging">packaging</a></td><td>infrastructure</td><td>Scripts and metadata for producing packaged binaries (components, hypervisors, kernel and rootfs).</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/src/runtime">runtime</a></td><td>core</td><td>Main component run by a container manager and providing a containerd shimv2 runtime implementation.</td></tr><tr><td><a href="https://github.com/kata-containers/kata-containers/blob/main/src/trace-forwarder">trace-forwarder</a></td><td>utility</td><td>Agent tracing helper.</td></tr></tbody></table><p><strong>与 Kubernetes 集成架构</strong></p><div align=center><img width="800" style="border: 0px" src="/gallery/kata-containers/with-kubernetes.png"></div><h1 id="流程示例"><a href="#流程示例" class="headerlink" title="流程示例"></a>流程示例</h1><p>以容器创建流程为例，初步理解下 Kata Containers 是如何运作</p><ol><li>用户通过类似于 <code>sudo ctr run --runtime &quot;io.containerd.kata.v2&quot; --rm -t &quot;quay.io/libpod/ubuntu:latest&quot; foo sh</code> 命令请求 Container Manager 创建容器</li><li>Container Manager 守护进程启动 Kata 运行时的单个实例，即 containerd-shim-kata-v2</li><li>Kata 运行时加载配置文件</li><li>Container Manager 调用一组 shimv2 的 API</li><li>Kata 运行时启动配置好的 hypervisor</li><li>hypervisor 使用 guest 资源配置创建并启动（引导）VM<ol><li>hypervisor DAX 将 guest 镜像共享到 VM 中成为 VM rootfs（安装在 &#x2F;dev&#x2F;pmem* 设备上），即 VM 根环境</li><li>hypervisor 使用 virtio FS 将 OCI bundle 安装到 VM 的 rootfs 内的容器特定目录中（这个容器特定目录将成为容器 rootfs，称为容器环境）</li></ol></li><li>Kata agent 作为 VM 启动的一部分</li><li>运行时调用 Kata agent 的 CreateSandbox API 来请求 agent 创建容器<ol><li>Kata agent 在包含容器 rootfs 的特定目录中创建容器环境（容器环境在容器 rootfs 目录中托管工作负载）（agent 创建的容器环境相当于 runc OCI 运行时创建的容器环境；Linux cgroups 和命名空间由 guest 内核在 VM 内创建，用于将工作负载与创建容器的 VM 环境隔离开来）</li><li>Kata agent 在容器环境中生成工作负载</li></ol></li><li>Container Manager 将容器的控制权返回给运行 ctr 命令的用户</li></ol>]]></content>
    
    
    <summary type="html">Kata Containers 2.x 与 1.x 版本架构差异对比与组件功能概述</summary>
    
    
    
    <category term="Container Runtime" scheme="http://shenxianghong.github.io/categories/Container-Runtime/"/>
    
    
    <category term="Kata Containers" scheme="http://shenxianghong.github.io/tags/Kata-Containers/"/>
    
  </entry>
  
</feed>
