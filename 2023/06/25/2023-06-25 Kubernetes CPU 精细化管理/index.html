<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>「 Kubernetes 」CPU 精细化管理 - 🐾Corgi</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="🐾Corgi"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="🐾Corgi"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Kubernetes NUMA 感知调度方案与节点 CPU 编排的探索与优化"><meta property="og:type" content="blog"><meta property="og:title" content="「 Kubernetes 」CPU 精细化管理"><meta property="og:url" content="http://shenxianghong.github.io/2023/06/25/2023-06-25%20Kubernetes%20CPU%20%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/"><meta property="og:site_name" content="🐾Corgi"><meta property="og:description" content="Kubernetes NUMA 感知调度方案与节点 CPU 编排的探索与优化"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://picsum.photos/0?sig=20230625"><meta property="article:published_time" content="2023-06-24T16:00:00.000Z"><meta property="article:modified_time" content="2023-06-28T08:40:51.386Z"><meta property="article:author" content="Shen Xianghong"><meta property="article:tag" content="Kubernetes"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://picsum.photos/0?sig=20230625"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://shenxianghong.github.io/2023/06/25/2023-06-25%20Kubernetes%20CPU%20%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/"},"headline":"「 Kubernetes 」CPU 精细化管理","image":[],"datePublished":"2023-06-24T16:00:00.000Z","dateModified":"2023-06-28T08:40:51.386Z","author":{"@type":"Person","name":"Shen Xianghong"},"publisher":{"@type":"Organization","name":"🐾Corgi","logo":{"@type":"ImageObject","url":"http://shenxianghong.github.io/img/logo.svg"}},"description":"Kubernetes NUMA 感知调度方案与节点 CPU 编排的探索与优化"}</script><link rel="canonical" href="http://shenxianghong.github.io/2023/06/25/2023-06-25%20Kubernetes%20CPU%20%E7%B2%BE%E7%BB%86%E5%8C%96%E7%AE%A1%E7%90%86/"><link rel="alternate" href="/atom.xml" title="🐾Corgi" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/xcode.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="🐾Corgi" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://picsum.photos/0?sig=20230625" alt="「 Kubernetes 」CPU 精细化管理"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="fa fa-calendar"></i> <time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2023-06-25</time></span><span class="level-item"><i class="fa fa-calendar-check"></i> <time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2023-06-28</time></span><span class="level-item"><i class="far fa-folder-open"></i> <a class="link-muted" href="/categories/Scheduling-Orchestration/">Scheduling &amp; Orchestration</a><span> / </span><a class="link-muted" href="/categories/Scheduling-Orchestration/Kubernetes/">Kubernetes</a></span><span class="level-item"><i class="far fa-clock"></i> an hour read (About 7734 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">「 Kubernetes 」CPU 精细化管理</h1><div class="content"><div align=center><img width="200" style="border: 0px" src="/gallery/kubernetes/logo.svg"></div>

<hr>
<blockquote>
<p>based on <strong>v1.24.10</strong></p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>现代多核服务器大多采用非统一内存访问架构（Non-uniform memory access，简称 NUMA）来提高硬件的可伸缩性。NUMA 是一种为多处理器的电脑设计的内存架构，内存访问时间取决于内存相对于处理器的位置。在 NUMA 架构下，处理器访问它自己的本地内存的速度比非本地内存（内存位于另一个处理器，或者是处理器之间共享的内存）快一些。</p>
<p>在 Kubernetes 中，调度器的调度粒度为节点级别，并不感知和考虑节点硬件拓扑的存在。在某些延迟敏感的场景下，可能希望 Kubernetes 为 Pod 分配拓扑最优的节点和硬件，以提升硬件利用率和程序性能。CPU 敏感型应用有如下特点：</p>
<ul>
<li>对 CPU throttling 敏感</li>
<li>对上下文切换敏感</li>
<li>对处理器缓存未命中敏感</li>
<li>对跨 socket 内存访问敏感</li>
</ul>
<p>同时，在某些复杂场景下，部分的 Pod 属于 CPU 密集型工作负载，Pod 之间会争抢节点的 CPU 资源。当争抢剧烈的时候，Pod 会在不同的 CPU core 之间进行频繁的切换，更糟糕的是在 NUMA node 之间的切换。这种大量的上下文切换，会影响程序运行的性能。Kubernetes 的 CPU manager 一定程度可以解决以上问题，但是因为 CPU manager 特性是节点级别的 CPU 调度选择，所以无法在集群维度中选择最优的 CPU core 组合。同时 CPU manager 特性要求 Pod QoS 为 Guaranteed 时才能生效，且无法适用于所有 QoS 类型的 Pod。</p>
<p>Kubernetes 中虽然有 Topology Manager 来管理节点资源的拓扑对齐，但是没有与调度器联动，导致调度结果和设备资源分配结果可能不一致。此外，Topology Manager 在进行资源对齐时，仅仅停留在 NUMA 维度，并未考量到 CPU socket 和 core 拓扑等细粒度概念。</p>
<h1 id="设计思考"><a href="#设计思考" class="headerlink" title="设计思考"></a>设计思考</h1><h2 id="NUMA-拓扑感知调度"><a href="#NUMA-拓扑感知调度" class="headerlink" title="NUMA 拓扑感知调度"></a>NUMA 拓扑感知调度</h2><p><em><a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/kep/119-node-resource-topology-aware-scheduling/README.md">KEP 议题</a></em></p>
<p>引入 Topology Manager 后，支持 Pod 在存在不同的 NUMA 拓扑和不同数量的拓扑资源集群节点中启动。但是存在 Pod 可能被调度到总资源量足够的节点上，但资源分配却无法满足预期的拓扑策略，从而导致 Pod 启动失败（TopologyAffinityError）。对于 Kube-scheduler 来说，更好的行为方式应该是选择适当的节点，与 Kubelet Topology Manager 策略对齐，以便 Kubelet 可以允许 Pod 运行。</p>
<p><strong>需要做出的改动有</strong></p>
<ul>
<li>当节点上有 NUMA 拓扑时，通过使用 scheduler-plugin 使调度过程更加精确</li>
<li>考虑 NUMA 拓扑，做出更优化的调度决策</li>
</ul>
<p>需要一个在 Kubelet 外部运行的 agent（<a target="_blank" rel="noopener" href="https://github.com/k8stopologyawareschedwg/resource-topology-exporter">社区参考实现</a>），用于收集有关正在运行 Pod 的所有必要信息，根据节点的可分配资源和 Pod 消耗的资源，它将在 CRD 中提供可用资源，其中一个 CRD 实例代表一个节点。 CRD 实例的名称就是节点的名称。</p>
<p>Filter 插件实现了一个与原 Topology Manager 算法不同的简化版的 Topology Manager。该插件以 single-numa-node 策略的标准检查各节点是否具备运行 Pod 的能力。由于这是最严格的 Topology Manager 策略，如果该策略条件通过，则意味着也必然满足其他策略条件。Filter 插件将使用 CRD 来识别节点上启用的拓扑策略以及节点上可用资源的拓扑信息。另外，Score 插件将进一步考虑最适合运行 Pod 的节点。</p>
<p><strong>CRD 设计</strong></p>
<p>具有节点拓扑的可用资源应存储在 CRD 中，其格式应遵循 <a target="_blank" rel="noopener" href="https://docs.google.com/document/d/12kj3fK8boNuPNqob6F_pPU9ZTaNEnPGaXEooW1Cilwg/edit?pli=1">Kubernetes Node Resource Topology Custom Resource Definition Standard</a>。<a target="_blank" rel="noopener" href="https://github.com/k8stopologyawareschedwg/noderesourcetopology-api">社区参考设计</a>。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// NodeResourceTopologyList is a list of NodeResourceTopology resources</span></span><br><span class="line"><span class="keyword">type</span> NodeResourceTopologyList <span class="keyword">struct</span> &#123;</span><br><span class="line">	metav1.TypeMeta <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">	metav1.ListMeta <span class="string">`json:&quot;metadata&quot;`</span></span><br><span class="line"></span><br><span class="line">	Items []NodeResourceTopology <span class="string">`json:&quot;items&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NodeResourceTopology is a specification for a NodeResourceTopology resource</span></span><br><span class="line"><span class="keyword">type</span> NodeResourceTopology <span class="keyword">struct</span> &#123;</span><br><span class="line">	metav1.TypeMeta   <span class="string">`json:&quot;,inline&quot;`</span></span><br><span class="line">	metav1.ObjectMeta <span class="string">`json:&quot;metadata,omitempty&quot;`</span></span><br><span class="line"></span><br><span class="line">	TopologyPolicies []<span class="type">string</span> <span class="string">`json:&quot;topologyPolicies&quot;`</span></span><br><span class="line">	Zones            ZoneList <span class="string">`json:&quot;zones&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Zone is the spec for a NodeResourceTopology resource</span></span><br><span class="line"><span class="keyword">type</span> Zone <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name       <span class="type">string</span>           <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">	Type       <span class="type">string</span>           <span class="string">`json:&quot;type&quot;`</span></span><br><span class="line">	Parent     <span class="type">string</span>           <span class="string">`json:&quot;parent,omitempty&quot;`</span></span><br><span class="line">	Costs      CostList         <span class="string">`json:&quot;costs,omitempty&quot;`</span></span><br><span class="line">	Attributes AttributeList    <span class="string">`json:&quot;attributes,omitempty&quot;`</span></span><br><span class="line">	Resources  ResourceInfoList <span class="string">`json:&quot;resources,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ZoneList []Zone</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ResourceInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name        <span class="type">string</span>             <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">	Allocatable intstr.IntOrString <span class="string">`json:&quot;allocatable&quot;`</span></span><br><span class="line">	Capacity    intstr.IntOrString <span class="string">`json:&quot;capacity&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> ResourceInfoList []ResourceInfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> CostInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name  <span class="type">string</span> <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">	Value <span class="type">int</span>    <span class="string">`json:&quot;value&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> CostList []CostInfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> AttributeInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name  <span class="type">string</span> <span class="string">`json:&quot;name&quot;`</span></span><br><span class="line">	Value <span class="type">string</span> <span class="string">`json:&quot;value&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> AttributeList []AttributeInfo</span><br></pre></td></tr></table></figure>

<p>例如：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">topology.node.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NodeResourceTopology</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node1</span></span><br><span class="line"><span class="attr">topologyPolicies:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SingleNUMANodeContainerLevel</span></span><br><span class="line"><span class="attr">zones:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">costs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">21</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;68590714880&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">memory</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Node</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">costs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-0</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">21</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">    <span class="attr">value:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-1</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">allocatable:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">available:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">capacity:</span> <span class="string">&quot;68719476736&quot;</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">memory</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Node</span></span><br></pre></td></tr></table></figure>

<p><strong>已知限制</strong></p>
<p>Kube-scheduler 在 NUMA 感知调度 Pod 流程之后，并不知道节点上 Topology Manager 实际为 Pod 分配的 NUMA 情况，节点上的 Topology Manager 也未必按照 scheduler-plugin 中的预选算法进行分配。 </p>
<p>因此，KEP 中建议 Kube-scheduler 可以将分配的 NUMA ID 作为 Pod 提示透传，节点的 Topology Manager 也可以根据 Pod 中的相关提示信息考虑实际的分配策略（这部分涉及到 Topology Manager 的改动，暂未实现）。</p>
<h2 id="节点-CPU-编排"><a href="#节点-CPU-编排" class="headerlink" title="节点 CPU 编排"></a>节点 CPU 编排</h2><div align=center><img width="600" style="border: 0px" src="/gallery/cpu-manage/cpu-assign.png"></div>

<p><strong>分配优先级</strong></p>
<ol>
<li>为了多核共享 L1 和 L2 cache，优先分配位于同一物理核心的两个逻辑核心。即图中的 0 和 16 号 CPU 分配优先级高于 0 和 1 号 CPU</li>
<li>为了多核共享 L3 cache ，优先分配位于同一 NUMA 的两个逻辑核心。即图中的 0 和 1 号 CPU 分配优先级高于 0 和 4 号 CPU</li>
</ol>
<p><strong>扩展思考点</strong></p>
<ul>
<li>考虑到超线程性能的发挥瓶颈，对于 CPU 满载服务而言，同一物理核心的两个逻辑核心未必比来自不同物理核心的性能强，因此可以针对应用本身的业务模型，是否分配自同一个物理核心有待考量</li>
<li>CPU 的分配优先级可以不仅仅从静态拓扑结构角度思考设计，也可以结合 CPU 频率、flag 等属性信息以及 CPU 真实使用率等动态实时信息，多维度的考量</li>
<li>考虑到节点资源利用率，对于非 Guaranteed QoS 的 Pod 而言，往往也需要不同程度的 CPU 精细化管理</li>
<li>由于集群资源动态变化，最初未满足最佳分配策略的服务，可以借助适时重分配或重调度调整至最优分配效果</li>
<li>拓扑资源对齐不仅仅限制于 CPU 资源，往往一套完整的拓扑资源对齐方案会将 CPU、内存、GPU、网卡等硬件设备均考虑在内</li>
<li>现阶段，在不修改 CPU Manager、Topology Manager 等原有模块逻辑的前提下，往往需要一个旁路 agent 或者 hook CRI 调用的模式来接管资源管理的能力，并且往往需要禁用原生的管理策略</li>
<li>随着 NRI（Node Resource Interface）规范的完善，可以基于 NRI hook 扩展，实现资源编排</li>
</ul>
<h1 id="社区成果"><a href="#社区成果" class="headerlink" title="社区成果"></a>社区成果</h1><h2 id="Crane"><a href="#Crane" class="headerlink" title="Crane"></a>Crane</h2><p><em><a target="_blank" rel="noopener" href="https://github.com/gocrane/crane">https://github.com/gocrane/crane</a></em></p>
<div align=center><img width="800" style="border: 0px" src="/gallery/crane/overview.png"></div>

<p>Crane 是一个基于 FinOps 的云资源分析与成本优化平台。它的愿景是在保证客户应用运行质量的前提下实现极致的降本。</p>
<p><strong>设计概述</strong></p>
<div align=center><img width="600" style="border: 0px" src="/gallery/crane/topology-awareness-architecture.png"></div>

<p>Crane-scheduler 和 Crane-agent 配合工作，完成拓扑感知调度与资源分配的工作：</p>
<ol>
<li>Crane-agent 从节点采集资源拓扑，包括 NUMA、socket、设备等信息，汇总到 NodeResourceTopology CRD 中</li>
<li>Crane-scheduler 在调度时会参考节点的 NodeResourceTopology 对象获取到节点详细的资源拓扑结构，在调度到节点的同时还会为 Pod 分配拓扑资源，并将结果写到 Pod 的 annotations 中</li>
<li>Crane-agent 在节点上 watch 到 Pod 被调度后，从 Pod 的 annotations 中获取到拓扑分配结果，并按照用户给定的 CPU 绑定策略进行 CPUset 的细粒度分配</li>
</ol>
<div align=center><img width="1000" style="border: 0px" src="/gallery/crane/topology-awareness-details.png"></div>

<p><strong>CPU 分配策略</strong></p>
<p>Crane 中提供了四种 CPU 分配策略，分别如下：</p>
<ol>
<li>none：该策略不进行特别的 CPUset 分配，Pod 会使用节点 CPU 共享池</li>
<li>exclusive：该策略对应 Kubelet 的 static 策略，Pod 会独占 CPU 核心，其他任何 Pod 都无法使用</li>
<li>numa：该策略会指定 NUMA Node，Pod 会使用该 NUMA Node 上的 CPU 共享池</li>
<li>immovable：该策略会将 Pod 固定在某些 CPU 核心上，但这些核心属于共享池，其他 Pod 仍可使用</li>
</ol>
<p><strong>为系统组件预留 CPU</strong></p>
<p>在某些场景下，希望能对 Kubelet 预留的 CPU 做一些保护，使用场景包括但不限于：</p>
<ul>
<li>在混部场景下，不希望离线任务绑定系统预留的 CPU 核心，防止对 K8s 系统组件产生影响</li>
<li>0 号核心在 Linux 有独特用途，比如处理网络包、内核调用、处理中断等，因此不希望任务绑定 0 号核心</li>
</ul>
<p>在 Crane 中，可以通过以下方式为系统组件预留 CPU：</p>
<ol>
<li>Kubelet 设置预留 CPU：按照<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#explicitly-reserved-cpu-list">官方指引</a>设置预留的 CPU 列表</li>
<li>查看 NodeResourceTopology 对象，spec.attributes 中的 <code>go.crane.io/reserved-system-cpus</code> 存储了预留的 CPU 列表</li>
<li>在 Pod 的 annotations 中添加 <code>topology.crane.io/exclude-reserved-cpus</code>，表明 Pod 不绑定预留的 CPU 核心</li>
</ol>
<h2 id="Koordinator"><a href="#Koordinator" class="headerlink" title="Koordinator"></a>Koordinator</h2><p><u><em><a target="_blank" rel="noopener" href="https://github.com/koordinator-sh/koordinator">https://github.com/koordinator-sh/koordinator</a></em></u></p>
<div align=center><img width="700" style="border: 0px" src="/gallery/koordinator/overview.png"></div>

<p>Koordinator 是一个基于 QoS 的 Kubernetes 混合工作负载调度系统，旨在提高对延迟敏感的工作负载和批处理作业的运行时效率和可靠性，简化与资源相关的配置调整的复杂性，并增加 Pod 部署密度以提高资源利用率。</p>
<p><strong>设计概述</strong></p>
<div align=center><img width="1000" style="border: 0px" src="/gallery/koordinator/cpu-orchestration.svg"></div>

<p>当 Koordlet 启动时，Koordlet 从 Kubelet 收集 NUMA 拓扑信息，包括 NUMA 拓扑、CPU 拓扑、Kubelet CPU 管理策略、Kubelet 为 Guaranteed Pod 分配的 CPU 等，并更新到节点资源拓扑 CRD。当延迟敏感的应用程序扩容时，可以为新 Pod 设置 Koordinator QoS LSE&#x2F;LSR、CPU 绑定策略和 CPU 独占策略，要求 Koord-scheduler 分配最适合的 CPU 以获得最佳性能。当 Koord-scheduler 调度 Pod 时，Koord-scheduler 会过滤满足 NUMA 拓扑对齐策略的节点，并通过评分选择最佳节点，在 Reserve 阶段分配 CPU，并在 PreBinding 时将结果记录到 Pod annotations。Koordlet 通过 hook Kubelet CRI 请求，替换通过 Koord-scheduler 调度的 CPU 配置参数到运行时，例如配置 cgroup。</p>
<p><strong>QoS</strong></p>
<p>Koordinator 调度系统支持的 QoS 有五种类型:</p>
<table>
<thead>
<tr>
<th>QoS</th>
<th>特点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>SYSTEM</td>
<td>系统进程，资源受限</td>
<td>对于 DaemonSets 等系统服务，虽然需要保证系统服务的延迟，但也需要限制节点上这些系统服务容器的资源使用，以确保其不占用过多的资源</td>
</tr>
<tr>
<td>LSE(Latency Sensitive Exclusive)</td>
<td>保留资源并组织同 QoS 的 Pod 共享资源</td>
<td>很少使用，常见于中间件类应用，一般在独立的资源池中使用</td>
</tr>
<tr>
<td>LSR(Latency Sensitive Reserved)</td>
<td>预留资源以获得更好的确定性</td>
<td>类似于社区的 Guaranteed，CPU 核被绑定</td>
</tr>
<tr>
<td>LS(Latency Sensitive)</td>
<td>共享资源，对突发流量有更好的弹性</td>
<td>微服务工作负载的典型QoS级别，实现更好的资源弹性和更灵活的资源调整能力</td>
</tr>
<tr>
<td>BE(Best Effort)</td>
<td>共享不包括 LSE 的资源，资源运行质量有限，甚至在极端情况下被杀死</td>
<td>批量作业的典型 QoS 水平，在一定时期内稳定的计算吞吐量，低成本资源</td>
</tr>
</tbody></table>
<p>Koordinator 和 Kubernetes QoS 之间是有对应关系的:</p>
<table>
<thead>
<tr>
<th>Koordinator QoS</th>
<th>Kubernetes QoS</th>
</tr>
</thead>
<tbody><tr>
<td>SYSTEM</td>
<td>—</td>
</tr>
<tr>
<td>LSE</td>
<td>Guaranteed</td>
</tr>
<tr>
<td>LSR</td>
<td>Guaranteed</td>
</tr>
<tr>
<td>LS</td>
<td>Guaranteed&#x2F;Burstable</td>
</tr>
<tr>
<td>BE</td>
<td>BestEffort</td>
</tr>
</tbody></table>
<p><strong>CPU 编排基本原则</strong></p>
<ol>
<li>仅支持 Pod 维度的 CPU 分配机制</li>
<li>Koordinator 将机器上的 CPU 分为 CPU Shared Pool，statically exclusive CPUs 和 BE CPU Shared Pool：<ol>
<li>CPU Shared Pool 是一组共享 CPU 池，Burstable 和 LS Pod 中的任何容器都可以在其上运行。Guaranteed fractional CPU requests 的 Pod 也可以运行在 CPU Shared Pool 中。CPU Shared Pool 包含节点中所有未分配的 CPU，但不包括由 Guaranteed、LSE 和 LSR Pod 分配的 CPU。如果 Kubelet 保留 CPU，则 CPU Shared Pool 包括保留的 CPU</li>
<li>statically exclusive CPUs 是指分配给 Guaranteed、LSE&#x2F;LSR Pods 使用的一组独占 CPU。当 Guaranteed、LSE 和 LSR Pod 申请 CPU 时，Koord-scheduler 将从 CPU Shared Pool 中分配</li>
<li>BE CPU Shared Pool 是一组 BestEffort 和 BE 的 Pod 都可运行的 CPU 池。BE CPU Shared Pool 包含节点中除 Guaranteed 和 LSE Pod 分配的之外的所有 CPU</li>
</ol>
</li>
</ol>
<p><strong>Koordinator QoS CPU 编排原则</strong></p>
<ol>
<li>LSE&#x2F;LSR Pod 的 requests 和 limits 必须相等，CPU 值必须是 1000 的整数倍</li>
<li>LSE Pod 分配的 CPU 是完全独占的，不得共享。如果节点是超线程架构，只保证逻辑核心维度是隔离的，但是可以通过 CPUBindPolicyFullPCPUs 策略获得更好的隔离</li>
<li>LSR Pod 分配的 CPU 只能与 BE Pod 共享</li>
<li>LS Pod 绑定了与 LSE&#x2F;LSR Pod 独占之外的共享 CPU 池</li>
<li>BE Pod 绑定使用节点中除 LSE Pod 独占之外的所有 CPU </li>
<li>如果 Kubelet 的 CPU 管理器策略为 static 策略，则已经运行的 Guaranteed Pods 等价于 LSR</li>
<li>如果 Kubelet 的 CPU 管理器策略为 none 策略，则已经运行的 Guaranteed Pods 等价于 LS</li>
<li>新创建但未指定 Koordinator QoS 的 Guaranteed Pod 等价于 LS</li>
</ol>
<div align=center><img width="800" style="border: 0px" src="/gallery/koordinator/qos-cpu-orchestration.png"></div>

<p><strong>Kubelet CPU Manager 策略兼容原则</strong></p>
<ol>
<li>如果 Kubelet 设置 CPU Manager 策略选项 <code>full-pcpus-only=true</code> 或者 <code>distribute-cpus-across-numa=true</code>，并且节点中没有 Koordinator 定义的新 CPU 绑定策略，则遵循 Kubelet 定义的这些参数的定义</li>
<li>如果 Kubelet 设置了 Topology Manager 策略，并且节点中没有 Koordinator 定义的新的 NUMA Topology Alignment 策略，则遵循 Kubelet 定义的这些参数的定义</li>
</ol>
<p><strong>接管 Kubelet CPU 管理策略</strong></p>
<p>Kubelet 预留的 CPU 主要服务于 BestEffort 和 Burstable Pods。但 Koordinator 不会遵守该策略。Burstable Pod 应该使用 CPU Shared Pool，而 BestEffort Pods 应该使用 BE CPU Shared Pool。LSE 和 LSR Pod 不会从被 Kubelet 预留的 CPU 中分配。</p>
<ol>
<li>对于 Burstable 和 LS Pod<ol>
<li>当 Koordlet 启动时，计算 CPU Shared Pool 并将共享池应用到节点中的所有 Burstable 和 LS Pod，即更新它们的 CPU cgroups, 设置 CPUset。在创建或销毁 LSE&#x2F;LSR Pod 时执行相同的逻辑</li>
<li>Koordlet 会忽略 Kubelet 预留的 CPU，将其替换为 Koordinator 定义的 CPU Shared Pool</li>
</ol>
</li>
<li>对于 BestEffort 和 BE Pod<ol>
<li>如果 Kubelet 预留了 CPU，BestEffort Pod 会首先使用预留的 CPU</li>
<li>Koordlet 可以使用节点中的所有 CPU，但不包括由具有整数 CPU 的 Guaranteed 和 LSE Pod 分配的 CPU。这意味着如果 Koordlet 启用 CPU Suppress 功能，则应遵循约束以保证不会影响 LSE Pod。同样，如果 Kubelet 启用了 CPU Manager static 策略，则也应排除 Guaranteed Pod</li>
</ol>
</li>
<li>对于 Guaranteed Pod<ol>
<li>如果 Pod 的 annotations 中有 Koord-scheduler 更新的 <code>scheduling.koordinator.sh/resource-status</code>，在 sandbox&#x2F;container 创建阶段，则会替换 Kubelet CRI 请求中的 CPUset</li>
<li>Kubelet 有时会调用 CRI 中定义的 Update 方法来更新容器 cgroup 以设置新的 CPU，因此 Koordlet 和 koord-runtime-proxy 需要 hook 该方法</li>
</ol>
</li>
<li>自动调整 CPU Shared Pool 大小<ol>
<li>Koordlet 会根据 Pod 创建&#x2F;销毁等变化自动调整 CPU Shared Pool 的大小。如果 CPU Shared Pool 发生变化，Koordlet 应该更新所有使用共享池的 LS 或 Burstable Pod 的 cgroups</li>
<li>如果 Pod 的 annotations <code>scheduling.koordinator.sh/resource-status</code> 中指定了对应的 CPU Shared Pool，Koordlet 在配置 cgroup 时只需要绑定对应共享池的 CPU 即可</li>
</ol>
</li>
</ol>
<p>接管逻辑要求 koord-runtime-proxy 添加新的扩展点并且 Koordlet 实现新的运行时插件的 hook 。当没有安装 koord-runtime-proxy 时，这些接管逻辑也将能够实现。</p>
<p><strong>CPU 绑定策略</strong></p>
<p>标签 <code>node.koordinator.sh/cpu-bind-policy</code> 限制了调度时如何绑定 CPU：</p>
<ul>
<li>None 或空值 — 不执行任何策略</li>
<li>FullPCPUsOnly — 要求调度器必须分配完整的物理核。等效于 Kubelet CPU Manager 策略选项 full-pcpus-only&#x3D;true</li>
<li>SpreadByPCPUs — 要求调度器必须按照物理核维度均匀的分配 CPU</li>
</ul>
<p><strong>NUMA 分配策略</strong></p>
<p>标签 <code>node.koordinator.sh/numa-allocate-strategy</code> 表示在调度时如何选择满意的 NUMA 节点：</p>
<ul>
<li>MostAllocated — 表示从可用资源最少的 NUMA 节点分配</li>
<li>LeastAllocated — 表示从可用资源最多的 NUMA 节点分配</li>
<li>DistributeEvenly — 表示在 NUMA 节点上平均分配 CPU</li>
</ul>
<p><strong>NUMA 拓扑对齐策略</strong></p>
<p>标签 <code>node.koordinator.sh/numa-topology-alignment-policy</code> 表示如何根据 NUMA 拓扑对齐资源分配。策略语义遵循 K8s 社区。相当于 NodeResourceTopology 中的 TopologyPolicies 字段，拓扑策略 SingleNUMANodePodLevel 和 SingleNUMANodeContainerLevel 映射到 SingleNUMANode 策略：</p>
<ul>
<li>None — 是默认策略，不执行任何拓扑对齐</li>
<li>BestEffort — 表示优先选择拓扑对齐的 NUMA node，如果没有，则继续为 Pod 分配资源</li>
<li>Restricted — 表示每个 Pod 在 NUMA 节点上请求的资源是拓扑对齐的，如果不是，Koord-scheduler 会在调度时跳过该节点</li>
<li>SingleNUMANode — 表示一个 Pod 请求的所有资源都必须在同一个 NUMA 节点上，如果不是，Koord-scheduler 调度时会跳过该节点</li>
</ul>
<p><strong>NodeResourceTopology 维护</strong></p>
<p>Koordinator 在社区提供的 NodeResourceTopology CRD 基础之上通过 annotations 和 label 扩展了更多的 CPU 管理策略与限制。</p>
<ul>
<li>Koordlet 负责创建&#x2F;更新 NodeResourceTopology</li>
<li>建议 Koordlet 通过解析 <code>/var/lib/kubelet/cpu_manager_state</code> 文件来获取现有 Guaranteed Pod 的 CPU 分配信息。或者通过 Kubelet 提供的 CRI 接口和 gRPC 获取这些信息</li>
<li>当 Koord-scheduler 分配 Pod 的 CPU 时，替换 Kubelet 状态检查点文件中的 CPU</li>
<li>建议 Koordlet 从 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/">kubeletConfiguration</a> 获取 CPU Manager 策略和选项</li>
</ul>
<h2 id="CRI-Resource-Manager"><a href="#CRI-Resource-Manager" class="headerlink" title="CRI Resource Manager"></a>CRI Resource Manager</h2><p><em><a target="_blank" rel="noopener" href="https://github.com/intel/cri-resource-manager">https://github.com/intel/cri-resource-manager</a></em></p>
<div align=center><img width="400" style="border: 0px" src="/gallery/cri-resource-manager/overview.png"></div>

<p>CRI Resource Manager 是 CRI 代理，位于客户端和实际容器运行时实现（Containerd、CRI-O）之间，用于转发请求和响应。代理的主要目的是通过在转发请求之前修改请求或在处理和代理期间执行与请求相关的额外操作来应用策略以将硬件感知的资源分配策略应用于系统中运行的容器。</p>
<p><strong>架构概述</strong></p>
<div align=center><img width="400" style="border: 0px" src="/gallery/cri-resource-manager/cri-resmgr.svg"></div>

<p>CRI Resource Manager 可以通过加载节点静态配置文件，也可以通过 gRPC 请求 CRI Resource Manager Node Agent 组件动态配置。 Node Agent 组件的主要功能是维护节点级别或者全局级别的 ConfigMap，以响应 CRI Resource Manager 的 gRPC 请求，返回策略配置。</p>
<p>默认情况下，CRI Resource Manager 无法获取 Pod spec 中指定的原始容器资源需求。它尝试使用 CRI 容器创建请求中的相关参数来预估 CPU 和内存资源。但是，无法使用这些参数来预估其他扩展资源。如果想确保 CRI Resource Manager 使用原始 Pod spec 资源需求，CRI Resource Manager Webhook 组件负责将这部分声明复制到 Pod annotations 中，用于 CRI Resource Manager 感知扩展资源。</p>
<p>CRI Resource Manager 提供了极为丰富的硬件拓扑感知的能力，包括但不限于 CPU、内存、blockIO、RDT、SST 等；提供了 topology-aware、static-pools、balloons、podpools 等多种策略。</p>
<p><em>CRI Resource Manager 聚焦在节点级别的拓扑资源管理，并未提供 NUMA 拓扑感知调度器。</em></p>
<p><strong>topology-aware 策略</strong></p>
<p>topology-aware 策略根据检测到的硬件拓扑自动构建池树。每个池都有一组分配为其资源的 CPU 和内存区域。工作负载的资源分配首先选择最适合工作负载资源需求的池，然后从该池中分配 CPU 和内存：</p>
<ul>
<li>CPU 和内存拓扑对齐分配，以最严格的可用对齐方式将 CPU 和内存分配给工作负载</li>
<li>设备的对齐分配，根据已分配设备的位置选择工作负载池</li>
<li>CPU 核心共享分配，将工作负载分配给池 CPU 的共享子集</li>
<li>CPU 核心独占分配，从共享子集中动态分割 CPU 核心并分配给工作负载</li>
<li>CPU 核心混合分配，将独占和共享 CPU 核心分配给工作负载</li>
<li>发现和使用内核隔离的 CPU 核心 ( <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html#cpu-lists">isolcpus</a> )，将内核隔离的 CPU 核心用于专门分配的 CPU 核心</li>
<li>将分配的资源暴露给工作负载</li>
<li>通知工作负载有关资源分配的更改</li>
<li>动态放缓内存对齐以防止 OOM，动态加宽工作负载内存集以避免池&#x2F;工作负载 OOM</li>
<li>多层内存分配：将工作负载分配到其首选类型的内存区域，该策略感知三种内存：DRAM 是常规系统主存储器；PMEM 是大容量内存，例如 <a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/products/memory-storage/optane-dc-persistent-memory.html">Intel® Optane™内存</a>；<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/High_Bandwidth_Memory">HBM</a> 是高速存储器，通常出现在一些专用计算系统上</li>
<li>冷启动，在初始预热期间将工作负载专门固定到 PMEM</li>
<li>动态页面降级，强制将只读和空闲容器内存页迁移到 PMEM</li>
</ul>
<p><strong>static-pools 策略</strong></p>
<p>static-pools 策略是 <a target="_blank" rel="noopener" href="https://github.com/intel/CPU-Manager-for-Kubernetes">Intel CMK </a>项目的功能移植。</p>
<p><strong>balloons 策略</strong> </p>
<p>balloons 策略是一种用于管理系统中容器 CPU 资源分配的方法。它涉及将可用的 CPU 划分为相互独立的池，称为 balloon，每个 balloon 可以根据容器的资源请求进行扩大或缩小，即可以增加或减少其中的 CPU 数量。</p>
<p>balloon 可以是静态的或动态的。静态 balloon 需要手动创建并保持固定的大小，而动态 balloon 则可以根据容器的资源需求自动创建和销毁。这可以实现更高效的资源利用，因为 balloon 可以实时调整以满足不断变化的需求。</p>
<p>除了控制每个 balloon 中 CPU 数量外，balloon 还可以配置特定的设置，例如 CPU 核心和非核心的最小和最大频率。这可以对 CPU 资源的分配进行精细控制，确保每个容器都分配了其运行所需的资源。</p>
<p>大致流程为：</p>
<ol>
<li>用户可以配置不同类型的 balloon，策略可以根据这些配置实例化 balloon</li>
<li>balloon 有一组 CPU 和一组在 CPU 上运行的容器</li>
<li>每个容器都被分配给一个 balloon。容器可以使用其 balloon 的所有 CPU，而不能使用其他 CPU</li>
<li>每个逻辑 CPU 最多属于一个 balloon，也可能存在不属于任何 balloon 的 CPU</li>
<li>balloon 中的 CPU 数量在 balloon 的生命周期内可能会发生变化。如果 balloon 膨胀，也就是增加了 CPU，那么 balloon 中的所有容器都可以使用更多的 CPU，反之亦然</li>
<li>当在 Kubernetes 节点上创建新容器时，策略首先决定将运行该容器的 balloon 的类型。该决定基于 Pod annotations，或者如果未给出 annotations 则基于命名空间</li>
<li>接下来，策略决定哪个 balloon 将运行容器。选项有：<ul>
<li>现有的 balloon 已经有足够的 CPU 来运行当前和新的容器</li>
<li>现有的 balloon 可以扩大以适应其当前和新的容器</li>
<li>新 balloon</li>
</ul>
</li>
<li>当向 balloon 添加或从其中移除 CPU 时，会根据 balloon 的 CPU 类属性或空闲 CPU 类属性重新配置 CPU</li>
</ol>
<p><strong>podpools 策略</strong></p>
<p>podpools 策略实现 Pod 级别的工作负载放置。它将 Pod 的所有容器分配到同一个 CPU&#x2F;内存池。池中的 CPU 数量可由用户配置。</p>
<p><strong>容器亲和与反亲和</strong></p>
<p>亲和与反亲和的提示是通过 Pod annotations 声明：</p>
<ul>
<li>同一 NUMA 节点内的 CPU 视为彼此亲和</li>
<li>同一 socket 中不同 NUMA 节点内的 CPU，以及不同 socket 内的 CPU 视为彼此反亲和</li>
</ul>
<p><strong>blockIO</strong></p>
<p>blockIO 提供以下控制：</p>
<ul>
<li>块设备 IO 调度优先级（权重）</li>
<li>限制 IO 带宽</li>
<li>限制 IO 操作的数量</li>
</ul>
<p>CRI Resource Manager 通过 cgroups blockIO 控制器将 blockIO 的相关参数应用于 Pod。</p>
<h2 id="Volcano"><a href="#Volcano" class="headerlink" title="Volcano"></a>Volcano</h2><p><em><a target="_blank" rel="noopener" href="https://github.com/volcano-sh/volcano">https://github.com/volcano-sh/volcano</a></em></p>
<div align=center><img width="600" style="border: 0px" src="/gallery/volcano/overview.png"></div>

<p>Volcano 是 CNCF 下首个也是唯一的基于 Kubernetes 的容器批量计算平台，主要用于高性能计算场景。它提供了 Kubernetes 目前缺少的一套机制，这些机制通常是机器学习大数据应用、科学计算、特效渲染等多种高性能工作负载所需的。作为一个通用批处理平台，Volcano 与几乎所有的主流计算框架无缝对接，如Spark、TensorFlow 、PyTorch、 Flink 、Argo 、MindSpore 、 PaddlePaddle 等。它还提供了包括基于各种主流架构的 CPU、GPU 在内的异构设备混合调度能力。Volcano 的设计理念建立在 15 年来多种系统和平台大规模运行各种高性能工作负载的使用经验之上，并结合来自开源社区的最佳思想和实践。</p>
<p><strong>感知调度流程</strong></p>
<div align=center><img width="800" style="border: 0px" src="/gallery/volcano/numa-aware-process.png"></div>

<table>
<thead>
<tr>
<th>policy</th>
<th>action</th>
</tr>
</thead>
<tbody><tr>
<td>none</td>
<td>无</td>
</tr>
<tr>
<td>best-effort</td>
<td>过滤出拓扑策略为 best-effort 的节点</td>
</tr>
<tr>
<td>restricted</td>
<td>过滤出拓扑策略为 restricted 且满足 CPU 拓扑要求的节点</td>
</tr>
<tr>
<td>single-numa-node</td>
<td>过滤出拓扑策略为 single-numa-node 且满足 CPU 拓扑要求的节点</td>
</tr>
</tbody></table>
<p>Volcano 在的感知调度和其他项目类似，将 Kubernetes Topology Manager 的原生策略扩展至调度器层面，只不过 CRD 采用的是 Volcano 设计的 <a target="_blank" rel="noopener" href="https://github.com/volcano-sh/apis/blob/master/pkg/apis/nodeinfo/v1alpha1/numatopo_types.go">Numatopology</a>，而非社区提出的 NodeResourceTopology CRD，其他流程方面大同小异。</p>
<p><strong>节点 CPU 编排</strong></p>
<p>Volcano 并未提供节点 CPU 编排的能力，但是参考华为 CCE 产品文档中，CCE 基于社区原生的 CPU Manager 策略的基础上，提出了 enhanced-static 策略，是在兼容 static 策略的基础上，新增一种符合某些资源特征的 Burstable Pod（CPU 的 requests 和 limits 值都是正整数）优先使用某些 CPU 的能力，以减少应用在多个 CPU 间频繁切换带来的影响。</p>
<p>该特性是基于 Huawei Cloud EulerOS 2.0 内核中优化了 CPU 调度能力实现的。在 Pod 容器优先使用的 CPU 利用率超过 85% 时，会自动分配到其他利用率较低的 CPU 上，进而保障了应用的响应能力。</p>
<div align=center><img width="500" style="border: 0px" src="/gallery/volcano/enhanced-static.png"></div>

<ul>
<li>开启 enhanced-static 策略时，应用性能优于 none 策略，但弱于 static 策略</li>
<li>应用分配的优先使用的 CPU 并不会被独占，仍处于共享的 CPU 池中。因此在该 Pod 处于业务波谷时，节点上其他 Pod 可使用该部分 CPU 资源</li>
</ul>
<h1 id="实践验证"><a href="#实践验证" class="headerlink" title="实践验证"></a>实践验证</h1><p><em>以 cri-resource-manager为例</em></p>
<blockquote>
<p>based on <strong>v0.8.3</strong></p>
</blockquote>
<p><strong>服务安装</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 cri-resource-manager 服务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum -y install https://github.com/intel/cri-resource-manager/releases/download/v0.8.3/cri-resource-manager-0.8.3-0.centos-7.x86_64.rpm</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 cri-resmgr-agent 服务（需要手动编译并替换 IMAGE_PLACEHOLDER 占位符，这里不做详述）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f https://raw.githubusercontent.com/intel/cri-resource-manager/master/cmd/cri-resmgr-agent/agent-deployment.yaml</span></span><br></pre></td></tr></table></figure>

<p><strong>安装结果</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start cri-resource-manager</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl status cri-resource-manager</span></span><br><span class="line">● cri-resource-manager.service - A CRI proxy with (hardware) resource aware container placement policies.</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/cri-resource-manager.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Mon 2023-06-28 16:26:04 CST; 29min ago</span><br><span class="line">     Docs: https://github.com/intel/cri-resource-manager</span><br><span class="line"> Main PID: 32130 (cri-resmgr)</span><br><span class="line">    Tasks: 49</span><br><span class="line">   Memory: 41.6M</span><br><span class="line">   CGroup: /system.slice/cri-resource-manager.service</span><br><span class="line">           └─32130 /usr/bin/cri-resmgr --fallback-config /etc/cri-resmgr/fallback.cfg</span><br><span class="line">           </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get ds -A</span></span><br><span class="line">NAMESPACE            NAME                  DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span><br><span class="line">kube-system          cri-resmgr-agent      1         1         1       1            1           &lt;none&gt;                   11m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">采用 cri-resmgr-agent 维护的动态配置，采用 topology-aware 策略</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">节点全量的 CPU 为 0-47</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">- 0-4 用于非 Kubernetes 平台使用，如节点系统服务等</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">- AvailableResources 中的 5-47 号 CPU 用于 Kubernetes 平台使用</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  - ReservedResources 5-10 号 CPU 用于 Kubernetes 的预留命名空间下的服务使用</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  - 剩余的 10-47 号 CPU 用于 Kubernetes 的其他命名空间下的服务使用</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get cm -n kube-system cri-resmgr-config.node.node1 -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  policy: |</span><br><span class="line">    Active: topology-aware</span><br><span class="line">    topology-aware:</span><br><span class="line">      ReservedPoolNamespaces: [kube-system,arsdn,secboat]</span><br><span class="line">    ReservedResources:</span><br><span class="line">      cpu: cpuset:5-10</span><br><span class="line">    AvailableResources:</span><br><span class="line">      cpu: cpuset:5-47</span><br><span class="line">kind: ConfigMap</span><br></pre></td></tr></table></figure>

<p><strong>服务配置</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置 Kubelet 的 CRI endpoint 为 cri-resmgr.sock</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /var/lib/kubelet/kubeadm-flags.env</span></span><br><span class="line">KUBELET_KUBEADM_ARGS=&quot;--container-runtime=remote --container-runtime-endpoint=unix:///var/run/cri-resmgr/cri-resmgr.sock&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/kubernetes/kubelet.env</span></span><br><span class="line">...</span><br><span class="line">KUBELET_ARGS=&quot;--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf \</span><br><span class="line">--config=/etc/kubernetes/kubelet-config.yaml \</span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf \</span><br><span class="line">--log-dir=/var/log/kubelet \</span><br><span class="line">--log-file=/var/log/kubelet/kubelet.log \</span><br><span class="line">--logtostderr=false \</span><br><span class="line">--alsologtostderr=false \</span><br><span class="line">--feature-gates=CSIInlineVolume=true,CSIVolumeHealth=true,CPUManagerPolicyOptions=true \</span><br><span class="line">--pod-infra-container-image=harbor.archeros.cn:443/library/ake/pause:3.5-amd64 \</span><br><span class="line">--container-runtime=remote \</span><br><span class="line">--runtime-request-timeout=15m \</span><br><span class="line">--container-runtime-endpoint=unix:///var/run/cri-resmgr/cri-resmgr.sock \</span><br><span class="line">--runtime-cgroups=/systemd/system.slice \</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span></span><br></pre></td></tr></table></figure>

<p><strong>节点 CPU 编排</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">numactl -H</span></span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 24 25 26 27 28 29 30 31 32 33 34 35</span><br><span class="line">node 0 size: 65413 MB</span><br><span class="line">node 0 free: 15969 MB</span><br><span class="line">node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23 36 37 38 39 40 41 42 43 44 45 46 47</span><br><span class="line">node 1 size: 65536 MB</span><br><span class="line">node 1 free: 21933 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  21</span><br><span class="line">  1:  21  10</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署共享 CPU 的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f besteffort.yaml &amp;&amp; kubectl apply -f busterable.yaml &amp;&amp; kubectl apply -f guaranteed.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 CPU 分配情况：共享一个合适的 NUMA node</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep besteffort | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep busterable | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-23,36-47&quot;,           </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署独占 CPU 的 Pod</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f guaranteed-exclusive.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 CPU 分配情况：独占同一物理核心的两个逻辑核心</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed-exclusive | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;23,47&quot;,</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看热更新，共享 CPU 中将独占的 CPU 扣除</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep besteffort | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep busterable | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep guaranteed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;12-22,36-46&quot;,</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">预留 namespace CPU 分配</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f reserved.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crictl ps | grep reserved | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs crictl inspect | grep <span class="string">&quot;\&quot;cpus\&quot;:&quot;</span></span></span><br><span class="line">            &quot;cpus&quot;: &quot;5-10&quot;,</span><br></pre></td></tr></table></figure>

</div><div class="article-licensing box"><div class="licensing-title"><p>「 Kubernetes 」CPU 精细化管理</p><p><a href="http://shenxianghong.github.io/2023/06/25/2023-06-25 Kubernetes CPU 精细化管理/">http://shenxianghong.github.io/2023/06/25/2023-06-25 Kubernetes CPU 精细化管理/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Shen Xianghong</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-06-25</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-06-28</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Kubernetes/">Kubernetes </a></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/06/13/2023-06-13%20Kubernetes%20%E8%8A%82%E7%82%B9%E8%B5%84%E6%BA%90%E8%B6%85%E5%8D%96/"><span class="level-item">「 Kubernetes 」节点资源超卖</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/35031258?v=4" alt="🐾Corgi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">🐾Corgi</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">53</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">9</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shenxianghong" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Youtube" href="https://youtube.com"><i class="fab fa-youtube"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://bilibili.com"><i class="fab fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Reddit" href="https://reddit.com"><i class="fab fa-reddit"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://google.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Google</span></span><span class="level-right"><span class="level-item tag">google.com</span></span></a></li><li><a class="level is-mobile" href="https://poe.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Poe</span></span><span class="level-right"><span class="level-item tag">poe.com</span></span></a></li></ul></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#背景"><span class="level-left"><span class="level-item">1</span><span class="level-item">背景</span></span></a></li><li><a class="level is-mobile" href="#设计思考"><span class="level-left"><span class="level-item">2</span><span class="level-item">设计思考</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#NUMA-拓扑感知调度"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">NUMA 拓扑感知调度</span></span></a></li><li><a class="level is-mobile" href="#节点-CPU-编排"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">节点 CPU 编排</span></span></a></li></ul></li><li><a class="level is-mobile" href="#社区成果"><span class="level-left"><span class="level-item">3</span><span class="level-item">社区成果</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Crane"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Crane</span></span></a></li><li><a class="level is-mobile" href="#Koordinator"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Koordinator</span></span></a></li><li><a class="level is-mobile" href="#CRI-Resource-Manager"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">CRI Resource Manager</span></span></a></li><li><a class="level is-mobile" href="#Volcano"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">Volcano</span></span></a></li></ul></li><li><a class="level is-mobile" href="#实践验证"><span class="level-left"><span class="level-item">4</span><span class="level-item">实践验证</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Container-Runtime/"><span class="level-start"><span class="level-item">Container Runtime</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Disaster-Recovery/"><span class="level-start"><span class="level-item">Disaster Recovery</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Scheduling-Orchestration/"><span class="level-start"><span class="level-item">Scheduling &amp; Orchestration</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Scheduling-Orchestration/Kubernetes/"><span class="level-start"><span class="level-item">Kubernetes</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Serverless/"><span class="level-start"><span class="level-item">Serverless</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Service-Mesh/"><span class="level-start"><span class="level-item">Service Mesh</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="🐾Corgi" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shen Xianghong</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p><p class="is-size-7"><br/>And did you get what you wanted from this life, even so?</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>